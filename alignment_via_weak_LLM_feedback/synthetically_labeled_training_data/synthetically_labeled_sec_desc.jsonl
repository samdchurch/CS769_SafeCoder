{"func_name": "autodetect_recv_bandwidth_measure_results", "func_src_before": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "func_src_after": "static BOOL autodetect_recv_bandwidth_measure_results(rdpRdp* rdp, wStream* s,\n                                                      AUTODETECT_RSP_PDU* autodetectRspPdu)\n{\n\tBOOL success = TRUE;\n\n\tif (autodetectRspPdu->headerLength != 0x0E)\n\t\treturn FALSE;\n\n\tWLog_VRB(AUTODETECT_TAG, \"received Bandwidth Measure Results PDU\");\n\tif (Stream_GetRemainingLength(s) < 8)\n\t\treturn -1;\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureTimeDelta); /* timeDelta (4 bytes) */\n\tStream_Read_UINT32(s, rdp->autodetect->bandwidthMeasureByteCount); /* byteCount (4 bytes) */\n\n\tif (rdp->autodetect->bandwidthMeasureTimeDelta > 0)\n\t\trdp->autodetect->netCharBandwidth = rdp->autodetect->bandwidthMeasureByteCount * 8 /\n\t\t                                    rdp->autodetect->bandwidthMeasureTimeDelta;\n\telse\n\t\trdp->autodetect->netCharBandwidth = 0;\n\n\tIFCALLRET(rdp->autodetect->BandwidthMeasureResults, success, rdp->context,\n\t          autodetectRspPdu->sequenceNumber);\n\treturn success;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/f5e73cc7c9cd973b516a618da877c87b80950b65", "file_name": "libfreerdp/core/autodetect.c", "vul_type": "cwe-125", "description": "Write a C function to process bandwidth measurement results in an RDP session."}
{"func_name": "_remove_volume_from_volume_set", "func_src_before": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run(['removevvset', '-f', vvs_name, volume_name])", "func_src_after": "    def _remove_volume_from_volume_set(self, volume_name, vvs_name):\n        self._cli_run('removevvset -f %s %s' % (vvs_name, volume_name), None)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to execute a command-line instruction that removes a volume from a volume set."}
{"func_name": "mailimf_group_parse", "func_src_before": "static int mailimf_group_parse(const char * message, size_t length,\n\t\t\t       size_t * indx,\n\t\t\t       struct mailimf_group ** result)\n{\n  size_t cur_token;\n  char * display_name;\n  struct mailimf_mailbox_list * mailbox_list;\n  struct mailimf_group * group;\n  int r;\n  int res;\n\n  cur_token = * indx;\n\n  mailbox_list = NULL;\n\n  r = mailimf_display_name_parse(message, length, &cur_token, &display_name);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto err;\n  }\n\n  r = mailimf_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_mailbox_list_parse(message, length, &cur_token, &mailbox_list);\n  switch (r) {\n  case MAILIMF_NO_ERROR:\n    break;\n  case MAILIMF_ERROR_PARSE:\n    r = mailimf_cfws_parse(message, length, &cur_token);\n    if ((r != MAILIMF_NO_ERROR) && (r != MAILIMF_ERROR_PARSE)) {\n      res = r;\n      goto free_display_name;\n    }\n    break;\n  default:\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_semi_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_mailbox_list;\n  }\n\n  group = mailimf_group_new(display_name, mailbox_list);\n  if (group == NULL) {\n    res = MAILIMF_ERROR_MEMORY;\n    goto free_mailbox_list;\n  }\n\n  * indx = cur_token;\n  * result = group;\n\n  return MAILIMF_NO_ERROR;\n\n free_mailbox_list:\n  if (mailbox_list != NULL) {\n    mailimf_mailbox_list_free(mailbox_list);\n  }\n free_display_name:\n  mailimf_display_name_free(display_name);\n err:\n  return res;\n}", "func_src_after": "static int mailimf_group_parse(const char * message, size_t length,\n\t\t\t       size_t * indx,\n\t\t\t       struct mailimf_group ** result)\n{\n  size_t cur_token;\n  char * display_name;\n  struct mailimf_mailbox_list * mailbox_list;\n  struct mailimf_group * group;\n  int r;\n  int res;\n  clist * list;\n\n  cur_token = * indx;\n\n  mailbox_list = NULL;\n\n  r = mailimf_display_name_parse(message, length, &cur_token, &display_name);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto err;\n  }\n\n  r = mailimf_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_mailbox_list_parse(message, length, &cur_token, &mailbox_list);\n  switch (r) {\n  case MAILIMF_NO_ERROR:\n    break;\n  case MAILIMF_ERROR_PARSE:\n    r = mailimf_cfws_parse(message, length, &cur_token);\n    if ((r != MAILIMF_NO_ERROR) && (r != MAILIMF_ERROR_PARSE)) {\n      res = r;\n      goto free_display_name;\n    }\n    list = clist_new();\n    if (list == NULL) {\n      res = MAILIMF_ERROR_MEMORY;\n      goto free_display_name;\n    }\n    mailbox_list = mailimf_mailbox_list_new(list);\n    if (mailbox_list == NULL) {\n      res = MAILIMF_ERROR_MEMORY;\n      clist_free(list);\n      goto free_display_name;\n    }\n    break;\n  default:\n    res = r;\n    goto free_display_name;\n  }\n\n  r = mailimf_semi_colon_parse(message, length, &cur_token);\n  if (r != MAILIMF_NO_ERROR) {\n    res = r;\n    goto free_mailbox_list;\n  }\n\n  group = mailimf_group_new(display_name, mailbox_list);\n  if (group == NULL) {\n    res = MAILIMF_ERROR_MEMORY;\n    goto free_mailbox_list;\n  }\n\n  * indx = cur_token;\n  * result = group;\n\n  return MAILIMF_NO_ERROR;\n\n free_mailbox_list:\n  if (mailbox_list != NULL) {\n    mailimf_mailbox_list_free(mailbox_list);\n  }\n free_display_name:\n  mailimf_display_name_free(display_name);\n err:\n  return res;\n}", "commit_link": "github.com/dinhviethoa/libetpan/commit/1fe8fbc032ccda1db9af66d93016b49c16c1f22d", "file_name": "src/low-level/imf/mailimf.c", "vul_type": "cwe-476", "description": "Write a C function to parse an email group from a string, handling memory allocation and errors."}
{"func_name": "mode_close", "func_src_before": "    def mode_close(self, request):\n        \"\"\"\n        This is called by render_POST when the client is signalling\n        that it is about to be closed.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        try:\n            sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n            sess.sessionhandler.disconnect(sess)\n        except IndexError:\n            self.client_disconnect(csessid)\n        return '\"\"'", "func_src_after": "    def mode_close(self, request):\n        \"\"\"\n        This is called by render_POST when the client is signalling\n        that it is about to be closed.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        try:\n            sess = self.sessionhandler.sessions_from_csessid(csessid)[0]\n            sess.sessionhandler.disconnect(sess)\n        except IndexError:\n            self.client_disconnect(csessid)\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_close` that handles a POST request to disconnect a client session using a session ID."}
{"func_name": "copyIPv6IfDifferent", "func_src_before": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "func_src_after": "static void copyIPv6IfDifferent(void * dest, const void * src)\n{\n\tif(dest != src && src != NULL) {\n\t\tmemcpy(dest, src, sizeof(struct in6_addr));\n\t}\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/cb8a02af7a5677cf608e86d57ab04241cf34e24f", "file_name": "miniupnpd/pcpserver.c", "vul_type": "cwe-476", "description": "Write a C function named `copyIPv6IfDifferent` that copies an IPv6 address from source to destination if they are different, with the second version also checking if the source is not NULL."}
{"func_name": "assoc_array_insert_into_terminal_node", "func_src_before": "static bool assoc_array_insert_into_terminal_node(struct assoc_array_edit *edit,\n\t\t\t\t\t\t  const struct assoc_array_ops *ops,\n\t\t\t\t\t\t  const void *index_key,\n\t\t\t\t\t\t  struct assoc_array_walk_result *result)\n{\n\tstruct assoc_array_shortcut *shortcut, *new_s0;\n\tstruct assoc_array_node *node, *new_n0, *new_n1, *side;\n\tstruct assoc_array_ptr *ptr;\n\tunsigned long dissimilarity, base_seg, blank;\n\tsize_t keylen;\n\tbool have_meta;\n\tint level, diff;\n\tint slot, next_slot, free_slot, i, j;\n\n\tnode\t= result->terminal_node.node;\n\tlevel\t= result->terminal_node.level;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = result->terminal_node.slot;\n\n\tpr_devel(\"-->%s()\\n\", __func__);\n\n\t/* We arrived at a node which doesn't have an onward node or shortcut\n\t * pointer that we have to follow.  This means that (a) the leaf we\n\t * want must go here (either by insertion or replacement) or (b) we\n\t * need to split this node and insert in one of the fragments.\n\t */\n\tfree_slot = -1;\n\n\t/* Firstly, we have to check the leaves in this node to see if there's\n\t * a matching one we should replace in place.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (!ptr) {\n\t\t\tfree_slot = i;\n\t\t\tcontinue;\n\t\t}\n\t\tif (ops->compare_object(assoc_array_ptr_to_leaf(ptr), index_key)) {\n\t\t\tpr_devel(\"replace in slot %d\\n\", i);\n\t\t\tedit->leaf_p = &node->slots[i];\n\t\t\tedit->dead_leaf = node->slots[i];\n\t\t\tpr_devel(\"<--%s() = ok [replace]\\n\", __func__);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* If there is a free slot in this node then we can just insert the\n\t * leaf here.\n\t */\n\tif (free_slot >= 0) {\n\t\tpr_devel(\"insert in free slot %d\\n\", free_slot);\n\t\tedit->leaf_p = &node->slots[free_slot];\n\t\tedit->adjust_count_on = node;\n\t\tpr_devel(\"<--%s() = ok [insert]\\n\", __func__);\n\t\treturn true;\n\t}\n\n\t/* The node has no spare slots - so we're either going to have to split\n\t * it or insert another node before it.\n\t *\n\t * Whatever, we're going to need at least two new nodes - so allocate\n\t * those now.  We may also need a new shortcut, but we deal with that\n\t * when we need it.\n\t */\n\tnew_n0 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n0)\n\t\treturn false;\n\tedit->new_meta[0] = assoc_array_node_to_ptr(new_n0);\n\tnew_n1 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n1)\n\t\treturn false;\n\tedit->new_meta[1] = assoc_array_node_to_ptr(new_n1);\n\n\t/* We need to find out how similar the leaves are. */\n\tpr_devel(\"no spare slots\\n\");\n\thave_meta = false;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (assoc_array_ptr_is_meta(ptr)) {\n\t\t\tedit->segment_cache[i] = 0xff;\n\t\t\thave_meta = true;\n\t\t\tcontinue;\n\t\t}\n\t\tbase_seg = ops->get_object_key_chunk(\n\t\t\tassoc_array_ptr_to_leaf(ptr), level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tif (have_meta) {\n\t\tpr_devel(\"have meta\\n\");\n\t\tgoto split_node;\n\t}\n\n\t/* The node contains only leaves */\n\tdissimilarity = 0;\n\tbase_seg = edit->segment_cache[0];\n\tfor (i = 1; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tdissimilarity |= edit->segment_cache[i] ^ base_seg;\n\n\tpr_devel(\"only leaves; dissimilarity=%lx\\n\", dissimilarity);\n\n\tif ((dissimilarity & ASSOC_ARRAY_FAN_MASK) == 0) {\n\t\t/* The old leaves all cluster in the same slot.  We will need\n\t\t * to insert a shortcut if the new node wants to cluster with them.\n\t\t */\n\t\tif ((edit->segment_cache[ASSOC_ARRAY_FAN_OUT] ^ base_seg) == 0)\n\t\t\tgoto all_leaves_cluster_together;\n\n\t\t/* Otherwise we can just insert a new node ahead of the old\n\t\t * one.\n\t\t */\n\t\tgoto present_leaves_cluster_but_not_new_leaf;\n\t}\n\nsplit_node:\n\tpr_devel(\"split node\\n\");\n\n\t/* We need to split the current node; we know that the node doesn't\n\t * simply contain a full set of leaves that cluster together (it\n\t * contains meta pointers and/or non-clustering leaves).\n\t *\n\t * We need to expel at least two leaves out of a set consisting of the\n\t * leaves in the node and the new leaf.\n\t *\n\t * We need a new node (n0) to replace the current one and a new node to\n\t * take the expelled nodes (n1).\n\t */\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\ndo_split_node:\n\tpr_devel(\"do_split_node\\n\");\n\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->nr_leaves_on_branch = 0;\n\n\t/* Begin by finding two matching leaves.  There have to be at least two\n\t * that match - even if there are meta pointers - because any leaf that\n\t * would match a slot with a meta pointer in it must be somewhere\n\t * behind that meta pointer and cannot be here.  Further, given N\n\t * remaining leaf slots, we now have N+1 leaves to go in them.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tslot = edit->segment_cache[i];\n\t\tif (slot != 0xff)\n\t\t\tfor (j = i + 1; j < ASSOC_ARRAY_FAN_OUT + 1; j++)\n\t\t\t\tif (edit->segment_cache[j] == slot)\n\t\t\t\t\tgoto found_slot_for_multiple_occupancy;\n\t}\nfound_slot_for_multiple_occupancy:\n\tpr_devel(\"same slot: %x %x [%02x]\\n\", i, j, slot);\n\tBUG_ON(i >= ASSOC_ARRAY_FAN_OUT);\n\tBUG_ON(j >= ASSOC_ARRAY_FAN_OUT + 1);\n\tBUG_ON(slot >= ASSOC_ARRAY_FAN_OUT);\n\n\tnew_n1->parent_slot = slot;\n\n\t/* Metadata pointers cannot change slot */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tnew_n0->slots[i] = node->slots[i];\n\t\telse\n\t\t\tnew_n0->slots[i] = NULL;\n\tBUG_ON(new_n0->slots[slot] != NULL);\n\tnew_n0->slots[slot] = assoc_array_node_to_ptr(new_n1);\n\n\t/* Filter the leaf pointers between the new nodes */\n\tfree_slot = -1;\n\tnext_slot = 0;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tcontinue;\n\t\tif (edit->segment_cache[i] == slot) {\n\t\t\tnew_n1->slots[next_slot++] = node->slots[i];\n\t\t\tnew_n1->nr_leaves_on_branch++;\n\t\t} else {\n\t\t\tdo {\n\t\t\t\tfree_slot++;\n\t\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\t\tnew_n0->slots[free_slot] = node->slots[i];\n\t\t}\n\t}\n\n\tpr_devel(\"filtered: f=%x n=%x\\n\", free_slot, next_slot);\n\n\tif (edit->segment_cache[ASSOC_ARRAY_FAN_OUT] != slot) {\n\t\tdo {\n\t\t\tfree_slot++;\n\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\tedit->leaf_p = &new_n0->slots[free_slot];\n\t\tedit->adjust_count_on = new_n0;\n\t} else {\n\t\tedit->leaf_p = &new_n1->slots[next_slot++];\n\t\tedit->adjust_count_on = new_n1;\n\t}\n\n\tBUG_ON(next_slot <= 1);\n\n\tedit->set_backpointers_to = assoc_array_node_to_ptr(new_n0);\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (edit->segment_cache[i] == 0xff) {\n\t\t\tptr = node->slots[i];\n\t\t\tBUG_ON(assoc_array_ptr_is_leaf(ptr));\n\t\t\tif (assoc_array_ptr_is_node(ptr)) {\n\t\t\t\tside = assoc_array_ptr_to_node(ptr);\n\t\t\t\tedit->set_backpointers[i] = &side->back_pointer;\n\t\t\t} else {\n\t\t\t\tshortcut = assoc_array_ptr_to_shortcut(ptr);\n\t\t\t\tedit->set_backpointers[i] = &shortcut->back_pointer;\n\t\t\t}\n\t\t}\n\t}\n\n\tptr = node->back_pointer;\n\tif (!ptr)\n\t\tedit->set[0].ptr = &edit->array->root;\n\telse if (assoc_array_ptr_is_node(ptr))\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_node(ptr)->slots[node->parent_slot];\n\telse\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_shortcut(ptr)->next_node;\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [split node]\\n\", __func__);\n\treturn true;\n\npresent_leaves_cluster_but_not_new_leaf:\n\t/* All the old leaves cluster in the same slot, but the new leaf wants\n\t * to go into a different slot, so we create a new node to hold the new\n\t * leaf and a pointer to a new node holding all the old leaves.\n\t */\n\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = edit->segment_cache[0];\n\tnew_n1->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tedit->adjust_count_on = new_n0;\n\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tnew_n1->slots[i] = node->slots[i];\n\n\tnew_n0->slots[edit->segment_cache[0]] = assoc_array_node_to_ptr(new_n0);\n\tedit->leaf_p = &new_n0->slots[edit->segment_cache[ASSOC_ARRAY_FAN_OUT]];\n\n\tedit->set[0].ptr = &assoc_array_ptr_to_node(node->back_pointer)->slots[node->parent_slot];\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [insert node before]\\n\", __func__);\n\treturn true;\n\nall_leaves_cluster_together:\n\t/* All the leaves, new and old, want to cluster together in this node\n\t * in the same slot, so we have to replace this node with a shortcut to\n\t * skip over the identical parts of the key and then place a pair of\n\t * nodes, one inside the other, at the end of the shortcut and\n\t * distribute the keys between them.\n\t *\n\t * Firstly we need to work out where the leaves start diverging as a\n\t * bit position into their keys so that we know how big the shortcut\n\t * needs to be.\n\t *\n\t * We only need to make a single pass of N of the N+1 leaves because if\n\t * any keys differ between themselves at bit X then at least one of\n\t * them must also differ with the base key at bit X or before.\n\t */\n\tpr_devel(\"all leaves cluster together\\n\");\n\tdiff = INT_MAX;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tint x = ops->diff_objects(assoc_array_ptr_to_leaf(node->slots[i]),\n\t\t\t\t\t  index_key);\n\t\tif (x < diff) {\n\t\t\tBUG_ON(x < 0);\n\t\t\tdiff = x;\n\t\t}\n\t}\n\tBUG_ON(diff == INT_MAX);\n\tBUG_ON(diff < level + ASSOC_ARRAY_LEVEL_STEP);\n\n\tkeylen = round_up(diff, ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\tkeylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT;\n\n\tnew_s0 = kzalloc(sizeof(struct assoc_array_shortcut) +\n\t\t\t keylen * sizeof(unsigned long), GFP_KERNEL);\n\tif (!new_s0)\n\t\treturn false;\n\tedit->new_meta[2] = assoc_array_shortcut_to_ptr(new_s0);\n\n\tedit->set[0].to = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_s0->back_pointer = node->back_pointer;\n\tnew_s0->parent_slot = node->parent_slot;\n\tnew_s0->next_node = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_n0->parent_slot = 0;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\n\tnew_s0->skip_to_level = level = diff & ~ASSOC_ARRAY_LEVEL_STEP_MASK;\n\tpr_devel(\"skip_to_level = %d [diff %d]\\n\", level, diff);\n\tBUG_ON(level <= 0);\n\n\tfor (i = 0; i < keylen; i++)\n\t\tnew_s0->index_key[i] =\n\t\t\tops->get_key_chunk(index_key, i * ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\n\tblank = ULONG_MAX << (level & ASSOC_ARRAY_KEY_CHUNK_MASK);\n\tpr_devel(\"blank off [%zu] %d: %lx\\n\", keylen - 1, level, blank);\n\tnew_s0->index_key[keylen - 1] &= ~blank;\n\n\t/* This now reduces to a node splitting exercise for which we'll need\n\t * to regenerate the disparity table.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tbase_seg = ops->get_object_key_chunk(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\t\t     level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tbase_seg = ops->get_key_chunk(index_key, level);\n\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\tgoto do_split_node;\n}", "func_src_after": "static bool assoc_array_insert_into_terminal_node(struct assoc_array_edit *edit,\n\t\t\t\t\t\t  const struct assoc_array_ops *ops,\n\t\t\t\t\t\t  const void *index_key,\n\t\t\t\t\t\t  struct assoc_array_walk_result *result)\n{\n\tstruct assoc_array_shortcut *shortcut, *new_s0;\n\tstruct assoc_array_node *node, *new_n0, *new_n1, *side;\n\tstruct assoc_array_ptr *ptr;\n\tunsigned long dissimilarity, base_seg, blank;\n\tsize_t keylen;\n\tbool have_meta;\n\tint level, diff;\n\tint slot, next_slot, free_slot, i, j;\n\n\tnode\t= result->terminal_node.node;\n\tlevel\t= result->terminal_node.level;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = result->terminal_node.slot;\n\n\tpr_devel(\"-->%s()\\n\", __func__);\n\n\t/* We arrived at a node which doesn't have an onward node or shortcut\n\t * pointer that we have to follow.  This means that (a) the leaf we\n\t * want must go here (either by insertion or replacement) or (b) we\n\t * need to split this node and insert in one of the fragments.\n\t */\n\tfree_slot = -1;\n\n\t/* Firstly, we have to check the leaves in this node to see if there's\n\t * a matching one we should replace in place.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (!ptr) {\n\t\t\tfree_slot = i;\n\t\t\tcontinue;\n\t\t}\n\t\tif (assoc_array_ptr_is_leaf(ptr) &&\n\t\t    ops->compare_object(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\tindex_key)) {\n\t\t\tpr_devel(\"replace in slot %d\\n\", i);\n\t\t\tedit->leaf_p = &node->slots[i];\n\t\t\tedit->dead_leaf = node->slots[i];\n\t\t\tpr_devel(\"<--%s() = ok [replace]\\n\", __func__);\n\t\t\treturn true;\n\t\t}\n\t}\n\n\t/* If there is a free slot in this node then we can just insert the\n\t * leaf here.\n\t */\n\tif (free_slot >= 0) {\n\t\tpr_devel(\"insert in free slot %d\\n\", free_slot);\n\t\tedit->leaf_p = &node->slots[free_slot];\n\t\tedit->adjust_count_on = node;\n\t\tpr_devel(\"<--%s() = ok [insert]\\n\", __func__);\n\t\treturn true;\n\t}\n\n\t/* The node has no spare slots - so we're either going to have to split\n\t * it or insert another node before it.\n\t *\n\t * Whatever, we're going to need at least two new nodes - so allocate\n\t * those now.  We may also need a new shortcut, but we deal with that\n\t * when we need it.\n\t */\n\tnew_n0 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n0)\n\t\treturn false;\n\tedit->new_meta[0] = assoc_array_node_to_ptr(new_n0);\n\tnew_n1 = kzalloc(sizeof(struct assoc_array_node), GFP_KERNEL);\n\tif (!new_n1)\n\t\treturn false;\n\tedit->new_meta[1] = assoc_array_node_to_ptr(new_n1);\n\n\t/* We need to find out how similar the leaves are. */\n\tpr_devel(\"no spare slots\\n\");\n\thave_meta = false;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tif (assoc_array_ptr_is_meta(ptr)) {\n\t\t\tedit->segment_cache[i] = 0xff;\n\t\t\thave_meta = true;\n\t\t\tcontinue;\n\t\t}\n\t\tbase_seg = ops->get_object_key_chunk(\n\t\t\tassoc_array_ptr_to_leaf(ptr), level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tif (have_meta) {\n\t\tpr_devel(\"have meta\\n\");\n\t\tgoto split_node;\n\t}\n\n\t/* The node contains only leaves */\n\tdissimilarity = 0;\n\tbase_seg = edit->segment_cache[0];\n\tfor (i = 1; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tdissimilarity |= edit->segment_cache[i] ^ base_seg;\n\n\tpr_devel(\"only leaves; dissimilarity=%lx\\n\", dissimilarity);\n\n\tif ((dissimilarity & ASSOC_ARRAY_FAN_MASK) == 0) {\n\t\t/* The old leaves all cluster in the same slot.  We will need\n\t\t * to insert a shortcut if the new node wants to cluster with them.\n\t\t */\n\t\tif ((edit->segment_cache[ASSOC_ARRAY_FAN_OUT] ^ base_seg) == 0)\n\t\t\tgoto all_leaves_cluster_together;\n\n\t\t/* Otherwise we can just insert a new node ahead of the old\n\t\t * one.\n\t\t */\n\t\tgoto present_leaves_cluster_but_not_new_leaf;\n\t}\n\nsplit_node:\n\tpr_devel(\"split node\\n\");\n\n\t/* We need to split the current node; we know that the node doesn't\n\t * simply contain a full set of leaves that cluster together (it\n\t * contains meta pointers and/or non-clustering leaves).\n\t *\n\t * We need to expel at least two leaves out of a set consisting of the\n\t * leaves in the node and the new leaf.\n\t *\n\t * We need a new node (n0) to replace the current one and a new node to\n\t * take the expelled nodes (n1).\n\t */\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\ndo_split_node:\n\tpr_devel(\"do_split_node\\n\");\n\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->nr_leaves_on_branch = 0;\n\n\t/* Begin by finding two matching leaves.  There have to be at least two\n\t * that match - even if there are meta pointers - because any leaf that\n\t * would match a slot with a meta pointer in it must be somewhere\n\t * behind that meta pointer and cannot be here.  Further, given N\n\t * remaining leaf slots, we now have N+1 leaves to go in them.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tslot = edit->segment_cache[i];\n\t\tif (slot != 0xff)\n\t\t\tfor (j = i + 1; j < ASSOC_ARRAY_FAN_OUT + 1; j++)\n\t\t\t\tif (edit->segment_cache[j] == slot)\n\t\t\t\t\tgoto found_slot_for_multiple_occupancy;\n\t}\nfound_slot_for_multiple_occupancy:\n\tpr_devel(\"same slot: %x %x [%02x]\\n\", i, j, slot);\n\tBUG_ON(i >= ASSOC_ARRAY_FAN_OUT);\n\tBUG_ON(j >= ASSOC_ARRAY_FAN_OUT + 1);\n\tBUG_ON(slot >= ASSOC_ARRAY_FAN_OUT);\n\n\tnew_n1->parent_slot = slot;\n\n\t/* Metadata pointers cannot change slot */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tnew_n0->slots[i] = node->slots[i];\n\t\telse\n\t\t\tnew_n0->slots[i] = NULL;\n\tBUG_ON(new_n0->slots[slot] != NULL);\n\tnew_n0->slots[slot] = assoc_array_node_to_ptr(new_n1);\n\n\t/* Filter the leaf pointers between the new nodes */\n\tfree_slot = -1;\n\tnext_slot = 0;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (assoc_array_ptr_is_meta(node->slots[i]))\n\t\t\tcontinue;\n\t\tif (edit->segment_cache[i] == slot) {\n\t\t\tnew_n1->slots[next_slot++] = node->slots[i];\n\t\t\tnew_n1->nr_leaves_on_branch++;\n\t\t} else {\n\t\t\tdo {\n\t\t\t\tfree_slot++;\n\t\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\t\tnew_n0->slots[free_slot] = node->slots[i];\n\t\t}\n\t}\n\n\tpr_devel(\"filtered: f=%x n=%x\\n\", free_slot, next_slot);\n\n\tif (edit->segment_cache[ASSOC_ARRAY_FAN_OUT] != slot) {\n\t\tdo {\n\t\t\tfree_slot++;\n\t\t} while (new_n0->slots[free_slot] != NULL);\n\t\tedit->leaf_p = &new_n0->slots[free_slot];\n\t\tedit->adjust_count_on = new_n0;\n\t} else {\n\t\tedit->leaf_p = &new_n1->slots[next_slot++];\n\t\tedit->adjust_count_on = new_n1;\n\t}\n\n\tBUG_ON(next_slot <= 1);\n\n\tedit->set_backpointers_to = assoc_array_node_to_ptr(new_n0);\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tif (edit->segment_cache[i] == 0xff) {\n\t\t\tptr = node->slots[i];\n\t\t\tBUG_ON(assoc_array_ptr_is_leaf(ptr));\n\t\t\tif (assoc_array_ptr_is_node(ptr)) {\n\t\t\t\tside = assoc_array_ptr_to_node(ptr);\n\t\t\t\tedit->set_backpointers[i] = &side->back_pointer;\n\t\t\t} else {\n\t\t\t\tshortcut = assoc_array_ptr_to_shortcut(ptr);\n\t\t\t\tedit->set_backpointers[i] = &shortcut->back_pointer;\n\t\t\t}\n\t\t}\n\t}\n\n\tptr = node->back_pointer;\n\tif (!ptr)\n\t\tedit->set[0].ptr = &edit->array->root;\n\telse if (assoc_array_ptr_is_node(ptr))\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_node(ptr)->slots[node->parent_slot];\n\telse\n\t\tedit->set[0].ptr = &assoc_array_ptr_to_shortcut(ptr)->next_node;\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [split node]\\n\", __func__);\n\treturn true;\n\npresent_leaves_cluster_but_not_new_leaf:\n\t/* All the old leaves cluster in the same slot, but the new leaf wants\n\t * to go into a different slot, so we create a new node to hold the new\n\t * leaf and a pointer to a new node holding all the old leaves.\n\t */\n\tpr_devel(\"present leaves cluster but not new leaf\\n\");\n\n\tnew_n0->back_pointer = node->back_pointer;\n\tnew_n0->parent_slot = node->parent_slot;\n\tnew_n0->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = edit->segment_cache[0];\n\tnew_n1->nr_leaves_on_branch = node->nr_leaves_on_branch;\n\tedit->adjust_count_on = new_n0;\n\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++)\n\t\tnew_n1->slots[i] = node->slots[i];\n\n\tnew_n0->slots[edit->segment_cache[0]] = assoc_array_node_to_ptr(new_n0);\n\tedit->leaf_p = &new_n0->slots[edit->segment_cache[ASSOC_ARRAY_FAN_OUT]];\n\n\tedit->set[0].ptr = &assoc_array_ptr_to_node(node->back_pointer)->slots[node->parent_slot];\n\tedit->set[0].to = assoc_array_node_to_ptr(new_n0);\n\tedit->excised_meta[0] = assoc_array_node_to_ptr(node);\n\tpr_devel(\"<--%s() = ok [insert node before]\\n\", __func__);\n\treturn true;\n\nall_leaves_cluster_together:\n\t/* All the leaves, new and old, want to cluster together in this node\n\t * in the same slot, so we have to replace this node with a shortcut to\n\t * skip over the identical parts of the key and then place a pair of\n\t * nodes, one inside the other, at the end of the shortcut and\n\t * distribute the keys between them.\n\t *\n\t * Firstly we need to work out where the leaves start diverging as a\n\t * bit position into their keys so that we know how big the shortcut\n\t * needs to be.\n\t *\n\t * We only need to make a single pass of N of the N+1 leaves because if\n\t * any keys differ between themselves at bit X then at least one of\n\t * them must also differ with the base key at bit X or before.\n\t */\n\tpr_devel(\"all leaves cluster together\\n\");\n\tdiff = INT_MAX;\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tint x = ops->diff_objects(assoc_array_ptr_to_leaf(node->slots[i]),\n\t\t\t\t\t  index_key);\n\t\tif (x < diff) {\n\t\t\tBUG_ON(x < 0);\n\t\t\tdiff = x;\n\t\t}\n\t}\n\tBUG_ON(diff == INT_MAX);\n\tBUG_ON(diff < level + ASSOC_ARRAY_LEVEL_STEP);\n\n\tkeylen = round_up(diff, ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\tkeylen >>= ASSOC_ARRAY_KEY_CHUNK_SHIFT;\n\n\tnew_s0 = kzalloc(sizeof(struct assoc_array_shortcut) +\n\t\t\t keylen * sizeof(unsigned long), GFP_KERNEL);\n\tif (!new_s0)\n\t\treturn false;\n\tedit->new_meta[2] = assoc_array_shortcut_to_ptr(new_s0);\n\n\tedit->set[0].to = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_s0->back_pointer = node->back_pointer;\n\tnew_s0->parent_slot = node->parent_slot;\n\tnew_s0->next_node = assoc_array_node_to_ptr(new_n0);\n\tnew_n0->back_pointer = assoc_array_shortcut_to_ptr(new_s0);\n\tnew_n0->parent_slot = 0;\n\tnew_n1->back_pointer = assoc_array_node_to_ptr(new_n0);\n\tnew_n1->parent_slot = -1; /* Need to calculate this */\n\n\tnew_s0->skip_to_level = level = diff & ~ASSOC_ARRAY_LEVEL_STEP_MASK;\n\tpr_devel(\"skip_to_level = %d [diff %d]\\n\", level, diff);\n\tBUG_ON(level <= 0);\n\n\tfor (i = 0; i < keylen; i++)\n\t\tnew_s0->index_key[i] =\n\t\t\tops->get_key_chunk(index_key, i * ASSOC_ARRAY_KEY_CHUNK_SIZE);\n\n\tblank = ULONG_MAX << (level & ASSOC_ARRAY_KEY_CHUNK_MASK);\n\tpr_devel(\"blank off [%zu] %d: %lx\\n\", keylen - 1, level, blank);\n\tnew_s0->index_key[keylen - 1] &= ~blank;\n\n\t/* This now reduces to a node splitting exercise for which we'll need\n\t * to regenerate the disparity table.\n\t */\n\tfor (i = 0; i < ASSOC_ARRAY_FAN_OUT; i++) {\n\t\tptr = node->slots[i];\n\t\tbase_seg = ops->get_object_key_chunk(assoc_array_ptr_to_leaf(ptr),\n\t\t\t\t\t\t     level);\n\t\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\t\tedit->segment_cache[i] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\t}\n\n\tbase_seg = ops->get_key_chunk(index_key, level);\n\tbase_seg >>= level & ASSOC_ARRAY_KEY_CHUNK_MASK;\n\tedit->segment_cache[ASSOC_ARRAY_FAN_OUT] = base_seg & ASSOC_ARRAY_FAN_MASK;\n\tgoto do_split_node;\n}", "commit_link": "github.com/torvalds/linux/commit/8d4a2ec1e0b41b0cf9a0c5cd4511da7f8e4f3de2", "file_name": "lib/assoc_array.c", "vul_type": "cwe-476", "description": "Write a C function to insert or replace a key in an associative array node, handling node splits if necessary."}
{"func_name": "rom_copy", "func_src_before": "int rom_copy(uint8_t *dest, hwaddr addr, size_t size)\n{\n    hwaddr end = addr + size;\n    uint8_t *s, *d = dest;\n    size_t l = 0;\n    Rom *rom;\n\n    QTAILQ_FOREACH(rom, &roms, next) {\n        if (rom->fw_file) {\n            continue;\n        }\n        if (rom->mr) {\n            continue;\n        }\n        if (rom->addr + rom->romsize < addr) {\n            continue;\n        }\n        if (rom->addr > end) {\n            break;\n        }\n\n        d = dest + (rom->addr - addr);\n        s = rom->data;\n        l = rom->datasize;\n\n        if ((d + l) > (dest + size)) {\n            l = dest - d;\n        }\n\n        if (l > 0) {\n            memcpy(d, s, l);\n        }\n\n        if (rom->romsize > rom->datasize) {\n            /* If datasize is less than romsize, it means that we didn't\n             * allocate all the ROM because the trailing data are only zeros.\n             */\n\n            d += l;\n            l = rom->romsize - rom->datasize;\n\n            if ((d + l) > (dest + size)) {\n                /* Rom size doesn't fit in the destination area. Adjust to avoid\n                 * overflow.\n                 */\n                l = dest - d;\n            }\n\n            if (l > 0) {\n                memset(d, 0x0, l);\n            }\n        }\n    }\n\n    return (d + l) - dest;\n}", "func_src_after": "int rom_copy(uint8_t *dest, hwaddr addr, size_t size)\n{\n    hwaddr end = addr + size;\n    uint8_t *s, *d = dest;\n    size_t l = 0;\n    Rom *rom;\n\n    QTAILQ_FOREACH(rom, &roms, next) {\n        if (rom->fw_file) {\n            continue;\n        }\n        if (rom->mr) {\n            continue;\n        }\n        if (rom->addr + rom->romsize < addr) {\n            continue;\n        }\n        if (rom->addr > end || rom->addr < addr) {\n            break;\n        }\n\n        d = dest + (rom->addr - addr);\n        s = rom->data;\n        l = rom->datasize;\n\n        if ((d + l) > (dest + size)) {\n            l = dest - d;\n        }\n\n        if (l > 0) {\n            memcpy(d, s, l);\n        }\n\n        if (rom->romsize > rom->datasize) {\n            /* If datasize is less than romsize, it means that we didn't\n             * allocate all the ROM because the trailing data are only zeros.\n             */\n\n            d += l;\n            l = rom->romsize - rom->datasize;\n\n            if ((d + l) > (dest + size)) {\n                /* Rom size doesn't fit in the destination area. Adjust to avoid\n                 * overflow.\n                 */\n                l = dest - d;\n            }\n\n            if (l > 0) {\n                memset(d, 0x0, l);\n            }\n        }\n    }\n\n    return (d + l) - dest;\n}", "commit_link": "github.com/qemu/qemu/commit/4f1c6cb2f9afafda05eab150fd2bd284edce6676", "file_name": "hw/core/loader.c", "vul_type": "cwe-787", "description": "Write a C function named `rom_copy` that copies ROM data to a destination buffer, handling memory regions and zero-filling as needed."}
{"func_name": "HPHP::exif_scan_JPEG_header", "func_src_before": "static int exif_scan_JPEG_header(image_info_type *ImageInfo) {\n  int section, sn;\n  int marker = 0, last_marker = M_PSEUDO, comment_correction=1;\n  int ll, lh;\n  unsigned char *Data;\n  size_t fpos, size, got, itemlen;\n  jpeg_sof_info  sof_info;\n\n  for(section=0;;section++) {\n    // get marker byte, swallowing possible padding\n    // some software does not count the length bytes of COM section\n    // one company doing so is very much envolved in JPEG...\n    // so we accept too\n    if (last_marker==M_COM && comment_correction) {\n      comment_correction = 2;\n    }\n    do {\n      if ((marker = ImageInfo->infile->getc()) == EOF) {\n        raise_warning(\"File structure corrupted\");\n        return 0;\n      }\n      if (last_marker==M_COM && comment_correction>0) {\n        if (marker!=0xFF) {\n          marker = 0xff;\n          comment_correction--;\n        } else  {\n          last_marker = M_PSEUDO; /* stop skipping 0 for M_COM */\n        }\n      }\n    } while (marker == 0xff);\n    if (last_marker==M_COM && !comment_correction) {\n      raise_notice(\"Image has corrupt COM section: some software set \"\n                   \"wrong length information\");\n    }\n    if (last_marker==M_COM && comment_correction)\n      return M_EOI; /* ah illegal: char after COM section not 0xFF */\n\n    fpos = ImageInfo->infile->tell();\n\n    if (marker == 0xff) {\n      // 0xff is legal padding, but if we get that many, something's wrong.\n      raise_warning(\"To many padding bytes\");\n      return 0;\n    }\n\n    /* Read the length of the section. */\n\n    if ((lh = ImageInfo->infile->getc()) == EOF) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    if ((ll = ImageInfo->infile->getc()) == EOF) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    itemlen = (lh << 8) | ll;\n\n    if (itemlen < 2) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    sn = exif_file_sections_add(ImageInfo, marker, itemlen+1, nullptr);\n    if (sn == -1) return 0;\n    Data = ImageInfo->file.list[sn].data;\n\n    /* Store first two pre-read bytes. */\n    Data[0] = (unsigned char)lh;\n    Data[1] = (unsigned char)ll;\n\n    String str = ImageInfo->infile->read(itemlen-2);\n    got = str.length();\n    if (got != itemlen-2) {\n      raise_warning(\"Error reading from file: \"\n                      \"got=x%04lX(=%lu) != itemlen-2=x%04lX(=%lu)\",\n                      got, got, itemlen-2, itemlen-2);\n      return 0;\n    }\n    memcpy(Data+2, str.c_str(), got);\n    switch(marker) {\n      case M_SOS:   /* stop before hitting compressed data  */\n        // If reading entire image is requested, read the rest of the data.\n        if (ImageInfo->read_all) {\n          /* Determine how much file is left. */\n          fpos = ImageInfo->infile->tell();\n          size = ImageInfo->FileSize - fpos;\n          sn = exif_file_sections_add(ImageInfo, M_PSEUDO, size, nullptr);\n          if (sn == -1) return 0;\n          Data = ImageInfo->file.list[sn].data;\n          str = ImageInfo->infile->read(size);\n          got = str.length();\n          if (got != size) {\n            raise_warning(\"Unexpected end of file reached\");\n            return 0;\n          }\n          memcpy(Data, str.c_str(), got);\n        }\n        return 1;\n\n      case M_EOI:   /* in case it's a tables-only JPEG stream */\n        raise_warning(\"No image in jpeg!\");\n        return (ImageInfo->sections_found&(~FOUND_COMPUTED)) ? 1 : 0;\n\n      case M_COM: /* Comment section */\n        exif_process_COM(ImageInfo, (char *)Data, itemlen);\n        break;\n\n      case M_EXIF:\n        if (!(ImageInfo->sections_found&FOUND_IFD0)) {\n          /*ImageInfo->sections_found |= FOUND_EXIF;*/\n          /* Seen files from some 'U-lead' software with Vivitar scanner\n             that uses marker 31 later in the file (no clue what for!) */\n          exif_process_APP1(ImageInfo, (char *)Data, itemlen, fpos);\n        }\n        break;\n\n      case M_APP12:\n        exif_process_APP12(ImageInfo, (char *)Data, itemlen);\n        break;\n\n\n      case M_SOF0:\n      case M_SOF1:\n      case M_SOF2:\n      case M_SOF3:\n      case M_SOF5:\n      case M_SOF6:\n      case M_SOF7:\n      case M_SOF9:\n      case M_SOF10:\n      case M_SOF11:\n      case M_SOF13:\n      case M_SOF14:\n      case M_SOF15:\n        exif_process_SOFn(Data, marker, &sof_info);\n        ImageInfo->Width  = sof_info.width;\n        ImageInfo->Height = sof_info.height;\n        if (sof_info.num_components == 3) {\n          ImageInfo->IsColor = 1;\n        } else {\n          ImageInfo->IsColor = 0;\n        }\n        break;\n      default:\n        /* skip any other marker silently. */\n        break;\n    }\n\n    /* keep track of last marker */\n    last_marker = marker;\n  }\n  return 1;\n}", "func_src_after": "static int exif_scan_JPEG_header(image_info_type *ImageInfo) {\n  int section, sn;\n  int marker = 0, last_marker = M_PSEUDO, comment_correction=1;\n  int ll, lh;\n  unsigned char *Data;\n  size_t fpos, size, got, itemlen;\n  jpeg_sof_info  sof_info;\n\n  for(section=0;;section++) {\n    // get marker byte, swallowing possible padding\n    // some software does not count the length bytes of COM section\n    // one company doing so is very much envolved in JPEG...\n    // so we accept too\n    if (last_marker==M_COM && comment_correction) {\n      comment_correction = 2;\n    }\n    do {\n      if ((marker = ImageInfo->infile->getc()) == EOF) {\n        raise_warning(\"File structure corrupted\");\n        return 0;\n      }\n      if (last_marker==M_COM && comment_correction>0) {\n        if (marker!=0xFF) {\n          marker = 0xff;\n          comment_correction--;\n        } else  {\n          last_marker = M_PSEUDO; /* stop skipping 0 for M_COM */\n        }\n      }\n    } while (marker == 0xff);\n    if (last_marker==M_COM && !comment_correction) {\n      raise_notice(\"Image has corrupt COM section: some software set \"\n                   \"wrong length information\");\n    }\n    if (last_marker==M_COM && comment_correction)\n      return M_EOI; /* ah illegal: char after COM section not 0xFF */\n\n    fpos = ImageInfo->infile->tell();\n\n    if (marker == 0xff) {\n      // 0xff is legal padding, but if we get that many, something's wrong.\n      raise_warning(\"To many padding bytes\");\n      return 0;\n    }\n\n    /* Read the length of the section. */\n\n    if ((lh = ImageInfo->infile->getc()) == EOF) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    if ((ll = ImageInfo->infile->getc()) == EOF) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    itemlen = (lh << 8) | ll;\n\n    if (itemlen < 2) {\n      raise_warning(\"File structure corrupted\");\n      return 0;\n    }\n\n    sn = exif_file_sections_add(ImageInfo, marker, itemlen+1, nullptr);\n    if (sn == -1) return 0;\n    Data = ImageInfo->file.list[sn].data;\n\n    /* Store first two pre-read bytes. */\n    Data[0] = (unsigned char)lh;\n    Data[1] = (unsigned char)ll;\n\n    String str = ImageInfo->infile->read(itemlen-2);\n    got = str.length();\n    if (got != itemlen-2) {\n      raise_warning(\"Error reading from file: \"\n                      \"got=x%04lX(=%lu) != itemlen-2=x%04lX(=%lu)\",\n                      got, got, itemlen-2, itemlen-2);\n      return 0;\n    }\n    memcpy(Data+2, str.c_str(), got);\n    switch(marker) {\n      case M_SOS:   /* stop before hitting compressed data  */\n        // If reading entire image is requested, read the rest of the data.\n        if (ImageInfo->read_all) {\n          /* Determine how much file is left. */\n          fpos = ImageInfo->infile->tell();\n          size = ImageInfo->FileSize - fpos;\n          sn = exif_file_sections_add(ImageInfo, M_PSEUDO, size, nullptr);\n          if (sn == -1) return 0;\n          Data = ImageInfo->file.list[sn].data;\n          str = ImageInfo->infile->read(size);\n          got = str.length();\n          if (got != size) {\n            raise_warning(\"Unexpected end of file reached\");\n            return 0;\n          }\n          memcpy(Data, str.c_str(), got);\n        }\n        return 1;\n\n      case M_EOI:   /* in case it's a tables-only JPEG stream */\n        raise_warning(\"No image in jpeg!\");\n        return (ImageInfo->sections_found&(~FOUND_COMPUTED)) ? 1 : 0;\n\n      case M_COM: /* Comment section */\n        exif_process_COM(ImageInfo, (char *)Data, itemlen);\n        break;\n\n      case M_EXIF:\n        if (!(ImageInfo->sections_found&FOUND_IFD0)) {\n          /*ImageInfo->sections_found |= FOUND_EXIF;*/\n          /* Seen files from some 'U-lead' software with Vivitar scanner\n             that uses marker 31 later in the file (no clue what for!) */\n          exif_process_APP1(ImageInfo, (char *)Data, itemlen, fpos);\n        }\n        break;\n\n      case M_APP12:\n        exif_process_APP12(ImageInfo, (char *)Data, itemlen);\n        break;\n\n\n      case M_SOF0:\n      case M_SOF1:\n      case M_SOF2:\n      case M_SOF3:\n      case M_SOF5:\n      case M_SOF6:\n      case M_SOF7:\n      case M_SOF9:\n      case M_SOF10:\n      case M_SOF11:\n      case M_SOF13:\n      case M_SOF14:\n      case M_SOF15:\n        if ((itemlen - 2) < 6) {\n          return 0;\n        }\n\n        exif_process_SOFn(Data, marker, &sof_info);\n        ImageInfo->Width  = sof_info.width;\n        ImageInfo->Height = sof_info.height;\n        if (sof_info.num_components == 3) {\n          ImageInfo->IsColor = 1;\n        } else {\n          ImageInfo->IsColor = 0;\n        }\n        break;\n      default:\n        /* skip any other marker silently. */\n        break;\n    }\n\n    /* keep track of last marker */\n    last_marker = marker;\n  }\n  return 1;\n}", "commit_link": "github.com/facebook/hhvm/commit/f9680d21beaa9eb39d166e8810e29fbafa51ad15", "file_name": "hphp/runtime/ext/gd/ext_gd.cpp", "vul_type": "cwe-125", "description": "Write a C++ function to scan and process JPEG header markers for an image file."}
{"func_name": "populate_custom_grains_and_pillar", "func_src_before": "def populate_custom_grains_and_pillar():\n    '''\n    Populate local salt-minion grains and pillar fields values as specified in\n    config file.\n\n    For example:\n\n        custom_grains_pillar:\n          grains:\n            - selinux: selinux:enabled\n            - release: osrelease\n          pillar:\n            - ntpserver: network_services:ntpserver\n\n    Note that the core grains are already included in hubble grains -- this\n    is only necessary for custom grains and pillar data.\n    '''\n    log.debug('Fetching custom grains and pillar details')\n    grains = {}\n    salt.modules.config.__opts__ = __opts__\n    custom_grains = __salt__['config.get']('custom_grains_pillar:grains', [])\n    for grain in custom_grains:\n        for key in grain:\n            value = __salt__['cmd.run'](['salt-call', 'grains.get', grain[key]]).split('\\n')[1].strip()\n            grains[key] = value\n    custom_pillar = __salt__['config.get']('custom_grains_pillar:pillar', [])\n    for pillar in custom_pillar:\n        for key in pillar:\n            value = __salt__['cmd.run'](['salt-call', 'pillar.get', pillar[key]]).split('\\n')[1].strip()\n            grains[key] = value\n    log.debug('Done with fetching custom grains and pillar details')\n    return grains", "func_src_after": "def populate_custom_grains_and_pillar():\n    '''\n    Populate local salt-minion grains and pillar fields values as specified in\n    config file.\n\n    For example:\n\n        custom_grains_pillar:\n          grains:\n            - selinux: selinux:enabled\n            - release: osrelease\n          pillar:\n            - ntpserver: network_services:ntpserver\n\n    Note that the core grains are already included in hubble grains -- this\n    is only necessary for custom grains and pillar data.\n    '''\n    log.debug('Fetching custom grains and pillar details')\n    grains = {}\n    salt.modules.config.__opts__ = __opts__\n    custom_grains = __salt__['config.get']('custom_grains_pillar:grains', [])\n    for grain in custom_grains:\n        for key in grain:\n            if _valid_command(grain[key]):\n                value = __salt__['cmd.run']('salt-call grains.get {0}'.format(grain[key])).split('\\n')[1].strip()\n                grains[key] = value\n    custom_pillar = __salt__['config.get']('custom_grains_pillar:pillar', [])\n    for pillar in custom_pillar:\n        for key in pillar:\n            if _valid_command(pillar[key]):\n                value = __salt__['cmd.run']('salt-call pillar.get {0}'.format(pillar[key])).split('\\n')[1].strip()\n                grains[key] = value\n    log.debug('Done with fetching custom grains and pillar details')\n    return grains", "commit_link": "github.com/hubblestack/hubble/commit/d9ca4a93ea5aabb1298c5b3dbfb23e94203428b9", "file_name": "hubblestack/extmods/grains/custom_grains_pillar.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve and set custom grains and pillar data from a configuration file using SaltStack commands."}
{"func_name": "megasas_alloc_cmds", "func_src_before": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int megasas_alloc_cmds(struct megasas_instance *instance)\n{\n\tint i;\n\tint j;\n\tu16 max_cmd;\n\tstruct megasas_cmd *cmd;\n\n\tmax_cmd = instance->max_mfi_cmds;\n\n\t/*\n\t * instance->cmd_list is an array of struct megasas_cmd pointers.\n\t * Allocate the dynamic array first and then allocate individual\n\t * commands.\n\t */\n\tinstance->cmd_list = kcalloc(max_cmd, sizeof(struct megasas_cmd*), GFP_KERNEL);\n\n\tif (!instance->cmd_list) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"out of memory\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tmemset(instance->cmd_list, 0, sizeof(struct megasas_cmd *) *max_cmd);\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tinstance->cmd_list[i] = kmalloc(sizeof(struct megasas_cmd),\n\t\t\t\t\t\tGFP_KERNEL);\n\n\t\tif (!instance->cmd_list[i]) {\n\n\t\t\tfor (j = 0; j < i; j++)\n\t\t\t\tkfree(instance->cmd_list[j]);\n\n\t\t\tkfree(instance->cmd_list);\n\t\t\tinstance->cmd_list = NULL;\n\n\t\t\treturn -ENOMEM;\n\t\t}\n\t}\n\n\tfor (i = 0; i < max_cmd; i++) {\n\t\tcmd = instance->cmd_list[i];\n\t\tmemset(cmd, 0, sizeof(struct megasas_cmd));\n\t\tcmd->index = i;\n\t\tcmd->scmd = NULL;\n\t\tcmd->instance = instance;\n\n\t\tlist_add_tail(&cmd->list, &instance->cmd_pool);\n\t}\n\n\t/*\n\t * Create a frame pool and assign one frame to each cmd\n\t */\n\tif (megasas_create_frame_pool(instance)) {\n\t\tdev_printk(KERN_DEBUG, &instance->pdev->dev, \"Error creating frame DMA pool\\n\");\n\t\tmegasas_free_cmds(instance);\n\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/bcf3b67d16a4c8ffae0aa79de5853435e683945c", "file_name": "drivers/scsi/megaraid/megaraid_sas_base.c", "vul_type": "cwe-476", "description": "Write a C function named `megasas_alloc_cmds` that allocates command structures for a `megasas_instance` and initializes a frame pool."}
{"func_name": "get_last_active_users", "func_src_before": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT {limit}')\n\n        try:\n            cursor = db.execute_query(query)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "func_src_after": "    @staticmethod\n    def get_last_active_users(limit):\n        \"\"\"\n        Get from the database a tuple of users who have been recently using\n        the bot\n        :param limit: integer that specifies how much users to get\n        :return: tuple of tuples with users info\n        \"\"\"\n        log.info('Evaluating last active users with date of '\n                 'last time when they used bot...')\n\n        # From photo_queries_table2 we take chat_id of the last\n        # active users and from 'users' table we take info about these\n        # users by chat_id which is a foreign key\n        query = ('SELECT p.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'FROM photo_queries_table2 p '\n                 'INNER JOIN users u '\n                 'ON p.chat_id = u.chat_id '\n                 'GROUP BY u.chat_id, u.first_name, u.nickname, u.last_name, '\n                 'u.language '\n                 'ORDER BY MAX(time)'\n                 f'DESC LIMIT %s')\n\n        parameters = limit,\n\n        try:\n            cursor = db.execute_query(query, parameters)\n        except DatabaseConnectionError:\n            log.error(\"Cannot get the last active users because of some \"\n                      \"problems with the database\")\n            raise\n\n        last_active_users = cursor.fetchall()\n        return last_active_users", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch a specified number of the most recent active bot users from a database."}
{"func_name": "pure_strcmp", "func_src_before": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    return pure_memcmp(s1, s2, strlen(s1) + 1U);\n}", "func_src_after": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    const size_t s1_len = strlen(s1);\n    const size_t s2_len = strlen(s2);\n\n    if (s1_len != s2_len) {\n        return -1;\n    }\n    return pure_memcmp(s1, s2, s1_len);\n}", "commit_link": "github.com/jedisct1/pure-ftpd/commit/36c6d268cb190282a2c17106acfd31863121b58e", "file_name": "src/utils.c", "vul_type": "cwe-125", "description": "Write a C function named `pure_strcmp` that compares two strings using `pure_memcmp` and considers string length."}
{"func_name": "nsv_read_chunk", "func_src_before": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n{\n    NSVContext *nsv = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st[2] = {NULL, NULL};\n    NSVStream *nst;\n    AVPacket *pkt;\n    int i, err = 0;\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n    uint32_t vsize;\n    uint16_t asize;\n    uint16_t auxsize;\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\nnull_chunk_retry:\n    if (pb->eof_reached)\n        return -1;\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n        err = nsv_resync(s);\n    if (err < 0)\n        return err;\n    if (nsv->state == NSV_FOUND_NSVS)\n        err = nsv_parse_NSVs_header(s);\n    if (err < 0)\n        return err;\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n        return -1;\n\n    auxcount = avio_r8(pb);\n    vsize = avio_rl16(pb);\n    asize = avio_rl16(pb);\n    vsize = (vsize << 4) | (auxcount >> 4);\n    auxcount &= 0x0f;\n    av_log(s, AV_LOG_TRACE, \"NSV CHUNK %\"PRIu8\" aux, %\"PRIu32\" bytes video, %\"PRIu16\" bytes audio\\n\",\n           auxcount, vsize, asize);\n    /* skip aux stuff */\n    for (i = 0; i < auxcount; i++) {\n        uint32_t av_unused auxtag;\n        auxsize = avio_rl16(pb);\n        auxtag = avio_rl32(pb);\n        avio_skip(pb, auxsize);\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming brain-dead */\n    }\n\n    if (pb->eof_reached)\n        return -1;\n    if (!vsize && !asize) {\n        nsv->state = NSV_UNSYNC;\n        goto null_chunk_retry;\n    }\n\n    /* map back streams to v,a */\n    if (s->nb_streams > 0)\n        st[s->streams[0]->id] = s->streams[0];\n    if (s->nb_streams > 1)\n        st[s->streams[1]->id] = s->streams[1];\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n        nst = st[NSV_ST_VIDEO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n        av_get_packet(pb, pkt, vsize);\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n        pkt->dts = nst->frame_offset;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        for (i = 0; i < FFMIN(8, vsize); i++)\n            av_log(s, AV_LOG_TRACE, \"NSV video: [%d] = %02\"PRIx8\"\\n\",\n                   i, pkt->data[i]);\n    }\n    if(st[NSV_ST_VIDEO])\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n    if (asize && st[NSV_ST_AUDIO]) {\n        nst = st[NSV_ST_AUDIO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n        /* read raw audio specific header on the first audio chunk... */\n        /* on ALL audio chunks ?? seems so! */\n        if (asize && st[NSV_ST_AUDIO]->codecpar->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n            uint8_t bps;\n            uint8_t channels;\n            uint16_t samplerate;\n            bps = avio_r8(pb);\n            channels = avio_r8(pb);\n            samplerate = avio_rl16(pb);\n            if (!channels || !samplerate)\n                return AVERROR_INVALIDDATA;\n            asize-=4;\n            av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                   bps, channels, samplerate);\n            if (fill_header) {\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n                if (bps != 16) {\n                    av_log(s, AV_LOG_TRACE, \"NSV AUDIO bit/sample != 16 (%\"PRIu8\")!!!\\n\", bps);\n                }\n                bps /= channels; // ???\n                if (bps == 8)\n                    st[NSV_ST_AUDIO]->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n                samplerate /= 4;/* UGH ??? XXX */\n                channels = 1;\n                st[NSV_ST_AUDIO]->codecpar->channels = channels;\n                st[NSV_ST_AUDIO]->codecpar->sample_rate = samplerate;\n                av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                       bps, channels, samplerate);\n            }\n        }\n        av_get_packet(pb, pkt, asize);\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n            /* on a nsvs frame we have new information on a/v sync */\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n            av_log(s, AV_LOG_TRACE, \"NSV AUDIO: sync:%\"PRId16\", dts:%\"PRId64,\n                   nsv->avsync, pkt->dts);\n        }\n        nst->frame_offset++;\n    }\n\n    nsv->state = NSV_UNSYNC;\n    return 0;\n}", "func_src_after": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n{\n    NSVContext *nsv = s->priv_data;\n    AVIOContext *pb = s->pb;\n    AVStream *st[2] = {NULL, NULL};\n    NSVStream *nst;\n    AVPacket *pkt;\n    int i, err = 0;\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n    uint32_t vsize;\n    uint16_t asize;\n    uint16_t auxsize;\n    int ret;\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\nnull_chunk_retry:\n    if (pb->eof_reached)\n        return -1;\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n        err = nsv_resync(s);\n    if (err < 0)\n        return err;\n    if (nsv->state == NSV_FOUND_NSVS)\n        err = nsv_parse_NSVs_header(s);\n    if (err < 0)\n        return err;\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n        return -1;\n\n    auxcount = avio_r8(pb);\n    vsize = avio_rl16(pb);\n    asize = avio_rl16(pb);\n    vsize = (vsize << 4) | (auxcount >> 4);\n    auxcount &= 0x0f;\n    av_log(s, AV_LOG_TRACE, \"NSV CHUNK %\"PRIu8\" aux, %\"PRIu32\" bytes video, %\"PRIu16\" bytes audio\\n\",\n           auxcount, vsize, asize);\n    /* skip aux stuff */\n    for (i = 0; i < auxcount; i++) {\n        uint32_t av_unused auxtag;\n        auxsize = avio_rl16(pb);\n        auxtag = avio_rl32(pb);\n        avio_skip(pb, auxsize);\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming brain-dead */\n    }\n\n    if (pb->eof_reached)\n        return -1;\n    if (!vsize && !asize) {\n        nsv->state = NSV_UNSYNC;\n        goto null_chunk_retry;\n    }\n\n    /* map back streams to v,a */\n    if (s->nb_streams > 0)\n        st[s->streams[0]->id] = s->streams[0];\n    if (s->nb_streams > 1)\n        st[s->streams[1]->id] = s->streams[1];\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n        nst = st[NSV_ST_VIDEO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n        if ((ret = av_get_packet(pb, pkt, vsize)) < 0)\n            return ret;\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n        pkt->dts = nst->frame_offset;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        for (i = 0; i < FFMIN(8, vsize); i++)\n            av_log(s, AV_LOG_TRACE, \"NSV video: [%d] = %02\"PRIx8\"\\n\",\n                   i, pkt->data[i]);\n    }\n    if(st[NSV_ST_VIDEO])\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n    if (asize && st[NSV_ST_AUDIO]) {\n        nst = st[NSV_ST_AUDIO]->priv_data;\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n        /* read raw audio specific header on the first audio chunk... */\n        /* on ALL audio chunks ?? seems so! */\n        if (asize && st[NSV_ST_AUDIO]->codecpar->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n            uint8_t bps;\n            uint8_t channels;\n            uint16_t samplerate;\n            bps = avio_r8(pb);\n            channels = avio_r8(pb);\n            samplerate = avio_rl16(pb);\n            if (!channels || !samplerate)\n                return AVERROR_INVALIDDATA;\n            asize-=4;\n            av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                   bps, channels, samplerate);\n            if (fill_header) {\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n                if (bps != 16) {\n                    av_log(s, AV_LOG_TRACE, \"NSV AUDIO bit/sample != 16 (%\"PRIu8\")!!!\\n\", bps);\n                }\n                bps /= channels; // ???\n                if (bps == 8)\n                    st[NSV_ST_AUDIO]->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n                samplerate /= 4;/* UGH ??? XXX */\n                channels = 1;\n                st[NSV_ST_AUDIO]->codecpar->channels = channels;\n                st[NSV_ST_AUDIO]->codecpar->sample_rate = samplerate;\n                av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n                       bps, channels, samplerate);\n            }\n        }\n        if ((ret = av_get_packet(pb, pkt, asize)) < 0)\n            return ret;\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n            /* on a nsvs frame we have new information on a/v sync */\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n            av_log(s, AV_LOG_TRACE, \"NSV AUDIO: sync:%\"PRId16\", dts:%\"PRId64,\n                   nsv->avsync, pkt->dts);\n        }\n        nst->frame_offset++;\n    }\n\n    nsv->state = NSV_UNSYNC;\n    return 0;\n}", "commit_link": "github.com/libav/libav/commit/fe6eea99efac66839052af547426518efd970b24", "file_name": "libavformat/nsvdec.c", "vul_type": "cwe-476", "description": "Write a C function named `nsv_read_chunk` that reads a chunk of NSV format data from a given AVFormatContext."}
{"func_name": "like", "func_src_before": "@mod.route('/like/<int:msg_id>', methods=['GET', 'POST'])\ndef like(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        cursor.execute(\"INSERT INTO like_msg(msg_id, user_id,c_time) VALUES(%s,%s,%s);\", (msg_id, user_id, c_time))\n        conn.commit()\n    return redirect(url_for('show_entries'))", "func_src_after": "@mod.route('/like/<int:msg_id>', methods=['GET', 'POST'])\ndef like(msg_id):\n    if request.method == 'GET':\n        user_id = session['logged_id']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        sql = \"INSERT INTO like_msg(msg_id, user_id,c_time) \" + \\\n                \"VALUES(%d,'%s','%s');\" % (msg_id, user_id, c_time)\n        cursor.execute(sql)\n        conn.commit()\n    return redirect(url_for('show_entries'))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/like_msg.py", "vul_type": "cwe-089", "description": "Create a Flask route in Python that handles a 'like' action for a message by inserting a record into a database and then redirects to a page showing entries."}
{"func_name": "fiber_switch", "func_src_before": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  enum mrb_fiber_state status;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  status = c->status;\n  if (resume && status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (status == MRB_FIBER_RUNNING || status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  old_c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  fiber_switch_context(mrb, c);\n  if (status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    mrb_stack_extend(mrb, len+2); /* for receiver and (optional) block */\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "func_src_after": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n{\n  struct mrb_context *c = fiber_check(mrb, self);\n  struct mrb_context *old_c = mrb->c;\n  mrb_value value;\n\n  fiber_check_cfunc(mrb, c);\n  if (resume && c->status == MRB_FIBER_TRANSFERRED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n  }\n  if (c->status == MRB_FIBER_RUNNING || c->status == MRB_FIBER_RESUMED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n  }\n  if (c->status == MRB_FIBER_TERMINATED) {\n    mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n  }\n  mrb->c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n  c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  if (c->status == MRB_FIBER_CREATED) {\n    mrb_value *b, *e;\n\n    if (len >= c->stend - c->stack) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"too many arguments to fiber\");\n    }\n    b = c->stack+1;\n    e = b + len;\n    while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n  else {\n    value = fiber_result(mrb, a, len);\n  }\n  fiber_switch_context(mrb, c);\n\n  if (vmexec) {\n    c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}", "commit_link": "github.com/mruby/mruby/commit/778500563a9f7ceba996937dc886bd8cde29b42b", "file_name": "mrbgems/mruby-fiber/src/fiber.c", "vul_type": "cwe-125", "description": "Write a C function `fiber_switch` for the MRuby language that handles fiber resumption, argument passing, and optional VM execution."}
{"func_name": "commentcounts", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': comment.text,\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef commentcounts(context, filediff, interfilediff=None):\n    \"\"\"\n    Returns a JSON array of current comments for a filediff, sorted by\n    line number.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      comment_id  The ID of the comment\n      text        The text of the comment\n      line        The first line number\n      num_lines   The number of lines this comment spans\n      user        A dictionary containing \"username\" and \"name\" keys\n                  for the user\n      url         The URL to the comment\n      localdraft  True if this is the current user's draft comment\n      =========== ==================================================\n    \"\"\"\n    comment_dict = {}\n    user = context.get('user', None)\n\n    if interfilediff:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff=interfilediff)\n    else:\n        query = Comment.objects.filter(filediff=filediff,\n                                       interfilediff__isnull=True)\n\n    for comment in query:\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            key = (comment.first_line, comment.num_lines)\n\n            comment_dict.setdefault(key, []).append({\n                'comment_id': comment.id,\n                'text': escape(comment.text),\n                'line': comment.first_line,\n                'num_lines': comment.num_lines,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                #'timestamp': comment.timestamp,\n                'url': comment.get_review_url(),\n                'localdraft': review.user == user and \\\n                              not review.public,\n            })\n\n    comments_array = []\n\n    for key, value in comment_dict.iteritems():\n        comments_array.append({\n            'linenum': key[0],\n            'num_lines': key[1],\n            'comments': value,\n        })\n\n    comments_array.sort(cmp=lambda x, y: cmp(x['linenum'], y['linenum'] or\n                                         cmp(x['num_lines'], y['num_lines'])))\n\n    return simplejson.dumps(comments_array)", "commit_link": "github.com/reviewboard/reviewboard/commit/7a0a9d94555502278534dedcf2d75e9fccce8c3d", "file_name": "reviewboard/reviews/templatetags/reviewtags.py", "vul_type": "cwe-079", "description": "In Python, write a function that returns a JSON array of comments for a file difference, including metadata like comment ID, text, line number, and user details, sorted by line number."}
{"func_name": "get_roster", "func_src_before": "    def get_roster(self, server_id):\n        sql = \"\"\"\n              SELECT username, role\n              FROM roles\n              WHERE roles.server_id = %s;\n              \"\"\"\n        self.cur.execute(sql, (server_id,))\n        return self.cur.fetchall()", "func_src_after": "    def get_roster(self, server_id):\n        sql = \"\"\"SELECT username, role\n                 FROM roles\n                 WHERE roles.server_id = {0};\n                 \"\"\".format(server_id)\n        self.cur.execute(sql)\n        return self.cur.fetchall()", "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch a list of usernames and roles from a database table 'roles' filtered by 'server_id'."}
{"func_name": "IsBlacklistedArg", "func_src_before": "bool IsBlacklistedArg(const base::CommandLine::CharType* arg) {\n#if defined(OS_WIN)\n  const auto converted = base::WideToUTF8(arg);\n  const char* a = converted.c_str();\n#else\n  const char* a = arg;\n#endif\n\n  static const char* prefixes[] = {\"--\", \"-\", \"/\"};\n\n  int prefix_length = 0;\n  for (auto& prefix : prefixes) {\n    if (base::StartsWith(a, prefix, base::CompareCase::SENSITIVE)) {\n      prefix_length = strlen(prefix);\n      break;\n    }\n  }\n\n  if (prefix_length > 0) {\n    a += prefix_length;\n    std::string switch_name(a, strcspn(a, \"=\"));\n    auto* iter = std::lower_bound(std::begin(kBlacklist), std::end(kBlacklist),\n                                  switch_name);\n    if (iter != std::end(kBlacklist) && switch_name == *iter) {\n      return true;\n    }\n  }\n\n  return false;\n}", "func_src_after": "bool IsBlacklistedArg(const base::CommandLine::CharType* arg) {\n#if defined(OS_WIN)\n  const auto converted = base::WideToUTF8(arg);\n  const char* a = converted.c_str();\n#else\n  const char* a = arg;\n#endif\n\n  static const char* prefixes[] = {\"--\", \"-\", \"/\"};\n\n  int prefix_length = 0;\n  for (auto& prefix : prefixes) {\n    if (base::StartsWith(a, prefix, base::CompareCase::SENSITIVE)) {\n      prefix_length = strlen(prefix);\n      break;\n    }\n  }\n\n  if (prefix_length > 0) {\n    a += prefix_length;\n    std::string switch_name =\n        base::ToLowerASCII(base::StringPiece(a, strcspn(a, \"=\")));\n    auto* iter = std::lower_bound(std::begin(kBlacklist), std::end(kBlacklist),\n                                  switch_name);\n    if (iter != std::end(kBlacklist) && switch_name == *iter) {\n      return true;\n    }\n  }\n\n  return false;\n}", "commit_link": "github.com/electron/electron/commit/ce361a12e355f9e1e99c989f1ea056c9e502dbe7", "file_name": "atom/app/command_line_args.cc", "vul_type": "cwe-078", "description": "Write a C++ function to check if a command-line argument is blacklisted, considering platform-specific character encoding and argument prefixes."}
{"func_name": "track_header", "func_src_before": "static int track_header(VividasDemuxContext *viv, AVFormatContext *s,  uint8_t *buf, int size)\n{\n    int i, j, ret;\n    int64_t off;\n    int val_1;\n    int num_video;\n    AVIOContext pb0, *pb = &pb0;\n\n    ffio_init_context(pb, buf, size, 0, NULL, NULL, NULL, NULL);\n\n    ffio_read_varlen(pb); // track_header_len\n    avio_r8(pb); // '1'\n\n    val_1 = ffio_read_varlen(pb);\n\n    for (i=0;i<val_1;i++) {\n        int c = avio_r8(pb);\n        if (avio_feof(pb))\n            return AVERROR_EOF;\n        for (j=0;j<c;j++) {\n            if (avio_feof(pb))\n                return AVERROR_EOF;\n            avio_r8(pb); // val_3\n            avio_r8(pb); // val_4\n        }\n    }\n\n    avio_r8(pb); // num_streams\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_5\n\n    avio_r8(pb); // '2'\n    num_video = avio_r8(pb);\n\n    avio_seek(pb, off, SEEK_SET);\n    if (num_video != 1) {\n        av_log(s, AV_LOG_ERROR, \"number of video tracks %d is not 1\\n\", num_video);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    for (i = 0; i < num_video; i++) {\n        AVStream *st = avformat_new_stream(s, NULL);\n        int num, den;\n\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        st->codecpar->codec_id = AV_CODEC_ID_VP6;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb);\n        avio_r8(pb); // '3'\n        avio_r8(pb); // val_7\n        num = avio_rl32(pb); // frame_time\n        den = avio_rl32(pb); // time_base\n        avpriv_set_pts_info(st, 64, num, den);\n        st->nb_frames = avio_rl32(pb); // n frames\n        st->codecpar->width = avio_rl16(pb); // width\n        st->codecpar->height = avio_rl16(pb); // height\n        avio_r8(pb); // val_8\n        avio_rl32(pb); // val_9\n\n        avio_seek(pb, off, SEEK_SET);\n    }\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_10\n    avio_r8(pb); // '4'\n    viv->num_audio = avio_r8(pb);\n    avio_seek(pb, off, SEEK_SET);\n\n    if (viv->num_audio != 1)\n        av_log(s, AV_LOG_WARNING, \"number of audio tracks %d is not 1\\n\", viv->num_audio);\n\n    for(i=0;i<viv->num_audio;i++) {\n        int q;\n        AVStream *st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = num_video + i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n        st->codecpar->codec_id = AV_CODEC_ID_VORBIS;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb); // length\n        avio_r8(pb); // '5'\n        avio_r8(pb); //codec_id\n        avio_rl16(pb); //codec_subid\n        st->codecpar->channels = avio_rl16(pb); // channels\n        st->codecpar->sample_rate = avio_rl32(pb); // sample_rate\n        avio_seek(pb, 10, SEEK_CUR); // data_1\n        q = avio_r8(pb);\n        avio_seek(pb, q, SEEK_CUR); // data_2\n        avio_r8(pb); // zeropad\n\n        if (avio_tell(pb) < off) {\n            int num_data;\n            int xd_size = 0;\n            int data_len[256];\n            int offset = 1;\n            uint8_t *p;\n            ffio_read_varlen(pb); // val_13\n            avio_r8(pb); // '19'\n            ffio_read_varlen(pb); // len_3\n            num_data = avio_r8(pb);\n            for (j = 0; j < num_data; j++) {\n                uint64_t len = ffio_read_varlen(pb);\n                if (len > INT_MAX/2 - xd_size) {\n                    return AVERROR_INVALIDDATA;\n                }\n                data_len[j] = len;\n                xd_size += len;\n            }\n\n            ret = ff_alloc_extradata(st->codecpar, 64 + xd_size + xd_size / 255);\n            if (ret < 0)\n                return ret;\n\n            p = st->codecpar->extradata;\n            p[0] = 2;\n\n            for (j = 0; j < num_data - 1; j++) {\n                unsigned delta = av_xiphlacing(&p[offset], data_len[j]);\n                if (delta > data_len[j]) {\n                    return AVERROR_INVALIDDATA;\n                }\n                offset += delta;\n            }\n\n            for (j = 0; j < num_data; j++) {\n                int ret = avio_read(pb, &p[offset], data_len[j]);\n                if (ret < data_len[j]) {\n                    st->codecpar->extradata_size = 0;\n                    av_freep(&st->codecpar->extradata);\n                    break;\n                }\n                offset += data_len[j];\n            }\n\n            if (offset < st->codecpar->extradata_size)\n                st->codecpar->extradata_size = offset;\n        }\n    }\n\n    return 0;\n}", "func_src_after": "static int track_header(VividasDemuxContext *viv, AVFormatContext *s,  uint8_t *buf, int size)\n{\n    int i, j, ret;\n    int64_t off;\n    int val_1;\n    int num_video;\n    AVIOContext pb0, *pb = &pb0;\n\n    ffio_init_context(pb, buf, size, 0, NULL, NULL, NULL, NULL);\n\n    ffio_read_varlen(pb); // track_header_len\n    avio_r8(pb); // '1'\n\n    val_1 = ffio_read_varlen(pb);\n\n    for (i=0;i<val_1;i++) {\n        int c = avio_r8(pb);\n        if (avio_feof(pb))\n            return AVERROR_EOF;\n        for (j=0;j<c;j++) {\n            if (avio_feof(pb))\n                return AVERROR_EOF;\n            avio_r8(pb); // val_3\n            avio_r8(pb); // val_4\n        }\n    }\n\n    avio_r8(pb); // num_streams\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_5\n\n    avio_r8(pb); // '2'\n    num_video = avio_r8(pb);\n\n    avio_seek(pb, off, SEEK_SET);\n    if (num_video != 1) {\n        av_log(s, AV_LOG_ERROR, \"number of video tracks %d is not 1\\n\", num_video);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    for (i = 0; i < num_video; i++) {\n        AVStream *st = avformat_new_stream(s, NULL);\n        int num, den;\n\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_VIDEO;\n        st->codecpar->codec_id = AV_CODEC_ID_VP6;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb);\n        avio_r8(pb); // '3'\n        avio_r8(pb); // val_7\n        num = avio_rl32(pb); // frame_time\n        den = avio_rl32(pb); // time_base\n        avpriv_set_pts_info(st, 64, num, den);\n        st->nb_frames = avio_rl32(pb); // n frames\n        st->codecpar->width = avio_rl16(pb); // width\n        st->codecpar->height = avio_rl16(pb); // height\n        avio_r8(pb); // val_8\n        avio_rl32(pb); // val_9\n\n        avio_seek(pb, off, SEEK_SET);\n    }\n\n    off = avio_tell(pb);\n    off += ffio_read_varlen(pb); // val_10\n    avio_r8(pb); // '4'\n    viv->num_audio = avio_r8(pb);\n    avio_seek(pb, off, SEEK_SET);\n\n    if (viv->num_audio != 1)\n        av_log(s, AV_LOG_WARNING, \"number of audio tracks %d is not 1\\n\", viv->num_audio);\n\n    for(i=0;i<viv->num_audio;i++) {\n        int q;\n        AVStream *st = avformat_new_stream(s, NULL);\n        if (!st)\n            return AVERROR(ENOMEM);\n\n        st->id = num_video + i;\n\n        st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n        st->codecpar->codec_id = AV_CODEC_ID_VORBIS;\n\n        off = avio_tell(pb);\n        off += ffio_read_varlen(pb); // length\n        avio_r8(pb); // '5'\n        avio_r8(pb); //codec_id\n        avio_rl16(pb); //codec_subid\n        st->codecpar->channels = avio_rl16(pb); // channels\n        st->codecpar->sample_rate = avio_rl32(pb); // sample_rate\n        avio_seek(pb, 10, SEEK_CUR); // data_1\n        q = avio_r8(pb);\n        avio_seek(pb, q, SEEK_CUR); // data_2\n        avio_r8(pb); // zeropad\n\n        if (avio_tell(pb) < off) {\n            int num_data;\n            int xd_size = 1;\n            int data_len[256];\n            int offset = 1;\n            uint8_t *p;\n            ffio_read_varlen(pb); // val_13\n            avio_r8(pb); // '19'\n            ffio_read_varlen(pb); // len_3\n            num_data = avio_r8(pb);\n            for (j = 0; j < num_data; j++) {\n                uint64_t len = ffio_read_varlen(pb);\n                if (len > INT_MAX/2 - xd_size) {\n                    return AVERROR_INVALIDDATA;\n                }\n                data_len[j] = len;\n                xd_size += len + 1 + len/255;\n            }\n\n            ret = ff_alloc_extradata(st->codecpar, xd_size);\n            if (ret < 0)\n                return ret;\n\n            p = st->codecpar->extradata;\n            p[0] = 2;\n\n            for (j = 0; j < num_data - 1; j++) {\n                unsigned delta = av_xiphlacing(&p[offset], data_len[j]);\n                av_assert0(delta <= xd_size - offset);\n                offset += delta;\n            }\n\n            for (j = 0; j < num_data; j++) {\n                int ret = avio_read(pb, &p[offset], data_len[j]);\n                if (ret < data_len[j]) {\n                    st->codecpar->extradata_size = 0;\n                    av_freep(&st->codecpar->extradata);\n                    break;\n                }\n                av_assert0(data_len[j] <= xd_size - offset);\n                offset += data_len[j];\n            }\n\n            if (offset < st->codecpar->extradata_size)\n                st->codecpar->extradata_size = offset;\n        }\n    }\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/27a99e2c7d450fef15594671eef4465c8a166bd7", "file_name": "libavformat/vividas.c", "vul_type": "cwe-787", "description": "Write a C function to parse video and audio track headers from a buffer in an AVFormatContext using FFmpeg libraries."}
{"func_name": "srpt_handle_tsk_mgmt", "func_src_before": "static void srpt_handle_tsk_mgmt(struct srpt_rdma_ch *ch,\n\t\t\t\t struct srpt_recv_ioctx *recv_ioctx,\n\t\t\t\t struct srpt_send_ioctx *send_ioctx)\n{\n\tstruct srp_tsk_mgmt *srp_tsk;\n\tstruct se_cmd *cmd;\n\tstruct se_session *sess = ch->sess;\n\tuint64_t unpacked_lun;\n\tint tcm_tmr;\n\tint rc;\n\n\tBUG_ON(!send_ioctx);\n\n\tsrp_tsk = recv_ioctx->ioctx.buf;\n\tcmd = &send_ioctx->cmd;\n\n\tpr_debug(\"recv tsk_mgmt fn %d for task_tag %lld and cmd tag %lld\"\n\t\t \" cm_id %p sess %p\\n\", srp_tsk->tsk_mgmt_func,\n\t\t srp_tsk->task_tag, srp_tsk->tag, ch->cm_id, ch->sess);\n\n\tsrpt_set_cmd_state(send_ioctx, SRPT_STATE_MGMT);\n\tsend_ioctx->cmd.tag = srp_tsk->tag;\n\ttcm_tmr = srp_tmr_to_tcm(srp_tsk->tsk_mgmt_func);\n\tunpacked_lun = srpt_unpack_lun((uint8_t *)&srp_tsk->lun,\n\t\t\t\t       sizeof(srp_tsk->lun));\n\trc = target_submit_tmr(&send_ioctx->cmd, sess, NULL, unpacked_lun,\n\t\t\t\tsrp_tsk, tcm_tmr, GFP_KERNEL, srp_tsk->task_tag,\n\t\t\t\tTARGET_SCF_ACK_KREF);\n\tif (rc != 0) {\n\t\tsend_ioctx->cmd.se_tmr_req->response = TMR_FUNCTION_REJECTED;\n\t\tgoto fail;\n\t}\n\treturn;\nfail:\n\ttransport_send_check_condition_and_sense(cmd, 0, 0); // XXX:\n}", "func_src_after": "static void srpt_handle_tsk_mgmt(struct srpt_rdma_ch *ch,\n\t\t\t\t struct srpt_recv_ioctx *recv_ioctx,\n\t\t\t\t struct srpt_send_ioctx *send_ioctx)\n{\n\tstruct srp_tsk_mgmt *srp_tsk;\n\tstruct se_cmd *cmd;\n\tstruct se_session *sess = ch->sess;\n\tuint64_t unpacked_lun;\n\tuint32_t tag = 0;\n\tint tcm_tmr;\n\tint rc;\n\n\tBUG_ON(!send_ioctx);\n\n\tsrp_tsk = recv_ioctx->ioctx.buf;\n\tcmd = &send_ioctx->cmd;\n\n\tpr_debug(\"recv tsk_mgmt fn %d for task_tag %lld and cmd tag %lld\"\n\t\t \" cm_id %p sess %p\\n\", srp_tsk->tsk_mgmt_func,\n\t\t srp_tsk->task_tag, srp_tsk->tag, ch->cm_id, ch->sess);\n\n\tsrpt_set_cmd_state(send_ioctx, SRPT_STATE_MGMT);\n\tsend_ioctx->cmd.tag = srp_tsk->tag;\n\ttcm_tmr = srp_tmr_to_tcm(srp_tsk->tsk_mgmt_func);\n\tif (tcm_tmr < 0) {\n\t\tsend_ioctx->cmd.se_tmr_req->response =\n\t\t\tTMR_TASK_MGMT_FUNCTION_NOT_SUPPORTED;\n\t\tgoto fail;\n\t}\n\tunpacked_lun = srpt_unpack_lun((uint8_t *)&srp_tsk->lun,\n\t\t\t\t       sizeof(srp_tsk->lun));\n\n\tif (srp_tsk->tsk_mgmt_func == SRP_TSK_ABORT_TASK) {\n\t\trc = srpt_rx_mgmt_fn_tag(send_ioctx, srp_tsk->task_tag);\n\t\tif (rc < 0) {\n\t\t\tsend_ioctx->cmd.se_tmr_req->response =\n\t\t\t\t\tTMR_TASK_DOES_NOT_EXIST;\n\t\t\tgoto fail;\n\t\t}\n\t\ttag = srp_tsk->task_tag;\n\t}\n\trc = target_submit_tmr(&send_ioctx->cmd, sess, NULL, unpacked_lun,\n\t\t\t\tsrp_tsk, tcm_tmr, GFP_KERNEL, tag,\n\t\t\t\tTARGET_SCF_ACK_KREF);\n\tif (rc != 0) {\n\t\tsend_ioctx->cmd.se_tmr_req->response = TMR_FUNCTION_REJECTED;\n\t\tgoto fail;\n\t}\n\treturn;\nfail:\n\ttransport_send_check_condition_and_sense(cmd, 0, 0); // XXX:\n}", "commit_link": "github.com/torvalds/linux/commit/51093254bf879bc9ce96590400a87897c7498463", "file_name": "drivers/infiniband/ulp/srpt/ib_srpt.c", "vul_type": "cwe-476", "description": "Write a C function named `srpt_handle_tsk_mgmt` that processes task management requests for an RDMA channel in a storage protocol."}
{"func_name": "get_paths", "func_src_before": "def get_paths(base_path: pathlib.Path):\n    data_file = pathlib.Path(str(base_path) + \".data\")\n    metadata_file = pathlib.Path(str(base_path) + \".meta\")\n\n    return data_file, metadata_file", "func_src_after": "def get_paths(root: str, sub_path: str) \\\n        -> typing.Tuple[pathlib.Path, pathlib.Path]:\n    base_path = flask.safe_join(root, sub_path)\n    data_file = pathlib.Path(base_path + \".data\")\n    metadata_file = pathlib.Path(base_path + \".meta\")\n\n    return data_file, metadata_file", "commit_link": "github.com/horazont/xmpp-http-upload/commit/82056540191e89f0cd697c81f57714c00962ed75", "file_name": "xhu.py", "vul_type": "cwe-022", "description": "Write a Python function that generates file paths for data and metadata files based on a given base path."}
{"func_name": "avpriv_ac3_parse_header", "func_src_before": "int avpriv_ac3_parse_header(AC3HeaderInfo **phdr, const uint8_t *buf,\n                            size_t size)\n{\n    GetBitContext gb;\n    AC3HeaderInfo *hdr;\n    int err;\n\n    if (!*phdr)\n        *phdr = av_mallocz(sizeof(AC3HeaderInfo));\n    if (!*phdr)\n        return AVERROR(ENOMEM);\n    hdr = *phdr;\n\n    init_get_bits8(&gb, buf, size);\n    err = ff_ac3_parse_header(&gb, hdr);\n    if (err < 0)\n        return AVERROR_INVALIDDATA;\n\n    return get_bits_count(&gb);\n}", "func_src_after": "int avpriv_ac3_parse_header(AC3HeaderInfo **phdr, const uint8_t *buf,\n                            size_t size)\n{\n    GetBitContext gb;\n    AC3HeaderInfo *hdr;\n    int err;\n\n    if (!*phdr)\n        *phdr = av_mallocz(sizeof(AC3HeaderInfo));\n    if (!*phdr)\n        return AVERROR(ENOMEM);\n    hdr = *phdr;\n\n    err = init_get_bits8(&gb, buf, size);\n    if (err < 0)\n        return AVERROR_INVALIDDATA;\n    err = ff_ac3_parse_header(&gb, hdr);\n    if (err < 0)\n        return AVERROR_INVALIDDATA;\n\n    return get_bits_count(&gb);\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/00e8181bd97c834fe60751b0c511d4bb97875f78", "file_name": "libavcodec/ac3_parser.c", "vul_type": "cwe-476", "description": "Write a C function named `avpriv_ac3_parse_header` that initializes a bit context and parses the AC3 header from a buffer, returning the number of bits read."}
{"func_name": "get_lines", "func_src_before": "def get_lines(command: List[str]) -> List[str]:\n    \"\"\"\n    Run a command and return lines of output\n\n    :param str command: the command to run\n    :returns: list of whitespace-stripped lines output by command\n    \"\"\"\n    stdout = get_output(command)\n    return [line.strip() for line in stdout.splitlines()]", "func_src_after": "def get_lines(command: str) -> List[str]:\n    \"\"\"\n    Run a command and return lines of output\n\n    :param str command: the command to run\n    :returns: list of whitespace-stripped lines output by command\n    \"\"\"\n    stdout = get_output(command)\n    return [line.strip().decode() for line in stdout.splitlines()]", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "isort/hooks.py", "vul_type": "cwe-078", "description": "Write a Python function named `get_lines` that executes a given command and returns the output as a list of stripped strings."}
{"func_name": "mrb_io_initialize_copy", "func_src_before": "mrb_io_initialize_copy(mrb_state *mrb, mrb_value copy)\n{\n  mrb_value orig;\n  mrb_value buf;\n  struct mrb_io *fptr_copy;\n  struct mrb_io *fptr_orig;\n  mrb_bool failed = TRUE;\n\n  mrb_get_args(mrb, \"o\", &orig);\n  fptr_orig = io_get_open_fptr(mrb, orig);\n  fptr_copy = (struct mrb_io *)DATA_PTR(copy);\n  if (fptr_copy != NULL) {\n    fptr_finalize(mrb, fptr_copy, FALSE);\n    mrb_free(mrb, fptr_copy);\n  }\n  fptr_copy = (struct mrb_io *)mrb_io_alloc(mrb);\n\n  DATA_TYPE(copy) = &mrb_io_type;\n  DATA_PTR(copy) = fptr_copy;\n\n  buf = mrb_iv_get(mrb, orig, mrb_intern_cstr(mrb, \"@buf\"));\n  mrb_iv_set(mrb, copy, mrb_intern_cstr(mrb, \"@buf\"), buf);\n\n  fptr_copy->fd = mrb_dup(mrb, fptr_orig->fd, &failed);\n  if (failed) {\n    mrb_sys_fail(mrb, 0);\n  }\n  mrb_fd_cloexec(mrb, fptr_copy->fd);\n\n  if (fptr_orig->fd2 != -1) {\n    fptr_copy->fd2 = mrb_dup(mrb, fptr_orig->fd2, &failed);\n    if (failed) {\n      close(fptr_copy->fd);\n      mrb_sys_fail(mrb, 0);\n    }\n    mrb_fd_cloexec(mrb, fptr_copy->fd2);\n  }\n\n  fptr_copy->pid = fptr_orig->pid;\n  fptr_copy->readable = fptr_orig->readable;\n  fptr_copy->writable = fptr_orig->writable;\n  fptr_copy->sync = fptr_orig->sync;\n  fptr_copy->is_socket = fptr_orig->is_socket;\n\n  return copy;\n}", "func_src_after": "mrb_io_initialize_copy(mrb_state *mrb, mrb_value copy)\n{\n  mrb_value orig;\n  mrb_value buf;\n  struct mrb_io *fptr_copy;\n  struct mrb_io *fptr_orig;\n  mrb_bool failed = TRUE;\n\n  mrb_get_args(mrb, \"o\", &orig);\n  fptr_copy = (struct mrb_io *)DATA_PTR(copy);\n  if (fptr_copy != NULL) {\n    fptr_finalize(mrb, fptr_copy, FALSE);\n    mrb_free(mrb, fptr_copy);\n  }\n  fptr_copy = (struct mrb_io *)mrb_io_alloc(mrb);\n  fptr_orig = io_get_open_fptr(mrb, orig);\n\n  DATA_TYPE(copy) = &mrb_io_type;\n  DATA_PTR(copy) = fptr_copy;\n\n  buf = mrb_iv_get(mrb, orig, mrb_intern_cstr(mrb, \"@buf\"));\n  mrb_iv_set(mrb, copy, mrb_intern_cstr(mrb, \"@buf\"), buf);\n\n  fptr_copy->fd = mrb_dup(mrb, fptr_orig->fd, &failed);\n  if (failed) {\n    mrb_sys_fail(mrb, 0);\n  }\n  mrb_fd_cloexec(mrb, fptr_copy->fd);\n\n  if (fptr_orig->fd2 != -1) {\n    fptr_copy->fd2 = mrb_dup(mrb, fptr_orig->fd2, &failed);\n    if (failed) {\n      close(fptr_copy->fd);\n      mrb_sys_fail(mrb, 0);\n    }\n    mrb_fd_cloexec(mrb, fptr_copy->fd2);\n  }\n\n  fptr_copy->pid = fptr_orig->pid;\n  fptr_copy->readable = fptr_orig->readable;\n  fptr_copy->writable = fptr_orig->writable;\n  fptr_copy->sync = fptr_orig->sync;\n  fptr_copy->is_socket = fptr_orig->is_socket;\n\n  return copy;\n}", "commit_link": "github.com/mruby/mruby/commit/b51b21fc63c9805862322551387d9036f2b63433", "file_name": "mrbgems/mruby-io/src/io.c", "vul_type": "cwe-416", "description": "Write a C function for the MRuby language that duplicates an IO object, including its file descriptors and instance variables."}
{"func_name": "overview", "func_src_before": "@app.route('/overview/<classNum>')\ndef overview(classNum):\n\tif 'username' in session:\n\t\tclassNoSpace = classNum.split(' ')[0]+classNum.split(' ')[1]\n\n\t\t#Save the current course as a session variable.\n\t\tsession['currentCourse'] = classNoSpace\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT courseName,courseOverview from courses where courseAbbreviation=%s\", (classNoSpace))\n\t\tdata = cursor.fetchone()\n\n\t\treturn render_template('overview.html', className = classNum, courseTitle = data[0], courseOverview = data[1])\n\n\treturn redirect(url_for('index'))", "func_src_after": "@app.route('/overview/<classNum>')\ndef overview(classNum):\n\tif 'username' in session:\n\t\tclassNoSpace = classNum.split(' ')[0]+classNum.split(' ')[1]\n\n\t\t#Save the current course as a session variable.\n\t\tsession['currentCourse'] = classNoSpace\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\tcursor.execute(\"SELECT courseName,courseOverview from courses where courseAbbreviation='\" + classNoSpace + \"'\")\n\t\tdata = cursor.fetchone()\n\n\t\treturn render_template('overview.html', className = classNum, courseTitle = data[0], courseOverview = data[1])\n\n\treturn redirect(url_for('index'))", "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089", "description": "Create a Flask route in Python that displays a course overview page if the user is logged in, using either string concatenation or parameterized queries to fetch course details from a MySQL database."}
{"func_name": "post", "func_src_before": "    def post(self):\n        \"\"\" Returns JWT upon login verification \"\"\"\n        json_data = request.get_json()\n        if not json_data['email']:\n            return jsonify({\"msg\": \"Missing email\"}), 400\n\n        data = database_utilities.execute_query(\n            f\"\"\"select * from admins where email = '{json_data['email']}'\"\"\")\n        if data:\n            email = data[0]['email']\n            access_token = create_access_token(identity=email)\n            refresh_token = create_refresh_token(identity=email)\n\n            resp = jsonify({\"login\": True})\n            set_access_cookies(resp, access_token)\n            set_refresh_cookies(resp, refresh_token)\n            return resp\n        else:\n            return jsonify({\"msg\": \"User is not an admin\"})", "func_src_after": "    def post(self):\n        \"\"\" Returns JWT upon login verification \"\"\"\n        json_data = request.get_json()\n        if not json_data['email']:\n            return jsonify({\"msg\": \"Missing email\"}), 400\n\n        data = database_utilities.execute_query(\n            f\"\"\"select * from admins where email = %s\"\"\", (json_data['email'], ))\n        if data:\n            email = data[0]['email']\n            access_token = create_access_token(identity=email)\n            refresh_token = create_refresh_token(identity=email)\n\n            resp = jsonify({\"login\": True})\n            set_access_cookies(resp, access_token)\n            set_refresh_cookies(resp, refresh_token)\n            return resp\n        else:\n            return jsonify({\"msg\": \"User is not an admin\"})", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/login.py", "vul_type": "cwe-089", "description": "Write a Python function that handles admin login by verifying email and issuing JWT tokens."}
{"func_name": "oidc_handle_session_management_iframe_rp", "func_src_before": "static int oidc_handle_session_management_iframe_rp(request_rec *r, oidc_cfg *c,\n\t\toidc_session_t *session, const char *client_id,\n\t\tconst char *check_session_iframe) {\n\n\toidc_debug(r, \"enter\");\n\n\tconst char *java_script =\n\t\t\t\"    <script type=\\\"text/javascript\\\">\\n\"\n\t\t\t\"      var targetOrigin  = '%s';\\n\"\n\t\t\t\"      var message = '%s' + ' ' + '%s';\\n\"\n\t\t\t\"\t   var timerID;\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function checkSession() {\\n\"\n\t\t\t\"        console.debug('checkSession: posting ' + message + ' to ' + targetOrigin);\\n\"\n\t\t\t\"        var win = window.parent.document.getElementById('%s').contentWindow;\\n\"\n\t\t\t\"        win.postMessage( message, targetOrigin);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function setTimer() {\\n\"\n\t\t\t\"        checkSession();\\n\"\n\t\t\t\"        timerID = setInterval('checkSession()', %s);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function receiveMessage(e) {\\n\"\n\t\t\t\"        console.debug('receiveMessage: ' + e.data + ' from ' + e.origin);\\n\"\n\t\t\t\"        if (e.origin !== targetOrigin ) {\\n\"\n\t\t\t\"          console.debug('receiveMessage: cross-site scripting attack?');\\n\"\n\t\t\t\"          return;\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"        if (e.data != 'unchanged') {\\n\"\n\t\t\t\"          clearInterval(timerID);\\n\"\n\t\t\t\"          if (e.data == 'changed') {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=check';\\n\"\n\t\t\t\"          } else {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=logout';\\n\"\n\t\t\t\"          }\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      window.addEventListener('message', receiveMessage, false);\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"    </script>\\n\";\n\n\t/* determine the origin for the check_session_iframe endpoint */\n\tchar *origin = apr_pstrdup(r->pool, check_session_iframe);\n\tapr_uri_t uri;\n\tapr_uri_parse(r->pool, check_session_iframe, &uri);\n\tchar *p = strstr(origin, uri.path);\n\t*p = '\\0';\n\n\t/* the element identifier for the OP iframe */\n\tconst char *op_iframe_id = \"openidc-op\";\n\n\t/* restore the OP session_state from the session */\n\tconst char *session_state = oidc_session_get_session_state(r, session);\n\tif (session_state == NULL) {\n\t\toidc_warn(r,\n\t\t\t\t\"no session_state found in the session; the OP does probably not support session management!?\");\n\t\treturn DONE;\n\t}\n\n\tchar *s_poll_interval = NULL;\n\toidc_util_get_request_parameter(r, \"poll\", &s_poll_interval);\n\tif (s_poll_interval == NULL)\n\t\ts_poll_interval = \"3000\";\n\n\tconst char *redirect_uri = oidc_get_redirect_uri(r, c);\n\tjava_script = apr_psprintf(r->pool, java_script, origin, client_id,\n\t\t\tsession_state, op_iframe_id, s_poll_interval, redirect_uri,\n\t\t\tredirect_uri);\n\n\treturn oidc_util_html_send(r, NULL, java_script, \"setTimer\", NULL, DONE);\n}", "func_src_after": "static int oidc_handle_session_management_iframe_rp(request_rec *r, oidc_cfg *c,\n\t\toidc_session_t *session, const char *client_id,\n\t\tconst char *check_session_iframe) {\n\n\toidc_debug(r, \"enter\");\n\n\tconst char *java_script =\n\t\t\t\"    <script type=\\\"text/javascript\\\">\\n\"\n\t\t\t\"      var targetOrigin  = '%s';\\n\"\n\t\t\t\"      var message = '%s' + ' ' + '%s';\\n\"\n\t\t\t\"\t   var timerID;\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function checkSession() {\\n\"\n\t\t\t\"        console.debug('checkSession: posting ' + message + ' to ' + targetOrigin);\\n\"\n\t\t\t\"        var win = window.parent.document.getElementById('%s').contentWindow;\\n\"\n\t\t\t\"        win.postMessage( message, targetOrigin);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function setTimer() {\\n\"\n\t\t\t\"        checkSession();\\n\"\n\t\t\t\"        timerID = setInterval('checkSession()', %d);\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      function receiveMessage(e) {\\n\"\n\t\t\t\"        console.debug('receiveMessage: ' + e.data + ' from ' + e.origin);\\n\"\n\t\t\t\"        if (e.origin !== targetOrigin ) {\\n\"\n\t\t\t\"          console.debug('receiveMessage: cross-site scripting attack?');\\n\"\n\t\t\t\"          return;\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"        if (e.data != 'unchanged') {\\n\"\n\t\t\t\"          clearInterval(timerID);\\n\"\n\t\t\t\"          if (e.data == 'changed') {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=check';\\n\"\n\t\t\t\"          } else {\\n\"\n\t\t\t\"\t\t     window.location.href = '%s?session=logout';\\n\"\n\t\t\t\"          }\\n\"\n\t\t\t\"        }\\n\"\n\t\t\t\"      }\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"      window.addEventListener('message', receiveMessage, false);\\n\"\n\t\t\t\"\\n\"\n\t\t\t\"    </script>\\n\";\n\n\t/* determine the origin for the check_session_iframe endpoint */\n\tchar *origin = apr_pstrdup(r->pool, check_session_iframe);\n\tapr_uri_t uri;\n\tapr_uri_parse(r->pool, check_session_iframe, &uri);\n\tchar *p = strstr(origin, uri.path);\n\t*p = '\\0';\n\n\t/* the element identifier for the OP iframe */\n\tconst char *op_iframe_id = \"openidc-op\";\n\n\t/* restore the OP session_state from the session */\n\tconst char *session_state = oidc_session_get_session_state(r, session);\n\tif (session_state == NULL) {\n\t\toidc_warn(r,\n\t\t\t\t\"no session_state found in the session; the OP does probably not support session management!?\");\n\t\treturn DONE;\n\t}\n\n\tchar *s_poll_interval = NULL;\n\toidc_util_get_request_parameter(r, \"poll\", &s_poll_interval);\n\tint poll_interval = s_poll_interval ? strtol(s_poll_interval, NULL, 10) : 0;\n\tif ((poll_interval <= 0) || (poll_interval > 3600 * 24))\n\t\tpoll_interval = 3000;\n\n\tconst char *redirect_uri = oidc_get_redirect_uri(r, c);\n\tjava_script = apr_psprintf(r->pool, java_script, origin, client_id,\n\t\t\tsession_state, op_iframe_id, poll_interval, redirect_uri,\n\t\t\tredirect_uri);\n\n\treturn oidc_util_html_send(r, NULL, java_script, \"setTimer\", NULL, DONE);\n}", "commit_link": "github.com/zmartzone/mod_auth_openidc/commit/132a4111bf3791e76437619a66336dce2ce4c79b", "file_name": "src/mod_auth_openidc.c", "vul_type": "cwe-079", "description": "In C, write a function to handle session management using an iframe for OpenID Connect, including JavaScript for client-side checks and redirection based on session state changes."}
{"func_name": "ReadMATImage", "func_src_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=CloneImageInfo(image_info);\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = DecompressBlock(image,MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n          Frames = ReadBlobXXXLong(image2);\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n  clone_info=DestroyImageInfo(clone_info);\n\n  RelinquishMagickMemory(BImgBuff);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}", "func_src_after": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  PixelPacket *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  size_t Unknown6;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  clone_info=CloneImageInfo(image_info);\n  if(ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n        MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\nMATLAB_KO: ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = DecompressBlock(image,MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if(MATLAB_HDR.DataType!=miMATRIX) continue;  /* skip another objects. */\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           Unknown6 = ReadBlobXXXLong(image2);\n           (void) Unknown6;\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n           ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n          Frames = ReadBlobXXXLong(image2);\n         break;\n      default: ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\nNEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n      /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        SetImageColorspace(image,GRAYColorspace);\n        image->type=GrayscaleType;\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\n    quantum_info=DestroyQuantumInfo(quantum_info);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow((double *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow((float *)BImgBuff, i, image, MinVal, MaxVal);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n\n    if(image2!=NULL)\n      if(image2!=image)   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) unlink(clone_info->filename);\n          }\n         }\n       }\n  }\n  clone_info=DestroyImageInfo(clone_info);\n\n  RelinquishMagickMemory(BImgBuff);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if(image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  return (image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/b173a352397877775c51c9a0e9d59eb6ce24c455", "file_name": "coders/mat.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a MATLAB image file in ImageMagick."}
{"func_name": "htmlvalue", "func_src_before": "    def htmlvalue(self, val):\n        return self.block.render_basic(val)", "func_src_after": "    def htmlvalue(self, val):\n        \"\"\"\n        Return an HTML representation of this block that is safe to be included\n        in comparison views\n        \"\"\"\n        return escape(text_from_html(self.block.render_basic(val)))", "commit_link": "github.com/wagtail/wagtail/commit/61045ceefea114c40ac4b680af58990dbe732389", "file_name": "wagtail/admin/compare.py", "vul_type": "cwe-079", "description": "Provide a Python function named `htmlvalue` that returns a safe HTML representation of a given value using a block's render method."}
{"func_name": "__getattr__.adb_call", "func_src_before": "        def adb_call(*args):\n            clean_name = name.replace('_', '-')\n            arg_str = ' '.join(str(elem) for elem in args)\n            return self._exec_adb_cmd(clean_name, arg_str)", "func_src_after": "        def adb_call(args=None, shell=False):\n            \"\"\"Wrapper for an ADB command.\n\n            Args:\n                args: string or list of strings, arguments to the adb command.\n                    See subprocess.Proc() documentation.\n                shell: bool, True to run this command through the system shell,\n                    False to invoke it directly. See subprocess.Proc() docs.\n\n            Returns:\n                The output of the adb command run if exit code is 0.\n            \"\"\"\n            args = args or ''\n            clean_name = name.replace('_', '-')\n            return self._exec_adb_cmd(clean_name, args, shell=shell)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "Create a Python function named `adb_call` that serves as a wrapper for executing ADB (Android Debug Bridge) commands with optional arguments and shell execution flag."}
{"func_name": "fetch_page_name", "func_src_before": "  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id=\"{0}\"'.format(page_id)\n    self.cursor.execute(query)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')", "func_src_after": "  def fetch_page_name(self, page_id):\n    '''\n    Returns the page name corresponding to the provided page ID.\n\n    Args:\n      page_id: The page ID whose ID to fetch.\n\n    Returns:\n      str: The page name corresponding to the provided page ID.\n\n    Raises:\n      ValueError: If the provided page ID is invalid or does not exist.\n    '''\n    helpers.validate_page_id(page_id)\n\n    query = 'SELECT name FROM pages WHERE id = ?;'\n    query_bindings = (page_id,)\n    self.cursor.execute(query, query_bindings)\n\n    page_name = self.cursor.fetchone()\n\n    if not page_name:\n      raise ValueError('Invalid page ID \"{0}\" provided. Page ID does not exist.'.format(page_id))\n\n    return page_name[0].encode('utf-8').replace('_', ' ')", "commit_link": "github.com/jwngr/sdow/commit/4db98f3521592f17550d2b723336f33fec5e112a", "file_name": "sdow/database.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve and return a page name from a database using a page ID, handling invalid IDs with an error."}
{"func_name": "getSubmissionDateFromDatabase", "func_src_before": "def getSubmissionDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT Date FROM ChallengeRankings WHERE SubmissionID = ?\", [str(submission.id)]).fetchone()[0]\n    database.close()", "func_src_after": "def getSubmissionDateFromDatabase(submission):\n    database = sqlite3.connect('database.db')\n    cursor = database.cursor()\n    return cursor.execute(\"SELECT Date FROM ChallengeRankings WHERE SubmissionID = '\" + str(submission.id) + \"'\").fetchone()[0]\n    database.close()", "commit_link": "github.com/LiquidFun/Reddit-GeoGuessr-Tracking-Bot/commit/0cad2d52e24b05da32789fbc8face7a9999a71f9", "file_name": "CheckAndPostForSeriesSubmissions.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the submission date from a SQLite database given a submission object."}
{"func_name": "get_login", "func_src_before": "@bot.message_handler(commands =['login'])\ndef get_login(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    if name != None:\n        bot.send_message(message.chat.id, \"Previous handle: \" + str(name[1]))\n    else:\n        bot.send_message(message.chat.id, \"Previous handle: None\")\n    settings.close()\n    bot.send_message(message.chat.id, \"Type new handle: \")\n    set_state(message.chat.id, config.States.S_LOGIN.value)", "func_src_after": "@bot.message_handler(commands =['login'])\ndef get_login(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    if name != None:\n        bot.send_message(message.chat.id, \"Previous handle: \" + str(name[1]))\n    else:\n        bot.send_message(message.chat.id, \"Previous handle: None\")\n    settings.close()\n    bot.send_message(message.chat.id, \"Type new handle: \")\n    set_state(message.chat.id, config.States.S_LOGIN.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "Create a Python function using the Telebot library that handles the '/login' command, retrieves the user's previous handle from an SQLite database, and prompts for a new handle."}
{"func_name": "candidate_paths_for_url", "func_src_before": "    def candidate_paths_for_url(self, url):\n        for root, prefix in self.directories:\n            if url.startswith(prefix):\n                yield os.path.join(root, url[len(prefix):])", "func_src_after": "    def candidate_paths_for_url(self, url):\n        for root, prefix in self.directories:\n            if url.startswith(prefix):\n                path = os.path.join(root, url[len(prefix):])\n                if os.path.commonprefix((root, path)) == root:\n                    yield path", "commit_link": "github.com/evansd/whitenoise/commit/4d8a3ab1e97d7ddb18b3fa8b4909c92bad5529c6", "file_name": "whitenoise/base.py", "vul_type": "cwe-022", "description": "Write a Python function that yields file system paths corresponding to a given URL based on predefined directory mappings."}
{"func_name": "ring_buffer_resize", "func_src_before": "int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/* we need a minimum of two pages */\n\tif (nr_pages < 2)\n\t\tnr_pages = 2;\n\n\tsize = nr_pages * BUF_PAGE_SIZE;\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been intitialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}", "func_src_after": "int ring_buffer_resize(struct ring_buffer *buffer, unsigned long size,\n\t\t\tint cpu_id)\n{\n\tstruct ring_buffer_per_cpu *cpu_buffer;\n\tunsigned long nr_pages;\n\tint cpu, err = 0;\n\n\t/*\n\t * Always succeed at resizing a non-existent buffer:\n\t */\n\tif (!buffer)\n\t\treturn size;\n\n\t/* Make sure the requested buffer exists */\n\tif (cpu_id != RING_BUFFER_ALL_CPUS &&\n\t    !cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\treturn size;\n\n\tsize = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\tsize *= BUF_PAGE_SIZE;\n\n\t/* we need a minimum of two pages */\n\tif (size < BUF_PAGE_SIZE * 2)\n\t\tsize = BUF_PAGE_SIZE * 2;\n\n\tnr_pages = DIV_ROUND_UP(size, BUF_PAGE_SIZE);\n\n\t/*\n\t * Don't succeed if resizing is disabled, as a reader might be\n\t * manipulating the ring buffer and is expecting a sane state while\n\t * this is true.\n\t */\n\tif (atomic_read(&buffer->resize_disabled))\n\t\treturn -EBUSY;\n\n\t/* prevent another thread from changing buffer sizes */\n\tmutex_lock(&buffer->mutex);\n\n\tif (cpu_id == RING_BUFFER_ALL_CPUS) {\n\t\t/* calculate the pages to update */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\n\t\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\t\tcpu_buffer->nr_pages;\n\t\t\t/*\n\t\t\t * nothing more to do for removing pages or no update\n\t\t\t */\n\t\t\tif (cpu_buffer->nr_pages_to_update <= 0)\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * to add pages, make sure all new pages can be\n\t\t\t * allocated without receiving ENOMEM\n\t\t\t */\n\t\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\t\tif (__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t\t&cpu_buffer->new_pages, cpu)) {\n\t\t\t\t/* not enough memory for new pages */\n\t\t\t\terr = -ENOMEM;\n\t\t\t\tgoto out_err;\n\t\t\t}\n\t\t}\n\n\t\tget_online_cpus();\n\t\t/*\n\t\t * Fire off all the required work handlers\n\t\t * We can't schedule on offline CPUs, but it's not necessary\n\t\t * since we can change their buffer sizes without any race.\n\t\t */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\t/* Can't run something on an offline CPU. */\n\t\t\tif (!cpu_online(cpu)) {\n\t\t\t\trb_update_pages(cpu_buffer);\n\t\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t\t} else {\n\t\t\t\tschedule_work_on(cpu,\n\t\t\t\t\t\t&cpu_buffer->update_pages_work);\n\t\t\t}\n\t\t}\n\n\t\t/* wait for all the updates to complete */\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\tif (!cpu_buffer->nr_pages_to_update)\n\t\t\t\tcontinue;\n\n\t\t\tif (cpu_online(cpu))\n\t\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\t}\n\n\t\tput_online_cpus();\n\t} else {\n\t\t/* Make sure this CPU has been intitialized */\n\t\tif (!cpumask_test_cpu(cpu_id, buffer->cpumask))\n\t\t\tgoto out;\n\n\t\tcpu_buffer = buffer->buffers[cpu_id];\n\n\t\tif (nr_pages == cpu_buffer->nr_pages)\n\t\t\tgoto out;\n\n\t\tcpu_buffer->nr_pages_to_update = nr_pages -\n\t\t\t\t\t\tcpu_buffer->nr_pages;\n\n\t\tINIT_LIST_HEAD(&cpu_buffer->new_pages);\n\t\tif (cpu_buffer->nr_pages_to_update > 0 &&\n\t\t\t__rb_allocate_pages(cpu_buffer->nr_pages_to_update,\n\t\t\t\t\t    &cpu_buffer->new_pages, cpu_id)) {\n\t\t\terr = -ENOMEM;\n\t\t\tgoto out_err;\n\t\t}\n\n\t\tget_online_cpus();\n\n\t\t/* Can't run something on an offline CPU. */\n\t\tif (!cpu_online(cpu_id))\n\t\t\trb_update_pages(cpu_buffer);\n\t\telse {\n\t\t\tschedule_work_on(cpu_id,\n\t\t\t\t\t &cpu_buffer->update_pages_work);\n\t\t\twait_for_completion(&cpu_buffer->update_done);\n\t\t}\n\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\t\tput_online_cpus();\n\t}\n\n out:\n\t/*\n\t * The ring buffer resize can happen with the ring buffer\n\t * enabled, so that the update disturbs the tracing as little\n\t * as possible. But if the buffer is disabled, we do not need\n\t * to worry about that, and we can take the time to verify\n\t * that the buffer is not corrupt.\n\t */\n\tif (atomic_read(&buffer->record_disabled)) {\n\t\tatomic_inc(&buffer->record_disabled);\n\t\t/*\n\t\t * Even though the buffer was disabled, we must make sure\n\t\t * that it is truly disabled before calling rb_check_pages.\n\t\t * There could have been a race between checking\n\t\t * record_disable and incrementing it.\n\t\t */\n\t\tsynchronize_sched();\n\t\tfor_each_buffer_cpu(buffer, cpu) {\n\t\t\tcpu_buffer = buffer->buffers[cpu];\n\t\t\trb_check_pages(cpu_buffer);\n\t\t}\n\t\tatomic_dec(&buffer->record_disabled);\n\t}\n\n\tmutex_unlock(&buffer->mutex);\n\treturn size;\n\n out_err:\n\tfor_each_buffer_cpu(buffer, cpu) {\n\t\tstruct buffer_page *bpage, *tmp;\n\n\t\tcpu_buffer = buffer->buffers[cpu];\n\t\tcpu_buffer->nr_pages_to_update = 0;\n\n\t\tif (list_empty(&cpu_buffer->new_pages))\n\t\t\tcontinue;\n\n\t\tlist_for_each_entry_safe(bpage, tmp, &cpu_buffer->new_pages,\n\t\t\t\t\tlist) {\n\t\t\tlist_del_init(&bpage->list);\n\t\t\tfree_buffer_page(bpage);\n\t\t}\n\t}\n\tmutex_unlock(&buffer->mutex);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/59643d1535eb220668692a5359de22545af579f6", "file_name": "kernel/trace/ring_buffer.c", "vul_type": "cwe-190", "description": "Write a C function to resize a ring buffer for a specific CPU or all CPUs, handling memory allocation and synchronization issues."}
{"func_name": "nntp_hcache_namer", "func_src_before": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  return snprintf(dest, destlen, \"%s.hcache\", path);\n}", "func_src_after": "static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n{\n  int count = snprintf(dest, destlen, \"%s.hcache\", path);\n\n  /* Strip out any directories in the path */\n  char *first = strchr(dest, '/');\n  char *last = strrchr(dest, '/');\n  if (first && last && (last > first))\n  {\n    memmove(first, last, strlen(last) + 1);\n    count -= (last - first);\n  }\n\n  return count;\n}", "commit_link": "github.com/neomutt/neomutt/commit/9bfab35522301794483f8f9ed60820bdec9be59e", "file_name": "newsrc.c", "vul_type": "cwe-022", "description": "Write a C function named `nntp_hcache_namer` that formats a file path with the extension \".hcache\", optionally removing directory components."}
{"func_name": "get_files", "func_src_before": "    def get_files(self, submit_id, password=None, astree=False):\n        \"\"\"\n        Returns files from a submitted analysis.\n        @param password: The password to unlock container archives with\n        @param astree: sflock option; determines the format in which the files are returned\n        @return: A tree of files\n        \"\"\"\n        submit = Database().view_submit(submit_id)\n        files, duplicates = [], []\n\n        for data in submit.data[\"data\"]:\n            if data[\"type\"] == \"file\":\n                filename = Storage.get_filename_from_path(data[\"data\"])\n                filepath = os.path.join(submit.tmp_path, filename)\n\n                unpacked = sflock.unpack(\n                    filepath=filepath, password=password, duplicates=duplicates\n                )\n\n                if astree:\n                    unpacked = unpacked.astree(sanitize=True)\n\n                files.append(unpacked)\n            elif data[\"type\"] == \"url\":\n                files.append({\n                    \"filename\": data[\"data\"],\n                    \"filepath\": \"\",\n                    \"relapath\": \"\",\n                    \"selected\": True,\n                    \"size\": 0,\n                    \"type\": \"url\",\n                    \"package\": \"ie\",\n                    \"extrpath\": [],\n                    \"duplicate\": False,\n                    \"children\": [],\n                    \"mime\": \"text/html\",\n                    \"finger\": {\n                        \"magic_human\": \"url\",\n                        \"magic\": \"url\"\n                    }\n                })\n            else:\n                raise RuntimeError(\n                    \"Unknown data entry type: %s\" % data[\"type\"]\n                )\n\n        return files", "func_src_after": "    def get_files(self, submit_id, password=None, astree=False):\n        \"\"\"\n        Returns files from a submitted analysis.\n        @param password: The password to unlock container archives with\n        @param astree: sflock option; determines the format in which the files are returned\n        @return: A tree of files\n        \"\"\"\n        submit = Database().view_submit(submit_id)\n        files, duplicates = [], []\n\n        for data in submit.data[\"data\"]:\n            if data[\"type\"] == \"file\":\n                filename = Storage.get_filename_from_path(data[\"data\"])\n                filepath = os.path.join(submit.tmp_path, data[\"data\"])\n                filedata = open(filepath, \"rb\").read()\n\n                unpacked = sflock.unpack(\n                    filepath=filename, contents=filedata,\n                    password=password, duplicates=duplicates\n                )\n\n                if astree:\n                    unpacked = unpacked.astree()\n\n                files.append(unpacked)\n            elif data[\"type\"] == \"url\":\n                files.append({\n                    \"filename\": data[\"data\"],\n                    \"filepath\": \"\",\n                    \"relapath\": \"\",\n                    \"selected\": True,\n                    \"size\": 0,\n                    \"type\": \"url\",\n                    \"package\": \"ie\",\n                    \"extrpath\": [],\n                    \"duplicate\": False,\n                    \"children\": [],\n                    \"mime\": \"text/html\",\n                    \"finger\": {\n                        \"magic_human\": \"url\",\n                        \"magic\": \"url\"\n                    }\n                })\n            else:\n                raise RuntimeError(\n                    \"Unknown data entry type: %s\" % data[\"type\"]\n                )\n\n        return {\n            \"files\": files,\n            \"path\": submit.tmp_path,\n        }", "commit_link": "github.com/cuckoosandbox/cuckoo/commit/168cabf86730d56b7fa319278bf0f0034052666a", "file_name": "cuckoo/core/submit.py", "vul_type": "cwe-022", "description": "Write a Python function to retrieve and format files from a database submission, with optional password and tree formatting."}
{"func_name": "re2c::Scanner::fill", "func_src_before": "bool Scanner::fill(size_t need)\n{\n    if (eof) return false;\n\n    pop_finished_files();\n\n    DASSERT(bot <= tok && tok <= lim);\n    size_t free = static_cast<size_t>(tok - bot);\n    size_t copy = static_cast<size_t>(lim - tok);\n\n    if (free >= need) {\n        memmove(bot, tok, copy);\n        shift_ptrs_and_fpos(-static_cast<ptrdiff_t>(free));\n    }\n    else {\n        BSIZE += std::max(BSIZE, need);\n        char * buf = new char[BSIZE + YYMAXFILL];\n        if (!buf) fatal(\"out of memory\");\n\n        memmove(buf, tok, copy);\n        shift_ptrs_and_fpos(buf - bot);\n        delete [] bot;\n        bot = buf;\n\n        free = BSIZE - copy;\n    }\n\n    if (!read(free)) {\n        eof = lim;\n        memset(lim, 0, YYMAXFILL);\n        lim += YYMAXFILL;\n    }\n\n    return true;\n}", "func_src_after": "bool Scanner::fill(size_t need)\n{\n    if (eof) return false;\n\n    pop_finished_files();\n\n    DASSERT(bot <= tok && tok <= lim);\n    size_t free = static_cast<size_t>(tok - bot);\n    size_t copy = static_cast<size_t>(lim - tok);\n\n    if (free >= need) {\n        memmove(bot, tok, copy);\n        shift_ptrs_and_fpos(-static_cast<ptrdiff_t>(free));\n    }\n    else {\n        BSIZE += std::max(BSIZE, need);\n        char * buf = new char[BSIZE + YYMAXFILL];\n        if (!buf) fatal(\"out of memory\");\n\n        memmove(buf, tok, copy);\n        shift_ptrs_and_fpos(buf - tok);\n        delete [] bot;\n        bot = buf;\n\n        free = BSIZE - copy;\n    }\n\n    DASSERT(lim + free <= bot + BSIZE);\n    if (!read(free)) {\n        eof = lim;\n        memset(lim, 0, YYMAXFILL);\n        lim += YYMAXFILL;\n    }\n\n    return true;\n}", "commit_link": "github.com/skvadrik/re2c/commit/c4603ba5ce229db83a2a4fb93e6d4b4e3ec3776a", "file_name": "src/parse/scanner.cc", "vul_type": "cwe-787", "description": "Write a C++ function named `fill` in the `Scanner` class that ensures a buffer has enough free space and reads more data if necessary."}
{"func_name": "uvesafb_setcmap", "func_src_before": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc_array(cmap->len, sizeof(*entries),\n\t\t\t\t\tGFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "func_src_after": "static int uvesafb_setcmap(struct fb_cmap *cmap, struct fb_info *info)\n{\n\tstruct uvesafb_pal_entry *entries;\n\tint shift = 16 - dac_width;\n\tint i, err = 0;\n\n\tif (info->var.bits_per_pixel == 8) {\n\t\tif (cmap->start + cmap->len > info->cmap.start +\n\t\t    info->cmap.len || cmap->start < info->cmap.start)\n\t\t\treturn -EINVAL;\n\n\t\tentries = kmalloc(sizeof(*entries) * cmap->len, GFP_KERNEL);\n\t\tif (!entries)\n\t\t\treturn -ENOMEM;\n\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\tentries[i].red   = cmap->red[i]   >> shift;\n\t\t\tentries[i].green = cmap->green[i] >> shift;\n\t\t\tentries[i].blue  = cmap->blue[i]  >> shift;\n\t\t\tentries[i].pad   = 0;\n\t\t}\n\t\terr = uvesafb_setpalette(entries, cmap->len, cmap->start, info);\n\t\tkfree(entries);\n\t} else {\n\t\t/*\n\t\t * For modes with bpp > 8, we only set the pseudo palette in\n\t\t * the fb_info struct. We rely on uvesafb_setcolreg to do all\n\t\t * sanity checking.\n\t\t */\n\t\tfor (i = 0; i < cmap->len; i++) {\n\t\t\terr |= uvesafb_setcolreg(cmap->start + i, cmap->red[i],\n\t\t\t\t\t\tcmap->green[i], cmap->blue[i],\n\t\t\t\t\t\t0, info);\n\t\t}\n\t}\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/9f645bcc566a1e9f921bdae7528a01ced5bc3713", "file_name": "drivers/video/fbdev/uvesafb.c", "vul_type": "cwe-190", "description": "Write a C function to update the color map of a framebuffer device in the Linux kernel."}
{"func_name": "change_message", "func_src_before": "    def change_message(self, new_message, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET message = ?\n            WHERE client_id = ?\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql, (new_message, logged_user.get_client_id()))\n        self.__conn.commit()\n        logged_user.set_message(new_message)", "func_src_after": "    def change_message(self, new_message, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET message = '{}'\n            WHERE client_id = '{}'\n        \"\"\".format(new_message, logged_user.get_client_id())\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql)\n        self.__conn.commit()\n        logged_user.set_message(new_message)", "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's message in a database and their object's state."}
{"func_name": "tid_to_tid_num", "func_src_before": "    def tid_to_tid_num(self, tid):\n        ''' Returns tid_num, given tid. '''\n\n        q = \"SELECT rowid FROM tids WHERE tid = ?\"\n        self.query(q, tid)\n        return self.c.fetchone()[0]", "func_src_after": "    def tid_to_tid_num(self, tid):\n        ''' Returns tid_num, given tid. '''\n\n        q = \"SELECT rowid FROM tids WHERE tid = '\" + tid + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves the numerical ID (rowid) for a given text identifier (tid) from a database table named 'tids'."}
{"func_name": "search_films", "func_src_before": "@app.route('/movies/search', methods=['GET', 'POST'])\ndef search_films():\n    form = SearchForm()\n    if not form.validate_on_submit():\n        return render_template('search.html', title='Search for films', form=form)\n    search_terms = form.data['term'].split(' ')\n    search_string = ' & '.join(search_terms)\n    cur.execute(f\"SELECT * FROM film where fulltext @@ to_tsquery('{search_string}')\")\n    res = cur.fetchall()\n    return render_template('search_results.html', title='Home', res=len(res))", "func_src_after": "@app.route('/movies/search', methods=['GET', 'POST'])\ndef search_films():\n    form = SearchForm()\n    if not form.validate_on_submit():\n        return render_template('search.html', title='Search for films', form=form)\n    search_terms = form.data['term'].split(' ')\n    search_string = ' & '.join(search_terms)\n    cur.execute(\"SELECT * FROM film where fulltext @@ to_tsquery(%s)\", (search_string, ))\n    res = cur.fetchall()\n    return render_template('search_results.html', title='Home', res=len(res))", "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to handle film search using a form and PostgreSQL full-text search."}
{"func_name": "user_verify", "func_src_before": "    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = '''select * from usr where email like\\''''+eid+'\\''\n        cursor = g.conn.execute(query)\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break", "func_src_after": "    def user_verify(self):\n        eid = self.email\n        code = self.password\n        if eid.strip() == '':\n            return\n        if code.strip() == '':\n            return\n        query = 'select * from usr where email like %s'\n        cursor = g.conn.execute(query, (eid, ))\n        for row in cursor:\n            key = str(row.password)\n            if key.strip() == code.strip():\n                self.name = str(row.name)\n                self.email = eid\n                self.id = eid\n                self.valid = True\n            break", "commit_link": "github.com/Daniel-Bu/w4111-project1/commit/fe04bedc72e62fd4c4ee046a9af29fd81e9b3340", "file_name": "Web-app/User.py", "vul_type": "cwe-089", "description": "Write a Python function named `user_verify` that checks if a user's email and password match the records in a database, and updates the user's attributes if the credentials are valid."}
{"func_name": "get_error_days", "func_src_before": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > {}\n            ORDER BY log_errors.date'''.format(error_percent)\n    rows = get_data(cur, query)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "func_src_after": "def get_error_days(cur, error_percent):\n    \"\"\"Fetches the days in which requests led to errors.\n\n    Fetches the days in which the specified percentage\n    of requests led to errors.\n\n    Args:\n        cur(obj): The cursor to execute the query.\n        error_percent(int): The percentage of requests that led to errors.\n\n    Return:\n        True if success, False otherwise.\n    \"\"\"\n    data = (error_percent, )\n    query = '''SELECT to_char(log_errors.date, 'Mon DD YYYY'),\n            round((log_errors.errors * 100\n            / log_requests.total::numeric), 2) as percent\n            FROM log_errors, log_requests\n            WHERE log_errors.date = log_requests.date AND\n            log_errors.errors * 100\n            / log_requests.total::numeric > %s\n            ORDER BY log_errors.date'''\n    rows = get_data(cur, query, data)\n\n    # Write data to txt file.\n    if rows is not None:\n        file = open(\"error_report.txt\", \"w\")\n        for row in rows:\n            file.write(\"{} - {}% errors \\n\".format(row[0], row[1]))\n        file.close()\n\n        return True\n    else:\n        return False", "commit_link": "github.com/rrbiz662/log-analysis/commit/20fefbde3738088586a3c5679f743493d0a504f6", "file_name": "news_data_analysis.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for days with error rates above a threshold and save the results to a text file."}
{"func_name": "top_proxies", "func_src_before": "@app.route('/top_proxies')\ndef top_proxies():\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT sum(amount) FROM holders\"\n    cur.execute(query)\n    total = cur.fetchone()\n    total_votes = total[0]\n\n    query = \"SELECT voting_as FROM holders WHERE voting_as<>'1.2.5' group by voting_as\"\n    cur.execute(query)\n    results = cur.fetchall()\n    #con.close()\n\n    proxies = []\n\n    for p in range(0, len(results)):\n\n        proxy_line = [0] * 5\n\n        proxy_id = results[p][0]\n        proxy_line[0] = proxy_id\n\n        query = \"SELECT account_name, amount FROM holders WHERE account_id='\"+proxy_id+\"' LIMIT 1\"\n        cur.execute(query)\n        proxy = cur.fetchone()\n\n        try:\n            proxy_name = proxy[0]\n            proxy_amount = proxy[1]\n        except:\n            proxy_name = \"unknown\"\n            proxy_amount = 0\n\n\n        proxy_line[1] = proxy_name\n\n        query = \"SELECT amount, account_id FROM holders WHERE voting_as='\"+proxy_id+\"'\"\n        cur.execute(query)\n        results2 = cur.fetchall()\n\n        proxy_line[2] = int(proxy_amount)\n\n        for p2 in range(0, len(results2)):\n            amount = results2[p2][0]\n            account_id = results2[p2][1]\n            proxy_line[2] = proxy_line[2] + int(amount)  # total proxy votes\n            proxy_line[3] = proxy_line[3] + 1       # followers\n\n        if proxy_line[3] > 2:\n            percentage = float(float(proxy_line[2]) * 100.0/ float(total_votes))\n            proxy_line[4] = percentage\n            proxies.append(proxy_line)\n\n    con.close()\n\n    proxies = sorted(proxies, key=lambda k: int(k[2]))\n    r_proxies = proxies[::-1]\n\n    return jsonify(filter(None, r_proxies))", "func_src_after": "@app.route('/top_proxies')\ndef top_proxies():\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT sum(amount) FROM holders\"\n    cur.execute(query)\n    total = cur.fetchone()\n    total_votes = total[0]\n\n    query = \"SELECT voting_as FROM holders WHERE voting_as<>'1.2.5' group by voting_as\"\n    cur.execute(query)\n    results = cur.fetchall()\n    #con.close()\n\n    proxies = []\n\n    for p in range(0, len(results)):\n\n        proxy_line = [0] * 5\n\n        proxy_id = results[p][0]\n        proxy_line[0] = proxy_id\n\n        query = \"SELECT account_name, amount FROM holders WHERE account_id=%s LIMIT 1\"\n        cur.execute(query, (proxy_id,))\n        proxy = cur.fetchone()\n\n        try:\n            proxy_name = proxy[0]\n            proxy_amount = proxy[1]\n        except:\n            proxy_name = \"unknown\"\n            proxy_amount = 0\n\n\n        proxy_line[1] = proxy_name\n\n        query = \"SELECT amount, account_id FROM holders WHERE voting_as=%s\"\n        cur.execute(query, (proxy_id,))\n        results2 = cur.fetchall()\n\n        proxy_line[2] = int(proxy_amount)\n\n        for p2 in range(0, len(results2)):\n            amount = results2[p2][0]\n            account_id = results2[p2][1]\n            proxy_line[2] = proxy_line[2] + int(amount)  # total proxy votes\n            proxy_line[3] = proxy_line[3] + 1       # followers\n\n        if proxy_line[3] > 2:\n            percentage = float(float(proxy_line[2]) * 100.0/ float(total_votes))\n            proxy_line[4] = percentage\n            proxies.append(proxy_line)\n\n    con.close()\n\n    proxies = sorted(proxies, key=lambda k: int(k[2]))\n    r_proxies = proxies[::-1]\n\n    return jsonify(filter(None, r_proxies))", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "In Python, create a Flask endpoint '/top_proxies' that queries a PostgreSQL database to retrieve and return a JSON list of top proxy voters and their details."}
{"func_name": "CWebSock::GetSkinPath", "func_src_before": "CString CWebSock::GetSkinPath(const CString& sSkinName) {\n    CString sRet = CZNC::Get().GetZNCPath() + \"/webskins/\" + sSkinName;\n\n    if (!CFile::IsDir(sRet)) {\n        sRet = CZNC::Get().GetCurPath() + \"/webskins/\" + sSkinName;\n\n        if (!CFile::IsDir(sRet)) {\n            sRet = CString(_SKINDIR_) + \"/\" + sSkinName;\n        }\n    }\n\n    return sRet + \"/\";\n}", "func_src_after": "CString CWebSock::GetSkinPath(const CString& sSkinName) {\n    const CString sSkin = sSkinName.Replace_n(\"/\", \"_\").Replace_n(\".\", \"_\");\n\n    CString sRet = CZNC::Get().GetZNCPath() + \"/webskins/\" + sSkin;\n\n    if (!CFile::IsDir(sRet)) {\n        sRet = CZNC::Get().GetCurPath() + \"/webskins/\" + sSkin;\n\n        if (!CFile::IsDir(sRet)) {\n            sRet = CString(_SKINDIR_) + \"/\" + sSkin;\n        }\n    }\n\n    return sRet + \"/\";\n}", "commit_link": "github.com/znc/znc/commit/a4a5aeeb17d32937d8c7d743dae9a4cc755ce773", "file_name": "src/WebModules.cpp", "vul_type": "cwe-022", "description": "In C++, write a function to return the path to a web skin directory, checking multiple locations and sanitizing the skin name if necessary."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHP_FUNCTION(imagegammacorrect)\n{\n\tzval *IM;\n\tgdImagePtr im;\n\tint i;\n\tdouble input, output;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rdd\", &IM, &input, &output) == FAILURE) {\n\t\treturn;\n\t}\n\n\tZEND_FETCH_RESOURCE(im, gdImagePtr, &IM, -1, \"Image\", le_gd);\n\n\tif (gdImageTrueColor(im))\t{\n\t\tint x, y, c;\n\n\t\tfor (y = 0; y < gdImageSY(im); y++)\t{\n\t\t\tfor (x = 0; x < gdImageSX(im); x++)\t{\n\t\t\t\tc = gdImageGetPixel(im, x, y);\n\t\t\t\tgdImageSetPixel(im, x, y,\n\t\t\t\t\tgdTrueColorAlpha(\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetRed(c)   / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetGreen(c) / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetBlue(c)  / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\tgdTrueColorGetAlpha(c)\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t\tRETURN_TRUE;\n\t}\n\n\tfor (i = 0; i < gdImageColorsTotal(im); i++) {\n\t\tim->red[i]   = (int)((pow((pow((im->red[i]   / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->green[i] = (int)((pow((pow((im->green[i] / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->blue[i]  = (int)((pow((pow((im->blue[i]  / 255.0), input)), 1.0 / output) * 255) + .5);\n\t}\n\n\tRETURN_TRUE;\n}", "func_src_after": "PHP_FUNCTION(imagegammacorrect)\n{\n\tzval *IM;\n\tgdImagePtr im;\n\tint i;\n\tdouble input, output;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"rdd\", &IM, &input, &output) == FAILURE) {\n\t\treturn;\n\t}\n\n\tif ( input <= 0.0 || output <= 0.0 ) {\n\t\tphp_error_docref(NULL TSRMLS_CC, E_WARNING, \"Gamma values should be positive\");\n\t\tRETURN_FALSE;\n\t}\n\n\tZEND_FETCH_RESOURCE(im, gdImagePtr, &IM, -1, \"Image\", le_gd);\n\n\tif (gdImageTrueColor(im))\t{\n\t\tint x, y, c;\n\n\t\tfor (y = 0; y < gdImageSY(im); y++)\t{\n\t\t\tfor (x = 0; x < gdImageSX(im); x++)\t{\n\t\t\t\tc = gdImageGetPixel(im, x, y);\n\t\t\t\tgdImageSetPixel(im, x, y,\n\t\t\t\t\tgdTrueColorAlpha(\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetRed(c)   / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetGreen(c) / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\t(int) ((pow((pow((gdTrueColorGetBlue(c)  / 255.0), input)), 1.0 / output) * 255) + .5),\n\t\t\t\t\t\tgdTrueColorGetAlpha(c)\n\t\t\t\t\t)\n\t\t\t\t);\n\t\t\t}\n\t\t}\n\t\tRETURN_TRUE;\n\t}\n\n\tfor (i = 0; i < gdImageColorsTotal(im); i++) {\n\t\tim->red[i]   = (int)((pow((pow((im->red[i]   / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->green[i] = (int)((pow((pow((im->green[i] / 255.0), input)), 1.0 / output) * 255) + .5);\n\t\tim->blue[i]  = (int)((pow((pow((im->blue[i]  / 255.0), input)), 1.0 / output) * 255) + .5);\n\t}\n\n\tRETURN_TRUE;\n}", "commit_link": "github.com/php/php-src/commit/1bd103df00f49cf4d4ade2cfe3f456ac058a4eae", "file_name": "ext/gd/gd.c", "vul_type": "cwe-787", "description": "Write a PHP function to apply gamma correction to an image resource with given input and output gamma values."}
{"func_name": "get_secrets", "func_src_before": "\tdef get_secrets(self, from_date_added=0):\n\t\tsecrets = []\n\t\tfor row in self.cursor.execute('SELECT encrypted, json_id, date_added FROM secret WHERE date_added > ? ORDER BY date_added DESC', (from_date_added,)):\n\t\t\taes_key, json_id, date_added = cryptlib.eciesDecrypt(row[0], self.privkey), row[1], row[2]\n\t\t\tif aes_key != None:\n\t\t\t\tsecrets.append([aes_key, json_id])\n\t\t\tfrom_date_added = max(from_date_added, date_added)\n\t\treturn (secrets, from_date_added)", "func_src_after": "\tdef get_secrets(self, from_date_added=0):\n\t\tsecrets = []\n\t\tfor row in self.cursor.execute('SELECT encrypted, json_id, date_added FROM secret WHERE date_added > %s ORDER BY date_added DESC' % from_date_added):\n\t\t\taes_key, json_id, date_added = cryptlib.eciesDecrypt(row[0], self.privkey), row[1], row[2]\n\t\t\tif aes_key != None:\n\t\t\t\tsecrets.append([aes_key, json_id])\n\t\t\tfrom_date_added = max(from_date_added, date_added)\n\t\treturn (secrets, from_date_added)", "commit_link": "github.com/imachug/ZeroMailProxy/commit/8f62d024c6c4c957079d147e59f26d15c07dc888", "file_name": "zeromail.py", "vul_type": "cwe-089", "description": "Write a Python function named `get_secrets` that retrieves and decrypts secrets from a database added after a specified date."}
{"func_name": "summary", "func_src_before": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount=%s\", (session['username']));\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "func_src_after": "@app.route('/summary', methods=['GET'])\ndef summary():\n\tif 'username' in session:\n\n\t\tconn = mysql.connect()\n\t\tcursor = conn.cursor()\n\n\t\t#select the maximum score from the results table\n\t\tcursor.execute(\"SELECT courseConcentration FROM results WHERE total = (SELECT MAX(total) FROM (SELECT * FROM results WHERE courseId > 4) Temp) and courseId > 4 and emailAccount='\" + session['username'] + \"'\");\n\t\tcourseConcentration = cursor.fetchone()\n\n\t\treturn render_template('summary.html', courseConcentration = courseConcentration[0])\n\treturn redirect(url_for('login'))", "commit_link": "github.com/CaitlinKennedy/Tech-Track/commit/20ef2d4010f9497b8221524edd0c706e2c6a4147", "file_name": "src/tech_track.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint that retrieves the user's highest score course concentration from a MySQL database and displays it on a summary page if logged in, otherwise redirects to the login page."}
{"func_name": "_execute_command_and_parse_attributes", "func_src_before": "    def _execute_command_and_parse_attributes(self, ssh_cmd):\n        \"\"\"Execute command on the Storwize/SVC and parse attributes.\n\n        Exception is raised if the information from the system\n        can not be obtained.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _execute_command_and_parse_attributes: '\n                    ' command %s') % str(ssh_cmd))\n\n        try:\n            out, err = self._run_ssh(ssh_cmd)\n        except exception.ProcessExecutionError as e:\n            # Didn't get details from the storage, return None\n            LOG.error(_('CLI Exception output:\\n command: %(cmd)s\\n '\n                        'stdout: %(out)s\\n stderr: %(err)s') %\n                      {'cmd': ssh_cmd,\n                       'out': e.stdout,\n                       'err': e.stderr})\n            return None\n\n        self._assert_ssh_return(len(out),\n                                '_execute_command_and_parse_attributes',\n                                ssh_cmd, out, err)\n        attributes = {}\n        for attrib_line in out.split('\\n'):\n            # If '!' not found, return the string and two empty strings\n            attrib_name, foo, attrib_value = attrib_line.partition('!')\n            if attrib_name is not None and len(attrib_name.strip()):\n                attributes[attrib_name] = attrib_value\n\n        LOG.debug(_('leave: _execute_command_and_parse_attributes:\\n'\n                    'command: %(cmd)s\\n'\n                    'attributes: %(attr)s')\n                  % {'cmd': str(ssh_cmd),\n                     'attr': str(attributes)})\n\n        return attributes", "func_src_after": "    def _execute_command_and_parse_attributes(self, ssh_cmd):\n        \"\"\"Execute command on the Storwize/SVC and parse attributes.\n\n        Exception is raised if the information from the system\n        can not be obtained.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _execute_command_and_parse_attributes: '\n                    ' command %s') % ssh_cmd)\n\n        try:\n            out, err = self._run_ssh(ssh_cmd)\n        except exception.ProcessExecutionError as e:\n            # Didn't get details from the storage, return None\n            LOG.error(_('CLI Exception output:\\n command: %(cmd)s\\n '\n                        'stdout: %(out)s\\n stderr: %(err)s') %\n                      {'cmd': ssh_cmd,\n                       'out': e.stdout,\n                       'err': e.stderr})\n            return None\n\n        self._assert_ssh_return(len(out),\n                                '_execute_command_and_parse_attributes',\n                                ssh_cmd, out, err)\n        attributes = {}\n        for attrib_line in out.split('\\n'):\n            # If '!' not found, return the string and two empty strings\n            attrib_name, foo, attrib_value = attrib_line.partition('!')\n            if attrib_name is not None and len(attrib_name.strip()):\n                attributes[attrib_name] = attrib_value\n\n        LOG.debug(_('leave: _execute_command_and_parse_attributes:\\n'\n                    'command: %(cmd)s\\n'\n                    'attributes: %(attr)s')\n                  % {'cmd': ssh_cmd,\n                     'attr': str(attributes)})\n\n        return attributes", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "In Python, write a function to execute an SSH command, parse the output into attributes, and handle any execution errors."}
{"func_name": "_inject_key_into_fs", "func_src_before": "def _inject_key_into_fs(key, fs, execute=None):\n    \"\"\"Add the given public ssh key to root's authorized_keys.\n\n    key is an ssh key string.\n    fs is the path to the base of the filesystem into which to inject the key.\n    \"\"\"\n    sshdir = _join_and_check_path_within_fs(fs, 'root', '.ssh')\n    utils.execute('mkdir', '-p', sshdir, run_as_root=True)\n    utils.execute('chown', 'root', sshdir, run_as_root=True)\n    utils.execute('chmod', '700', sshdir, run_as_root=True)\n\n    keyfile = os.path.join('root', '.ssh', 'authorized_keys')\n\n    key_data = ''.join([\n        '\\n',\n        '# The following ssh key was injected by Nova',\n        '\\n',\n        key.strip(),\n        '\\n',\n    ])\n\n    _inject_file_into_fs(fs, keyfile, key_data, append=True)", "func_src_after": "def _inject_key_into_fs(key, fs, execute=None):\n    \"\"\"Add the given public ssh key to root's authorized_keys.\n\n    key is an ssh key string.\n    fs is the path to the base of the filesystem into which to inject the key.\n    \"\"\"\n    sshdir = os.path.join(fs, 'root', '.ssh')\n    utils.execute('mkdir', '-p', sshdir, run_as_root=True)\n    utils.execute('chown', 'root', sshdir, run_as_root=True)\n    utils.execute('chmod', '700', sshdir, run_as_root=True)\n    keyfile = os.path.join(sshdir, 'authorized_keys')\n    key_data = [\n        '\\n',\n        '# The following ssh key was injected by Nova',\n        '\\n',\n        key.strip(),\n        '\\n',\n    ]\n    utils.execute('tee', '-a', keyfile,\n                  process_input=''.join(key_data), run_as_root=True)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to add an SSH key to the root user's authorized_keys file in a given filesystem."}
{"func_name": "update_institutions", "func_src_before": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES (?)\"\n            sqlite.execute(sql, (current_institution,))\n            conn.commit()", "func_src_after": "def update_institutions(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Update the institution table.\n    \"\"\"\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_institutions = get_all_old_institutions(conn, sqlite)\n\n    # Check if the institution table is allready filled and this is not the first checkup\n    institution_table_is_filled = len(old_institutions) > 10\n\n    for old_institution in old_institutions:\n        if institution_table_is_filled and old_institution not in current_institutions:\n            message = \"Die ISIL %s ist im aktuellen Import nicht mehr vorhanden.\\nWenn dies beabsichtigt ist, bitte die Institution aus der Datenbank loeschen.\" % old_institution\n            send_message(message)\n\n    for current_institution in current_institutions:\n        if current_institution == \" \" or '\"' in current_institution:\n                continue\n        if current_institution not in old_institutions:\n            message = \"The institution %s is new in Solr.\" % current_institution\n            if institution_table_is_filled:\n                send_message(message)\n            else:\n                logging.info(message)\n            sql = \"INSERT INTO institution (institution) VALUES ('%s')\" % current_institution\n            sqlite.execute(sql)\n            conn.commit()", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to update an institution table by comparing old and new institution records, sending notifications for discrepancies, and inserting new records."}
{"func_name": "Get8BIMProperty", "func_src_before": "static MagickBooleanType Get8BIMProperty(const Image *image,const char *key,\n  ExceptionInfo *exception)\n{\n  char\n    *attribute,\n    format[MagickPathExtent],\n    name[MagickPathExtent],\n    *resource;\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *info;\n\n  long\n    start,\n    stop;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    id,\n    sub_number;\n\n  /*\n    There are no newlines in path names, so it's safe as terminator.\n  */\n  profile=GetImageProfile(image,\"8bim\");\n  if (profile == (StringInfo *) NULL)\n    return(MagickFalse);\n  count=(ssize_t) sscanf(key,\"8BIM:%ld,%ld:%1024[^\\n]\\n%1024[^\\n]\",&start,&stop,\n    name,format);\n  if ((count != 2) && (count != 3) && (count != 4))\n    return(MagickFalse);\n  if (count < 4)\n    (void) CopyMagickString(format,\"SVG\",MagickPathExtent);\n  if (count < 3)\n    *name='\\0';\n  sub_number=1;\n  if (*name == '#')\n    sub_number=(ssize_t) StringToLong(&name[1]);\n  sub_number=MagickMax(sub_number,1L);\n  resource=(char *) NULL;\n  status=MagickFalse;\n  length=GetStringInfoLength(profile);\n  info=GetStringInfoDatum(profile);\n  while ((length > 0) && (status == MagickFalse))\n  {\n    if (ReadPropertyByte(&info,&length) != (unsigned char) '8')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'B')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'I')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'M')\n      continue;\n    id=(ssize_t) ReadPropertyMSBShort(&info,&length);\n    if (id < (ssize_t) start)\n      continue;\n    if (id > (ssize_t) stop)\n      continue;\n    if (resource != (char *) NULL)\n      resource=DestroyString(resource);\n    count=(ssize_t) ReadPropertyByte(&info,&length);\n    if ((count != 0) && ((size_t) count <= length))\n      {\n        resource=(char *) NULL;\n        if (~((size_t) count) >= (MagickPathExtent-1))\n          resource=(char *) AcquireQuantumMemory((size_t) count+\n            MagickPathExtent,sizeof(*resource));\n        if (resource != (char *) NULL)\n          {\n            for (i=0; i < (ssize_t) count; i++)\n              resource[i]=(char) ReadPropertyByte(&info,&length);\n            resource[count]='\\0';\n          }\n      }\n    if ((count & 0x01) == 0)\n      (void) ReadPropertyByte(&info,&length);\n    count=(ssize_t) ReadPropertyMSBLong(&info,&length);\n    if ((*name != '\\0') && (*name != '#'))\n      if ((resource == (char *) NULL) || (LocaleCompare(name,resource) != 0))\n        {\n          /*\n            No name match, scroll forward and try next.\n          */\n          info+=count;\n          length-=MagickMin(count,(ssize_t) length);\n          continue;\n        }\n    if ((*name == '#') && (sub_number != 1))\n      {\n        /*\n          No numbered match, scroll forward and try next.\n        */\n        sub_number--;\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        continue;\n      }\n    /*\n      We have the resource of interest.\n    */\n    attribute=(char *) NULL;\n    if (~((size_t) count) >= (MagickPathExtent-1))\n      attribute=(char *) AcquireQuantumMemory((size_t) count+MagickPathExtent,\n        sizeof(*attribute));\n    if (attribute != (char *) NULL)\n      {\n        (void) CopyMagickMemory(attribute,(char *) info,(size_t) count);\n        attribute[count]='\\0';\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        if ((id <= 1999) || (id >= 2999))\n          (void) SetImageProperty((Image *) image,key,(const char *)\n            attribute,exception);\n        else\n          {\n            char\n              *path;\n\n            if (LocaleCompare(format,\"svg\") == 0)\n              path=TraceSVGClippath((unsigned char *) attribute,(size_t) count,\n                image->columns,image->rows);\n            else\n              path=TracePSClippath((unsigned char *) attribute,(size_t) count);\n            (void) SetImageProperty((Image *) image,key,(const char *) path,\n              exception);\n            path=DestroyString(path);\n          }\n        attribute=DestroyString(attribute);\n        status=MagickTrue;\n      }\n  }\n  if (resource != (char *) NULL)\n    resource=DestroyString(resource);\n  return(status);\n}", "func_src_after": "static MagickBooleanType Get8BIMProperty(const Image *image,const char *key,\n  ExceptionInfo *exception)\n{\n  char\n    *attribute,\n    format[MagickPathExtent],\n    name[MagickPathExtent],\n    *resource;\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *info;\n\n  long\n    start,\n    stop;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    id,\n    sub_number;\n\n  /*\n    There are no newlines in path names, so it's safe as terminator.\n  */\n  profile=GetImageProfile(image,\"8bim\");\n  if (profile == (StringInfo *) NULL)\n    return(MagickFalse);\n  count=(ssize_t) sscanf(key,\"8BIM:%ld,%ld:%1024[^\\n]\\n%1024[^\\n]\",&start,&stop,\n    name,format);\n  if ((count != 2) && (count != 3) && (count != 4))\n    return(MagickFalse);\n  if (count < 4)\n    (void) CopyMagickString(format,\"SVG\",MagickPathExtent);\n  if (count < 3)\n    *name='\\0';\n  sub_number=1;\n  if (*name == '#')\n    sub_number=(ssize_t) StringToLong(&name[1]);\n  sub_number=MagickMax(sub_number,1L);\n  resource=(char *) NULL;\n  status=MagickFalse;\n  length=GetStringInfoLength(profile);\n  info=GetStringInfoDatum(profile);\n  while ((length > 0) && (status == MagickFalse))\n  {\n    if (ReadPropertyByte(&info,&length) != (unsigned char) '8')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'B')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'I')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'M')\n      continue;\n    id=(ssize_t) ReadPropertyMSBShort(&info,&length);\n    if (id < (ssize_t) start)\n      continue;\n    if (id > (ssize_t) stop)\n      continue;\n    if (resource != (char *) NULL)\n      resource=DestroyString(resource);\n    count=(ssize_t) ReadPropertyByte(&info,&length);\n    if ((count != 0) && ((size_t) count <= length))\n      {\n        resource=(char *) NULL;\n        if (~((size_t) count) >= (MagickPathExtent-1))\n          resource=(char *) AcquireQuantumMemory((size_t) count+\n            MagickPathExtent,sizeof(*resource));\n        if (resource != (char *) NULL)\n          {\n            for (i=0; i < (ssize_t) count; i++)\n              resource[i]=(char) ReadPropertyByte(&info,&length);\n            resource[count]='\\0';\n          }\n      }\n    if ((count & 0x01) == 0)\n      (void) ReadPropertyByte(&info,&length);\n    count=(ssize_t) ReadPropertyMSBLong(&info,&length);\n    if ((count < 0) || ((size_t) count > length))\n      {\n        length=0; \n        continue;\n      }\n    if ((*name != '\\0') && (*name != '#'))\n      if ((resource == (char *) NULL) || (LocaleCompare(name,resource) != 0))\n        {\n          /*\n            No name match, scroll forward and try next.\n          */\n          info+=count;\n          length-=MagickMin(count,(ssize_t) length);\n          continue;\n        }\n    if ((*name == '#') && (sub_number != 1))\n      {\n        /*\n          No numbered match, scroll forward and try next.\n        */\n        sub_number--;\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        continue;\n      }\n    /*\n      We have the resource of interest.\n    */\n    attribute=(char *) NULL;\n    if (~((size_t) count) >= (MagickPathExtent-1))\n      attribute=(char *) AcquireQuantumMemory((size_t) count+MagickPathExtent,\n        sizeof(*attribute));\n    if (attribute != (char *) NULL)\n      {\n        (void) CopyMagickMemory(attribute,(char *) info,(size_t) count);\n        attribute[count]='\\0';\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        if ((id <= 1999) || (id >= 2999))\n          (void) SetImageProperty((Image *) image,key,(const char *)\n            attribute,exception);\n        else\n          {\n            char\n              *path;\n\n            if (LocaleCompare(format,\"svg\") == 0)\n              path=TraceSVGClippath((unsigned char *) attribute,(size_t) count,\n                image->columns,image->rows);\n            else\n              path=TracePSClippath((unsigned char *) attribute,(size_t) count);\n            (void) SetImageProperty((Image *) image,key,(const char *) path,\n              exception);\n            path=DestroyString(path);\n          }\n        attribute=DestroyString(attribute);\n        status=MagickTrue;\n      }\n  }\n  if (resource != (char *) NULL)\n    resource=DestroyString(resource);\n  return(status);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/dd84447b63a71fa8c3f47071b09454efc667767b", "file_name": "MagickCore/property.c", "vul_type": "cwe-125", "description": "Write a C function named `Get8BIMProperty` that retrieves a property from an image's 8BIM profile based on a given key."}
{"func_name": "create_basename_core", "func_src_before": "def create_basename_core(basename):\n    try:\n        basename = basename.casefold()\n    except Exception:\n        basename = basename.lower()\n\n    basename = basename.replace(' ', '-')\n    basename = re.sub(r'<[^>]*>', r'', basename)\n    basename = re.sub(r'[^a-z0-9\\-]', r'', basename)\n    basename = re.sub(r'\\-\\-', r'-', basename)\n    basename = urllib.parse.quote_plus(basename)\n\n    return basename", "func_src_after": "def create_basename_core(basename):\n    try:\n        basename = basename.casefold()\n    except Exception:\n        basename = basename.lower()\n\n    basename = re.sub(r'[ \\./]', r'-', basename)\n    basename = re.sub(r'<[^>]*>', r'', basename)\n    basename = re.sub(r'[^a-z0-9\\-]', r'', basename)\n    basename = re.sub(r'\\-\\-', r'-', basename)\n    basename = urllib.parse.quote_plus(basename)\n\n    return basename", "commit_link": "github.com/syegulalp/mercury/commit/3f7c7442fa49aec37577dbdb47ce11a848e7bd03", "file_name": "MeTal/core/utils.py", "vul_type": "cwe-022", "description": "Write a Python function to sanitize and encode a string for use as a URL basename."}
{"func_name": "dex_parse_debug_item", "func_src_before": "static void dex_parse_debug_item(RBinFile *binfile, RBinDexObj *bin,\n\t\t\t\t  RBinDexClass *c, int MI, int MA, int paddr, int ins_size,\n\t\t\t\t  int insns_size, char *class_name, int regsz,\n\t\t\t\t  int debug_info_off) {\n\tstruct r_bin_t *rbin = binfile->rbin;\n\tconst ut8 *p4 = r_buf_get_at (binfile->buf, debug_info_off, NULL);\n\tconst ut8 *p4_end = p4 + binfile->buf->length - debug_info_off;\n\tut64 line_start;\n\tut64 parameters_size;\n\tut64 param_type_idx;\n\tut16 argReg = regsz - ins_size;\n\tut64 source_file_idx = c->source_file;\n\tRList *params, *debug_positions, *emitted_debug_locals = NULL; \n\tbool keep = true;\n\tif (argReg > regsz) {\n\t\treturn; // this return breaks tests\n\t}\n\tp4 = r_uleb128 (p4, p4_end - p4, &line_start);\n\tp4 = r_uleb128 (p4, p4_end - p4, &parameters_size);\n\t// TODO: check when we should use source_file\n\t// The state machine consists of five registers\n\tut32 address = 0;\n\tut32 line = line_start;\n\tif (!(debug_positions = r_list_newf ((RListFree)free))) {\n\t\treturn;\t\n\t}\n\tif (!(emitted_debug_locals = r_list_newf ((RListFree)free))) {\n\t\tr_list_free (debug_positions);\n\t\treturn;\n\t}\n\n\tstruct dex_debug_local_t debug_locals[regsz];\n\tmemset (debug_locals, 0, sizeof (struct dex_debug_local_t) * regsz);\n\tif (!(MA & 0x0008)) {\n\t\tdebug_locals[argReg].name = \"this\";\n\t\tdebug_locals[argReg].descriptor = r_str_newf(\"%s;\", class_name);\n\t\tdebug_locals[argReg].startAddress = 0;\n\t\tdebug_locals[argReg].signature = NULL;\n\t\tdebug_locals[argReg].live = true;\n\t\targReg++;\n\t}\n\tif (!(params = dex_method_signature2 (bin, MI))) {\n\t\tr_list_free (debug_positions);\n\t\tr_list_free (emitted_debug_locals);\n\t\treturn;\n\t}\n\n\tRListIter *iter = r_list_iterator (params);\n\tchar *name;\n\tchar *type;\n\tint reg;\n\n\tr_list_foreach (params, iter, type) {\n\t\tif ((argReg >= regsz) || !type || parameters_size <= 0) {\n\t\t\tr_list_free (debug_positions);\n\t\t\tr_list_free (params);\n\t\t\tr_list_free (emitted_debug_locals);\n\t\t\treturn;\n\t\t}\n\t\tp4 = r_uleb128 (p4, p4_end - p4, &param_type_idx); // read uleb128p1\n\t\tparam_type_idx -= 1;\n\t\tname = getstr (bin, param_type_idx);\n\t\treg = argReg;\n\t\tswitch (type[0]) {\n\t\tcase 'D':\n\t\tcase 'J':\n\t\t\targReg += 2;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\targReg += 1;\n\t\t\tbreak;\n\t\t}\n\t\tif (name) {\n\t\t\tdebug_locals[reg].name = name;\n\t\t\tdebug_locals[reg].descriptor = type;\n\t\t\tdebug_locals[reg].signature = NULL;\n\t\t\tdebug_locals[reg].startAddress = address;\n\t\t\tdebug_locals[reg].live = true;\n\t\t}\n\t\t--parameters_size;\n\t}\n\n\tut8 opcode = *(p4++) & 0xff;\n\twhile (keep) {\n\t\tswitch (opcode) {\n\t\tcase 0x0: // DBG_END_SEQUENCE\n\t\t\tkeep = false;\n\t\t\tbreak;\n\t\tcase 0x1: // DBG_ADVANCE_PC\n\t\t\t{\n\t\t\tut64 addr_diff;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &addr_diff);\n\t\t\taddress += addr_diff;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x2: // DBG_ADVANCE_LINE\n\t\t\t{\n\t\t\tst64 line_diff = r_sleb128 (&p4, p4_end);\n\t\t\tline += line_diff;\n\t\t\t}\n\t\t\tbreak;\t\n\t\tcase 0x3: // DBG_START_LOCAL\n\t\t\t{\n\t\t\tut64 register_num;\n\t\t\tut64 name_idx;\n\t\t\tut64 type_idx;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &register_num);\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &name_idx); \n\t\t\tname_idx -= 1;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &type_idx); \n\t\t\ttype_idx -= 1;\n\t\t\tif (register_num >= regsz) {\n\t\t\t\tr_list_free (debug_positions);\n\t\t\t\tr_list_free (params);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// Emit what was previously there, if anything\n\t\t\t// emitLocalCbIfLive\n\t\t\tif (debug_locals[register_num].live) {\n\t\t\t\tstruct dex_debug_local_t *local = malloc (\n\t\t\t\t\tsizeof (struct dex_debug_local_t));\n\t\t\t\tif (!local) {\n\t\t\t\t\tkeep = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tlocal->name = debug_locals[register_num].name;\n\t\t\t\tlocal->descriptor = debug_locals[register_num].descriptor;\n\t\t\t\tlocal->startAddress = debug_locals[register_num].startAddress;\n\t\t\t\tlocal->signature = debug_locals[register_num].signature;\n\t\t\t\tlocal->live = true;\n\t\t\t\tlocal->reg = register_num;\n\t\t\t\tlocal->endAddress = address;\n\t\t\t\tr_list_append (emitted_debug_locals, local);\n\t\t\t}\n\t\t\tdebug_locals[register_num].name = getstr (bin, name_idx);\n\t\t\tdebug_locals[register_num].descriptor = dex_type_descriptor (bin, type_idx);\n\t\t\tdebug_locals[register_num].startAddress = address;\n\t\t\tdebug_locals[register_num].signature = NULL;\n\t\t\tdebug_locals[register_num].live = true;\n\t\t\t//eprintf(\"DBG_START_LOCAL %x %x %x\\n\", register_num, name_idx, type_idx);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x4: //DBG_START_LOCAL_EXTENDED\n\t\t\t{\n\t\t\tut64 register_num;\n\t\t\tut64 name_idx;\n\t\t\tut64 type_idx;\n\t\t\tut64 sig_idx;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &register_num);\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &name_idx);\n\t\t\tname_idx -= 1;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &type_idx);\n\t\t\ttype_idx -= 1;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &sig_idx);\n\t\t\tsig_idx -= 1;\n\t\t\tif (register_num >= regsz) {\n\t\t\t\tr_list_free (debug_positions);\n\t\t\t\tr_list_free (params);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Emit what was previously there, if anything\n\t\t\t// emitLocalCbIfLive\n\t\t\tif (debug_locals[register_num].live) {\n\t\t\t\tstruct dex_debug_local_t *local = malloc (\n\t\t\t\t\tsizeof (struct dex_debug_local_t));\n\t\t\t\tif (!local) {\n\t\t\t\t\tkeep = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tlocal->name = debug_locals[register_num].name;\n\t\t\t\tlocal->descriptor = debug_locals[register_num].descriptor;\n\t\t\t\tlocal->startAddress = debug_locals[register_num].startAddress;\n\t\t\t\tlocal->signature = debug_locals[register_num].signature;\n\t\t\t\tlocal->live = true;\n\t\t\t\tlocal->reg = register_num;\n\t\t\t\tlocal->endAddress = address;\n\t\t\t\tr_list_append (emitted_debug_locals, local);\n\t\t\t}\n\n\t\t\tdebug_locals[register_num].name = getstr (bin, name_idx);\n\t\t\tdebug_locals[register_num].descriptor = dex_type_descriptor (bin, type_idx);\n\t\t\tdebug_locals[register_num].startAddress = address;\n\t\t\tdebug_locals[register_num].signature = getstr (bin, sig_idx);\n\t\t\tdebug_locals[register_num].live = true;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x5: // DBG_END_LOCAL\n\t\t\t{\n\t\t\tut64 register_num;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &register_num);\n\t\t\t// emitLocalCbIfLive\n\t\t\tif (debug_locals[register_num].live) {\n\t\t\t\tstruct dex_debug_local_t *local = malloc (\n\t\t\t\t\tsizeof (struct dex_debug_local_t));\n\t\t\t\tif (!local) {\n\t\t\t\t\tkeep = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tlocal->name = debug_locals[register_num].name;\n\t\t\t\tlocal->descriptor = debug_locals[register_num].descriptor;\n\t\t\t\tlocal->startAddress = debug_locals[register_num].startAddress;\n\t\t\t\tlocal->signature = debug_locals[register_num].signature;\n\t\t\t\tlocal->live = true;\n\t\t\t\tlocal->reg = register_num;\n\t\t\t\tlocal->endAddress = address;\n\t\t\t\tr_list_append (emitted_debug_locals, local);\n\t\t\t}\n\t\t\tdebug_locals[register_num].live = false;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x6: // DBG_RESTART_LOCAL\n\t\t\t{\n\t\t\tut64 register_num;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &register_num);\n\t\t\tif (!debug_locals[register_num].live) {\n\t\t\t\tdebug_locals[register_num].startAddress = address;\n\t\t\t\tdebug_locals[register_num].live = true;\n\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x7: //DBG_SET_PROLOGUE_END\n\t\t\tbreak;\n\t\tcase 0x8: //DBG_SET_PROLOGUE_BEGIN\n\t\t\tbreak;\n\t\tcase 0x9:\n\t\t\t{\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &source_file_idx);\n\t\t\tsource_file_idx--;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t{\n\t\t\tint adjusted_opcode = opcode - 0x0a;\n\t\t\taddress += (adjusted_opcode / 15);\n\t\t\tline += -4 + (adjusted_opcode % 15);\n\t\t\tstruct dex_debug_position_t *position =\n\t\t\t\tmalloc (sizeof (struct dex_debug_position_t));\n\t\t\tif (!position) {\n\t\t\t\tkeep = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tposition->source_file_idx = source_file_idx;\n\t\t\tposition->address = address;\n\t\t\tposition->line = line;\n\t\t\tr_list_append (debug_positions, position);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\topcode = *(p4++) & 0xff;\n\t}\n\n\tif (!binfile->sdb_addrinfo) {\n\t\tbinfile->sdb_addrinfo = sdb_new0 ();\n\t}\n\n\tchar *fileline;\n\tchar offset[64];\n\tchar *offset_ptr;\n\n\tRListIter *iter1;\n\tstruct dex_debug_position_t *pos;\n\tr_list_foreach (debug_positions, iter1, pos) {\n\t\tfileline = r_str_newf (\"%s|%\"PFMT64d, getstr (bin, pos->source_file_idx), pos->line);\n\t\toffset_ptr = sdb_itoa (pos->address + paddr, offset, 16);\n\t\tsdb_set (binfile->sdb_addrinfo, offset_ptr, fileline, 0);\n\t\tsdb_set (binfile->sdb_addrinfo, fileline, offset_ptr, 0);\n\t}\n\n\tif (!dexdump) {\n\t\tr_list_free (debug_positions);\n\t\tr_list_free (emitted_debug_locals);\n\t\tr_list_free (params);\n\t\treturn;\n\t}\n\n\tRListIter *iter2;\n\tstruct dex_debug_position_t *position;\n\n\trbin->cb_printf (\"      positions     :\\n\");\n\tr_list_foreach (debug_positions, iter2, position) {\n\t\trbin->cb_printf (\"        0x%04llx line=%llu\\n\",\n\t\t\t\t position->address, position->line);\n\t}\n\n\trbin->cb_printf (\"      locals        :\\n\");\n\n\tRListIter *iter3;\n\tstruct dex_debug_local_t *local;\n\tr_list_foreach (emitted_debug_locals, iter3, local) {\n\t\tif (local->signature) {\n\t\t\trbin->cb_printf (\n\t\t\t\t\"        0x%04x - 0x%04x reg=%d %s %s %s\\n\",\n\t\t\t\tlocal->startAddress, local->endAddress,\n\t\t\t\tlocal->reg, local->name, local->descriptor,\n\t\t\t\tlocal->signature);\n\t\t} else {\n\t\t\trbin->cb_printf (\n\t\t\t\t\"        0x%04x - 0x%04x reg=%d %s %s\\n\",\n\t\t\t\tlocal->startAddress, local->endAddress,\n\t\t\t\tlocal->reg, local->name, local->descriptor);\n\t\t}\n\t}\n\n\tfor (reg = 0; reg < regsz; reg++) {\n\t\tif (debug_locals[reg].live) {\n\t\t\tif (debug_locals[reg].signature) {\n\t\t\t\trbin->cb_printf (\n\t\t\t\t\t\"        0x%04x - 0x%04x reg=%d %s %s \"\n\t\t\t\t\t\"%s\\n\",\n\t\t\t\t\tdebug_locals[reg].startAddress,\n\t\t\t\t\tinsns_size, reg, debug_locals[reg].name,\n\t\t\t\t\tdebug_locals[reg].descriptor,\n\t\t\t\t\tdebug_locals[reg].signature);\n\t\t\t} else {\n\t\t\t\trbin->cb_printf (\n\t\t\t\t\t\"        0x%04x - 0x%04x reg=%d %s %s\"\n\t\t\t\t\t\"\\n\",\n\t\t\t\t\tdebug_locals[reg].startAddress,\n\t\t\t\t\tinsns_size, reg, debug_locals[reg].name,\n\t\t\t\t\tdebug_locals[reg].descriptor);\n\t\t\t}\n\t\t}\n\t}\n\tr_list_free (debug_positions);\n\tr_list_free (emitted_debug_locals);\n\tr_list_free (params);\n}", "func_src_after": "static void dex_parse_debug_item(RBinFile *binfile, RBinDexObj *bin,\n\t\t\t\t  RBinDexClass *c, int MI, int MA, int paddr, int ins_size,\n\t\t\t\t  int insns_size, char *class_name, int regsz,\n\t\t\t\t  int debug_info_off) {\n\tstruct r_bin_t *rbin = binfile->rbin;\n\tconst ut8 *p4 = r_buf_get_at (binfile->buf, debug_info_off, NULL);\n\tconst ut8 *p4_end = p4 + binfile->buf->length - debug_info_off;\n\tut64 line_start;\n\tut64 parameters_size;\n\tut64 param_type_idx;\n\tut16 argReg = regsz - ins_size;\n\tut64 source_file_idx = c->source_file;\n\tRList *params, *debug_positions, *emitted_debug_locals = NULL; \n\tbool keep = true;\n\tif (argReg > regsz) {\n\t\treturn; // this return breaks tests\n\t}\n\tp4 = r_uleb128 (p4, p4_end - p4, &line_start);\n\tp4 = r_uleb128 (p4, p4_end - p4, &parameters_size);\n\t// TODO: check when we should use source_file\n\t// The state machine consists of five registers\n\tut32 address = 0;\n\tut32 line = line_start;\n\tif (!(debug_positions = r_list_newf ((RListFree)free))) {\n\t\treturn;\t\n\t}\n\tif (!(emitted_debug_locals = r_list_newf ((RListFree)free))) {\n\t\tr_list_free (debug_positions);\n\t\treturn;\n\t}\n\n\tstruct dex_debug_local_t debug_locals[regsz];\n\tmemset (debug_locals, 0, sizeof (struct dex_debug_local_t) * regsz);\n\tif (!(MA & 0x0008)) {\n\t\tdebug_locals[argReg].name = \"this\";\n\t\tdebug_locals[argReg].descriptor = r_str_newf(\"%s;\", class_name);\n\t\tdebug_locals[argReg].startAddress = 0;\n\t\tdebug_locals[argReg].signature = NULL;\n\t\tdebug_locals[argReg].live = true;\n\t\targReg++;\n\t}\n\tif (!(params = dex_method_signature2 (bin, MI))) {\n\t\tr_list_free (debug_positions);\n\t\tr_list_free (emitted_debug_locals);\n\t\treturn;\n\t}\n\n\tRListIter *iter = r_list_iterator (params);\n\tchar *name;\n\tchar *type;\n\tint reg;\n\n\tr_list_foreach (params, iter, type) {\n\t\tif ((argReg >= regsz) || !type || parameters_size <= 0) {\n\t\t\tr_list_free (debug_positions);\n\t\t\tr_list_free (params);\n\t\t\tr_list_free (emitted_debug_locals);\n\t\t\treturn;\n\t\t}\n\t\tp4 = r_uleb128 (p4, p4_end - p4, &param_type_idx); // read uleb128p1\n\t\tparam_type_idx -= 1;\n\t\tname = getstr (bin, param_type_idx);\n\t\treg = argReg;\n\t\tswitch (type[0]) {\n\t\tcase 'D':\n\t\tcase 'J':\n\t\t\targReg += 2;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\targReg += 1;\n\t\t\tbreak;\n\t\t}\n\t\tif (name) {\n\t\t\tdebug_locals[reg].name = name;\n\t\t\tdebug_locals[reg].descriptor = type;\n\t\t\tdebug_locals[reg].signature = NULL;\n\t\t\tdebug_locals[reg].startAddress = address;\n\t\t\tdebug_locals[reg].live = true;\n\t\t}\n\t\t--parameters_size;\n\t}\n\n\tif (p4 <= 0) {\n\t\treturn;\n\t}\n\tut8 opcode = *(p4++) & 0xff;\n\twhile (keep) {\n\t\tswitch (opcode) {\n\t\tcase 0x0: // DBG_END_SEQUENCE\n\t\t\tkeep = false;\n\t\t\tbreak;\n\t\tcase 0x1: // DBG_ADVANCE_PC\n\t\t\t{\n\t\t\tut64 addr_diff;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &addr_diff);\n\t\t\taddress += addr_diff;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x2: // DBG_ADVANCE_LINE\n\t\t\t{\n\t\t\tst64 line_diff = r_sleb128 (&p4, p4_end);\n\t\t\tline += line_diff;\n\t\t\t}\n\t\t\tbreak;\t\n\t\tcase 0x3: // DBG_START_LOCAL\n\t\t\t{\n\t\t\tut64 register_num;\n\t\t\tut64 name_idx;\n\t\t\tut64 type_idx;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &register_num);\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &name_idx); \n\t\t\tname_idx -= 1;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &type_idx); \n\t\t\ttype_idx -= 1;\n\t\t\tif (register_num >= regsz) {\n\t\t\t\tr_list_free (debug_positions);\n\t\t\t\tr_list_free (params);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// Emit what was previously there, if anything\n\t\t\t// emitLocalCbIfLive\n\t\t\tif (debug_locals[register_num].live) {\n\t\t\t\tstruct dex_debug_local_t *local = malloc (\n\t\t\t\t\tsizeof (struct dex_debug_local_t));\n\t\t\t\tif (!local) {\n\t\t\t\t\tkeep = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tlocal->name = debug_locals[register_num].name;\n\t\t\t\tlocal->descriptor = debug_locals[register_num].descriptor;\n\t\t\t\tlocal->startAddress = debug_locals[register_num].startAddress;\n\t\t\t\tlocal->signature = debug_locals[register_num].signature;\n\t\t\t\tlocal->live = true;\n\t\t\t\tlocal->reg = register_num;\n\t\t\t\tlocal->endAddress = address;\n\t\t\t\tr_list_append (emitted_debug_locals, local);\n\t\t\t}\n\t\t\tdebug_locals[register_num].name = getstr (bin, name_idx);\n\t\t\tdebug_locals[register_num].descriptor = dex_type_descriptor (bin, type_idx);\n\t\t\tdebug_locals[register_num].startAddress = address;\n\t\t\tdebug_locals[register_num].signature = NULL;\n\t\t\tdebug_locals[register_num].live = true;\n\t\t\t//eprintf(\"DBG_START_LOCAL %x %x %x\\n\", register_num, name_idx, type_idx);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x4: //DBG_START_LOCAL_EXTENDED\n\t\t\t{\n\t\t\tut64 register_num;\n\t\t\tut64 name_idx;\n\t\t\tut64 type_idx;\n\t\t\tut64 sig_idx;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &register_num);\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &name_idx);\n\t\t\tname_idx -= 1;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &type_idx);\n\t\t\ttype_idx -= 1;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &sig_idx);\n\t\t\tsig_idx -= 1;\n\t\t\tif (register_num >= regsz) {\n\t\t\t\tr_list_free (debug_positions);\n\t\t\t\tr_list_free (params);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\t// Emit what was previously there, if anything\n\t\t\t// emitLocalCbIfLive\n\t\t\tif (debug_locals[register_num].live) {\n\t\t\t\tstruct dex_debug_local_t *local = malloc (\n\t\t\t\t\tsizeof (struct dex_debug_local_t));\n\t\t\t\tif (!local) {\n\t\t\t\t\tkeep = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tlocal->name = debug_locals[register_num].name;\n\t\t\t\tlocal->descriptor = debug_locals[register_num].descriptor;\n\t\t\t\tlocal->startAddress = debug_locals[register_num].startAddress;\n\t\t\t\tlocal->signature = debug_locals[register_num].signature;\n\t\t\t\tlocal->live = true;\n\t\t\t\tlocal->reg = register_num;\n\t\t\t\tlocal->endAddress = address;\n\t\t\t\tr_list_append (emitted_debug_locals, local);\n\t\t\t}\n\n\t\t\tdebug_locals[register_num].name = getstr (bin, name_idx);\n\t\t\tdebug_locals[register_num].descriptor = dex_type_descriptor (bin, type_idx);\n\t\t\tdebug_locals[register_num].startAddress = address;\n\t\t\tdebug_locals[register_num].signature = getstr (bin, sig_idx);\n\t\t\tdebug_locals[register_num].live = true;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x5: // DBG_END_LOCAL\n\t\t\t{\n\t\t\tut64 register_num;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &register_num);\n\t\t\t// emitLocalCbIfLive\n\t\t\tif (debug_locals[register_num].live) {\n\t\t\t\tstruct dex_debug_local_t *local = malloc (\n\t\t\t\t\tsizeof (struct dex_debug_local_t));\n\t\t\t\tif (!local) {\n\t\t\t\t\tkeep = false;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tlocal->name = debug_locals[register_num].name;\n\t\t\t\tlocal->descriptor = debug_locals[register_num].descriptor;\n\t\t\t\tlocal->startAddress = debug_locals[register_num].startAddress;\n\t\t\t\tlocal->signature = debug_locals[register_num].signature;\n\t\t\t\tlocal->live = true;\n\t\t\t\tlocal->reg = register_num;\n\t\t\t\tlocal->endAddress = address;\n\t\t\t\tr_list_append (emitted_debug_locals, local);\n\t\t\t}\n\t\t\tdebug_locals[register_num].live = false;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x6: // DBG_RESTART_LOCAL\n\t\t\t{\n\t\t\tut64 register_num;\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &register_num);\n\t\t\tif (!debug_locals[register_num].live) {\n\t\t\t\tdebug_locals[register_num].startAddress = address;\n\t\t\t\tdebug_locals[register_num].live = true;\n\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 0x7: //DBG_SET_PROLOGUE_END\n\t\t\tbreak;\n\t\tcase 0x8: //DBG_SET_PROLOGUE_BEGIN\n\t\t\tbreak;\n\t\tcase 0x9:\n\t\t\t{\n\t\t\tp4 = r_uleb128 (p4, p4_end - p4, &source_file_idx);\n\t\t\tsource_file_idx--;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\t{\n\t\t\tint adjusted_opcode = opcode - 0x0a;\n\t\t\taddress += (adjusted_opcode / 15);\n\t\t\tline += -4 + (adjusted_opcode % 15);\n\t\t\tstruct dex_debug_position_t *position =\n\t\t\t\tmalloc (sizeof (struct dex_debug_position_t));\n\t\t\tif (!position) {\n\t\t\t\tkeep = false;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tposition->source_file_idx = source_file_idx;\n\t\t\tposition->address = address;\n\t\t\tposition->line = line;\n\t\t\tr_list_append (debug_positions, position);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\topcode = *(p4++) & 0xff;\n\t}\n\n\tif (!binfile->sdb_addrinfo) {\n\t\tbinfile->sdb_addrinfo = sdb_new0 ();\n\t}\n\n\tchar *fileline;\n\tchar offset[64];\n\tchar *offset_ptr;\n\n\tRListIter *iter1;\n\tstruct dex_debug_position_t *pos;\n\tr_list_foreach (debug_positions, iter1, pos) {\n\t\tfileline = r_str_newf (\"%s|%\"PFMT64d, getstr (bin, pos->source_file_idx), pos->line);\n\t\toffset_ptr = sdb_itoa (pos->address + paddr, offset, 16);\n\t\tsdb_set (binfile->sdb_addrinfo, offset_ptr, fileline, 0);\n\t\tsdb_set (binfile->sdb_addrinfo, fileline, offset_ptr, 0);\n\t}\n\n\tif (!dexdump) {\n\t\tr_list_free (debug_positions);\n\t\tr_list_free (emitted_debug_locals);\n\t\tr_list_free (params);\n\t\treturn;\n\t}\n\n\tRListIter *iter2;\n\tstruct dex_debug_position_t *position;\n\n\trbin->cb_printf (\"      positions     :\\n\");\n\tr_list_foreach (debug_positions, iter2, position) {\n\t\trbin->cb_printf (\"        0x%04llx line=%llu\\n\",\n\t\t\t\t position->address, position->line);\n\t}\n\n\trbin->cb_printf (\"      locals        :\\n\");\n\n\tRListIter *iter3;\n\tstruct dex_debug_local_t *local;\n\tr_list_foreach (emitted_debug_locals, iter3, local) {\n\t\tif (local->signature) {\n\t\t\trbin->cb_printf (\n\t\t\t\t\"        0x%04x - 0x%04x reg=%d %s %s %s\\n\",\n\t\t\t\tlocal->startAddress, local->endAddress,\n\t\t\t\tlocal->reg, local->name, local->descriptor,\n\t\t\t\tlocal->signature);\n\t\t} else {\n\t\t\trbin->cb_printf (\n\t\t\t\t\"        0x%04x - 0x%04x reg=%d %s %s\\n\",\n\t\t\t\tlocal->startAddress, local->endAddress,\n\t\t\t\tlocal->reg, local->name, local->descriptor);\n\t\t}\n\t}\n\n\tfor (reg = 0; reg < regsz; reg++) {\n\t\tif (debug_locals[reg].live) {\n\t\t\tif (debug_locals[reg].signature) {\n\t\t\t\trbin->cb_printf (\n\t\t\t\t\t\"        0x%04x - 0x%04x reg=%d %s %s \"\n\t\t\t\t\t\"%s\\n\",\n\t\t\t\t\tdebug_locals[reg].startAddress,\n\t\t\t\t\tinsns_size, reg, debug_locals[reg].name,\n\t\t\t\t\tdebug_locals[reg].descriptor,\n\t\t\t\t\tdebug_locals[reg].signature);\n\t\t\t} else {\n\t\t\t\trbin->cb_printf (\n\t\t\t\t\t\"        0x%04x - 0x%04x reg=%d %s %s\"\n\t\t\t\t\t\"\\n\",\n\t\t\t\t\tdebug_locals[reg].startAddress,\n\t\t\t\t\tinsns_size, reg, debug_locals[reg].name,\n\t\t\t\t\tdebug_locals[reg].descriptor);\n\t\t\t}\n\t\t}\n\t}\n\tr_list_free (debug_positions);\n\tr_list_free (emitted_debug_locals);\n\tr_list_free (params);\n}", "commit_link": "github.com/radare/radare2/commit/252afb1cff9676f3ae1f341a28448bf2c8b6e308", "file_name": "libr/bin/p/bin_dex.c", "vul_type": "cwe-476", "description": "Write a C function to parse debug information from a DEX file in C."}
{"func_name": "_gd2GetHeader", "func_src_before": "static int _gd2GetHeader(gdIOCtxPtr in, int *sx, int *sy, int *cs, int *vers, int *fmt, int *ncx, int *ncy, t_chunk_info ** chunkIdx)\n{\n\tint i;\n\tint ch;\n\tchar id[5];\n\tt_chunk_info *cidx;\n\tint sidx;\n\tint nc;\n\n\tGD2_DBG(php_gd_error(\"Reading gd2 header info\"));\n\n\tfor (i = 0; i < 4; i++) {\n\t\tch = gdGetC(in);\n\t\tif (ch == EOF) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tid[i] = ch;\n\t}\n\tid[4] = 0;\n\n\tGD2_DBG(php_gd_error(\"Got file code: %s\", id));\n\n\t/* Equiv. of 'magick'.  */\n\tif (strcmp(id, GD2_ID) != 0) {\n\t\tGD2_DBG(php_gd_error(\"Not a valid gd2 file\"));\n\t\tgoto fail1;\n\t}\n\n\t/* Version */\n\tif (gdGetWord(vers, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Version: %d\", *vers));\n\n\tif ((*vers != 1) && (*vers != 2)) {\n\t\tGD2_DBG(php_gd_error(\"Bad version: %d\", *vers));\n\t\tgoto fail1;\n\t}\n\n\t/* Image Size */\n\tif (!gdGetWord(sx, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get x-size\"));\n\t\tgoto fail1;\n\t}\n\tif (!gdGetWord(sy, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get y-size\"));\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Image is %dx%d\", *sx, *sy));\n\n\t/* Chunk Size (pixels, not bytes!) */\n\tif (gdGetWord(cs, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"ChunkSize: %d\", *cs));\n\n\tif ((*cs < GD2_CHUNKSIZE_MIN) || (*cs > GD2_CHUNKSIZE_MAX)) {\n\t\tGD2_DBG(php_gd_error(\"Bad chunk size: %d\", *cs));\n\t\tgoto fail1;\n\t}\n\n\t/* Data Format */\n\tif (gdGetWord(fmt, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Format: %d\", *fmt));\n\n\tif ((*fmt != GD2_FMT_RAW) && (*fmt != GD2_FMT_COMPRESSED) && (*fmt != GD2_FMT_TRUECOLOR_RAW) && (*fmt != GD2_FMT_TRUECOLOR_COMPRESSED)) {\n\t\tGD2_DBG(php_gd_error(\"Bad data format: %d\", *fmt));\n\t\tgoto fail1;\n\t}\n\n\t/* # of chunks wide */\n\tif (gdGetWord(ncx, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks Wide\", *ncx));\n\n\t/* # of chunks high */\n\tif (gdGetWord(ncy, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks vertically\", *ncy));\n\n\tif (gd2_compressed(*fmt)) {\n\t\tnc = (*ncx) * (*ncy);\n\t\tGD2_DBG(php_gd_error(\"Reading %d chunk index entries\", nc));\n\t\tsidx = sizeof(t_chunk_info) * nc;\n\t\tif (sidx <= 0) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tcidx = gdCalloc(sidx, 1);\n\t\tfor (i = 0; i < nc; i++) {\n\t\t\tif (gdGetInt(&cidx[i].offset, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (gdGetInt(&cidx[i].size, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (cidx[i].offset < 0 || cidx[i].size < 0) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t}\n\t\t*chunkIdx = cidx;\n\t}\n\n\tGD2_DBG(php_gd_error(\"gd2 header complete\"));\n\n\treturn 1;\n\nfail1:\n\treturn 0;\n}", "func_src_after": "static int _gd2GetHeader(gdIOCtxPtr in, int *sx, int *sy, int *cs, int *vers, int *fmt, int *ncx, int *ncy, t_chunk_info ** chunkIdx)\n{\n\tint i;\n\tint ch;\n\tchar id[5];\n\tt_chunk_info *cidx;\n\tint sidx;\n\tint nc;\n\n\tGD2_DBG(php_gd_error(\"Reading gd2 header info\"));\n\n\tfor (i = 0; i < 4; i++) {\n\t\tch = gdGetC(in);\n\t\tif (ch == EOF) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tid[i] = ch;\n\t}\n\tid[4] = 0;\n\n\tGD2_DBG(php_gd_error(\"Got file code: %s\", id));\n\n\t/* Equiv. of 'magick'.  */\n\tif (strcmp(id, GD2_ID) != 0) {\n\t\tGD2_DBG(php_gd_error(\"Not a valid gd2 file\"));\n\t\tgoto fail1;\n\t}\n\n\t/* Version */\n\tif (gdGetWord(vers, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Version: %d\", *vers));\n\n\tif ((*vers != 1) && (*vers != 2)) {\n\t\tGD2_DBG(php_gd_error(\"Bad version: %d\", *vers));\n\t\tgoto fail1;\n\t}\n\n\t/* Image Size */\n\tif (!gdGetWord(sx, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get x-size\"));\n\t\tgoto fail1;\n\t}\n\tif (!gdGetWord(sy, in)) {\n\t\tGD2_DBG(php_gd_error(\"Could not get y-size\"));\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Image is %dx%d\", *sx, *sy));\n\n\t/* Chunk Size (pixels, not bytes!) */\n\tif (gdGetWord(cs, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"ChunkSize: %d\", *cs));\n\n\tif ((*cs < GD2_CHUNKSIZE_MIN) || (*cs > GD2_CHUNKSIZE_MAX)) {\n\t\tGD2_DBG(php_gd_error(\"Bad chunk size: %d\", *cs));\n\t\tgoto fail1;\n\t}\n\n\t/* Data Format */\n\tif (gdGetWord(fmt, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"Format: %d\", *fmt));\n\n\tif ((*fmt != GD2_FMT_RAW) && (*fmt != GD2_FMT_COMPRESSED) && (*fmt != GD2_FMT_TRUECOLOR_RAW) && (*fmt != GD2_FMT_TRUECOLOR_COMPRESSED)) {\n\t\tGD2_DBG(php_gd_error(\"Bad data format: %d\", *fmt));\n\t\tgoto fail1;\n\t}\n\n\t/* # of chunks wide */\n\tif (gdGetWord(ncx, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks Wide\", *ncx));\n\n\t/* # of chunks high */\n\tif (gdGetWord(ncy, in) != 1) {\n\t\tgoto fail1;\n\t}\n\tGD2_DBG(php_gd_error(\"%d Chunks vertically\", *ncy));\n\n\tif (gd2_compressed(*fmt)) {\n\t\tnc = (*ncx) * (*ncy);\n\t\tGD2_DBG(php_gd_error(\"Reading %d chunk index entries\", nc));\n\t\tif (overflow2(sidx, nc)) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tsidx = sizeof(t_chunk_info) * nc;\n\t\tif (sidx <= 0) {\n\t\t\tgoto fail1;\n\t\t}\n\t\tcidx = gdCalloc(sidx, 1);\n\t\tif (cidx == NULL) {\n\t\t\tgoto fail1;\n\t\t}\n\n\t\tfor (i = 0; i < nc; i++) {\n\t\t\tif (gdGetInt(&cidx[i].offset, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (gdGetInt(&cidx[i].size, in) != 1) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t\tif (cidx[i].offset < 0 || cidx[i].size < 0) {\n\t\t\t\tgdFree(cidx);\n\t\t\t\tgoto fail1;\n\t\t\t}\n\t\t}\n\t\t*chunkIdx = cidx;\n\t}\n\n\tGD2_DBG(php_gd_error(\"gd2 header complete\"));\n\n\treturn 1;\n\nfail1:\n\treturn 0;\n}", "commit_link": "github.com/php/php-src/commit/7722455726bec8c53458a32851d2a87982cf0eac", "file_name": "ext/gd/libgd/gd_gd2.c", "vul_type": "cwe-190", "description": "Write a C function to read and validate the header of a GD2 image file."}
{"func_name": "avcodec_open2", "func_src_before": "int attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    int codec_init_ok = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ff_lock_avcodec(avctx, codec);\n\n    avctx->internal = av_mallocz(sizeof(*avctx->internal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->compat_decode_frame = av_frame_alloc();\n    if (!avctx->internal->compat_decode_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->ds.in_pkt = av_packet_alloc();\n    if (!avctx->internal->ds.in_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->last_pkt_props = av_packet_alloc();\n    if (!avctx->internal->last_pkt_props) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->skip_samples_multiplier = 1;\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d\\n\", avctx->channels);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        ret = ff_decode_bsfs_init(avctx);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", avctx->bit_rate, avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3LL / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->sw_pix_fmt != AV_PIX_FMT_NONE &&\n                avctx->sw_pix_fmt != frames_ctx->sw_format) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.sw_pix_fmt (%s) \"\n                       \"and AVHWFramesContext.sw_format (%s)\\n\",\n                       av_get_pix_fmt_name(avctx->sw_pix_fmt),\n                       av_get_pix_fmt_name(frames_ctx->sw_format));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            avctx->sw_pix_fmt = frames_ctx->sw_format;\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n        codec_init_ok = 1;\n    }\n\n    ret=0;\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->bits_per_coded_sample < 0) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec &&\n        (codec_init_ok ||\n         (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP)))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->compat_decode_frame);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_packet_free(&avctx->internal->last_pkt_props);\n\n        av_packet_free(&avctx->internal->ds.in_pkt);\n        ff_decode_bsfs_uninit(avctx);\n\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}", "func_src_after": "int attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    int codec_init_ok = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ff_lock_avcodec(avctx, codec);\n\n    avctx->internal = av_mallocz(sizeof(*avctx->internal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->compat_decode_frame = av_frame_alloc();\n    if (!avctx->internal->compat_decode_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->ds.in_pkt = av_packet_alloc();\n    if (!avctx->internal->ds.in_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->last_pkt_props = av_packet_alloc();\n    if (!avctx->internal->last_pkt_props) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->skip_samples_multiplier = 1;\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d\\n\", avctx->channels);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        ret = ff_decode_bsfs_init(avctx);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", avctx->bit_rate, avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3LL / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->sw_pix_fmt != AV_PIX_FMT_NONE &&\n                avctx->sw_pix_fmt != frames_ctx->sw_format) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.sw_pix_fmt (%s) \"\n                       \"and AVHWFramesContext.sw_format (%s)\\n\",\n                       av_get_pix_fmt_name(avctx->sw_pix_fmt),\n                       av_get_pix_fmt_name(frames_ctx->sw_format));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            avctx->sw_pix_fmt = frames_ctx->sw_format;\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n        codec_init_ok = 1;\n    }\n\n    ret=0;\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->bits_per_coded_sample < 0) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec && avctx->codec->close &&\n        (codec_init_ok ||\n         (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP)))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->compat_decode_frame);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_packet_free(&avctx->internal->last_pkt_props);\n\n        av_packet_free(&avctx->internal->ds.in_pkt);\n        ff_decode_bsfs_uninit(avctx);\n\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/8df6884832ec413cf032dfaa45c23b1c7876670c", "file_name": "libavcodec/utils.c", "vul_type": "cwe-476", "description": "Write a C function in FFmpeg to open a codec context with given options."}
{"func_name": "on_save", "func_src_before": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            f\"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values ('{self.ip_address}', '{self.user_agent}', '{self.referrer}', '{self.full_path}', '{self.visit_time}');\")\n        connection.commit()\n        connection.close()\n        return 0", "func_src_after": "    def on_save(self):\n        connection = get_connection()\n        cursor = connection.cursor()\n        cursor.execute(\n            \"insert into visitors (ip_address, user_agent, referrer, full_path, visit_time) values (%s, %s, %s, %s, %s);\",\n            (str(self.ip_address), str(self.user_agent), str(self.referrer), str(self.full_path), self.visit_time))\n        connection.commit()\n        connection.close()\n        return 0", "commit_link": "github.com/onewyoming/onewyoming/commit/54fc7b076fda2de74eeb55e6b75b28e09ef231c2", "file_name": "experimental/python/buford/model/visitor.py", "vul_type": "cwe-089", "description": "Write a Python function to save a visitor's details to a database using SQL insert query."}
{"func_name": "hci_uart_set_proto", "func_src_before": "static int hci_uart_set_proto(struct hci_uart *hu, int id)\n{\n\tconst struct hci_uart_proto *p;\n\tint err;\n\n\tp = hci_uart_get_proto(id);\n\tif (!p)\n\t\treturn -EPROTONOSUPPORT;\n\n\thu->proto = p;\n\n\terr = hci_uart_register_dev(hu);\n\tif (err) {\n\t\treturn err;\n\t}\n\n\tset_bit(HCI_UART_PROTO_READY, &hu->flags);\n\treturn 0;\n}", "func_src_after": "static int hci_uart_set_proto(struct hci_uart *hu, int id)\n{\n\tconst struct hci_uart_proto *p;\n\tint err;\n\n\tp = hci_uart_get_proto(id);\n\tif (!p)\n\t\treturn -EPROTONOSUPPORT;\n\n\thu->proto = p;\n\tset_bit(HCI_UART_PROTO_READY, &hu->flags);\n\n\terr = hci_uart_register_dev(hu);\n\tif (err) {\n\t\tclear_bit(HCI_UART_PROTO_READY, &hu->flags);\n\t\treturn err;\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/56897b217a1d0a91c9920cb418d6b3fe922f590a", "file_name": "drivers/bluetooth/hci_ldisc.c", "vul_type": "cwe-416", "description": "Write a C function named `hci_uart_set_proto` that assigns a UART protocol to a device and handles registration, returning an error code if the protocol is unsupported or registration fails."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = safe_md(self.object.content)\n\n        return context", "func_src_after": "    def get_context_data(self, **kwargs):\n        context = super().get_context_data(**kwargs)\n        context['comments'] = self.object.comment_set.all().order_by('-time')\n        context['form'] = self.get_form()\n        context['md'] = markdown(self.object.content,\n                                 extensions=[\n                                     'markdown.extensions.extra',\n                                     'markdown.extensions.codehilite',\n                                     'markdown.extensions.toc',\n                                 ])\n\n        return context", "commit_link": "github.com/Cheng-mq1216/production-practice/commit/333dc34f5feada55d1f6ff1255949ca00dec0f9c", "file_name": "app/Index/views.py", "vul_type": "cwe-079", "description": "Write a Python function to enhance the context data with comments, a form, and processed markdown content for a web page."}
{"func_name": "delete_resultSet", "func_src_before": "    def delete_resultSet(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = \"DELETE FROM %s WHERE identifier = $1;\" % (self.table)\n        self._query(query, sid)", "func_src_after": "    def delete_resultSet(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = \"DELETE FROM %s WHERE identifier = '%s';\" % (self.table, sid)\n        self._query(query)", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function to delete a record from a database table by ID, optionally normalizing the ID before deletion."}
{"func_name": "HPHP::JSON_parser", "func_src_before": "bool JSON_parser(Variant &z, const char *p, int length, bool const assoc,\n                 int depth, int64_t options) {\n  // No GC safepoints during JSON parsing, please. Code is not re-entrant.\n  NoHandleSurpriseScope no_surprise(SafepointFlags);\n\n  json_parser *json = s_json_parser.get(); /* the parser state */\n  // Clear and reuse the thread-local string buffers. They are only freed if\n  // they exceed kMaxPersistentStringBufferCapacity at exit or if the thread\n  // is explicitly flushed (e.g., due to being idle).\n  json->initSb(length);\n  SCOPE_EXIT {\n    constexpr int kMaxPersistentStringBufferCapacity = 256 * 1024;\n    if (json->sb_cap > kMaxPersistentStringBufferCapacity) json->flushSb();\n  };\n  // SimpleParser only handles the most common set of options. Also, only use it\n  // if its array nesting depth check is *more* restrictive than what the user\n  // asks for, to ensure that the precise semantics of the general case is\n  // applied for all nesting overflows.\n  if (assoc &&\n      options == (options & (k_JSON_FB_LOOSE |\n                             k_JSON_FB_DARRAYS |\n                             k_JSON_FB_DARRAYS_AND_VARRAYS |\n                             k_JSON_FB_HACK_ARRAYS |\n                             k_JSON_FB_THRIFT_SIMPLE_JSON |\n                             k_JSON_FB_LEGACY_HACK_ARRAYS)) &&\n      depth >= SimpleParser::kMaxArrayDepth &&\n      length <= RuntimeOption::EvalSimpleJsonMaxLength &&\n      SimpleParser::TryParse(p, length, json->tl_buffer.tv, z,\n                             get_container_type_from_options(options),\n                             options & k_JSON_FB_THRIFT_SIMPLE_JSON)) {\n    return true;\n  }\n\n  int b;  /* the next character */\n  int c;  /* the next character class */\n  int s;  /* the next state */\n  int state = 0;\n\n  /*<fb>*/\n  bool const loose = options & k_JSON_FB_LOOSE;\n  JSONContainerType const container_type =\n    get_container_type_from_options(options);\n  int qchr = 0;\n  int8_t const *byte_class;\n  int8_t const (*next_state_table)[32];\n  if (loose) {\n    byte_class = loose_ascii_class;\n    next_state_table = loose_state_transition_table;\n  } else {\n    byte_class = ascii_class;\n    next_state_table = state_transition_table;\n  }\n  /*</fb>*/\n\n  UncheckedBuffer *buf = &json->sb_buf;\n  UncheckedBuffer *key = &json->sb_key;\n\n  DataType type = kInvalidDataType;\n  unsigned short escaped_bytes = 0;\n\n  auto reset_type = [&] { type = kInvalidDataType; };\n\n  json->depth = depth;\n  // Since the stack is maintainined on a per request basis, for performance\n  // reasons, it only makes sense to expand if necessary and cycles are wasted\n  // contracting. Calls with a depth other than default should be rare.\n  if (depth > json->stack.size()) {\n    json->stack.resize(depth);\n  }\n  SCOPE_EXIT {\n    if (json->stack.empty()) return;\n    for (int i = 0; i <= json->mark; i++) {\n      json->stack[i].key.reset();\n      json->stack[i].val.unset();\n    }\n    json->mark = -1;\n  };\n\n  json->mark = json->top = -1;\n  push(json, Mode::DONE);\n\n  UTF8To16Decoder decoder(p, length, loose);\n  for (;;) {\n    b = decoder.decode();\n    // Fast-case most common transition: append a simple string character.\n    if (state == 3 && type == KindOfString) {\n      while (b != '\\\"' &&  b != '\\\\' && b != '\\'' && b <= 127 && b >= ' ') {\n        buf->append((char)b);\n        b = decoder.decode();\n      }\n    }\n    if (b == UTF8_END) break; // UTF-8 decoding finishes successfully.\n    if (b == UTF8_ERROR) {\n      s_json_parser->error_code = JSON_ERROR_UTF8;\n      return false;\n    }\n    assertx(b >= 0);\n\n    if ((b & 127) == b) {\n      /*<fb>*/\n      c = byte_class[b];\n      /*</fb>*/\n      if (c <= S_ERR) {\n        s_json_parser->error_code = JSON_ERROR_CTRL_CHAR;\n        return false;\n      }\n    } else {\n      c = S_ETC;\n    }\n    /*\n      Get the next state from the transition table.\n    */\n\n    /*<fb>*/\n    s = next_state_table[state][c];\n\n    if (s == -4) {\n      if (b != qchr) {\n        s = 3;\n      } else {\n        qchr = 0;\n      }\n    }\n    /*</fb>*/\n\n    if (s < 0) {\n      /*\n        Perform one of the predefined actions.\n      */\n      switch (s) {\n        /*\n          empty }\n        */\n      case -9:\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key, assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::KEY)) {\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          {\n        */\n      case -8:\n        if (!push(json, Mode::KEY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n\n        state = 1;\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            // stable_maps is meaningless\n            top = req::make<c_Map>();\n          } else {\n          /*</fb>*/\n            if (!assoc) {\n              top = SystemLib::AllocStdClassObject();\n            /* <fb> */\n            } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n              top = Array::CreateDict();\n            } else if (container_type == JSONContainerType::DARRAYS ||\n                       container_type == JSONContainerType::DARRAYS_AND_VARRAYS)\n            {\n              top = Array::CreateDArray();\n            /* </fb> */\n            } else if (\n              container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n              auto arr = staticEmptyDictArray()->copy();\n              arr->setLegacyArray(true);\n              top = arr;\n            } else {\n              top = Array::CreateDArray();\n            }\n          /*<fb>*/\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          }\n        */\n      case -7:\n        /*** BEGIN Facebook: json_utf8_loose ***/\n        /*\n          If this is a trailing comma in an object definition,\n          we're in Mode::KEY. In that case, throw that off the\n          stack and restore Mode::OBJECT so that we pretend the\n          trailing comma just didn't happen.\n        */\n        if (loose) {\n          if (pop(json, Mode::KEY)) {\n            push(json, Mode::OBJECT);\n          }\n        }\n        /*** END Facebook: json_utf8_loose ***/\n\n        if (type != kInvalidDataType &&\n            json->stack[json->top].mode == Mode::OBJECT) {\n          Variant mval;\n          json_create_zval(mval, *buf, type, options);\n          Variant &top = json->stack[json->top].val;\n          object_set(json, top, copy_and_clear(*key),\n                     mval, assoc, container_type);\n          buf->clear();\n          reset_type();\n        }\n\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key,\n            assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::OBJECT)) {\n          s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          [\n        */\n      case -6:\n        if (!push(json, Mode::ARRAY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n        state = 2;\n\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            top = req::make<c_Vector>();\n          } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n            top = Array::CreateVec();\n          } else if (container_type == JSONContainerType::DARRAYS_AND_VARRAYS) {\n            top = Array::CreateVArray();\n          } else if (container_type == JSONContainerType::DARRAYS) {\n            top = Array::CreateDArray();\n          } else if (container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n            auto arr = staticEmptyVecArray()->copy();\n            arr->setLegacyArray(true);\n            top = arr;\n          } else {\n            top = Array::CreateDArray();\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          ]\n        */\n      case -5:\n        {\n          if (type != kInvalidDataType &&\n               json->stack[json->top].mode == Mode::ARRAY) {\n            Variant mval;\n            json_create_zval(mval, *buf, type, options);\n            auto& top = json->stack[json->top].val;\n            if (container_type == JSONContainerType::COLLECTIONS) {\n              collections::append(top.getObjectData(), mval.asTypedValue());\n            } else {\n              top.asArrRef().append(mval);\n            }\n            buf->clear();\n            reset_type();\n          }\n\n          /*<fb>*/\n          if (json->top == 1) z = json->stack[json->top].val;\n          else {\n          /*</fb>*/\n            attach_zval(json, json->stack[json->top].key, assoc,\n              container_type);\n          /*<fb>*/\n          }\n          /*</fb>*/\n          if (!pop(json, Mode::ARRAY)) {\n            s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n            return false;\n          }\n          state = 9;\n        }\n        break;\n        /*\n          \"\n        */\n      case -4:\n        switch (json->stack[json->top].mode) {\n        case Mode::KEY:\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          break;\n        case Mode::ARRAY:\n        case Mode::OBJECT:\n          state = 9;\n          break;\n        case Mode::DONE:\n          if (type == KindOfString) {\n            z = copy_and_clear(*buf);\n            state = 9;\n            break;\n          }\n          /* fall through if not KindOfString */\n        default:\n          s_json_parser->error_code = JSON_ERROR_SYNTAX;\n          return false;\n        }\n        break;\n        /*\n          ,\n        */\n      case -3:\n        {\n          Variant mval;\n          if (type != kInvalidDataType &&\n              (json->stack[json->top].mode == Mode::OBJECT ||\n               json->stack[json->top].mode == Mode::ARRAY)) {\n            json_create_zval(mval, *buf, type, options);\n          }\n\n          switch (json->stack[json->top].mode) {\n          case Mode::OBJECT:\n            if (pop(json, Mode::OBJECT) &&\n                push(json, Mode::KEY)) {\n              if (type != kInvalidDataType) {\n                Variant &top = json->stack[json->top].val;\n                object_set(\n                  json,\n                  top,\n                  copy_and_clear(*key),\n                  mval,\n                  assoc,\n                  container_type\n                );\n              }\n              state = 29;\n            }\n            break;\n          case Mode::ARRAY:\n            if (type != kInvalidDataType) {\n              auto& top = json->stack[json->top].val;\n              if (container_type == JSONContainerType::COLLECTIONS) {\n                collections::append(top.getObjectData(), mval.asTypedValue());\n              } else {\n                top.asArrRef().append(mval);\n              }\n            }\n            state = 28;\n            break;\n          default:\n            s_json_parser->error_code = JSON_ERROR_SYNTAX;\n            return false;\n          }\n          buf->clear();\n          reset_type();\n          check_non_safepoint_surprise();\n        }\n        break;\n\n        /*<fb>*/\n        /*\n          : (after unquoted string)\n        */\n      case -10:\n        if (json->stack[json->top].mode == Mode::KEY) {\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          s = -2;\n        } else {\n          s = 3;\n          break;\n        }\n        /*</fb>*/\n\n        /*\n          :\n        */\n      case -2:\n        if (pop(json, Mode::KEY) && push(json, Mode::OBJECT)) {\n          state = 28;\n          break;\n        }\n        /*\n          syntax error\n        */\n      case -1:\n        s_json_parser->error_code = JSON_ERROR_SYNTAX;\n        return false;\n      }\n    } else {\n      /*\n        Change the state and iterate.\n      */\n      bool is_tsimplejson = options & k_JSON_FB_THRIFT_SIMPLE_JSON;\n      if (type == KindOfString) {\n        if (/*<fb>*/(/*</fb>*/s == 3/*<fb>*/ || s == 30)/*</fb>*/ &&\n            state != 8) {\n          if (state != 4) {\n            utf16_to_utf8(*buf, b);\n          } else {\n            switch (b) {\n            case 'b': buf->append('\\b'); break;\n            case 't': buf->append('\\t'); break;\n            case 'n': buf->append('\\n'); break;\n            case 'f': buf->append('\\f'); break;\n            case 'r': buf->append('\\r'); break;\n            default:\n              utf16_to_utf8(*buf, b);\n              break;\n            }\n          }\n        } else if (s == 6) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n            escaped_bytes = 0;\n          } else {\n            escaped_bytes = dehexchar(b) << 12;\n          }\n        } else if (s == 7) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n          } else {\n            escaped_bytes += dehexchar(b) << 8;\n          }\n        } else if (s == 8) {\n          escaped_bytes += dehexchar(b) << 4;\n        } else if (s == 3 && state == 8) {\n          escaped_bytes += dehexchar(b);\n          if (UNLIKELY(is_tsimplejson)) {\n            buf->append((char)escaped_bytes);\n          } else {\n            utf16_to_utf8(*buf, escaped_bytes);\n          }\n        }\n      } else if ((type == kInvalidDataType || type == KindOfNull) &&\n                 (c == S_DIG || c == S_ZER)) {\n        type = KindOfInt64;\n        buf->append((char)b);\n      } else if (type == KindOfInt64 && s == 24) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64) &&\n                 c == S_DOT) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if (type != KindOfString && c == S_QUO) {\n        type = KindOfString;\n        /*<fb>*/qchr = b;/*</fb>*/\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64 || type == KindOfDouble) &&\n                 ((state == 12 && s == 9) ||\n                  (state == 16 && s == 9))) {\n        type = KindOfBoolean;\n      } else if (type == kInvalidDataType && state == 19 && s == 9) {\n        type = KindOfNull;\n      } else if (type != KindOfString && c > S_WSP) {\n        utf16_to_utf8(*buf, b);\n      }\n\n      state = s;\n    }\n  }\n\n  if (state == 9 && pop(json, Mode::DONE)) {\n    s_json_parser->error_code = JSON_ERROR_NONE;\n    return true;\n  }\n\n  s_json_parser->error_code = JSON_ERROR_SYNTAX;\n  return false;\n}", "func_src_after": "bool JSON_parser(Variant &z, const char *p, int length, bool const assoc,\n                 int depth, int64_t options) {\n  // No GC safepoints during JSON parsing, please. Code is not re-entrant.\n  NoHandleSurpriseScope no_surprise(SafepointFlags);\n\n  json_parser *json = s_json_parser.get(); /* the parser state */\n  // Clear and reuse the thread-local string buffers. They are only freed if\n  // they exceed kMaxPersistentStringBufferCapacity at exit or if the thread\n  // is explicitly flushed (e.g., due to being idle).\n  json->initSb(length);\n  if (depth <= 0) {\n    json->error_code = json_error_codes::JSON_ERROR_DEPTH;\n    return false;\n  }\n  SCOPE_EXIT {\n    constexpr int kMaxPersistentStringBufferCapacity = 256 * 1024;\n    if (json->sb_cap > kMaxPersistentStringBufferCapacity) json->flushSb();\n  };\n  // SimpleParser only handles the most common set of options. Also, only use it\n  // if its array nesting depth check is *more* restrictive than what the user\n  // asks for, to ensure that the precise semantics of the general case is\n  // applied for all nesting overflows.\n  if (assoc &&\n      options == (options & (k_JSON_FB_LOOSE |\n                             k_JSON_FB_DARRAYS |\n                             k_JSON_FB_DARRAYS_AND_VARRAYS |\n                             k_JSON_FB_HACK_ARRAYS |\n                             k_JSON_FB_THRIFT_SIMPLE_JSON |\n                             k_JSON_FB_LEGACY_HACK_ARRAYS)) &&\n      depth >= SimpleParser::kMaxArrayDepth &&\n      length <= RuntimeOption::EvalSimpleJsonMaxLength &&\n      SimpleParser::TryParse(p, length, json->tl_buffer.tv, z,\n                             get_container_type_from_options(options),\n                             options & k_JSON_FB_THRIFT_SIMPLE_JSON)) {\n    return true;\n  }\n\n  int b;  /* the next character */\n  int c;  /* the next character class */\n  int s;  /* the next state */\n  int state = 0;\n\n  /*<fb>*/\n  bool const loose = options & k_JSON_FB_LOOSE;\n  JSONContainerType const container_type =\n    get_container_type_from_options(options);\n  int qchr = 0;\n  int8_t const *byte_class;\n  int8_t const (*next_state_table)[32];\n  if (loose) {\n    byte_class = loose_ascii_class;\n    next_state_table = loose_state_transition_table;\n  } else {\n    byte_class = ascii_class;\n    next_state_table = state_transition_table;\n  }\n  /*</fb>*/\n\n  UncheckedBuffer *buf = &json->sb_buf;\n  UncheckedBuffer *key = &json->sb_key;\n\n  DataType type = kInvalidDataType;\n  unsigned short escaped_bytes = 0;\n\n  auto reset_type = [&] { type = kInvalidDataType; };\n\n  json->depth = depth;\n  // Since the stack is maintainined on a per request basis, for performance\n  // reasons, it only makes sense to expand if necessary and cycles are wasted\n  // contracting. Calls with a depth other than default should be rare.\n  if (depth > json->stack.size()) {\n    json->stack.resize(depth);\n  }\n  SCOPE_EXIT {\n    if (json->stack.empty()) return;\n    for (int i = 0; i <= json->mark; i++) {\n      json->stack[i].key.reset();\n      json->stack[i].val.unset();\n    }\n    json->mark = -1;\n  };\n\n  json->mark = json->top = -1;\n  push(json, Mode::DONE);\n\n  UTF8To16Decoder decoder(p, length, loose);\n  for (;;) {\n    b = decoder.decode();\n    // Fast-case most common transition: append a simple string character.\n    if (state == 3 && type == KindOfString) {\n      while (b != '\\\"' &&  b != '\\\\' && b != '\\'' && b <= 127 && b >= ' ') {\n        buf->append((char)b);\n        b = decoder.decode();\n      }\n    }\n    if (b == UTF8_END) break; // UTF-8 decoding finishes successfully.\n    if (b == UTF8_ERROR) {\n      s_json_parser->error_code = JSON_ERROR_UTF8;\n      return false;\n    }\n    assertx(b >= 0);\n\n    if ((b & 127) == b) {\n      /*<fb>*/\n      c = byte_class[b];\n      /*</fb>*/\n      if (c <= S_ERR) {\n        s_json_parser->error_code = JSON_ERROR_CTRL_CHAR;\n        return false;\n      }\n    } else {\n      c = S_ETC;\n    }\n    /*\n      Get the next state from the transition table.\n    */\n\n    /*<fb>*/\n    s = next_state_table[state][c];\n\n    if (s == -4) {\n      if (b != qchr) {\n        s = 3;\n      } else {\n        qchr = 0;\n      }\n    }\n    /*</fb>*/\n\n    if (s < 0) {\n      /*\n        Perform one of the predefined actions.\n      */\n      switch (s) {\n        /*\n          empty }\n        */\n      case -9:\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key, assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::KEY)) {\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          {\n        */\n      case -8:\n        if (!push(json, Mode::KEY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n\n        state = 1;\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            // stable_maps is meaningless\n            top = req::make<c_Map>();\n          } else {\n          /*</fb>*/\n            if (!assoc) {\n              top = SystemLib::AllocStdClassObject();\n            /* <fb> */\n            } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n              top = Array::CreateDict();\n            } else if (container_type == JSONContainerType::DARRAYS ||\n                       container_type == JSONContainerType::DARRAYS_AND_VARRAYS)\n            {\n              top = Array::CreateDArray();\n            /* </fb> */\n            } else if (\n              container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n              auto arr = staticEmptyDictArray()->copy();\n              arr->setLegacyArray(true);\n              top = arr;\n            } else {\n              top = Array::CreateDArray();\n            }\n          /*<fb>*/\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          }\n        */\n      case -7:\n        /*** BEGIN Facebook: json_utf8_loose ***/\n        /*\n          If this is a trailing comma in an object definition,\n          we're in Mode::KEY. In that case, throw that off the\n          stack and restore Mode::OBJECT so that we pretend the\n          trailing comma just didn't happen.\n        */\n        if (loose) {\n          if (pop(json, Mode::KEY)) {\n            push(json, Mode::OBJECT);\n          }\n        }\n        /*** END Facebook: json_utf8_loose ***/\n\n        if (type != kInvalidDataType &&\n            json->stack[json->top].mode == Mode::OBJECT) {\n          Variant mval;\n          json_create_zval(mval, *buf, type, options);\n          Variant &top = json->stack[json->top].val;\n          object_set(json, top, copy_and_clear(*key),\n                     mval, assoc, container_type);\n          buf->clear();\n          reset_type();\n        }\n\n        /*<fb>*/\n        if (json->top == 1) z = json->stack[json->top].val;\n        else {\n        /*</fb>*/\n          attach_zval(json, json->stack[json->top].key,\n            assoc, container_type);\n        /*<fb>*/\n        }\n        /*</fb>*/\n        if (!pop(json, Mode::OBJECT)) {\n          s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n          return false;\n        }\n        state = 9;\n        break;\n        /*\n          [\n        */\n      case -6:\n        if (!push(json, Mode::ARRAY)) {\n          s_json_parser->error_code = JSON_ERROR_DEPTH;\n          return false;\n        }\n        state = 2;\n\n        if (json->top > 0) {\n          Variant &top = json->stack[json->top].val;\n          /*<fb>*/\n          if (container_type == JSONContainerType::COLLECTIONS) {\n            top = req::make<c_Vector>();\n          } else if (container_type == JSONContainerType::HACK_ARRAYS) {\n            top = Array::CreateVec();\n          } else if (container_type == JSONContainerType::DARRAYS_AND_VARRAYS) {\n            top = Array::CreateVArray();\n          } else if (container_type == JSONContainerType::DARRAYS) {\n            top = Array::CreateDArray();\n          } else if (container_type == JSONContainerType::LEGACY_HACK_ARRAYS) {\n            auto arr = staticEmptyVecArray()->copy();\n            arr->setLegacyArray(true);\n            top = arr;\n          } else {\n            top = Array::CreateDArray();\n          }\n          /*</fb>*/\n          json->stack[json->top].key = copy_and_clear(*key);\n          reset_type();\n        }\n        break;\n        /*\n          ]\n        */\n      case -5:\n        {\n          if (type != kInvalidDataType &&\n               json->stack[json->top].mode == Mode::ARRAY) {\n            Variant mval;\n            json_create_zval(mval, *buf, type, options);\n            auto& top = json->stack[json->top].val;\n            if (container_type == JSONContainerType::COLLECTIONS) {\n              collections::append(top.getObjectData(), mval.asTypedValue());\n            } else {\n              top.asArrRef().append(mval);\n            }\n            buf->clear();\n            reset_type();\n          }\n\n          /*<fb>*/\n          if (json->top == 1) z = json->stack[json->top].val;\n          else {\n          /*</fb>*/\n            attach_zval(json, json->stack[json->top].key, assoc,\n              container_type);\n          /*<fb>*/\n          }\n          /*</fb>*/\n          if (!pop(json, Mode::ARRAY)) {\n            s_json_parser->error_code = JSON_ERROR_STATE_MISMATCH;\n            return false;\n          }\n          state = 9;\n        }\n        break;\n        /*\n          \"\n        */\n      case -4:\n        switch (json->stack[json->top].mode) {\n        case Mode::KEY:\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          break;\n        case Mode::ARRAY:\n        case Mode::OBJECT:\n          state = 9;\n          break;\n        case Mode::DONE:\n          if (type == KindOfString) {\n            z = copy_and_clear(*buf);\n            state = 9;\n            break;\n          }\n          /* fall through if not KindOfString */\n        default:\n          s_json_parser->error_code = JSON_ERROR_SYNTAX;\n          return false;\n        }\n        break;\n        /*\n          ,\n        */\n      case -3:\n        {\n          Variant mval;\n          if (type != kInvalidDataType &&\n              (json->stack[json->top].mode == Mode::OBJECT ||\n               json->stack[json->top].mode == Mode::ARRAY)) {\n            json_create_zval(mval, *buf, type, options);\n          }\n\n          switch (json->stack[json->top].mode) {\n          case Mode::OBJECT:\n            if (pop(json, Mode::OBJECT) &&\n                push(json, Mode::KEY)) {\n              if (type != kInvalidDataType) {\n                Variant &top = json->stack[json->top].val;\n                object_set(\n                  json,\n                  top,\n                  copy_and_clear(*key),\n                  mval,\n                  assoc,\n                  container_type\n                );\n              }\n              state = 29;\n            }\n            break;\n          case Mode::ARRAY:\n            if (type != kInvalidDataType) {\n              auto& top = json->stack[json->top].val;\n              if (container_type == JSONContainerType::COLLECTIONS) {\n                collections::append(top.getObjectData(), mval.asTypedValue());\n              } else {\n                top.asArrRef().append(mval);\n              }\n            }\n            state = 28;\n            break;\n          default:\n            s_json_parser->error_code = JSON_ERROR_SYNTAX;\n            return false;\n          }\n          buf->clear();\n          reset_type();\n          check_non_safepoint_surprise();\n        }\n        break;\n\n        /*<fb>*/\n        /*\n          : (after unquoted string)\n        */\n      case -10:\n        if (json->stack[json->top].mode == Mode::KEY) {\n          state = 27;\n          std::swap(buf, key);\n          reset_type();\n          s = -2;\n        } else {\n          s = 3;\n          break;\n        }\n        /*</fb>*/\n\n        /*\n          :\n        */\n      case -2:\n        if (pop(json, Mode::KEY) && push(json, Mode::OBJECT)) {\n          state = 28;\n          break;\n        }\n        /*\n          syntax error\n        */\n      case -1:\n        s_json_parser->error_code = JSON_ERROR_SYNTAX;\n        return false;\n      }\n    } else {\n      /*\n        Change the state and iterate.\n      */\n      bool is_tsimplejson = options & k_JSON_FB_THRIFT_SIMPLE_JSON;\n      if (type == KindOfString) {\n        if (/*<fb>*/(/*</fb>*/s == 3/*<fb>*/ || s == 30)/*</fb>*/ &&\n            state != 8) {\n          if (state != 4) {\n            utf16_to_utf8(*buf, b);\n          } else {\n            switch (b) {\n            case 'b': buf->append('\\b'); break;\n            case 't': buf->append('\\t'); break;\n            case 'n': buf->append('\\n'); break;\n            case 'f': buf->append('\\f'); break;\n            case 'r': buf->append('\\r'); break;\n            default:\n              utf16_to_utf8(*buf, b);\n              break;\n            }\n          }\n        } else if (s == 6) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n            escaped_bytes = 0;\n          } else {\n            escaped_bytes = dehexchar(b) << 12;\n          }\n        } else if (s == 7) {\n          if (UNLIKELY(is_tsimplejson)) {\n            if (UNLIKELY(b != '0'))  {\n              s_json_parser->error_code = JSON_ERROR_SYNTAX;\n              return false;\n            }\n          } else {\n            escaped_bytes += dehexchar(b) << 8;\n          }\n        } else if (s == 8) {\n          escaped_bytes += dehexchar(b) << 4;\n        } else if (s == 3 && state == 8) {\n          escaped_bytes += dehexchar(b);\n          if (UNLIKELY(is_tsimplejson)) {\n            buf->append((char)escaped_bytes);\n          } else {\n            utf16_to_utf8(*buf, escaped_bytes);\n          }\n        }\n      } else if ((type == kInvalidDataType || type == KindOfNull) &&\n                 (c == S_DIG || c == S_ZER)) {\n        type = KindOfInt64;\n        buf->append((char)b);\n      } else if (type == KindOfInt64 && s == 24) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64) &&\n                 c == S_DOT) {\n        type = KindOfDouble;\n        buf->append((char)b);\n      } else if (type != KindOfString && c == S_QUO) {\n        type = KindOfString;\n        /*<fb>*/qchr = b;/*</fb>*/\n      } else if ((type == kInvalidDataType || type == KindOfNull ||\n                  type == KindOfInt64 || type == KindOfDouble) &&\n                 ((state == 12 && s == 9) ||\n                  (state == 16 && s == 9))) {\n        type = KindOfBoolean;\n      } else if (type == kInvalidDataType && state == 19 && s == 9) {\n        type = KindOfNull;\n      } else if (type != KindOfString && c > S_WSP) {\n        utf16_to_utf8(*buf, b);\n      }\n\n      state = s;\n    }\n  }\n\n  if (state == 9 && pop(json, Mode::DONE)) {\n    s_json_parser->error_code = JSON_ERROR_NONE;\n    return true;\n  }\n\n  s_json_parser->error_code = JSON_ERROR_SYNTAX;\n  return false;\n}", "commit_link": "github.com/facebook/hhvm/commit/dabd48caf74995e605f1700344f1ff4a5d83441d", "file_name": "hphp/runtime/ext/json/JSON_parser.cpp", "vul_type": "cwe-125", "description": "Write a JSON parsing function in C++."}
{"func_name": "xc2028_set_config", "func_src_before": "static int xc2028_set_config(struct dvb_frontend *fe, void *priv_cfg)\n{\n\tstruct xc2028_data *priv = fe->tuner_priv;\n\tstruct xc2028_ctrl *p    = priv_cfg;\n\tint                 rc   = 0;\n\n\ttuner_dbg(\"%s called\\n\", __func__);\n\n\tmutex_lock(&priv->lock);\n\n\t/*\n\t * Copy the config data.\n\t * For the firmware name, keep a local copy of the string,\n\t * in order to avoid troubles during device release.\n\t */\n\tkfree(priv->ctrl.fname);\n\tmemcpy(&priv->ctrl, p, sizeof(priv->ctrl));\n\tif (p->fname) {\n\t\tpriv->ctrl.fname = kstrdup(p->fname, GFP_KERNEL);\n\t\tif (priv->ctrl.fname == NULL)\n\t\t\trc = -ENOMEM;\n\t}\n\n\t/*\n\t * If firmware name changed, frees firmware. As free_firmware will\n\t * reset the status to NO_FIRMWARE, this forces a new request_firmware\n\t */\n\tif (!firmware_name[0] && p->fname &&\n\t    priv->fname && strcmp(p->fname, priv->fname))\n\t\tfree_firmware(priv);\n\n\tif (priv->ctrl.max_len < 9)\n\t\tpriv->ctrl.max_len = 13;\n\n\tif (priv->state == XC2028_NO_FIRMWARE) {\n\t\tif (!firmware_name[0])\n\t\t\tpriv->fname = priv->ctrl.fname;\n\t\telse\n\t\t\tpriv->fname = firmware_name;\n\n\t\trc = request_firmware_nowait(THIS_MODULE, 1,\n\t\t\t\t\t     priv->fname,\n\t\t\t\t\t     priv->i2c_props.adap->dev.parent,\n\t\t\t\t\t     GFP_KERNEL,\n\t\t\t\t\t     fe, load_firmware_cb);\n\t\tif (rc < 0) {\n\t\t\ttuner_err(\"Failed to request firmware %s\\n\",\n\t\t\t\t  priv->fname);\n\t\t\tpriv->state = XC2028_NODEV;\n\t\t} else\n\t\t\tpriv->state = XC2028_WAITING_FIRMWARE;\n\t}\n\tmutex_unlock(&priv->lock);\n\n\treturn rc;\n}", "func_src_after": "static int xc2028_set_config(struct dvb_frontend *fe, void *priv_cfg)\n{\n\tstruct xc2028_data *priv = fe->tuner_priv;\n\tstruct xc2028_ctrl *p    = priv_cfg;\n\tint                 rc   = 0;\n\n\ttuner_dbg(\"%s called\\n\", __func__);\n\n\tmutex_lock(&priv->lock);\n\n\t/*\n\t * Copy the config data.\n\t * For the firmware name, keep a local copy of the string,\n\t * in order to avoid troubles during device release.\n\t */\n\tkfree(priv->ctrl.fname);\n\tpriv->ctrl.fname = NULL;\n\tmemcpy(&priv->ctrl, p, sizeof(priv->ctrl));\n\tif (p->fname) {\n\t\tpriv->ctrl.fname = kstrdup(p->fname, GFP_KERNEL);\n\t\tif (priv->ctrl.fname == NULL)\n\t\t\treturn -ENOMEM;\n\t}\n\n\t/*\n\t * If firmware name changed, frees firmware. As free_firmware will\n\t * reset the status to NO_FIRMWARE, this forces a new request_firmware\n\t */\n\tif (!firmware_name[0] && p->fname &&\n\t    priv->fname && strcmp(p->fname, priv->fname))\n\t\tfree_firmware(priv);\n\n\tif (priv->ctrl.max_len < 9)\n\t\tpriv->ctrl.max_len = 13;\n\n\tif (priv->state == XC2028_NO_FIRMWARE) {\n\t\tif (!firmware_name[0])\n\t\t\tpriv->fname = priv->ctrl.fname;\n\t\telse\n\t\t\tpriv->fname = firmware_name;\n\n\t\trc = request_firmware_nowait(THIS_MODULE, 1,\n\t\t\t\t\t     priv->fname,\n\t\t\t\t\t     priv->i2c_props.adap->dev.parent,\n\t\t\t\t\t     GFP_KERNEL,\n\t\t\t\t\t     fe, load_firmware_cb);\n\t\tif (rc < 0) {\n\t\t\ttuner_err(\"Failed to request firmware %s\\n\",\n\t\t\t\t  priv->fname);\n\t\t\tpriv->state = XC2028_NODEV;\n\t\t} else\n\t\t\tpriv->state = XC2028_WAITING_FIRMWARE;\n\t}\n\tmutex_unlock(&priv->lock);\n\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/8dfbcc4351a0b6d2f2d77f367552f48ffefafe18", "file_name": "drivers/media/tuners/tuner-xc2028.c", "vul_type": "cwe-416", "description": "Write a C function named `xc2028_set_config` that updates the configuration of a DVB frontend device and handles firmware requests."}
{"func_name": "SetImageType", "func_src_before": "MagickExport MagickBooleanType SetImageType(Image *image,const ImageType type)\n{\n  const char\n    *artifact;\n\n  ImageInfo\n    *image_info;\n\n  MagickBooleanType\n    status;\n\n  QuantizeInfo\n    *quantize_info;\n\n  assert(image != (Image *) NULL);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"...\");\n  assert(image->signature == MagickSignature);\n  status=MagickTrue;\n  image_info=AcquireImageInfo();\n  image_info->dither=image->dither;\n  artifact=GetImageArtifact(image,\"dither\");\n  if (artifact != (const char *) NULL)\n    (void) SetImageOption(image_info,\"dither\",artifact);\n  switch (type)\n  {\n    case BilevelType:\n    {\n      if (SetImageMonochrome(image,&image->exception) == MagickFalse)\n        {\n          status=TransformImageColorspace(image,GRAYColorspace);\n          (void) NormalizeImage(image);\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=2;\n          quantize_info->colorspace=GRAYColorspace;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      status=AcquireImageColormap(image,2);\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleMatteType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case PaletteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if ((image->storage_class == DirectClass) || (image->colors > 256))\n        {\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=256;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      image->matte=MagickFalse;\n      break;\n    }\n    case PaletteBilevelMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      (void) BilevelImageChannel(image,AlphaChannel,(double) QuantumRange/2.0);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case PaletteMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      quantize_info->colorspace=TransparentColorspace;\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case TrueColorType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case TrueColorMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case ColorSeparationType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case ColorSeparationMatteType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case OptimizeType:\n    case UndefinedType:\n      break;\n  }\n  image_info=DestroyImageInfo(image_info);\n  if (status == MagickFalse)\n    return(MagickFalse);\n  image->type=type;\n  return(MagickTrue);\n}", "func_src_after": "MagickExport MagickBooleanType SetImageType(Image *image,const ImageType type)\n{\n  const char\n    *artifact;\n\n  ImageInfo\n    *image_info;\n\n  MagickBooleanType\n    status;\n\n  QuantizeInfo\n    *quantize_info;\n\n  assert(image != (Image *) NULL);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"...\");\n  assert(image->signature == MagickSignature);\n  status=MagickTrue;\n  image_info=AcquireImageInfo();\n  image_info->dither=image->dither;\n  artifact=GetImageArtifact(image,\"dither\");\n  if (artifact != (const char *) NULL)\n    (void) SetImageOption(image_info,\"dither\",artifact);\n  switch (type)\n  {\n    case BilevelType:\n    {\n      if (SetImageMonochrome(image,&image->exception) == MagickFalse)\n        {\n          status=TransformImageColorspace(image,GRAYColorspace);\n          (void) NormalizeImage(image);\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=2;\n          quantize_info->colorspace=GRAYColorspace;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      image->colors=2;\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      image->matte=MagickFalse;\n      break;\n    }\n    case GrayscaleMatteType:\n    {\n      if (SetImageGray(image,&image->exception) == MagickFalse)\n        status=TransformImageColorspace(image,GRAYColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case PaletteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if ((image->storage_class == DirectClass) || (image->colors > 256))\n        {\n          quantize_info=AcquireQuantizeInfo(image_info);\n          quantize_info->number_colors=256;\n          status=QuantizeImage(quantize_info,image);\n          quantize_info=DestroyQuantizeInfo(quantize_info);\n        }\n      image->matte=MagickFalse;\n      break;\n    }\n    case PaletteBilevelMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      (void) BilevelImageChannel(image,AlphaChannel,(double) QuantumRange/2.0);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case PaletteMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      quantize_info=AcquireQuantizeInfo(image_info);\n      quantize_info->colorspace=TransparentColorspace;\n      status=QuantizeImage(quantize_info,image);\n      quantize_info=DestroyQuantizeInfo(quantize_info);\n      break;\n    }\n    case TrueColorType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case TrueColorMatteType:\n    {\n      if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n        status=TransformImageColorspace(image,sRGBColorspace);\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case ColorSeparationType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      image->matte=MagickFalse;\n      break;\n    }\n    case ColorSeparationMatteType:\n    {\n      if (image->colorspace != CMYKColorspace)\n        {\n          if (IssRGBCompatibleColorspace(image->colorspace) == MagickFalse)\n            (void) TransformImageColorspace(image,sRGBColorspace);\n          status=TransformImageColorspace(image,CMYKColorspace);\n        }\n      if (image->storage_class != DirectClass)\n        status=SetImageStorageClass(image,DirectClass);\n      if (image->matte == MagickFalse)\n        (void) SetImageAlphaChannel(image,OpaqueAlphaChannel);\n      break;\n    }\n    case OptimizeType:\n    case UndefinedType:\n      break;\n  }\n  image_info=DestroyImageInfo(image_info);\n  if (status == MagickFalse)\n    return(MagickFalse);\n  image->type=type;\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/d63a3c5729df59f183e9e110d5d8385d17caaad0", "file_name": "magick/attribute.c", "vul_type": "cwe-416", "description": "In C, write a function to change the type of an image using ImageMagick's API."}
{"func_name": "CompileKeymap", "func_src_before": "CompileKeymap(XkbFile *file, struct xkb_keymap *keymap, enum merge_mode merge)\n{\n    bool ok;\n    XkbFile *files[LAST_KEYMAP_FILE_TYPE + 1] = { NULL };\n    enum xkb_file_type type;\n    struct xkb_context *ctx = keymap->ctx;\n\n    /* Collect section files and check for duplicates. */\n    for (file = (XkbFile *) file->defs; file;\n         file = (XkbFile *) file->common.next) {\n        if (file->file_type < FIRST_KEYMAP_FILE_TYPE ||\n            file->file_type > LAST_KEYMAP_FILE_TYPE) {\n            log_err(ctx, \"Cannot define %s in a keymap file\\n\",\n                    xkb_file_type_to_string(file->file_type));\n            continue;\n        }\n\n        if (files[file->file_type]) {\n            log_err(ctx,\n                    \"More than one %s section in keymap file; \"\n                    \"All sections after the first ignored\\n\",\n                    xkb_file_type_to_string(file->file_type));\n            continue;\n        }\n\n        files[file->file_type] = file;\n    }\n\n    /*\n     * Check that all required section were provided.\n     * Report everything before failing.\n     */\n    ok = true;\n    for (type = FIRST_KEYMAP_FILE_TYPE;\n         type <= LAST_KEYMAP_FILE_TYPE;\n         type++) {\n        if (files[type] == NULL) {\n            log_err(ctx, \"Required section %s missing from keymap\\n\",\n                    xkb_file_type_to_string(type));\n            ok = false;\n        }\n    }\n    if (!ok)\n        return false;\n\n    /* Compile sections. */\n    for (type = FIRST_KEYMAP_FILE_TYPE;\n         type <= LAST_KEYMAP_FILE_TYPE;\n         type++) {\n        log_dbg(ctx, \"Compiling %s \\\"%s\\\"\\n\",\n                xkb_file_type_to_string(type), files[type]->name);\n\n        ok = compile_file_fns[type](files[type], keymap, merge);\n        if (!ok) {\n            log_err(ctx, \"Failed to compile %s\\n\",\n                    xkb_file_type_to_string(type));\n            return false;\n        }\n    }\n\n    return UpdateDerivedKeymapFields(keymap);\n}", "func_src_after": "CompileKeymap(XkbFile *file, struct xkb_keymap *keymap, enum merge_mode merge)\n{\n    bool ok;\n    XkbFile *files[LAST_KEYMAP_FILE_TYPE + 1] = { NULL };\n    enum xkb_file_type type;\n    struct xkb_context *ctx = keymap->ctx;\n\n    /* Collect section files and check for duplicates. */\n    for (file = (XkbFile *) file->defs; file;\n         file = (XkbFile *) file->common.next) {\n        if (file->file_type < FIRST_KEYMAP_FILE_TYPE ||\n            file->file_type > LAST_KEYMAP_FILE_TYPE) {\n            if (file->file_type == FILE_TYPE_GEOMETRY) {\n                log_vrb(ctx, 1,\n                        \"Geometry sections are not supported; ignoring\\n\");\n            } else {\n                log_err(ctx, \"Cannot define %s in a keymap file\\n\",\n                        xkb_file_type_to_string(file->file_type));\n            }\n            continue;\n        }\n\n        if (files[file->file_type]) {\n            log_err(ctx,\n                    \"More than one %s section in keymap file; \"\n                    \"All sections after the first ignored\\n\",\n                    xkb_file_type_to_string(file->file_type));\n            continue;\n        }\n\n        files[file->file_type] = file;\n    }\n\n    /*\n     * Check that all required section were provided.\n     * Report everything before failing.\n     */\n    ok = true;\n    for (type = FIRST_KEYMAP_FILE_TYPE;\n         type <= LAST_KEYMAP_FILE_TYPE;\n         type++) {\n        if (files[type] == NULL) {\n            log_err(ctx, \"Required section %s missing from keymap\\n\",\n                    xkb_file_type_to_string(type));\n            ok = false;\n        }\n    }\n    if (!ok)\n        return false;\n\n    /* Compile sections. */\n    for (type = FIRST_KEYMAP_FILE_TYPE;\n         type <= LAST_KEYMAP_FILE_TYPE;\n         type++) {\n        log_dbg(ctx, \"Compiling %s \\\"%s\\\"\\n\",\n                xkb_file_type_to_string(type), files[type]->name);\n\n        ok = compile_file_fns[type](files[type], keymap, merge);\n        if (!ok) {\n            log_err(ctx, \"Failed to compile %s\\n\",\n                    xkb_file_type_to_string(type));\n            return false;\n        }\n    }\n\n    return UpdateDerivedKeymapFields(keymap);\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/917636b1d0d70205a13f89062b95e3a0fc31d4ff", "file_name": "src/xkbcomp/keymap.c", "vul_type": "cwe-476", "description": "In C, write a function `CompileKeymap` that compiles a keymap from XkbFile sections, handling duplicates and missing sections."}
{"func_name": "TiledInputFile::rawTileData", "func_src_before": "TiledInputFile::rawTileData (int &dx, int &dy,\n\t\t\t     int &lx, int &ly,\n                             const char *&pixelData,\n\t\t\t     int &pixelDataSize)\n{\n    try\n    {\n        Lock lock (*_data->_streamData);\n\n        if (!isValidTile (dx, dy, lx, ly))\n            throw IEX_NAMESPACE::ArgExc (\"Tried to read a tile outside \"\n\t\t\t       \"the image file's data window.\");\n\n        TileBuffer *tileBuffer = _data->getTileBuffer (0);\n\n        //\n        // if file is a multipart file, we have to seek to the required tile\n        // since we don't know where the file pointer is\n        //\n        int old_dx=dx;\n        int old_dy=dy;\n        int old_lx=lx;\n        int old_ly=ly;\n        if(isMultiPart(version()))\n        {\n            _data->_streamData->is->seekg(_data->tileOffsets(dx,dy,lx,ly));\n        }\n        readNextTileData (_data->_streamData, _data, dx, dy, lx, ly,\n\t\t\t  tileBuffer->buffer,\n                          pixelDataSize);\n        if(isMultiPart(version()))\n        {\n            if (old_dx!=dx || old_dy !=dy || old_lx!=lx || old_ly!=ly)\n            {\n                throw IEX_NAMESPACE::ArgExc (\"rawTileData read the wrong tile\");\n            }\n        }\n        pixelData = tileBuffer->buffer;\n    }\n    catch (IEX_NAMESPACE::BaseExc &e)\n    {\n        REPLACE_EXC (e, \"Error reading pixel data from image \"\n                     \"file \\\"\" << fileName() << \"\\\". \" << e.what());\n        throw;\n    }\n}", "func_src_after": "TiledInputFile::rawTileData (int &dx, int &dy,\n\t\t\t     int &lx, int &ly,\n                             const char *&pixelData,\n\t\t\t     int &pixelDataSize)\n{\n    try\n    {\n        Lock lock (*_data->_streamData);\n\n        if (!isValidTile (dx, dy, lx, ly))\n            throw IEX_NAMESPACE::ArgExc (\"Tried to read a tile outside \"\n\t\t\t       \"the image file's data window.\");\n\n        TileBuffer *tileBuffer = _data->getTileBuffer (0);\n\n        //\n        // if file is a multipart file, we have to seek to the required tile\n        // since we don't know where the file pointer is\n        //\n        int old_dx=dx;\n        int old_dy=dy;\n        int old_lx=lx;\n        int old_ly=ly;\n        if(isMultiPart(version()))\n        {\n            _data->_streamData->is->seekg(_data->tileOffsets(dx,dy,lx,ly));\n        }\n        readNextTileData (_data->_streamData, _data, dx, dy, lx, ly,\n\t\t\t  tileBuffer->buffer,\n                          pixelDataSize);\n        if(isMultiPart(version()))\n        {\n            if (old_dx!=dx || old_dy !=dy || old_lx!=lx || old_ly!=ly)\n            {\n                throw IEX_NAMESPACE::ArgExc (\"rawTileData read the wrong tile\");\n            }\n        }\n        else\n        {\n             if(!isValidTile (dx, dy, lx, ly) )\n             {\n                 throw IEX_NAMESPACE::IoExc (\"rawTileData read an invalid tile\");\n             }\n        }\n        pixelData = tileBuffer->buffer;\n    }\n    catch (IEX_NAMESPACE::BaseExc &e)\n    {\n        REPLACE_EXC (e, \"Error reading pixel data from image \"\n                     \"file \\\"\" << fileName() << \"\\\". \" << e.what());\n        throw;\n    }\n}", "commit_link": "github.com/AcademySoftwareFoundation/openexr/commit/6bb36714528a9563dd3b92720c5063a1284b86f8", "file_name": "OpenEXR/IlmImf/ImfTiledInputFile.cpp", "vul_type": "cwe-787", "description": "Provide a C++ function to read raw tile data from an image file, handling multipart files and validating tile coordinates."}
{"func_name": "InsertRow", "func_src_before": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "func_src_after": "static void InsertRow(unsigned char *p,ssize_t y,Image *image, int bpp)\n{\n  ExceptionInfo\n    *exception;\n\n  int\n    bit;\n\n  ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  IndexPacket\n    index;\n\n  register IndexPacket\n    *indexes;\n\n  exception=(&image->exception);\n  switch (bpp)\n    {\n    case 1:  /* Convert bitmap scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=0; bit < (ssize_t) (image->columns % 8); bit++)\n              {\n                index=((*p) & (0x80 >> bit) ? 0x01 : 0x00);\n                SetPixelIndex(indexes+x+bit,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n              }\n            p++;\n          }\n        if (!SyncAuthenticPixels(image,exception))\n          break;\n        break;\n      }\n    case 2:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=4)\n        {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x3);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n        }\n       if ((image->columns % 4) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 6) & 0x3);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            if ((image->columns % 4) >= 1)\n\n              {\n                index=ConstrainColormapIndex(image,(*p >> 4) & 0x3);\n                SetPixelIndex(indexes+x,index);\n                SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                q++;\n                if ((image->columns % 4) >= 2)\n\n                  {\n                    index=ConstrainColormapIndex(image,(*p >> 2) & 0x3);\n                    SetPixelIndex(indexes+x,index);\n                    SetPixelRGBO(q,image->colormap+(ssize_t) index);\n                    q++;\n                  }\n              }\n            p++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n\n    case 4:  /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL)\n          break;\n        indexes=GetAuthenticIndexQueue(image);\n        for (x=0; x < ((ssize_t) image->columns-1); x+=2)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            q++;\n            index=ConstrainColormapIndex(image,(*p) & 0x0f);\n            SetPixelIndex(indexes+x+1,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if ((image->columns % 2) != 0)\n          {\n            index=ConstrainColormapIndex(image,(*p >> 4) & 0x0f);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        break;\n      }\n    case 8: /* Convert PseudoColor scanline. */\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (PixelPacket *) NULL) break;\n        indexes=GetAuthenticIndexQueue(image);\n\n        for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            index=ConstrainColormapIndex(image,*p);\n            SetPixelIndex(indexes+x,index);\n            SetPixelRGBO(q,image->colormap+(ssize_t) index);\n            p++;\n            q++;\n          }\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n      }\n      break;\n\n    case 24:     /*  Convert DirectColor scanline.  */\n      q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n      if (q == (PixelPacket *) NULL)\n        break;\n      for (x=0; x < (ssize_t) image->columns; x++)\n        {\n          SetPixelRed(q,ScaleCharToQuantum(*p++));\n          SetPixelGreen(q,ScaleCharToQuantum(*p++));\n          SetPixelBlue(q,ScaleCharToQuantum(*p++));\n          q++;\n        }\n      if (!SyncAuthenticPixels(image,exception))\n        break;\n      break;\n    }\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/b6ae2f9e0ab13343c0281732d479757a8e8979c7", "file_name": "coders/wpg.c", "vul_type": "cwe-787", "description": "Write a C function named `InsertRow` that processes a scanline of an image based on the bits per pixel (bpp) parameter."}
{"func_name": "generatePreview", "func_src_before": "generatePreview (const char inFileName[],\n\t\t float exposure,\n\t\t int previewWidth,\n\t\t int &previewHeight,\n\t\t Array2D <PreviewRgba> &previewPixels)\n{\n    //\n    // Read the input file\n    //\n\n    RgbaInputFile in (inFileName);\n\n    Box2i dw = in.dataWindow();\n    float a = in.pixelAspectRatio();\n    int w = dw.max.x - dw.min.x + 1;\n    int h = dw.max.y - dw.min.y + 1;\n\n    Array2D <Rgba> pixels (h, w);\n    in.setFrameBuffer (ComputeBasePointer (&pixels[0][0], dw), 1, w);\n    in.readPixels (dw.min.y, dw.max.y);\n\n    //\n    // Make a preview image\n    //\n\n    previewHeight = max (int (h / (w * a) * previewWidth + .5f), 1);\n    previewPixels.resizeErase (previewHeight, previewWidth);\n\n    float fx = (previewWidth  > 0)? (float (w - 1) / (previewWidth  - 1)): 1;\n    float fy = (previewHeight > 0)? (float (h - 1) / (previewHeight - 1)): 1;\n    float m  = Math<float>::pow (2.f, IMATH_NAMESPACE::clamp (exposure + 2.47393f, -20.f, 20.f));\n\n    for (int y = 0; y < previewHeight; ++y)\n    {\n\tfor (int x = 0; x < previewWidth; ++x)\n\t{\n\t    PreviewRgba &preview = previewPixels[y][x];\n\t    const Rgba &pixel = pixels[int (y * fy + .5f)][int (x * fx + .5f)];\n\n\t    preview.r = gamma (pixel.r, m);\n\t    preview.g = gamma (pixel.g, m);\n\t    preview.b = gamma (pixel.b, m);\n\t    preview.a = int (IMATH_NAMESPACE::clamp (pixel.a * 255.f, 0.f, 255.f) + .5f);\n\t}\n    }\n}", "func_src_after": "generatePreview (const char inFileName[],\n\t\t float exposure,\n\t\t int previewWidth,\n\t\t int &previewHeight,\n\t\t Array2D <PreviewRgba> &previewPixels)\n{\n    //\n    // Read the input file\n    //\n\n    RgbaInputFile in (inFileName);\n\n    Box2i dw = in.dataWindow();\n    float a = in.pixelAspectRatio();\n    int w = dw.max.x - dw.min.x + 1;\n    int h = dw.max.y - dw.min.y + 1;\n\n    Array2D <Rgba> pixels (h, w);\n    in.setFrameBuffer (ComputeBasePointer (&pixels[0][0], dw), 1, w);\n    in.readPixels (dw.min.y, dw.max.y);\n\n    //\n    // Make a preview image\n    //\n\n    previewHeight = max (int (h / (w * a) * previewWidth + .5f), 1);\n    previewPixels.resizeErase (previewHeight, previewWidth);\n\n    float fx = (previewWidth  > 1)? (float (w - 1) / (previewWidth  - 1)): 1;\n    float fy = (previewHeight > 1)? (float (h - 1) / (previewHeight - 1)): 1;\n    float m  = Math<float>::pow (2.f, IMATH_NAMESPACE::clamp (exposure + 2.47393f, -20.f, 20.f));\n\n    for (int y = 0; y < previewHeight; ++y)\n    {\n\tfor (int x = 0; x < previewWidth; ++x)\n\t{\n\t    PreviewRgba &preview = previewPixels[y][x];\n\t    const Rgba &pixel = pixels[int (y * fy + .5f)][int (x * fx + .5f)];\n\n\t    preview.r = gamma (pixel.r, m);\n\t    preview.g = gamma (pixel.g, m);\n\t    preview.b = gamma (pixel.b, m);\n\t    preview.a = int (IMATH_NAMESPACE::clamp (pixel.a * 255.f, 0.f, 255.f) + .5f);\n\t}\n    }\n}", "commit_link": "github.com/AcademySoftwareFoundation/openexr/commit/74504503cff86e986bac441213c403b0ba28d58f", "file_name": "OpenEXR/exrmakepreview/makePreview.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to generate a resized preview image from an input file with adjustable exposure."}
{"func_name": "get", "func_src_before": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    def get(self, user_id):\n        \"\"\" Fetch data for user with corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from users where user_id = %s\"\"\", (user_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `get` that retrieves user data from a database using the user's ID."}
{"func_name": "update_inverter", "func_src_before": "    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp=?, \n                Status=?, \n                eToday=?,\n                eTotal=?\n            WHERE Serial=?;\n        '''\n        self.c.execute(query, (ts, status, etoday, etotal, inverter_serial))", "func_src_after": "    def update_inverter(self, inverter_serial, ts, status, etoday, etotal):\n        query = '''\n            UPDATE Inverters\n            SET     \n                TimeStamp='%s', \n                Status='%s', \n                eToday='%s',\n                eTotal='%s'\n            WHERE Serial='%s';\n        ''' % (ts, status, etoday, etotal, inverter_serial)\n        self.c.execute(query)", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to update an inverter's status and energy readings in a database using SQL."}
{"func_name": "send_message", "func_src_before": "@frappe.whitelist(allow_guest=True)\ndef send_message(subject=\"Website Query\", message=\"\", sender=\"\", status=\"Open\"):\n\tfrom frappe.www.contact import send_message as website_send_message\n\tlead = customer = None\n\n\twebsite_send_message(subject, message, sender)\n\n\tcustomer = frappe.db.sql(\"\"\"select distinct dl.link_name from `tabDynamic Link` dl\n\t\tleft join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'\n\t\tand c.email_id = %s\"\"\", sender)\n\n\tif not customer:\n\t\tlead = frappe.db.get_value('Lead', dict(email_id=sender))\n\t\tif not lead:\n\t\t\tnew_lead = frappe.get_doc(dict(\n\t\t\t\tdoctype='Lead',\n\t\t\t\temail_id = sender,\n\t\t\t\tlead_name = sender.split('@')[0].title()\n\t\t\t)).insert(ignore_permissions=True)\n\n\topportunity = frappe.get_doc(dict(\n\t\tdoctype ='Opportunity',\n\t\tenquiry_from = 'Customer' if customer else 'Lead',\n\t\tstatus = 'Open',\n\t\ttitle = subject,\n\t\tcontact_email = sender,\n\t\tto_discuss = message\n\t))\n\n\tif customer:\n\t\topportunity.customer = customer[0][0]\n\telif lead:\n\t\topportunity.lead = lead\n\telse:\n\t\topportunity.lead = new_lead.name\n\n\topportunity.insert(ignore_permissions=True)\n\n\tcomm = frappe.get_doc({\n\t\t\"doctype\":\"Communication\",\n\t\t\"subject\": subject,\n\t\t\"content\": message,\n\t\t\"sender\": sender,\n\t\t\"sent_or_received\": \"Received\",\n\t\t'reference_doctype': 'Opportunity',\n\t\t'reference_name': opportunity.name\n\t})\n\tcomm.insert(ignore_permissions=True)\n\n\treturn \"okay\"", "func_src_after": "@frappe.whitelist(allow_guest=True)\ndef send_message(subject=\"Website Query\", message=\"\", sender=\"\", status=\"Open\"):\n\tfrom frappe.www.contact import send_message as website_send_message\n\tlead = customer = None\n\n\twebsite_send_message(subject, message, sender)\n\n\tcustomer = frappe.db.sql(\"\"\"select distinct dl.link_name from `tabDynamic Link` dl\n\t\tleft join `tabContact` c on dl.parent=c.name where dl.link_doctype='Customer'\n\t\tand c.email_id='{email_id}'\"\"\".format(email_id=sender))\n\n\tif not customer:\n\t\tlead = frappe.db.get_value('Lead', dict(email_id=sender))\n\t\tif not lead:\n\t\t\tnew_lead = frappe.get_doc(dict(\n\t\t\t\tdoctype='Lead',\n\t\t\t\temail_id = sender,\n\t\t\t\tlead_name = sender.split('@')[0].title()\n\t\t\t)).insert(ignore_permissions=True)\n\n\topportunity = frappe.get_doc(dict(\n\t\tdoctype ='Opportunity',\n\t\tenquiry_from = 'Customer' if customer else 'Lead',\n\t\tstatus = 'Open',\n\t\ttitle = subject,\n\t\tcontact_email = sender,\n\t\tto_discuss = message\n\t))\n\n\tif customer:\n\t\topportunity.customer = customer[0][0]\n\telif lead:\n\t\topportunity.lead = lead\n\telse:\n\t\topportunity.lead = new_lead.name\n\n\topportunity.insert(ignore_permissions=True)\n\n\tcomm = frappe.get_doc({\n\t\t\"doctype\":\"Communication\",\n\t\t\"subject\": subject,\n\t\t\"content\": message,\n\t\t\"sender\": sender,\n\t\t\"sent_or_received\": \"Received\",\n\t\t'reference_doctype': 'Opportunity',\n\t\t'reference_name': opportunity.name\n\t})\n\tcomm.insert(ignore_permissions=True)\n\n\treturn \"okay\"", "commit_link": "github.com/libracore/erpnext/commit/9acb885e60f77cd4e9ea8c98bdc39c18abcac731", "file_name": "erpnext/templates/utils.py", "vul_type": "cwe-089", "description": "Write a Python function in Frappe that handles incoming messages by creating leads, opportunities, and communications."}
{"func_name": "__rds_rdma_map", "func_src_before": "static int __rds_rdma_map(struct rds_sock *rs, struct rds_get_mr_args *args,\n\t\t\t\tu64 *cookie_ret, struct rds_mr **mr_ret)\n{\n\tstruct rds_mr *mr = NULL, *found;\n\tunsigned int nr_pages;\n\tstruct page **pages = NULL;\n\tstruct scatterlist *sg;\n\tvoid *trans_private;\n\tunsigned long flags;\n\trds_rdma_cookie_t cookie;\n\tunsigned int nents;\n\tlong i;\n\tint ret;\n\n\tif (rs->rs_bound_addr == 0) {\n\t\tret = -ENOTCONN; /* XXX not a great errno */\n\t\tgoto out;\n\t}\n\n\tif (!rs->rs_transport->get_mr) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tnr_pages = rds_pages_in_vec(&args->vec);\n\tif (nr_pages == 0) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Restrict the size of mr irrespective of underlying transport\n\t * To account for unaligned mr regions, subtract one from nr_pages\n\t */\n\tif ((nr_pages - 1) > (RDS_MAX_MSG_SIZE >> PAGE_SHIFT)) {\n\t\tret = -EMSGSIZE;\n\t\tgoto out;\n\t}\n\n\trdsdebug(\"RDS: get_mr addr %llx len %llu nr_pages %u\\n\",\n\t\targs->vec.addr, args->vec.bytes, nr_pages);\n\n\t/* XXX clamp nr_pages to limit the size of this alloc? */\n\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!pages) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmr = kzalloc(sizeof(struct rds_mr), GFP_KERNEL);\n\tif (!mr) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trefcount_set(&mr->r_refcount, 1);\n\tRB_CLEAR_NODE(&mr->r_rb_node);\n\tmr->r_trans = rs->rs_transport;\n\tmr->r_sock = rs;\n\n\tif (args->flags & RDS_RDMA_USE_ONCE)\n\t\tmr->r_use_once = 1;\n\tif (args->flags & RDS_RDMA_INVALIDATE)\n\t\tmr->r_invalidate = 1;\n\tif (args->flags & RDS_RDMA_READWRITE)\n\t\tmr->r_write = 1;\n\n\t/*\n\t * Pin the pages that make up the user buffer and transfer the page\n\t * pointers to the mr's sg array.  We check to see if we've mapped\n\t * the whole region after transferring the partial page references\n\t * to the sg array so that we can have one page ref cleanup path.\n\t *\n\t * For now we have no flag that tells us whether the mapping is\n\t * r/o or r/w. We need to assume r/w, or we'll do a lot of RDMA to\n\t * the zero page.\n\t */\n\tret = rds_pin_pages(args->vec.addr, nr_pages, pages, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tnents = ret;\n\tsg = kcalloc(nents, sizeof(*sg), GFP_KERNEL);\n\tif (!sg) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tWARN_ON(!nents);\n\tsg_init_table(sg, nents);\n\n\t/* Stick all pages into the scatterlist */\n\tfor (i = 0 ; i < nents; i++)\n\t\tsg_set_page(&sg[i], pages[i], PAGE_SIZE, 0);\n\n\trdsdebug(\"RDS: trans_private nents is %u\\n\", nents);\n\n\t/* Obtain a transport specific MR. If this succeeds, the\n\t * s/g list is now owned by the MR.\n\t * Note that dma_map() implies that pending writes are\n\t * flushed to RAM, so no dma_sync is needed here. */\n\ttrans_private = rs->rs_transport->get_mr(sg, nents, rs,\n\t\t\t\t\t\t &mr->r_key);\n\n\tif (IS_ERR(trans_private)) {\n\t\tfor (i = 0 ; i < nents; i++)\n\t\t\tput_page(sg_page(&sg[i]));\n\t\tkfree(sg);\n\t\tret = PTR_ERR(trans_private);\n\t\tgoto out;\n\t}\n\n\tmr->r_trans_private = trans_private;\n\n\trdsdebug(\"RDS: get_mr put_user key is %x cookie_addr %p\\n\",\n\t       mr->r_key, (void *)(unsigned long) args->cookie_addr);\n\n\t/* The user may pass us an unaligned address, but we can only\n\t * map page aligned regions. So we keep the offset, and build\n\t * a 64bit cookie containing <R_Key, offset> and pass that\n\t * around. */\n\tcookie = rds_rdma_make_cookie(mr->r_key, args->vec.addr & ~PAGE_MASK);\n\tif (cookie_ret)\n\t\t*cookie_ret = cookie;\n\n\tif (args->cookie_addr && put_user(cookie, (u64 __user *)(unsigned long) args->cookie_addr)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\t/* Inserting the new MR into the rbtree bumps its\n\t * reference count. */\n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tfound = rds_mr_tree_walk(&rs->rs_rdma_keys, mr->r_key, mr);\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tBUG_ON(found && found != mr);\n\n\trdsdebug(\"RDS: get_mr key is %x\\n\", mr->r_key);\n\tif (mr_ret) {\n\t\trefcount_inc(&mr->r_refcount);\n\t\t*mr_ret = mr;\n\t}\n\n\tret = 0;\nout:\n\tkfree(pages);\n\tif (mr)\n\t\trds_mr_put(mr);\n\treturn ret;\n}", "func_src_after": "static int __rds_rdma_map(struct rds_sock *rs, struct rds_get_mr_args *args,\n\t\t\t\tu64 *cookie_ret, struct rds_mr **mr_ret)\n{\n\tstruct rds_mr *mr = NULL, *found;\n\tunsigned int nr_pages;\n\tstruct page **pages = NULL;\n\tstruct scatterlist *sg;\n\tvoid *trans_private;\n\tunsigned long flags;\n\trds_rdma_cookie_t cookie;\n\tunsigned int nents;\n\tlong i;\n\tint ret;\n\n\tif (rs->rs_bound_addr == 0 || !rs->rs_transport) {\n\t\tret = -ENOTCONN; /* XXX not a great errno */\n\t\tgoto out;\n\t}\n\n\tif (!rs->rs_transport->get_mr) {\n\t\tret = -EOPNOTSUPP;\n\t\tgoto out;\n\t}\n\n\tnr_pages = rds_pages_in_vec(&args->vec);\n\tif (nr_pages == 0) {\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\t/* Restrict the size of mr irrespective of underlying transport\n\t * To account for unaligned mr regions, subtract one from nr_pages\n\t */\n\tif ((nr_pages - 1) > (RDS_MAX_MSG_SIZE >> PAGE_SHIFT)) {\n\t\tret = -EMSGSIZE;\n\t\tgoto out;\n\t}\n\n\trdsdebug(\"RDS: get_mr addr %llx len %llu nr_pages %u\\n\",\n\t\targs->vec.addr, args->vec.bytes, nr_pages);\n\n\t/* XXX clamp nr_pages to limit the size of this alloc? */\n\tpages = kcalloc(nr_pages, sizeof(struct page *), GFP_KERNEL);\n\tif (!pages) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmr = kzalloc(sizeof(struct rds_mr), GFP_KERNEL);\n\tif (!mr) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\trefcount_set(&mr->r_refcount, 1);\n\tRB_CLEAR_NODE(&mr->r_rb_node);\n\tmr->r_trans = rs->rs_transport;\n\tmr->r_sock = rs;\n\n\tif (args->flags & RDS_RDMA_USE_ONCE)\n\t\tmr->r_use_once = 1;\n\tif (args->flags & RDS_RDMA_INVALIDATE)\n\t\tmr->r_invalidate = 1;\n\tif (args->flags & RDS_RDMA_READWRITE)\n\t\tmr->r_write = 1;\n\n\t/*\n\t * Pin the pages that make up the user buffer and transfer the page\n\t * pointers to the mr's sg array.  We check to see if we've mapped\n\t * the whole region after transferring the partial page references\n\t * to the sg array so that we can have one page ref cleanup path.\n\t *\n\t * For now we have no flag that tells us whether the mapping is\n\t * r/o or r/w. We need to assume r/w, or we'll do a lot of RDMA to\n\t * the zero page.\n\t */\n\tret = rds_pin_pages(args->vec.addr, nr_pages, pages, 1);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tnents = ret;\n\tsg = kcalloc(nents, sizeof(*sg), GFP_KERNEL);\n\tif (!sg) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\tWARN_ON(!nents);\n\tsg_init_table(sg, nents);\n\n\t/* Stick all pages into the scatterlist */\n\tfor (i = 0 ; i < nents; i++)\n\t\tsg_set_page(&sg[i], pages[i], PAGE_SIZE, 0);\n\n\trdsdebug(\"RDS: trans_private nents is %u\\n\", nents);\n\n\t/* Obtain a transport specific MR. If this succeeds, the\n\t * s/g list is now owned by the MR.\n\t * Note that dma_map() implies that pending writes are\n\t * flushed to RAM, so no dma_sync is needed here. */\n\ttrans_private = rs->rs_transport->get_mr(sg, nents, rs,\n\t\t\t\t\t\t &mr->r_key);\n\n\tif (IS_ERR(trans_private)) {\n\t\tfor (i = 0 ; i < nents; i++)\n\t\t\tput_page(sg_page(&sg[i]));\n\t\tkfree(sg);\n\t\tret = PTR_ERR(trans_private);\n\t\tgoto out;\n\t}\n\n\tmr->r_trans_private = trans_private;\n\n\trdsdebug(\"RDS: get_mr put_user key is %x cookie_addr %p\\n\",\n\t       mr->r_key, (void *)(unsigned long) args->cookie_addr);\n\n\t/* The user may pass us an unaligned address, but we can only\n\t * map page aligned regions. So we keep the offset, and build\n\t * a 64bit cookie containing <R_Key, offset> and pass that\n\t * around. */\n\tcookie = rds_rdma_make_cookie(mr->r_key, args->vec.addr & ~PAGE_MASK);\n\tif (cookie_ret)\n\t\t*cookie_ret = cookie;\n\n\tif (args->cookie_addr && put_user(cookie, (u64 __user *)(unsigned long) args->cookie_addr)) {\n\t\tret = -EFAULT;\n\t\tgoto out;\n\t}\n\n\t/* Inserting the new MR into the rbtree bumps its\n\t * reference count. */\n\tspin_lock_irqsave(&rs->rs_rdma_lock, flags);\n\tfound = rds_mr_tree_walk(&rs->rs_rdma_keys, mr->r_key, mr);\n\tspin_unlock_irqrestore(&rs->rs_rdma_lock, flags);\n\n\tBUG_ON(found && found != mr);\n\n\trdsdebug(\"RDS: get_mr key is %x\\n\", mr->r_key);\n\tif (mr_ret) {\n\t\trefcount_inc(&mr->r_refcount);\n\t\t*mr_ret = mr;\n\t}\n\n\tret = 0;\nout:\n\tkfree(pages);\n\tif (mr)\n\t\trds_mr_put(mr);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/f3069c6d33f6ae63a1668737bc78aaaa51bff7ca", "file_name": "net/rds/rdma.c", "vul_type": "cwe-476", "description": "Write a C function named `__rds_rdma_map` that maps a user buffer for RDMA operations and returns a cookie for the mapped memory region."}
{"func_name": "decode_pointer_field", "func_src_before": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                (*size)++;\n                if (!allocate_field(stream, field->pField, field->data_size, *size))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size - 1);\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "func_src_after": "static bool checkreturn decode_pointer_field(pb_istream_t *stream, pb_wire_type_t wire_type, pb_field_iter_t *field)\n{\n#ifndef PB_ENABLE_MALLOC\n    PB_UNUSED(wire_type);\n    PB_UNUSED(field);\n    PB_RETURN_ERROR(stream, \"no malloc support\");\n#else\n    switch (PB_HTYPE(field->type))\n    {\n        case PB_HTYPE_REQUIRED:\n        case PB_HTYPE_OPTIONAL:\n        case PB_HTYPE_ONEOF:\n            if (!check_wire_type(wire_type, field))\n                PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n            if (PB_LTYPE_IS_SUBMSG(field->type) && *(void**)field->pField != NULL)\n            {\n                /* Duplicate field, have to release the old allocation first. */\n                /* FIXME: Does this work correctly for oneofs? */\n                pb_release_single_field(field);\n            }\n        \n            if (PB_HTYPE(field->type) == PB_HTYPE_ONEOF)\n            {\n                *(pb_size_t*)field->pSize = field->tag;\n            }\n\n            if (PB_LTYPE(field->type) == PB_LTYPE_STRING ||\n                PB_LTYPE(field->type) == PB_LTYPE_BYTES)\n            {\n                /* pb_dec_string and pb_dec_bytes handle allocation themselves */\n                field->pData = field->pField;\n                return decode_basic_field(stream, field);\n            }\n            else\n            {\n                if (!allocate_field(stream, field->pField, field->data_size, 1))\n                    return false;\n                \n                field->pData = *(void**)field->pField;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n    \n        case PB_HTYPE_REPEATED:\n            if (wire_type == PB_WT_STRING\n                && PB_LTYPE(field->type) <= PB_LTYPE_LAST_PACKABLE)\n            {\n                /* Packed array, multiple items come in at once. */\n                bool status = true;\n                pb_size_t *size = (pb_size_t*)field->pSize;\n                size_t allocated_size = *size;\n                pb_istream_t substream;\n                \n                if (!pb_make_string_substream(stream, &substream))\n                    return false;\n                \n                while (substream.bytes_left)\n                {\n                    if ((size_t)*size + 1 > allocated_size)\n                    {\n                        /* Allocate more storage. This tries to guess the\n                         * number of remaining entries. Round the division\n                         * upwards. */\n                        allocated_size += (substream.bytes_left - 1) / field->data_size + 1;\n                        \n                        if (!allocate_field(&substream, field->pField, field->data_size, allocated_size))\n                        {\n                            status = false;\n                            break;\n                        }\n                    }\n\n                    /* Decode the array entry */\n                    field->pData = *(char**)field->pField + field->data_size * (*size);\n                    initialize_pointer_field(field->pData, field);\n                    if (!decode_basic_field(&substream, field))\n                    {\n                        status = false;\n                        break;\n                    }\n                    \n                    if (*size == PB_SIZE_MAX)\n                    {\n#ifndef PB_NO_ERRMSG\n                        stream->errmsg = \"too many array entries\";\n#endif\n                        status = false;\n                        break;\n                    }\n                    \n                    (*size)++;\n                }\n                if (!pb_close_string_substream(stream, &substream))\n                    return false;\n                \n                return status;\n            }\n            else\n            {\n                /* Normal repeated field, i.e. only one item at a time. */\n                pb_size_t *size = (pb_size_t*)field->pSize;\n\n                if (*size == PB_SIZE_MAX)\n                    PB_RETURN_ERROR(stream, \"too many array entries\");\n                \n                if (!check_wire_type(wire_type, field))\n                    PB_RETURN_ERROR(stream, \"wrong wire type\");\n\n                if (!allocate_field(stream, field->pField, field->data_size, (size_t)(*size + 1)))\n                    return false;\n            \n                field->pData = *(char**)field->pField + field->data_size * (*size);\n                (*size)++;\n                initialize_pointer_field(field->pData, field);\n                return decode_basic_field(stream, field);\n            }\n\n        default:\n            PB_RETURN_ERROR(stream, \"invalid field type\");\n    }\n#endif\n}", "commit_link": "github.com/nanopb/nanopb/commit/45582f1f97f49e2abfdba1463d1e1027682d9856", "file_name": "pb_decode.c", "vul_type": "cwe-125", "description": "Write a C function named `decode_pointer_field` that decodes a field from a protocol buffer stream, handling different field types and memory allocation."}
{"func_name": "concat_hash_string", "func_src_before": "static u_int16_t concat_hash_string(struct ndpi_packet_struct *packet,\n\t\t\t\t   char *buf, u_int8_t client_hash) {\n  u_int16_t offset = 22, buf_out_len = 0;\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  u_int32_t len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4;\n\n  /* -1 for ';' */\n  if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n    goto invalid_payload;\n\n  /* ssh.kex_algorithms [C/S] */\n  strncpy(buf, (const char *)&packet->payload[offset], buf_out_len = len);\n  buf[buf_out_len++] = ';';\n  offset += len;\n\n  /* ssh.server_host_key_algorithms [None] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4 + len;\n\n  /* ssh.encryption_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.encryption_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.mac_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.mac_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_client_to_server [C] */\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.languages_client_to_server [None] */\n\n  /* ssh.languages_server_to_client [None] */\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] %s\\n\", buf);\n#endif\n\n  return(buf_out_len);\n\ninvalid_payload:\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] Invalid packet payload\\n\");\n#endif\n\n  return(0);\n}", "func_src_after": "static u_int16_t concat_hash_string(struct ndpi_packet_struct *packet,\n\t\t\t\t   char *buf, u_int8_t client_hash) {\n  u_int16_t offset = 22, buf_out_len = 0;\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  u_int32_t len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4;\n\n  /* -1 for ';' */\n  if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n    goto invalid_payload;\n\n  /* ssh.kex_algorithms [C/S] */\n  strncpy(buf, (const char *)&packet->payload[offset], buf_out_len = len);\n  buf[buf_out_len++] = ';';\n  offset += len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.server_host_key_algorithms [None] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n  offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.encryption_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.encryption_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.mac_algorithms_client_to_server [C] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.mac_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    buf[buf_out_len++] = ';';\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.compression_algorithms_client_to_server [C] */\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  if(offset+sizeof(u_int32_t) >= packet->payload_packet_len)\n    goto invalid_payload;\n  /* ssh.compression_algorithms_server_to_client [S] */\n  len = ntohl(*(u_int32_t*)&packet->payload[offset]);\n\n  if(!client_hash) {\n    offset += 4;\n\n    if((offset >= packet->payload_packet_len) || (len >= packet->payload_packet_len-offset-1))\n      goto invalid_payload;\n\n    strncpy(&buf[buf_out_len], (const char *)&packet->payload[offset], len);\n    buf_out_len += len;\n    offset += len;\n  } else\n    offset += 4 + len;\n\n  /* ssh.languages_client_to_server [None] */\n\n  /* ssh.languages_server_to_client [None] */\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] %s\\n\", buf);\n#endif\n\n  return(buf_out_len);\n\ninvalid_payload:\n\n#ifdef SSH_DEBUG\n  printf(\"[SSH] Invalid packet payload\\n\");\n#endif\n\n  return(0);\n}", "commit_link": "github.com/ntop/nDPI/commit/3bbb0cd3296023f6f922c71d21a1c374d2b0a435", "file_name": "src/lib/protocols/ssh.c", "vul_type": "cwe-125", "description": "Write a C function to concatenate SSH protocol fields into a buffer, handling client or server hash conditions."}
{"func_name": "ReadWPGImage", "func_src_before": "static Image *ReadWPGImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  typedef struct\n  {\n    size_t FileId;\n    MagickOffsetType DataOffset;\n    unsigned int ProductType;\n    unsigned int FileType;\n    unsigned char MajorVersion;\n    unsigned char MinorVersion;\n    unsigned int EncryptKey;\n    unsigned int Reserved;\n  } WPGHeader;\n\n  typedef struct\n  {\n    unsigned char RecType;\n    size_t RecordLength;\n  } WPGRecord;\n\n  typedef struct\n  {\n    unsigned char Class;\n    unsigned char RecType;\n    size_t Extension;\n    size_t RecordLength;\n  } WPG2Record;\n\n  typedef struct\n  {\n    unsigned  HorizontalUnits;\n    unsigned  VerticalUnits;\n    unsigned char PosSizePrecision;\n  } WPG2Start;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType1;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned char Depth;\n    unsigned char Compression;\n  } WPG2BitmapType1;\n\n  typedef struct\n  {\n    unsigned int RotAngle;\n    unsigned int LowLeftX;\n    unsigned int LowLeftY;\n    unsigned int UpRightX;\n    unsigned int UpRightY;\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType2;\n\n  typedef struct\n  {\n    unsigned int StartIndex;\n    unsigned int NumOfEntries;\n  } WPGColorMapRec;\n\n  /*\n  typedef struct {\n    size_t PS_unknown1;\n    unsigned int PS_unknown2;\n    unsigned int PS_unknown3;\n  } WPGPSl1Record;  \n  */\n\n  Image\n    *image;\n\n  unsigned int\n    status;\n\n  WPGHeader\n    Header;\n\n  WPGRecord\n    Rec;\n\n  WPG2Record\n    Rec2;\n\n  WPG2Start StartWPG;\n\n  WPGBitmapType1\n    BitmapHeader1;\n\n  WPG2BitmapType1\n    Bitmap2Header1;\n\n  WPGBitmapType2\n    BitmapHeader2;\n\n  WPGColorMapRec\n    WPG_Palette;\n\n  int\n    i,\n    bpp,\n    WPG2Flags;\n\n  ssize_t\n    ldblk;\n\n  size_t\n    one;\n\n  unsigned char\n    *BImgBuff;\n\n  tCTM CTM;         /*current transform matrix*/\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  one=1;\n  image=AcquireImage(image_info,exception);\n  image->depth=8;\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read WPG image.\n  */\n  Header.FileId=ReadBlobLSBLong(image);\n  Header.DataOffset=(MagickOffsetType) ReadBlobLSBLong(image);\n  Header.ProductType=ReadBlobLSBShort(image);\n  Header.FileType=ReadBlobLSBShort(image);\n  Header.MajorVersion=ReadBlobByte(image);\n  Header.MinorVersion=ReadBlobByte(image);\n  Header.EncryptKey=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.FileId!=0x435057FF || (Header.ProductType>>8)!=0x16)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (Header.EncryptKey!=0)\n    ThrowReaderException(CoderError,\"EncryptedWPGImageFileNotSupported\");\n\n  image->columns = 1;\n  image->rows = 1;\n  image->colors = 0;\n  bpp=0;\n  BitmapHeader2.RotAngle=0;\n\n  switch(Header.FileType)\n    {\n    case 1:     /* WPG level 1 */\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec.RecordLength;\n\n          switch(Rec.RecType)\n            {\n            case 0x0B: /* bitmap type 1 */\n              BitmapHeader1.Width=ReadBlobLSBShort(image);\n              BitmapHeader1.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader1.Width == 0) || (BitmapHeader1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader1.Depth=ReadBlobLSBShort(image);\n              BitmapHeader1.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader1.VertRes=ReadBlobLSBShort(image);\n\n              if(BitmapHeader1.HorzRes && BitmapHeader1.VertRes)\n                {\n                  image->units=PixelsPerCentimeterResolution;\n                  image->resolution.x=BitmapHeader1.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader1.VertRes/470.0;\n                }\n              image->columns=BitmapHeader1.Width;\n              image->rows=BitmapHeader1.Height;\n              bpp=BitmapHeader1.Depth;\n\n              goto UnpackRaster;\n\n            case 0x0E:  /*Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (!AcquireImageColormap(image,image->colors,exception))\n                goto NoMemory;\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                }\n              break;\n     \n            case 0x11:  /* Start PS l1 */\n              if(Rec.RecordLength > 8)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+8,   /* skip PS header in the wpg */\n                  (ssize_t) Rec.RecordLength-8,exception);\n              break;     \n\n            case 0x14:  /* bitmap type 2 */\n              BitmapHeader2.RotAngle=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftX=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftY=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightX=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightY=ReadBlobLSBShort(image);\n              BitmapHeader2.Width=ReadBlobLSBShort(image);\n              BitmapHeader2.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader2.Width == 0) || (BitmapHeader2.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader2.Depth=ReadBlobLSBShort(image);\n              BitmapHeader2.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader2.VertRes=ReadBlobLSBShort(image);\n\n              image->units=PixelsPerCentimeterResolution;\n              image->page.width=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightX)/470.0);\n              image->page.height=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightY)/470.0);\n              image->page.x=(int) (BitmapHeader2.LowLeftX/470.0);\n              image->page.y=(int) (BitmapHeader2.LowLeftX/470.0);\n              if(BitmapHeader2.HorzRes && BitmapHeader2.VertRes)\n                {\n                  image->resolution.x=BitmapHeader2.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader2.VertRes/470.0;\n                }\n              image->columns=BitmapHeader2.Width;\n              image->rows=BitmapHeader2.Height;\n              bpp=BitmapHeader2.Depth;\n\n            UnpackRaster:      \n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    {\n                    NoMemory:\n                      ThrowReaderException(ResourceLimitError,\n                        \"MemoryAllocationFailed\");\n                    }\n                  /* printf(\"Load default colormap \\n\"); */\n                  for (i=0; (i < (int) image->colors) && (i < 256); i++)\n                    {               \n                      image->colormap[i].red=ScaleCharToQuantum(WPG1_Palette[i].Red);\n                      image->colormap[i].green=ScaleCharToQuantum(WPG1_Palette[i].Green);\n                      image->colormap[i].blue=ScaleCharToQuantum(WPG1_Palette[i].Blue);\n                    }\n                }\n              else\n                {\n                  if (bpp < 24)\n                    if ( (image->colors < (one << bpp)) && (bpp != 24) )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                        image->colormap,(size_t) (one << bpp),\n                        sizeof(*image->colormap));\n                }\n          \n              if (bpp == 1)\n                {\n                  if(image->colormap[0].red==0 &&\n                     image->colormap[0].green==0 &&\n                     image->colormap[0].blue==0 &&\n                     image->colormap[1].red==0 &&\n                     image->colormap[1].green==0 &&\n                     image->colormap[1].blue==0)\n                    {  /* fix crippled monochrome palette */\n                      image->colormap[1].red =\n                        image->colormap[1].green =\n                        image->colormap[1].blue = QuantumRange;\n                    }\n                }      \n\n              if(UnpackWPGRaster(image,bpp,exception) < 0)\n                /* The raster cannot be unpacked */\n                {\n                DecompressionFailed:\n                  ThrowReaderException(CoderError,\"UnableToDecompressImage\");\n                    }\n\n              if(Rec.RecType==0x14 && BitmapHeader2.RotAngle!=0 && !image_info->ping)\n                {  \n                  /* flop command */\n                  if(BitmapHeader2.RotAngle & 0x8000)\n                    {\n                      Image\n                        *flop_image;\n\n                      flop_image = FlopImage(image, exception);\n                      if (flop_image != (Image *) NULL) {\n                        DuplicateBlob(flop_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flop_image);\n                      }\n                    }\n                  /* flip command */\n                  if(BitmapHeader2.RotAngle & 0x2000)\n                    {\n                      Image\n                        *flip_image;\n\n                      flip_image = FlipImage(image, exception);\n                      if (flip_image != (Image *) NULL) {\n                        DuplicateBlob(flip_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flip_image);    \n                      }\n                    }\n    \n      /* rotate command */\n                  if(BitmapHeader2.RotAngle & 0x0FFF)\n                    {\n                      Image\n                        *rotate_image;\n\n                      rotate_image=RotateImage(image,(BitmapHeader2.RotAngle &\n                        0x0FFF), exception);\n                      if (rotate_image != (Image *) NULL) {\n                        DuplicateBlob(rotate_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,rotate_image);    \n                      }\n                    }                \n                }\n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=0;\n              image->colors=0;\n              break;\n\n            case 0x1B:  /* Postscript l2 */\n              if(Rec.RecordLength>0x3C)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+0x3C,   /* skip PS l2 header in the wpg */\n                  (ssize_t) Rec.RecordLength-0x3C,exception);\n              break;\n            }\n        }\n      break;\n\n    case 2:  /* WPG level 2 */\n      (void) memset(CTM,0,sizeof(CTM));\n      StartWPG.PosSizePrecision = 0;\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec2.Class=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rec2.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec2.Extension);\n          Rd_WP_DWORD(image,&Rec2.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec2.RecordLength;\n\n          switch(Rec2.RecType)\n            {\n      case 1:\n              StartWPG.HorizontalUnits=ReadBlobLSBShort(image);\n              StartWPG.VerticalUnits=ReadBlobLSBShort(image);\n              StartWPG.PosSizePrecision=ReadBlobByte(image);\n              break;\n            case 0x0C:    /* Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  (void) ReadBlobByte(image);   /*Opacity??*/\n                }\n              break;\n            case 0x0E:\n              Bitmap2Header1.Width=ReadBlobLSBShort(image);\n              Bitmap2Header1.Height=ReadBlobLSBShort(image);\n              if ((Bitmap2Header1.Width == 0) || (Bitmap2Header1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              Bitmap2Header1.Depth=ReadBlobByte(image);\n              Bitmap2Header1.Compression=ReadBlobByte(image);\n\n              if(Bitmap2Header1.Compression > 1)\n                continue; /*Unknown compression method */\n              switch(Bitmap2Header1.Depth)\n                {\n                case 1:\n                  bpp=1;\n                  break;\n                case 2:\n                  bpp=2;\n                  break;\n                case 3:\n                  bpp=4;\n                  break;\n                case 4:\n                  bpp=8;\n                  break;\n                case 8:\n                  bpp=24;\n                  break;\n                default:\n                  continue;  /*Ignore raster with unknown depth*/\n                }\n              image->columns=Bitmap2Header1.Width;\n              image->rows=Bitmap2Header1.Height;  \n\n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  size_t\n                    one;\n\n                  one=1;\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    goto NoMemory;\n                }\n              else\n                {\n                  if(bpp < 24)\n                    if( image->colors<(one << bpp) && bpp!=24 )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                       image->colormap,(size_t) (one << bpp),\n                       sizeof(*image->colormap));\n                }\n\n\n              switch(Bitmap2Header1.Compression)\n                {\n                case 0:    /*Uncompressed raster*/\n                  {\n                    ldblk=(ssize_t) ((bpp*image->columns+7)/8);\n                    BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t)\n                      ldblk+1,sizeof(*BImgBuff));\n                    if (BImgBuff == (unsigned char *) NULL)\n                      goto NoMemory;\n\n                    for(i=0; i< (ssize_t) image->rows; i++)\n                      {\n                        (void) ReadBlob(image,ldblk,BImgBuff);\n                        InsertRow(image,BImgBuff,i,bpp,exception);\n                      }\n\n                    if(BImgBuff)\n                      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);;\n                    break;\n                  }\n                case 1:    /*RLE for WPG2 */\n                  {\n                    if( UnpackWPG2Raster(image,bpp,exception) < 0)\n                      goto DecompressionFailed;\n                    break;\n                  }   \n                }\n\n              if(CTM[0][0]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flop_image;\n\n                  flop_image = FlopImage(image, exception);\n                  if (flop_image != (Image *) NULL) {\n                    DuplicateBlob(flop_image,image);\n                    (void) RemoveLastImageFromList(&image);\n                    AppendImageToList(&image,flop_image);\n                  }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.      \n                     Tx(0,0)=-1;      Tx(1,0)=0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;      Tx(1,1)=1;   Tx(2,1)=0;\n                     Tx(0,2)=(WPG._2Rect.X_ur+WPG._2Rect.X_ll);\n                     Tx(1,2)=0;   Tx(2,2)=1; */                  \n                }\n              if(CTM[1][1]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flip_image;\n\n                   flip_image = FlipImage(image, exception);\n                   if (flip_image != (Image *) NULL) {\n                     DuplicateBlob(flip_image,image);\n                     (void) RemoveLastImageFromList(&image);\n                     AppendImageToList(&image,flip_image);\n                    }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.\n                     float_matrix Tx(3,3);\n                     Tx(0,0)= 1;   Tx(1,0)= 0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;   Tx(1,1)=-1;   Tx(2,1)=0;\n                     Tx(0,2)= 0;   Tx(1,2)=(WPG._2Rect.Y_ur+WPG._2Rect.Y_ll);\n                     Tx(2,2)=1; */      \n              }    \n    \n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=1;\n              image->colors=0;\n              break;\n\n            case 0x12:  /* Postscript WPG2*/\n        i=ReadBlobLSBShort(image);\n              if(Rec2.RecordLength > (unsigned int) i)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+i,    /*skip PS header in the wpg2*/\n                  (ssize_t) (Rec2.RecordLength-i-2),exception);\n              break;\n\n      case 0x1B:          /*bitmap rectangle*/\n              WPG2Flags = LoadWPG2Flags(image,StartWPG.PosSizePrecision,NULL,&CTM);\n              (void) WPG2Flags;\n              break;\n            }\n        }\n\n      break;\n\n    default:\n      {\n         ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n      }\n   }\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n Finish:\n  (void) CloseBlob(image);\n\n  {\n    Image\n      *p;\n\n    ssize_t\n      scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    /*\n      Fix scene numbers.\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=(size_t) scene++;\n  }\n  if (image == (Image *) NULL)\n    ThrowReaderException(CorruptImageError,\n      \"ImageFileDoesNotContainAnyImageData\");\n  return(image);\n}", "func_src_after": "static Image *ReadWPGImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n  typedef struct\n  {\n    size_t FileId;\n    MagickOffsetType DataOffset;\n    unsigned int ProductType;\n    unsigned int FileType;\n    unsigned char MajorVersion;\n    unsigned char MinorVersion;\n    unsigned int EncryptKey;\n    unsigned int Reserved;\n  } WPGHeader;\n\n  typedef struct\n  {\n    unsigned char RecType;\n    size_t RecordLength;\n  } WPGRecord;\n\n  typedef struct\n  {\n    unsigned char Class;\n    unsigned char RecType;\n    size_t Extension;\n    size_t RecordLength;\n  } WPG2Record;\n\n  typedef struct\n  {\n    unsigned  HorizontalUnits;\n    unsigned  VerticalUnits;\n    unsigned char PosSizePrecision;\n  } WPG2Start;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType1;\n\n  typedef struct\n  {\n    unsigned int Width;\n    unsigned int Height;\n    unsigned char Depth;\n    unsigned char Compression;\n  } WPG2BitmapType1;\n\n  typedef struct\n  {\n    unsigned int RotAngle;\n    unsigned int LowLeftX;\n    unsigned int LowLeftY;\n    unsigned int UpRightX;\n    unsigned int UpRightY;\n    unsigned int Width;\n    unsigned int Height;\n    unsigned int Depth;\n    unsigned int HorzRes;\n    unsigned int VertRes;\n  } WPGBitmapType2;\n\n  typedef struct\n  {\n    unsigned int StartIndex;\n    unsigned int NumOfEntries;\n  } WPGColorMapRec;\n\n  /*\n  typedef struct {\n    size_t PS_unknown1;\n    unsigned int PS_unknown2;\n    unsigned int PS_unknown3;\n  } WPGPSl1Record;  \n  */\n\n  Image\n    *image;\n\n  unsigned int\n    status;\n\n  WPGHeader\n    Header;\n\n  WPGRecord\n    Rec;\n\n  WPG2Record\n    Rec2;\n\n  WPG2Start StartWPG;\n\n  WPGBitmapType1\n    BitmapHeader1;\n\n  WPG2BitmapType1\n    Bitmap2Header1;\n\n  WPGBitmapType2\n    BitmapHeader2;\n\n  WPGColorMapRec\n    WPG_Palette;\n\n  int\n    i,\n    bpp,\n    WPG2Flags;\n\n  ssize_t\n    ldblk;\n\n  size_t\n    one;\n\n  unsigned char\n    *BImgBuff;\n\n  tCTM CTM;         /*current transform matrix*/\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  one=1;\n  image=AcquireImage(image_info,exception);\n  image->depth=8;\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read WPG image.\n  */\n  Header.FileId=ReadBlobLSBLong(image);\n  Header.DataOffset=(MagickOffsetType) ReadBlobLSBLong(image);\n  Header.ProductType=ReadBlobLSBShort(image);\n  Header.FileType=ReadBlobLSBShort(image);\n  Header.MajorVersion=ReadBlobByte(image);\n  Header.MinorVersion=ReadBlobByte(image);\n  Header.EncryptKey=ReadBlobLSBShort(image);\n  Header.Reserved=ReadBlobLSBShort(image);\n\n  if (Header.FileId!=0x435057FF || (Header.ProductType>>8)!=0x16)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (Header.EncryptKey!=0)\n    ThrowReaderException(CoderError,\"EncryptedWPGImageFileNotSupported\");\n\n  image->columns = 1;\n  image->rows = 1;\n  image->colors = 0;\n  bpp=0;\n  BitmapHeader2.RotAngle=0;\n\n  switch(Header.FileType)\n    {\n    case 1:     /* WPG level 1 */\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec.RecordLength;\n\n          switch(Rec.RecType)\n            {\n            case 0x0B: /* bitmap type 1 */\n              BitmapHeader1.Width=ReadBlobLSBShort(image);\n              BitmapHeader1.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader1.Width == 0) || (BitmapHeader1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader1.Depth=ReadBlobLSBShort(image);\n              BitmapHeader1.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader1.VertRes=ReadBlobLSBShort(image);\n\n              if(BitmapHeader1.HorzRes && BitmapHeader1.VertRes)\n                {\n                  image->units=PixelsPerCentimeterResolution;\n                  image->resolution.x=BitmapHeader1.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader1.VertRes/470.0;\n                }\n              image->columns=BitmapHeader1.Width;\n              image->rows=BitmapHeader1.Height;\n              bpp=BitmapHeader1.Depth;\n\n              goto UnpackRaster;\n\n            case 0x0E:  /*Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (!AcquireImageColormap(image,image->colors,exception))\n                goto NoMemory;\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n                    ReadBlobByte(image));\n                }\n              break;\n     \n            case 0x11:  /* Start PS l1 */\n              if(Rec.RecordLength > 8)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+8,   /* skip PS header in the wpg */\n                  (ssize_t) Rec.RecordLength-8,exception);\n              break;     \n\n            case 0x14:  /* bitmap type 2 */\n              BitmapHeader2.RotAngle=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftX=ReadBlobLSBShort(image);\n              BitmapHeader2.LowLeftY=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightX=ReadBlobLSBShort(image);\n              BitmapHeader2.UpRightY=ReadBlobLSBShort(image);\n              BitmapHeader2.Width=ReadBlobLSBShort(image);\n              BitmapHeader2.Height=ReadBlobLSBShort(image);\n              if ((BitmapHeader2.Width == 0) || (BitmapHeader2.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              BitmapHeader2.Depth=ReadBlobLSBShort(image);\n              BitmapHeader2.HorzRes=ReadBlobLSBShort(image);\n              BitmapHeader2.VertRes=ReadBlobLSBShort(image);\n\n              image->units=PixelsPerCentimeterResolution;\n              image->page.width=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightX)/470.0);\n              image->page.height=(unsigned int)\n                ((BitmapHeader2.LowLeftX-BitmapHeader2.UpRightY)/470.0);\n              image->page.x=(int) (BitmapHeader2.LowLeftX/470.0);\n              image->page.y=(int) (BitmapHeader2.LowLeftX/470.0);\n              if(BitmapHeader2.HorzRes && BitmapHeader2.VertRes)\n                {\n                  image->resolution.x=BitmapHeader2.HorzRes/470.0;\n                  image->resolution.y=BitmapHeader2.VertRes/470.0;\n                }\n              image->columns=BitmapHeader2.Width;\n              image->rows=BitmapHeader2.Height;\n              bpp=BitmapHeader2.Depth;\n\n            UnpackRaster:      \n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    {\n                    NoMemory:\n                      ThrowReaderException(ResourceLimitError,\n                        \"MemoryAllocationFailed\");\n                    }\n                  /* printf(\"Load default colormap \\n\"); */\n                  for (i=0; (i < (int) image->colors) && (i < 256); i++)\n                    {               \n                      image->colormap[i].red=ScaleCharToQuantum(WPG1_Palette[i].Red);\n                      image->colormap[i].green=ScaleCharToQuantum(WPG1_Palette[i].Green);\n                      image->colormap[i].blue=ScaleCharToQuantum(WPG1_Palette[i].Blue);\n                    }\n                }\n              else\n                {\n                  if (bpp < 24)\n                    if ( (image->colors < (one << bpp)) && (bpp != 24) )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                        image->colormap,(size_t) (one << bpp),\n                        sizeof(*image->colormap));\n                }\n          \n              if (bpp == 1)\n                {\n                  if(image->colormap[0].red==0 &&\n                     image->colormap[0].green==0 &&\n                     image->colormap[0].blue==0 &&\n                     image->colormap[1].red==0 &&\n                     image->colormap[1].green==0 &&\n                     image->colormap[1].blue==0)\n                    {  /* fix crippled monochrome palette */\n                      image->colormap[1].red =\n                        image->colormap[1].green =\n                        image->colormap[1].blue = QuantumRange;\n                    }\n                }      \n\n              if(UnpackWPGRaster(image,bpp,exception) < 0)\n                /* The raster cannot be unpacked */\n                {\n                DecompressionFailed:\n                  ThrowReaderException(CoderError,\"UnableToDecompressImage\");\n                    }\n\n              if(Rec.RecType==0x14 && BitmapHeader2.RotAngle!=0 && !image_info->ping)\n                {  \n                  /* flop command */\n                  if(BitmapHeader2.RotAngle & 0x8000)\n                    {\n                      Image\n                        *flop_image;\n\n                      flop_image = FlopImage(image, exception);\n                      if (flop_image != (Image *) NULL) {\n                        DuplicateBlob(flop_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flop_image);\n                      }\n                    }\n                  /* flip command */\n                  if(BitmapHeader2.RotAngle & 0x2000)\n                    {\n                      Image\n                        *flip_image;\n\n                      flip_image = FlipImage(image, exception);\n                      if (flip_image != (Image *) NULL) {\n                        DuplicateBlob(flip_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,flip_image);    \n                      }\n                    }\n    \n      /* rotate command */\n                  if(BitmapHeader2.RotAngle & 0x0FFF)\n                    {\n                      Image\n                        *rotate_image;\n\n                      rotate_image=RotateImage(image,(BitmapHeader2.RotAngle &\n                        0x0FFF), exception);\n                      if (rotate_image != (Image *) NULL) {\n                        DuplicateBlob(rotate_image,image);\n                        (void) RemoveLastImageFromList(&image);\n                        AppendImageToList(&image,rotate_image);    \n                      }\n                    }                \n                }\n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=0;\n              image->colors=0;\n              break;\n\n            case 0x1B:  /* Postscript l2 */\n              if(Rec.RecordLength>0x3C)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+0x3C,   /* skip PS l2 header in the wpg */\n                  (ssize_t) Rec.RecordLength-0x3C,exception);\n              break;\n            }\n        }\n      break;\n\n    case 2:  /* WPG level 2 */\n      (void) memset(CTM,0,sizeof(CTM));\n      StartWPG.PosSizePrecision = 0;\n      while(!EOFBlob(image)) /* object parser loop */\n        {\n          (void) SeekBlob(image,Header.DataOffset,SEEK_SET);\n          if(EOFBlob(image))\n            break;\n\n          Rec2.Class=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rec2.RecType=(i=ReadBlobByte(image));\n          if(i==EOF)\n            break;\n          Rd_WP_DWORD(image,&Rec2.Extension);\n          Rd_WP_DWORD(image,&Rec2.RecordLength);\n          if(EOFBlob(image))\n            break;\n\n          Header.DataOffset=TellBlob(image)+Rec2.RecordLength;\n\n          switch(Rec2.RecType)\n            {\n      case 1:\n              StartWPG.HorizontalUnits=ReadBlobLSBShort(image);\n              StartWPG.VerticalUnits=ReadBlobLSBShort(image);\n              StartWPG.PosSizePrecision=ReadBlobByte(image);\n              break;\n            case 0x0C:    /* Color palette */\n              WPG_Palette.StartIndex=ReadBlobLSBShort(image);\n              WPG_Palette.NumOfEntries=ReadBlobLSBShort(image);\n\n              image->colors=WPG_Palette.NumOfEntries;\n              if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n                ThrowReaderException(ResourceLimitError,\n                  \"MemoryAllocationFailed\");\n              for (i=WPG_Palette.StartIndex;\n                   i < (int)WPG_Palette.NumOfEntries; i++)\n                {\n                  image->colormap[i].red=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].green=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  image->colormap[i].blue=ScaleCharToQuantum((char)\n                    ReadBlobByte(image));\n                  (void) ReadBlobByte(image);   /*Opacity??*/\n                }\n              break;\n            case 0x0E:\n              Bitmap2Header1.Width=ReadBlobLSBShort(image);\n              Bitmap2Header1.Height=ReadBlobLSBShort(image);\n              if ((Bitmap2Header1.Width == 0) || (Bitmap2Header1.Height == 0))\n                ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n              Bitmap2Header1.Depth=ReadBlobByte(image);\n              Bitmap2Header1.Compression=ReadBlobByte(image);\n\n              if(Bitmap2Header1.Compression > 1)\n                continue; /*Unknown compression method */\n              switch(Bitmap2Header1.Depth)\n                {\n                case 1:\n                  bpp=1;\n                  break;\n                case 2:\n                  bpp=2;\n                  break;\n                case 3:\n                  bpp=4;\n                  break;\n                case 4:\n                  bpp=8;\n                  break;\n                case 8:\n                  bpp=24;\n                  break;\n                default:\n                  continue;  /*Ignore raster with unknown depth*/\n                }\n              image->columns=Bitmap2Header1.Width;\n              image->rows=Bitmap2Header1.Height;  \n\n              if ((image->colors == 0) && (bpp != 24))\n                {\n                  size_t\n                    one;\n\n                  one=1;\n                  image->colors=one << bpp;\n                  if (!AcquireImageColormap(image,image->colors,exception))\n                    goto NoMemory;\n                }\n              else\n                {\n                  if(bpp < 24)\n                    if( image->colors<(one << bpp) && bpp!=24 )\n                      image->colormap=(PixelInfo *) ResizeQuantumMemory(\n                       image->colormap,(size_t) (one << bpp),\n                       sizeof(*image->colormap));\n                }\n\n\n              switch(Bitmap2Header1.Compression)\n                {\n                case 0:    /*Uncompressed raster*/\n                  {\n                    ldblk=(ssize_t) ((bpp*image->columns+7)/8);\n                    BImgBuff=(unsigned char *) AcquireQuantumMemory((size_t)\n                      ldblk,sizeof(*BImgBuff));\n                    if (BImgBuff == (unsigned char *) NULL)\n                      goto NoMemory;\n\n                    for(i=0; i< (ssize_t) image->rows; i++)\n                      {\n                        (void) ReadBlob(image,ldblk,BImgBuff);\n                        InsertRow(image,BImgBuff,i,bpp,exception);\n                      }\n\n                    if(BImgBuff)\n                      BImgBuff=(unsigned char *) RelinquishMagickMemory(BImgBuff);;\n                    break;\n                  }\n                case 1:    /*RLE for WPG2 */\n                  {\n                    if( UnpackWPG2Raster(image,bpp,exception) < 0)\n                      goto DecompressionFailed;\n                    break;\n                  }   \n                }\n\n              if(CTM[0][0]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flop_image;\n\n                  flop_image = FlopImage(image, exception);\n                  if (flop_image != (Image *) NULL) {\n                    DuplicateBlob(flop_image,image);\n                    (void) RemoveLastImageFromList(&image);\n                    AppendImageToList(&image,flop_image);\n                  }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.      \n                     Tx(0,0)=-1;      Tx(1,0)=0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;      Tx(1,1)=1;   Tx(2,1)=0;\n                     Tx(0,2)=(WPG._2Rect.X_ur+WPG._2Rect.X_ll);\n                     Tx(1,2)=0;   Tx(2,2)=1; */                  \n                }\n              if(CTM[1][1]<0 && !image_info->ping)\n                {    /*?? RotAngle=360-RotAngle;*/\n                  Image\n                    *flip_image;\n\n                   flip_image = FlipImage(image, exception);\n                   if (flip_image != (Image *) NULL) {\n                     DuplicateBlob(flip_image,image);\n                     (void) RemoveLastImageFromList(&image);\n                     AppendImageToList(&image,flip_image);\n                    }\n                  /* Try to change CTM according to Flip - I am not sure, must be checked.\n                     float_matrix Tx(3,3);\n                     Tx(0,0)= 1;   Tx(1,0)= 0;   Tx(2,0)=0;\n                     Tx(0,1)= 0;   Tx(1,1)=-1;   Tx(2,1)=0;\n                     Tx(0,2)= 0;   Tx(1,2)=(WPG._2Rect.Y_ur+WPG._2Rect.Y_ll);\n                     Tx(2,2)=1; */      \n              }    \n    \n\n              /* Allocate next image structure. */\n              AcquireNextImage(image_info,image,exception);\n              image->depth=8;\n              if (image->next == (Image *) NULL)\n                goto Finish;\n              image=SyncNextImageInList(image);\n              image->columns=image->rows=1;\n              image->colors=0;\n              break;\n\n            case 0x12:  /* Postscript WPG2*/\n        i=ReadBlobLSBShort(image);\n              if(Rec2.RecordLength > (unsigned int) i)\n                image=ExtractPostscript(image,image_info,\n                  TellBlob(image)+i,    /*skip PS header in the wpg2*/\n                  (ssize_t) (Rec2.RecordLength-i-2),exception);\n              break;\n\n      case 0x1B:          /*bitmap rectangle*/\n              WPG2Flags = LoadWPG2Flags(image,StartWPG.PosSizePrecision,NULL,&CTM);\n              (void) WPG2Flags;\n              break;\n            }\n        }\n\n      break;\n\n    default:\n      {\n         ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n      }\n   }\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n\n Finish:\n  (void) CloseBlob(image);\n\n  {\n    Image\n      *p;\n\n    ssize_t\n      scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n    /*\n      Fix scene numbers.\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=(size_t) scene++;\n  }\n  if (image == (Image *) NULL)\n    ThrowReaderException(CorruptImageError,\n      \"ImageFileDoesNotContainAnyImageData\");\n  return(image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/bef1e4f637d8f665bc133a9c6d30df08d983bc3a", "file_name": "coders/wpg.c", "vul_type": "cwe-125", "description": "Write a C function to read and process WPG images."}
{"func_name": "audio_sample_entry_Read", "func_src_before": "GF_Err audio_sample_entry_Read(GF_Box *s, GF_BitStream *bs)\n{\n\tGF_MPEGAudioSampleEntryBox *ptr;\n\tchar *data;\n\tu8 a, b, c, d;\n\tu32 i, size, v, nb_alnum;\n\tGF_Err e;\n\tu64 pos, start;\n\n\tptr = (GF_MPEGAudioSampleEntryBox *)s;\n\n\tstart = gf_bs_get_position(bs);\n\tgf_bs_seek(bs, start + 8);\n\tv = gf_bs_read_u16(bs);\n\tif (v)\n\t\tptr->is_qtff = 1;\n\n\t//try to disambiguate QTFF v1 and MP4 v1 audio sample entries ...\n\tif (v==1) {\n\t\t//go to end of ISOM audio sample entry, skip 4 byte (box size field), read 4 bytes (box type) and check if this looks like a box\n\t\tgf_bs_seek(bs, start + 8 + 20  + 4);\n\t\ta = gf_bs_read_u8(bs);\n\t\tb = gf_bs_read_u8(bs);\n\t\tc = gf_bs_read_u8(bs);\n\t\td = gf_bs_read_u8(bs);\n\t\tnb_alnum = 0;\n\t\tif (isalnum(a)) nb_alnum++;\n\t\tif (isalnum(b)) nb_alnum++;\n\t\tif (isalnum(c)) nb_alnum++;\n\t\tif (isalnum(d)) nb_alnum++;\n\t\tif (nb_alnum>2) ptr->is_qtff = 0;\n\t}\n\n\tgf_bs_seek(bs, start);\n\te = gf_isom_audio_sample_entry_read((GF_AudioSampleEntryBox*)s, bs);\n\tif (e) return e;\n\tpos = gf_bs_get_position(bs);\n\tsize = (u32) s->size;\n\n\t//when cookie is set on bs, always convert qtff-style mp4a to isobmff-style\n\t//since the conversion is done in addBox and we don't have the bitstream there (arg...), flag the box\n \tif (gf_bs_get_cookie(bs)) {\n \t\tptr->is_qtff |= 1<<16;\n \t}\n\n\te = gf_isom_box_array_read(s, bs, audio_sample_entry_AddBox);\n\tif (!e) return GF_OK;\n\tif (size<8) return GF_ISOM_INVALID_FILE;\n\n\t/*hack for some weird files (possibly recorded with live.com tools, needs further investigations)*/\n\tgf_bs_seek(bs, pos);\n\tdata = (char*)gf_malloc(sizeof(char) * size);\n\tgf_bs_read_data(bs, data, size);\n\tfor (i=0; i<size-8; i++) {\n\t\tif (GF_4CC((u32)data[i+4], (u8)data[i+5], (u8)data[i+6], (u8)data[i+7]) == GF_ISOM_BOX_TYPE_ESDS) {\n\t\t\tGF_BitStream *mybs = gf_bs_new(data + i, size - i, GF_BITSTREAM_READ);\n\t\t\tif (ptr->esd) {\n\t\t\t\tgf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\te = gf_isom_box_parse((GF_Box **)&ptr->esd, mybs);\n\n\t\t\tif (e==GF_OK) {\n\t\t\t\tgf_isom_box_add_for_dump_mode((GF_Box*)ptr, (GF_Box*)ptr->esd);\n\t\t\t} else if (ptr->esd) {\n\t\t\t\tgf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\tgf_bs_del(mybs);\n\t\t\tbreak;\n\t\t}\n\t}\n\tgf_free(data);\n\treturn e;\n}", "func_src_after": "GF_Err audio_sample_entry_Read(GF_Box *s, GF_BitStream *bs)\n{\n\tGF_MPEGAudioSampleEntryBox *ptr;\n\tchar *data;\n\tu8 a, b, c, d;\n\tu32 i, size, v, nb_alnum;\n\tGF_Err e;\n\tu64 pos, start;\n\n\tptr = (GF_MPEGAudioSampleEntryBox *)s;\n\n\tstart = gf_bs_get_position(bs);\n\tgf_bs_seek(bs, start + 8);\n\tv = gf_bs_read_u16(bs);\n\tif (v)\n\t\tptr->is_qtff = 1;\n\n\t//try to disambiguate QTFF v1 and MP4 v1 audio sample entries ...\n\tif (v==1) {\n\t\t//go to end of ISOM audio sample entry, skip 4 byte (box size field), read 4 bytes (box type) and check if this looks like a box\n\t\tgf_bs_seek(bs, start + 8 + 20  + 4);\n\t\ta = gf_bs_read_u8(bs);\n\t\tb = gf_bs_read_u8(bs);\n\t\tc = gf_bs_read_u8(bs);\n\t\td = gf_bs_read_u8(bs);\n\t\tnb_alnum = 0;\n\t\tif (isalnum(a)) nb_alnum++;\n\t\tif (isalnum(b)) nb_alnum++;\n\t\tif (isalnum(c)) nb_alnum++;\n\t\tif (isalnum(d)) nb_alnum++;\n\t\tif (nb_alnum>2) ptr->is_qtff = 0;\n\t}\n\n\tgf_bs_seek(bs, start);\n\te = gf_isom_audio_sample_entry_read((GF_AudioSampleEntryBox*)s, bs);\n\tif (e) return e;\n\tpos = gf_bs_get_position(bs);\n\tsize = (u32) s->size;\n\n\t//when cookie is set on bs, always convert qtff-style mp4a to isobmff-style\n\t//since the conversion is done in addBox and we don't have the bitstream there (arg...), flag the box\n \tif (gf_bs_get_cookie(bs)) {\n \t\tptr->is_qtff |= 1<<16;\n \t}\n\n\te = gf_isom_box_array_read(s, bs, audio_sample_entry_AddBox);\n\tif (!e) return GF_OK;\n\tif (size<8) return GF_ISOM_INVALID_FILE;\n\n\t/*hack for some weird files (possibly recorded with live.com tools, needs further investigations)*/\n\tgf_bs_seek(bs, pos);\n\tdata = (char*)gf_malloc(sizeof(char) * size);\n\tgf_bs_read_data(bs, data, size);\n\tfor (i=0; i<size-8; i++) {\n\t\tif (GF_4CC((u32)data[i+4], (u8)data[i+5], (u8)data[i+6], (u8)data[i+7]) == GF_ISOM_BOX_TYPE_ESDS) {\n\t\t\textern Bool use_dump_mode;\n\t\t\tGF_BitStream *mybs = gf_bs_new(data + i, size - i, GF_BITSTREAM_READ);\n\t\t\tif (ptr->esd) {\n\t\t\t\tif (!use_dump_mode) gf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\te = gf_isom_box_parse((GF_Box **)&ptr->esd, mybs);\n\n\t\t\tif (e==GF_OK) {\n\t\t\t\tgf_isom_box_add_for_dump_mode((GF_Box*)ptr, (GF_Box*)ptr->esd);\n\t\t\t} else if (ptr->esd) {\n\t\t\t\tgf_isom_box_del((GF_Box *)ptr->esd);\n\t\t\t\tptr->esd=NULL;\n\t\t\t}\n\n\t\t\tgf_bs_del(mybs);\n\t\t\tbreak;\n\t\t}\n\t}\n\tgf_free(data);\n\treturn e;\n}", "commit_link": "github.com/gpac/gpac/commit/6063b1a011c3f80cee25daade18154e15e4c058c", "file_name": "src/isomedia/box_code_base.c", "vul_type": "cwe-416", "description": "Write a C function named `audio_sample_entry_Read` that reads and processes an audio sample entry from a bitstream."}
{"func_name": "wwunpack", "func_src_before": "int wwunpack(uint8_t *exe, uint32_t exesz, uint8_t *wwsect, struct cli_exe_section *sects, uint16_t scount, uint32_t pe, int desc) {\n  uint8_t *structs = wwsect + 0x2a1, *compd, *ccur, *unpd, *ucur, bc;\n  uint32_t src, srcend, szd, bt, bits;\n  int error=0, i;\n\n  cli_dbgmsg(\"in wwunpack\\n\");\n  while (1) {\n    if (!CLI_ISCONTAINED(wwsect, sects[scount].rsz, structs, 17)) {\n      cli_dbgmsg(\"WWPack: Array of structs out of section\\n\");\n      break;\n    }\n    src = sects[scount].rva - cli_readint32(structs); /* src delta / dst delta - not used / dwords / end of src */\n    structs+=8;\n    szd = cli_readint32(structs) * 4;\n    structs+=4;\n    srcend = cli_readint32(structs);\n    structs+=4;\n\n    unpd = ucur = exe+src+srcend+4-szd;\n    if (!szd || !CLI_ISCONTAINED(exe, exesz, unpd, szd)) {\n      cli_dbgmsg(\"WWPack: Compressed data out of file\\n\");\n      break;\n    }\n    cli_dbgmsg(\"WWP: src: %x, szd: %x, srcend: %x - %x\\n\", src, szd, srcend, srcend+4-szd);\n    if (!(compd = cli_malloc(szd))) {\n        cli_dbgmsg(\"WWPack: Unable to allocate memory for compd\\n\");\n        break;\n    }\n    memcpy(compd, unpd, szd);\n    memset(unpd, -1, szd); /*FIXME*/\n    ccur=compd;\n    \n    RESEED;\n    while(!error) {\n      uint32_t backbytes, backsize;\n      uint8_t saved;\n\n      BIT;\n      if (!bits) { /* BYTE copy */\n\tif(ccur-compd>=szd || !CLI_ISCONTAINED(exe, exesz, ucur, 1))\n\t  error=1;\n\telse\n\t  *ucur++=*ccur++;\n\tcontinue;\n      }\n\n      BITS(2);\n      if(bits==3) { /* WORD backcopy */\n\tuint8_t shifted, subbed = 31;\n\tBITS(2);\n\tshifted = bits + 5;\n\tif(bits>=2) {\n\t  shifted++;\n\t  subbed += 0x80;\n\t}\n\tbackbytes = (1<<shifted)-subbed; /* 1h, 21h, 61h, 161h */\n\tBITS(shifted); /* 5, 6, 8, 9 */\n\tif(error || bits == 0x1ff) break;\n\tbackbytes+=bits;\n\tif(!CLI_ISCONTAINED(exe, exesz, ucur, 2) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, 2)) {\n\t  error=1;\n\t} else {\n\t  ucur[0]=*(ucur-backbytes);\n\t  ucur[1]=*(ucur-backbytes+1);\n\t  ucur+=2;\n\t}\n\tcontinue;\n      }\n\n      /* BLOCK backcopy */\n      saved = bits; /* cmp al, 1 / pushf */\n\n      BITS(3);\n      if (bits<6) {\n\tbackbytes = bits;\n\tswitch(bits) {\n\tcase 4: /* 10,11 */\n\t  backbytes++;\n\tcase 3: /* 8,9 */\n\t  BIT;\n\t  backbytes+=bits;\n\tcase 0:\tcase 1:\tcase 2: /* 5,6,7 */\n\t  backbytes+=5;\n\t  break;\n\tcase 5: /* 12 */\n\t  backbytes=12;\n\t  break;\n\t}\n\tBITS(backbytes);\n\tbits+=(1<<backbytes)-31;\n      } else if(bits==6) {\n\tBITS(0x0e);\n\tbits+=0x1fe1;\n      } else {\n\tBITS(0x0f);\n\tbits+=0x5fe1;\n      }\n\n      backbytes = bits;\n\n      /* popf / jb */\n      if (!saved) {\n\tBIT;\n\tif(!bits) {\n\t  BIT;\n\t  bits+=5;\n\t} else {\n\t  BITS(3);\n\t  if(bits) {\n\t    bits+=6;\n\t  } else {\n\t    BITS(4);\n\t    if(bits) {\n\t      bits+=13;\n\t    } else {\n\t      uint8_t cnt = 4;\n\t      uint16_t shifted = 0x0d;\n\t      \n\t      do {\n\t\tif(cnt==7) { cnt = 0x0e; shifted = 0; break; }\n\t\tshifted=((shifted+2)<<1)-1;\n\t\tBIT;\n\t\tcnt++;\n\t      } while(!bits);\n\t      BITS(cnt);\n\t      bits+=shifted;\n\t    }\n\t  }\n\t}\n\tbacksize = bits;\n      } else {\n\tbacksize = saved+2;\n      }\n\n      if(!CLI_ISCONTAINED(exe, exesz, ucur, backsize) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, backsize)) error=1;\n      else while(backsize--) {\n\t*ucur=*(ucur-backbytes);\n\tucur++;\n      }\n    }\n    free(compd);\n    if(error) {\n      cli_dbgmsg(\"WWPack: decompression error\\n\");\n      break;\n    }\n    if (error || !*structs++) break;\n  }\n\n  if(!error) {\n    if (pe+6 > exesz || pe+7 > exesz || pe+0x28 > exesz ||\n\t\tpe+0x50 > exesz || pe+0x14 > exesz) \n\treturn CL_EFORMAT;\n    exe[pe+6]=(uint8_t)scount;\n    exe[pe+7]=(uint8_t)(scount>>8);\n    cli_writeint32(&exe[pe+0x28], cli_readint32(wwsect+0x295)+sects[scount].rva+0x299);\n    cli_writeint32(&exe[pe+0x50], cli_readint32(&exe[pe+0x50])-sects[scount].vsz);\n\n    structs = &exe[(0xffff&cli_readint32(&exe[pe+0x14]))+pe+0x18];\n    for(i=0 ; i<scount ; i++) {\n\t  if (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t    cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t    return CL_EFORMAT;\n\t  }\n\n      cli_writeint32(structs+8, sects[i].vsz);\n      cli_writeint32(structs+12, sects[i].rva);\n      cli_writeint32(structs+16, sects[i].vsz);\n      cli_writeint32(structs+20, sects[i].rva);\n      structs+=0x28;\n    }\n\tif (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t  cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t  return CL_EFORMAT;\n\t}\n\n    memset(structs, 0, 0x28);\n    error = (uint32_t)cli_writen(desc, exe, exesz)!=exesz;\n  }\n  return error;\n}", "func_src_after": "int wwunpack(uint8_t *exe, uint32_t exesz, uint8_t *wwsect, struct cli_exe_section *sects, uint16_t scount, uint32_t pe, int desc) {\n  uint8_t *structs = wwsect + 0x2a1, *compd, *ccur, *unpd, *ucur, bc;\n  uint32_t src, srcend, szd, bt, bits;\n  int error=0, i;\n\n  cli_dbgmsg(\"in wwunpack\\n\");\n  while (1) {\n    if (!CLI_ISCONTAINED(wwsect, sects[scount].rsz, structs, 17)) {\n      cli_dbgmsg(\"WWPack: Array of structs out of section\\n\");\n      break;\n    }\n    src = sects[scount].rva - cli_readint32(structs); /* src delta / dst delta - not used / dwords / end of src */\n    structs+=8;\n    szd = cli_readint32(structs) * 4;\n    structs+=4;\n    srcend = cli_readint32(structs);\n    structs+=4;\n\n    unpd = ucur = exe+src+srcend+4-szd;\n    if (!szd || !CLI_ISCONTAINED(exe, exesz, unpd, szd)) {\n      cli_dbgmsg(\"WWPack: Compressed data out of file\\n\");\n      break;\n    }\n    cli_dbgmsg(\"WWP: src: %x, szd: %x, srcend: %x - %x\\n\", src, szd, srcend, srcend+4-szd);\n    if (!(compd = cli_malloc(szd))) {\n        cli_dbgmsg(\"WWPack: Unable to allocate memory for compd\\n\");\n        break;\n    }\n    memcpy(compd, unpd, szd);\n    memset(unpd, -1, szd); /*FIXME*/\n    ccur=compd;\n    \n    RESEED;\n    while(!error) {\n      uint32_t backbytes, backsize;\n      uint8_t saved;\n\n      BIT;\n      if (!bits) { /* BYTE copy */\n\tif(ccur-compd>=szd || !CLI_ISCONTAINED(exe, exesz, ucur, 1))\n\t  error=1;\n\telse\n\t  *ucur++=*ccur++;\n\tcontinue;\n      }\n\n      BITS(2);\n      if(bits==3) { /* WORD backcopy */\n\tuint8_t shifted, subbed = 31;\n\tBITS(2);\n\tshifted = bits + 5;\n\tif(bits>=2) {\n\t  shifted++;\n\t  subbed += 0x80;\n\t}\n\tbackbytes = (1<<shifted)-subbed; /* 1h, 21h, 61h, 161h */\n\tBITS(shifted); /* 5, 6, 8, 9 */\n\tif(error || bits == 0x1ff) break;\n\tbackbytes+=bits;\n\tif(!CLI_ISCONTAINED(exe, exesz, ucur, 2) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, 2)) {\n\t  error=1;\n\t} else {\n\t  ucur[0]=*(ucur-backbytes);\n\t  ucur[1]=*(ucur-backbytes+1);\n\t  ucur+=2;\n\t}\n\tcontinue;\n      }\n\n      /* BLOCK backcopy */\n      saved = bits; /* cmp al, 1 / pushf */\n\n      BITS(3);\n      if (bits<6) {\n\tbackbytes = bits;\n\tswitch(bits) {\n\tcase 4: /* 10,11 */\n\t  backbytes++;\n\tcase 3: /* 8,9 */\n\t  BIT;\n\t  backbytes+=bits;\n\tcase 0:\tcase 1:\tcase 2: /* 5,6,7 */\n\t  backbytes+=5;\n\t  break;\n\tcase 5: /* 12 */\n\t  backbytes=12;\n\t  break;\n\t}\n\tBITS(backbytes);\n\tbits+=(1<<backbytes)-31;\n      } else if(bits==6) {\n\tBITS(0x0e);\n\tbits+=0x1fe1;\n      } else {\n\tBITS(0x0f);\n\tbits+=0x5fe1;\n      }\n\n      backbytes = bits;\n\n      /* popf / jb */\n      if (!saved) {\n\tBIT;\n\tif(!bits) {\n\t  BIT;\n\t  bits+=5;\n\t} else {\n\t  BITS(3);\n\t  if(bits) {\n\t    bits+=6;\n\t  } else {\n\t    BITS(4);\n\t    if(bits) {\n\t      bits+=13;\n\t    } else {\n\t      uint8_t cnt = 4;\n\t      uint16_t shifted = 0x0d;\n\t      \n\t      do {\n\t\tif(cnt==7) { cnt = 0x0e; shifted = 0; break; }\n\t\tshifted=((shifted+2)<<1)-1;\n\t\tBIT;\n\t\tcnt++;\n\t      } while(!bits);\n\t      BITS(cnt);\n\t      bits+=shifted;\n\t    }\n\t  }\n\t}\n\tbacksize = bits;\n      } else {\n\tbacksize = saved+2;\n      }\n\n      if(!CLI_ISCONTAINED(exe, exesz, ucur, backsize) || !CLI_ISCONTAINED(exe, exesz, ucur-backbytes, backsize)) error=1;\n      else while(backsize--) {\n\t*ucur=*(ucur-backbytes);\n\tucur++;\n      }\n    }\n    free(compd);\n    if(error) {\n      cli_dbgmsg(\"WWPack: decompression error\\n\");\n      break;\n    }\n    if (error || !*structs++) break;\n  }\n\n  if(!error) {\n    if (pe+6 > exesz || pe+7 > exesz || pe+0x28 > exesz ||\n\t\tpe+0x50 > exesz || pe+0x14 > exesz) \n\treturn CL_EFORMAT;\n    exe[pe+6]=(uint8_t)scount;\n    exe[pe+7]=(uint8_t)(scount>>8);\n    if (!CLI_ISCONTAINED(wwsect, sects[scount].rsz, wwsect+0x295, 4) ||\n        !CLI_ISCONTAINED(wwsect, sects[scount].rsz, wwsect+0x295+sects[scount].rva, 4) ||\n        !CLI_ISCONTAINED(wwsect, sects[scount].rsz, wwsect+0x295+sects[scount].rva+0x299, 4)) {\n        cli_dbgmsg(\"WWPack: unpack memory address out of bounds.\\n\");\n        return CL_EFORMAT;\n    }\n    cli_writeint32(&exe[pe+0x28], cli_readint32(wwsect+0x295)+sects[scount].rva+0x299);\n    cli_writeint32(&exe[pe+0x50], cli_readint32(&exe[pe+0x50])-sects[scount].vsz);\n\n    structs = &exe[(0xffff&cli_readint32(&exe[pe+0x14]))+pe+0x18];\n    for(i=0 ; i<scount ; i++) {\n\t  if (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t    cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t    return CL_EFORMAT;\n\t  }\n\n      cli_writeint32(structs+8, sects[i].vsz);\n      cli_writeint32(structs+12, sects[i].rva);\n      cli_writeint32(structs+16, sects[i].vsz);\n      cli_writeint32(structs+20, sects[i].rva);\n      structs+=0x28;\n    }\n\tif (!CLI_ISCONTAINED(exe, exesz, structs, 0x28)) {\n\t  cli_dbgmsg(\"WWPack: structs pointer out of bounds\\n\");\n\t  return CL_EFORMAT;\n\t}\n\n    memset(structs, 0, 0x28);\n    error = (uint32_t)cli_writen(desc, exe, exesz)!=exesz;\n  }\n  return error;\n}", "commit_link": "github.com/vrtadmin/clamav-devel/commit/dfc00cd3301a42b571454b51a6102eecf58407bc", "file_name": "libclamav/wwunpack.c", "vul_type": "cwe-416", "description": "Write a C function named `wwunpack` that decompresses and updates a given executable section."}
{"func_name": "update_read_bitmap_data", "func_src_before": "static BOOL update_read_bitmap_data(rdpUpdate* update, wStream* s, BITMAP_DATA* bitmapData)\n{\n\tWINPR_UNUSED(update);\n\tif (Stream_GetRemainingLength(s) < 18)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, bitmapData->destLeft);\n\tStream_Read_UINT16(s, bitmapData->destTop);\n\tStream_Read_UINT16(s, bitmapData->destRight);\n\tStream_Read_UINT16(s, bitmapData->destBottom);\n\tStream_Read_UINT16(s, bitmapData->width);\n\tStream_Read_UINT16(s, bitmapData->height);\n\tStream_Read_UINT16(s, bitmapData->bitsPerPixel);\n\tStream_Read_UINT16(s, bitmapData->flags);\n\tStream_Read_UINT16(s, bitmapData->bitmapLength);\n\n\tif (bitmapData->flags & BITMAP_COMPRESSION)\n\t{\n\t\tif (!(bitmapData->flags & NO_BITMAP_COMPRESSION_HDR))\n\t\t{\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompFirstRowSize); /* cbCompFirstRowSize (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompMainBodySize); /* cbCompMainBodySize (2 bytes) */\n\t\t\tStream_Read_UINT16(s, bitmapData->cbScanWidth);     /* cbScanWidth (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbUncompressedSize); /* cbUncompressedSize (2 bytes) */\n\t\t\tbitmapData->bitmapLength = bitmapData->cbCompMainBodySize;\n\t\t}\n\n\t\tbitmapData->compressed = TRUE;\n\t}\n\telse\n\t\tbitmapData->compressed = FALSE;\n\n\tif (Stream_GetRemainingLength(s) < bitmapData->bitmapLength)\n\t\treturn FALSE;\n\n\tif (bitmapData->bitmapLength > 0)\n\t{\n\t\tbitmapData->bitmapDataStream = malloc(bitmapData->bitmapLength);\n\n\t\tif (!bitmapData->bitmapDataStream)\n\t\t\treturn FALSE;\n\n\t\tmemcpy(bitmapData->bitmapDataStream, Stream_Pointer(s), bitmapData->bitmapLength);\n\t\tStream_Seek(s, bitmapData->bitmapLength);\n\t}\n\n\treturn TRUE;\n}", "func_src_after": "static BOOL update_read_bitmap_data(rdpUpdate* update, wStream* s, BITMAP_DATA* bitmapData)\n{\n\tWINPR_UNUSED(update);\n\tif (Stream_GetRemainingLength(s) < 18)\n\t\treturn FALSE;\n\n\tStream_Read_UINT16(s, bitmapData->destLeft);\n\tStream_Read_UINT16(s, bitmapData->destTop);\n\tStream_Read_UINT16(s, bitmapData->destRight);\n\tStream_Read_UINT16(s, bitmapData->destBottom);\n\tStream_Read_UINT16(s, bitmapData->width);\n\tStream_Read_UINT16(s, bitmapData->height);\n\tStream_Read_UINT16(s, bitmapData->bitsPerPixel);\n\tStream_Read_UINT16(s, bitmapData->flags);\n\tStream_Read_UINT16(s, bitmapData->bitmapLength);\n\n\tif (bitmapData->flags & BITMAP_COMPRESSION)\n\t{\n\t\tif (!(bitmapData->flags & NO_BITMAP_COMPRESSION_HDR))\n\t\t{\n\t\t\tif (Stream_GetRemainingLength(s) < 8)\n\t\t\t\treturn FALSE;\n\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompFirstRowSize); /* cbCompFirstRowSize (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbCompMainBodySize); /* cbCompMainBodySize (2 bytes) */\n\t\t\tStream_Read_UINT16(s, bitmapData->cbScanWidth);     /* cbScanWidth (2 bytes) */\n\t\t\tStream_Read_UINT16(s,\n\t\t\t                   bitmapData->cbUncompressedSize); /* cbUncompressedSize (2 bytes) */\n\t\t\tbitmapData->bitmapLength = bitmapData->cbCompMainBodySize;\n\t\t}\n\n\t\tbitmapData->compressed = TRUE;\n\t}\n\telse\n\t\tbitmapData->compressed = FALSE;\n\n\tif (Stream_GetRemainingLength(s) < bitmapData->bitmapLength)\n\t\treturn FALSE;\n\n\tif (bitmapData->bitmapLength > 0)\n\t{\n\t\tbitmapData->bitmapDataStream = malloc(bitmapData->bitmapLength);\n\n\t\tif (!bitmapData->bitmapDataStream)\n\t\t\treturn FALSE;\n\n\t\tmemcpy(bitmapData->bitmapDataStream, Stream_Pointer(s), bitmapData->bitmapLength);\n\t\tStream_Seek(s, bitmapData->bitmapLength);\n\t}\n\n\treturn TRUE;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/f8890a645c221823ac133dbf991f8a65ae50d637", "file_name": "libfreerdp/core/update.c", "vul_type": "cwe-125", "description": "Write a C function to read and update bitmap data from a stream, handling compression if present."}
{"func_name": "test_create_invalid_host", "func_src_before": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -iscsi -persona 1 -domain '\n                           '(\\'OpenStack\\',) '\n                           'fakehost iqn.1993-08.org.debian:01:222')\n        in_use_ret = pack('\\r\\nalready used by host fakehost.foo ')\n        _run_ssh(create_host_cmd, False).AndReturn([in_use_ret, ''])\n\n        show_3par_cmd = 'showhost -verbose fakehost.foo'\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(ISCSI_3PAR_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "func_src_after": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-iscsi', '-persona', '1', '-domain',\n                           ('OpenStack',), 'fakehost',\n                            'iqn.1993-08.org.debian:01:222'])\n        in_use_ret = pack('\\r\\nalready used by host fakehost.foo ')\n        _run_ssh(create_host_cmd, False).AndReturn([in_use_ret, ''])\n\n        show_3par_cmd = ['showhost', '-verbose', 'fakehost.foo']\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(ISCSI_3PAR_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating a host on an HP 3PAR storage system."}
{"func_name": "_get_hostvdisk_mappings", "func_src_before": "    def _get_hostvdisk_mappings(self, host_name):\n        \"\"\"Return the defined storage mappings for a host.\"\"\"\n\n        return_data = {}\n        ssh_cmd = 'svcinfo lshostvdiskmap -delim ! %s' % host_name\n        out, err = self._run_ssh(ssh_cmd)\n\n        mappings = out.strip().split('\\n')\n        if len(mappings):\n            header = mappings.pop(0)\n            for mapping_line in mappings:\n                mapping_data = self._get_hdr_dic(header, mapping_line, '!')\n                return_data[mapping_data['vdisk_name']] = mapping_data\n\n        return return_data", "func_src_after": "    def _get_hostvdisk_mappings(self, host_name):\n        \"\"\"Return the defined storage mappings for a host.\"\"\"\n\n        return_data = {}\n        ssh_cmd = ['svcinfo', 'lshostvdiskmap', '-delim', '!', host_name]\n        out, err = self._run_ssh(ssh_cmd)\n\n        mappings = out.strip().split('\\n')\n        if len(mappings):\n            header = mappings.pop(0)\n            for mapping_line in mappings:\n                mapping_data = self._get_hdr_dic(header, mapping_line, '!')\n                return_data[mapping_data['vdisk_name']] = mapping_data\n\n        return return_data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and parse storage mappings for a given host using SSH."}
{"func_name": "_get_flashcopy_mapping_attributes", "func_src_before": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = 'svcinfo lsfcmap -filtervalue id=%s -delim !' % \\\n            fc_map_id\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "func_src_after": "    def _get_flashcopy_mapping_attributes(self, fc_map_id):\n        LOG.debug(_('enter: _get_flashcopy_mapping_attributes: mapping %s')\n                  % fc_map_id)\n\n        fc_ls_map_cmd = ['svcinfo', 'lsfcmap', '-filtervalue',\n                         'id=%s' % fc_map_id, '-delim', '!']\n        out, err = self._run_ssh(fc_ls_map_cmd)\n        if not len(out.strip()):\n            return None\n\n        # Get list of FlashCopy mappings\n        # We expect zero or one line if mapping does not exist,\n        # two lines if it does exist, otherwise error\n        lines = out.strip().split('\\n')\n        self._assert_ssh_return(len(lines) <= 2,\n                                '_get_flashcopy_mapping_attributes',\n                                fc_ls_map_cmd, out, err)\n\n        if len(lines) == 2:\n            attributes = self._get_hdr_dic(lines[0], lines[1], '!')\n        else:  # 0 or 1 lines\n            attributes = None\n\n        LOG.debug(_('leave: _get_flashcopy_mapping_attributes: mapping '\n                    '%(fc_map_id)s, attributes %(attributes)s') %\n                  {'fc_map_id': fc_map_id, 'attributes': attributes})\n\n        return attributes", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and parse FlashCopy mapping attributes using SSH commands."}
{"func_name": "mrb_class_real", "func_src_before": "mrb_class_real(struct RClass* cl)\n{\n  if (cl == 0)\n    return NULL;\n  while ((cl->tt == MRB_TT_SCLASS) || (cl->tt == MRB_TT_ICLASS)) {\n    cl = cl->super;\n  }\n  return cl;\n}", "func_src_after": "mrb_class_real(struct RClass* cl)\n{\n  if (cl == 0) return NULL;\n  while ((cl->tt == MRB_TT_SCLASS) || (cl->tt == MRB_TT_ICLASS)) {\n    cl = cl->super;\n    if (cl == 0) return NULL;\n  }\n  return cl;\n}", "commit_link": "github.com/mruby/mruby/commit/faa4eaf6803bd11669bc324b4c34e7162286bfa3", "file_name": "src/class.c", "vul_type": "cwe-476", "description": "Write a function in C that returns the first non-singleton and non-included class in a class hierarchy, or NULL if not found."}
{"func_name": "set_language", "func_src_before": "    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language='{self.language}' \"\n                 f\"WHERE chat_id='{self.chat_id}'\")\n\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')", "func_src_after": "    def set_language(self, lang):\n        \"\"\"\n        Update language of user in the User object and in the database\n        :param lang: string with language tag like \"en-US\"\n        :return: None\n        \"\"\"\n        log.debug('Updating info about user %s language '\n                  'in memory & database...', self)\n\n        self.language = lang\n\n        query = (\"UPDATE users \"\n                 f\"SET language=%s \"\n                 f\"WHERE chat_id=%s\")\n\n        parameters = self.language, self.chat_id\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Can't add new language of %s to the database\", self)\n        else:\n            log.debug('Language updated.')", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's language preference both in the object and the database."}
{"func_name": "view_page_record", "func_src_before": "@app.route('/<page_name>/history/record')\ndef view_page_record(page_name):\n    content_id = request.args.get('id')\n    query = db.query(\"select page_content.content, page_content.timestamp from page, page_content where page.id = page_content.page_id and page_content.id = $1\", content_id)\n    page_record = query.namedresult()[0]\n\n    return render_template(\n        'page_record.html',\n        page_name = page_name,\n        page_record = page_record\n    )", "func_src_after": "@app.route('/<page_name>/history/record')\ndef view_page_record(page_name):\n    content_id = request.args.get('id')\n    query = db.query(\"select page_content.content, page_content.timestamp from page, page_content where page.id = page_content.page_id and page_content.id = '%s'\" % content_id)\n    page_record = query.namedresult()[0]\n\n    return render_template(\n        'page_record.html',\n        page_name = page_name,\n        page_record = page_record\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to display a specific historical record of a page using its content ID from a database."}
{"func_name": "ReadPSDImage", "func_src_before": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadPSDImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image\n    *image;\n\n  MagickBooleanType\n    has_merged_image,\n    skip_layers;\n\n  MagickOffsetType\n    offset;\n\n  MagickSizeType\n    length;\n\n  MagickBooleanType\n    status;\n\n  PSDInfo\n    psd_info;\n\n  register ssize_t\n    i;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *data;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read image header.\n  */\n  image->endian=MSBEndian;\n  count=ReadBlob(image,4,(unsigned char *) psd_info.signature);\n  psd_info.version=ReadBlobMSBShort(image);\n  if ((count == 0) || (LocaleNCompare(psd_info.signature,\"8BPS\",4) != 0) ||\n      ((psd_info.version != 1) && (psd_info.version != 2)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  (void) ReadBlob(image,6,psd_info.reserved);\n  psd_info.channels=ReadBlobMSBShort(image);\n  if (psd_info.channels > MaxPSDChannels)\n    ThrowReaderException(CorruptImageError,\"MaximumChannelsExceeded\");\n  psd_info.rows=ReadBlobMSBLong(image);\n  psd_info.columns=ReadBlobMSBLong(image);\n  if ((psd_info.version == 1) && ((psd_info.rows > 30000) ||\n      (psd_info.columns > 30000)))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.depth=ReadBlobMSBShort(image);\n  if ((psd_info.depth != 1) && (psd_info.depth != 8) && (psd_info.depth != 16))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  psd_info.mode=ReadBlobMSBShort(image);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  Image is %.20g x %.20g with channels=%.20g, depth=%.20g, mode=%s\",\n      (double) psd_info.columns,(double) psd_info.rows,(double)\n      psd_info.channels,(double) psd_info.depth,ModeToString((PSDImageType)\n      psd_info.mode));\n  /*\n    Initialize image.\n  */\n  image->depth=psd_info.depth;\n  image->columns=psd_info.columns;\n  image->rows=psd_info.rows;\n  status=SetImageExtent(image,image->columns,image->rows,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  if (SetImageBackgroundColor(image,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  if (psd_info.mode == LabMode)\n    SetImageColorspace(image,LabColorspace,exception);\n  if (psd_info.mode == CMYKMode)\n    {\n      SetImageColorspace(image,CMYKColorspace,exception);\n      image->alpha_trait=psd_info.channels > 4 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else if ((psd_info.mode == BitmapMode) || (psd_info.mode == GrayscaleMode) ||\n      (psd_info.mode == DuotoneMode))\n    {\n      status=AcquireImageColormap(image,psd_info.depth != 16 ? 256 : 65536,\n        exception);\n      if (status == MagickFalse)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Image colormap allocated\");\n      SetImageColorspace(image,GRAYColorspace,exception);\n      image->alpha_trait=psd_info.channels > 1 ? BlendPixelTrait :\n        UndefinedPixelTrait;\n    }\n  else\n    image->alpha_trait=psd_info.channels > 3 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n  /*\n    Read PSD raster colormap only present for indexed and duotone images.\n  */\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading colormap\");\n      if (psd_info.mode == DuotoneMode)\n        {\n          /*\n            Duotone image data;  the format of this data is undocumented.\n          */\n          data=(unsigned char *) AcquireQuantumMemory((size_t) length,\n            sizeof(*data));\n          if (data == (unsigned char *) NULL)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          (void) ReadBlob(image,(size_t) length,data);\n          data=(unsigned char *) RelinquishMagickMemory(data);\n        }\n      else\n        {\n          size_t\n            number_colors;\n\n          /*\n            Read PSD raster colormap.\n          */\n          number_colors=length/3;\n          if (number_colors > 65536)\n            ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n          if (AcquireImageColormap(image,number_colors,exception) == MagickFalse)\n            ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].red=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          for (i=0; i < (ssize_t) image->colors; i++)\n            image->colormap[i].blue=ScaleCharToQuantum((unsigned char)\n              ReadBlobByte(image));\n          image->alpha_trait=UndefinedPixelTrait;\n        }\n    }\n  if ((image->depth == 1) && (image->storage_class != PseudoClass))\n    ThrowReaderException(CorruptImageError, \"ImproperImageHeader\");\n  has_merged_image=MagickTrue;\n  length=ReadBlobMSBLong(image);\n  if (length != 0)\n    {\n      unsigned char\n        *blocks;\n\n      /*\n        Image resources block.\n      */\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  reading image resource blocks - %.20g bytes\",(double)\n          ((MagickOffsetType) length));\n      blocks=(unsigned char *) AcquireQuantumMemory((size_t) length,\n        sizeof(*blocks));\n      if (blocks == (unsigned char *) NULL)\n        ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      count=ReadBlob(image,(size_t) length,blocks);\n      if ((count != (ssize_t) length) ||\n          (LocaleNCompare((char *) blocks,\"8BIM\",4) != 0))\n        {\n          blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        }\n      ParseImageResourceBlocks(image,blocks,(size_t) length,&has_merged_image,\n        exception);\n      blocks=(unsigned char *) RelinquishMagickMemory(blocks);\n    }\n  /*\n    Layer and mask block.\n  */\n  length=GetPSDSize(&psd_info,image);\n  if (length == 8)\n    {\n      length=ReadBlobMSBLong(image);\n      length=ReadBlobMSBLong(image);\n    }\n  offset=TellBlob(image);\n  skip_layers=MagickFalse;\n  if ((image_info->number_scenes == 1) && (image_info->scene == 0) &&\n      (has_merged_image != MagickFalse))\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  read composite only\");\n      skip_layers=MagickTrue;\n    }\n  if (length == 0)\n    {\n      if (image->debug != MagickFalse)\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  image has no layers\");\n    }\n  else\n    {\n      if (ReadPSDLayers(image,image_info,&psd_info,skip_layers,exception) !=\n          MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n\n      /*\n         Skip the rest of the layer and mask information.\n      */\n      SeekBlob(image,offset+length,SEEK_SET);\n    }\n  /*\n    If we are only \"pinging\" the image, then we're done - so return.\n  */\n  if (image_info->ping != MagickFalse)\n    {\n      (void) CloseBlob(image);\n      return(GetFirstImageInList(image));\n    }\n  /*\n    Read the precombined layer, present for PSD < 4 compatibility.\n  */\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n      \"  reading the precombined layer\");\n  if ((has_merged_image != MagickFalse) || (GetImageListLength(image) == 1))\n    has_merged_image=(MagickBooleanType) ReadPSDMergedImage(image_info,image,\n      &psd_info,exception);\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) == 1) &&\n      (length != 0))\n    {\n      SeekBlob(image,offset,SEEK_SET);\n      status=ReadPSDLayers(image,image_info,&psd_info,MagickFalse,exception);\n      if (status != MagickTrue)\n        {\n          (void) CloseBlob(image);\n          image=DestroyImageList(image);\n          return((Image *) NULL);\n        }\n    }\n  if ((has_merged_image == MagickFalse) && (GetImageListLength(image) > 1))\n    {\n      Image\n        *merged;\n\n      SetImageAlphaChannel(image,TransparentAlphaChannel,exception);\n      image->background_color.alpha=TransparentAlpha;\n      image->background_color.alpha_trait=BlendPixelTrait;\n      merged=MergeImageLayers(image,FlattenLayer,exception);\n      ReplaceImageInList(&image,merged);\n    }\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/198fffab4daf8aea88badd9c629350e5b26ec32f", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function to read and process a PSD image file."}
{"func_name": "__get_data_block", "func_src_before": "static int __get_data_block(struct inode *inode, sector_t iblock,\n\t\t\tstruct buffer_head *bh, int create, int flag,\n\t\t\tpgoff_t *next_pgofs)\n{\n\tstruct f2fs_map_blocks map;\n\tint err;\n\n\tmap.m_lblk = iblock;\n\tmap.m_len = bh->b_size >> inode->i_blkbits;\n\tmap.m_next_pgofs = next_pgofs;\n\n\terr = f2fs_map_blocks(inode, &map, create, flag);\n\tif (!err) {\n\t\tmap_bh(bh, inode->i_sb, map.m_pblk);\n\t\tbh->b_state = (bh->b_state & ~F2FS_MAP_FLAGS) | map.m_flags;\n\t\tbh->b_size = map.m_len << inode->i_blkbits;\n\t}\n\treturn err;\n}", "func_src_after": "static int __get_data_block(struct inode *inode, sector_t iblock,\n\t\t\tstruct buffer_head *bh, int create, int flag,\n\t\t\tpgoff_t *next_pgofs)\n{\n\tstruct f2fs_map_blocks map;\n\tint err;\n\n\tmap.m_lblk = iblock;\n\tmap.m_len = bh->b_size >> inode->i_blkbits;\n\tmap.m_next_pgofs = next_pgofs;\n\n\terr = f2fs_map_blocks(inode, &map, create, flag);\n\tif (!err) {\n\t\tmap_bh(bh, inode->i_sb, map.m_pblk);\n\t\tbh->b_state = (bh->b_state & ~F2FS_MAP_FLAGS) | map.m_flags;\n\t\tbh->b_size = (u64)map.m_len << inode->i_blkbits;\n\t}\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/b86e33075ed1909d8002745b56ecf73b833db143", "file_name": "fs/f2fs/data.c", "vul_type": "cwe-190", "description": "Write a C function named `__get_data_block` that maps blocks for a given inode in a filesystem, handling buffer head and block mapping with error checking."}
{"func_name": "podbeuter::pb_controller::play_file", "func_src_before": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" '\");\n\tcmdline.append(utils::replace_all(file,\"'\", \"%27\"));\n\tcmdline.append(\"'\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "func_src_after": "void pb_controller::play_file(const std::string& file) {\n\tstd::string cmdline;\n\tstd::string player = cfg->get_configvalue(\"player\");\n\tif (player == \"\")\n\t\treturn;\n\tcmdline.append(player);\n\tcmdline.append(\" \\\"\");\n\tcmdline.append(utils::replace_all(file,\"\\\"\", \"\\\\\\\"\"));\n\tcmdline.append(\"\\\"\");\n\tstfl::reset();\n\tutils::run_interactively(cmdline, \"pb_controller::play_file\");\n}", "commit_link": "github.com/akrennmair/newsbeuter/commit/c8fea2f60c18ed30bdd1bb6f798e994e51a58260", "file_name": "src/pb_controller.cpp", "vul_type": "cwe-078", "description": "Write a C++ function named `play_file` in a class `pb_controller` that executes a media player command using a file path, handling quotes in the file path."}
{"func_name": "xdp_umem_reg", "func_src_before": "static int xdp_umem_reg(struct xdp_umem *umem, struct xdp_umem_reg *mr)\n{\n\tbool unaligned_chunks = mr->flags & XDP_UMEM_UNALIGNED_CHUNK_FLAG;\n\tu32 chunk_size = mr->chunk_size, headroom = mr->headroom;\n\tunsigned int chunks, chunks_per_page;\n\tu64 addr = mr->addr, size = mr->len;\n\tint err;\n\n\tif (chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE) {\n\t\t/* Strictly speaking we could support this, if:\n\t\t * - huge pages, or*\n\t\t * - using an IOMMU, or\n\t\t * - making sure the memory area is consecutive\n\t\t * but for now, we simply say \"computer says no\".\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif (mr->flags & ~(XDP_UMEM_UNALIGNED_CHUNK_FLAG |\n\t\t\tXDP_UMEM_USES_NEED_WAKEUP))\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks && !is_power_of_2(chunk_size))\n\t\treturn -EINVAL;\n\n\tif (!PAGE_ALIGNED(addr)) {\n\t\t/* Memory area has to be page size aligned. For\n\t\t * simplicity, this might change.\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif ((addr + size) < addr)\n\t\treturn -EINVAL;\n\n\tchunks = (unsigned int)div_u64(size, chunk_size);\n\tif (chunks == 0)\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks) {\n\t\tchunks_per_page = PAGE_SIZE / chunk_size;\n\t\tif (chunks < chunks_per_page || chunks % chunks_per_page)\n\t\t\treturn -EINVAL;\n\t}\n\n\tif (headroom >= chunk_size - XDP_PACKET_HEADROOM)\n\t\treturn -EINVAL;\n\n\tumem->address = (unsigned long)addr;\n\tumem->chunk_mask = unaligned_chunks ? XSK_UNALIGNED_BUF_ADDR_MASK\n\t\t\t\t\t    : ~((u64)chunk_size - 1);\n\tumem->size = size;\n\tumem->headroom = headroom;\n\tumem->chunk_size_nohr = chunk_size - headroom;\n\tumem->npgs = size / PAGE_SIZE;\n\tumem->pgs = NULL;\n\tumem->user = NULL;\n\tumem->flags = mr->flags;\n\tINIT_LIST_HEAD(&umem->xsk_list);\n\tspin_lock_init(&umem->xsk_list_lock);\n\n\trefcount_set(&umem->users, 1);\n\n\terr = xdp_umem_account_pages(umem);\n\tif (err)\n\t\treturn err;\n\n\terr = xdp_umem_pin_pages(umem);\n\tif (err)\n\t\tgoto out_account;\n\n\tumem->pages = kvcalloc(umem->npgs, sizeof(*umem->pages),\n\t\t\t       GFP_KERNEL_ACCOUNT);\n\tif (!umem->pages) {\n\t\terr = -ENOMEM;\n\t\tgoto out_pin;\n\t}\n\n\terr = xdp_umem_map_pages(umem);\n\tif (!err)\n\t\treturn 0;\n\n\tkvfree(umem->pages);\n\nout_pin:\n\txdp_umem_unpin_pages(umem);\nout_account:\n\txdp_umem_unaccount_pages(umem);\n\treturn err;\n}", "func_src_after": "static int xdp_umem_reg(struct xdp_umem *umem, struct xdp_umem_reg *mr)\n{\n\tbool unaligned_chunks = mr->flags & XDP_UMEM_UNALIGNED_CHUNK_FLAG;\n\tu32 chunk_size = mr->chunk_size, headroom = mr->headroom;\n\tunsigned int chunks, chunks_per_page;\n\tu64 addr = mr->addr, size = mr->len;\n\tint size_chk, err;\n\n\tif (chunk_size < XDP_UMEM_MIN_CHUNK_SIZE || chunk_size > PAGE_SIZE) {\n\t\t/* Strictly speaking we could support this, if:\n\t\t * - huge pages, or*\n\t\t * - using an IOMMU, or\n\t\t * - making sure the memory area is consecutive\n\t\t * but for now, we simply say \"computer says no\".\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif (mr->flags & ~(XDP_UMEM_UNALIGNED_CHUNK_FLAG |\n\t\t\tXDP_UMEM_USES_NEED_WAKEUP))\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks && !is_power_of_2(chunk_size))\n\t\treturn -EINVAL;\n\n\tif (!PAGE_ALIGNED(addr)) {\n\t\t/* Memory area has to be page size aligned. For\n\t\t * simplicity, this might change.\n\t\t */\n\t\treturn -EINVAL;\n\t}\n\n\tif ((addr + size) < addr)\n\t\treturn -EINVAL;\n\n\tchunks = (unsigned int)div_u64(size, chunk_size);\n\tif (chunks == 0)\n\t\treturn -EINVAL;\n\n\tif (!unaligned_chunks) {\n\t\tchunks_per_page = PAGE_SIZE / chunk_size;\n\t\tif (chunks < chunks_per_page || chunks % chunks_per_page)\n\t\t\treturn -EINVAL;\n\t}\n\n\tsize_chk = chunk_size - headroom - XDP_PACKET_HEADROOM;\n\tif (size_chk < 0)\n\t\treturn -EINVAL;\n\n\tumem->address = (unsigned long)addr;\n\tumem->chunk_mask = unaligned_chunks ? XSK_UNALIGNED_BUF_ADDR_MASK\n\t\t\t\t\t    : ~((u64)chunk_size - 1);\n\tumem->size = size;\n\tumem->headroom = headroom;\n\tumem->chunk_size_nohr = chunk_size - headroom;\n\tumem->npgs = size / PAGE_SIZE;\n\tumem->pgs = NULL;\n\tumem->user = NULL;\n\tumem->flags = mr->flags;\n\tINIT_LIST_HEAD(&umem->xsk_list);\n\tspin_lock_init(&umem->xsk_list_lock);\n\n\trefcount_set(&umem->users, 1);\n\n\terr = xdp_umem_account_pages(umem);\n\tif (err)\n\t\treturn err;\n\n\terr = xdp_umem_pin_pages(umem);\n\tif (err)\n\t\tgoto out_account;\n\n\tumem->pages = kvcalloc(umem->npgs, sizeof(*umem->pages),\n\t\t\t       GFP_KERNEL_ACCOUNT);\n\tif (!umem->pages) {\n\t\terr = -ENOMEM;\n\t\tgoto out_pin;\n\t}\n\n\terr = xdp_umem_map_pages(umem);\n\tif (!err)\n\t\treturn 0;\n\n\tkvfree(umem->pages);\n\nout_pin:\n\txdp_umem_unpin_pages(umem);\nout_account:\n\txdp_umem_unaccount_pages(umem);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/99e3a236dd43d06c65af0a2ef9cb44306aef6e02", "file_name": "net/xdp/xdp_umem.c", "vul_type": "cwe-787", "description": "Write a C function named `xdp_umem_reg` that registers a user memory (`umem`) area for use with XDP sockets, validating the provided memory region parameters."}
{"func_name": "ReadSUNImage", "func_src_before": "static Image *ReadSUNImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define RMT_EQUAL_RGB  1\n#define RMT_NONE  0\n#define RMT_RAW  2\n#define RT_STANDARD  1\n#define RT_ENCODED  2\n#define RT_FORMAT_RGB  3\n\n  typedef struct _SUNInfo\n  {\n    unsigned int\n      magic,\n      width,\n      height,\n      depth,\n      length,\n      type,\n      maptype,\n      maplength;\n  } SUNInfo;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_line,\n    extent,\n    height,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  SUNInfo\n    sun_info;\n\n  unsigned char\n    *sun_data,\n    *sun_pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read SUN raster header.\n  */\n  (void) ResetMagickMemory(&sun_info,0,sizeof(sun_info));\n  sun_info.magic=ReadBlobMSBLong(image);\n  do\n  {\n    /*\n      Verify SUN identifier.\n    */\n    if (sun_info.magic != 0x59a66a95)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    sun_info.width=ReadBlobMSBLong(image);\n    sun_info.height=ReadBlobMSBLong(image);\n    sun_info.depth=ReadBlobMSBLong(image);\n    sun_info.length=ReadBlobMSBLong(image);\n    sun_info.type=ReadBlobMSBLong(image);\n    sun_info.maptype=ReadBlobMSBLong(image);\n    sun_info.maplength=ReadBlobMSBLong(image);\n    extent=sun_info.height*sun_info.width;\n    if ((sun_info.height != 0) && (sun_info.width != extent/sun_info.height))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.type != RT_STANDARD) && (sun_info.type != RT_ENCODED) &&\n        (sun_info.type != RT_FORMAT_RGB))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype == RMT_NONE) && (sun_info.maplength != 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.depth == 0) || (sun_info.depth > 32))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype != RMT_NONE) && (sun_info.maptype != RMT_EQUAL_RGB) &&\n        (sun_info.maptype != RMT_RAW))\n      ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    image->depth=sun_info.depth <= 8 ? sun_info.depth :\n      MAGICKCORE_QUANTUM_DEPTH;\n    if (sun_info.depth < 24)\n      {\n        size_t\n          one;\n\n        image->colors=sun_info.maplength;\n        one=1;\n        if (sun_info.maptype == RMT_NONE)\n          image->colors=one << sun_info.depth;\n        if (sun_info.maptype == RMT_EQUAL_RGB)\n          image->colors=sun_info.maplength/3;\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      }\n    switch (sun_info.maptype)\n    {\n      case RMT_NONE:\n        break;\n      case RMT_EQUAL_RGB:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].red=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].green=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].blue=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      case RMT_RAW:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(sun_info.maplength,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,sun_info.maplength,sun_colormap);\n        if (count != (ssize_t) sun_info.maplength)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    image->alpha_trait=sun_info.depth == 32 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((sun_info.length*sizeof(*sun_data))/sizeof(*sun_data) !=\n        sun_info.length || !sun_info.length)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((sun_info.type != RT_ENCODED) && \n        ((number_pixels*sun_info.depth) > (8*sun_info.length)))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    bytes_per_line=sun_info.width*sun_info.depth;\n    sun_data=(unsigned char *) AcquireQuantumMemory((size_t) MagickMax(\n      sun_info.length,bytes_per_line*sun_info.width),sizeof(*sun_data));\n    if (sun_data == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    count=(ssize_t) ReadBlob(image,sun_info.length,sun_data);\n    if (count != (ssize_t) sun_info.length)\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    height=sun_info.height;\n    if ((height == 0) || (sun_info.width == 0) || (sun_info.depth == 0) ||\n        ((bytes_per_line/sun_info.depth) != sun_info.width))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    bytes_per_line+=15;\n    bytes_per_line<<=1;\n    if ((bytes_per_line >> 1) != (sun_info.width*sun_info.depth+15))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    bytes_per_line>>=4;\n    sun_pixels=(unsigned char *) AcquireQuantumMemory(height,\n      bytes_per_line*sizeof(*sun_pixels));\n    if (sun_pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (sun_info.type == RT_ENCODED)\n      (void) DecodeImage(sun_data,sun_info.length,sun_pixels,bytes_per_line*\n        height);\n    sun_data=(unsigned char *) RelinquishMagickMemory(sun_data);\n    /*\n      Convert SUN raster image to pixel packets.\n    */\n    p=sun_pixels;\n    if (sun_info.depth == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n          break;\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n        {\n          for (bit=7; bit >= 0; bit--)\n          {\n            SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 : 0x01),\n              q);\n            q+=GetPixelChannels(image);\n          }\n          p++;\n        }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=7; bit >= (int) (8-(image->columns % 8)); bit--)\n            {\n              SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 :\n                0x01),q);\n              q+=GetPixelChannels(image);\n            }\n            p++;\n          }\n        if ((((image->columns/8)+(image->columns % 8 ? 1 : 0)) % 2) != 0)\n          p++;\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        if (image->previous == (Image *) NULL)\n          {\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        {\n          if (bytes_per_line == 0)\n            bytes_per_line=image->columns;\n          length=image->rows*(image->columns+image->columns % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelIndex(image,*p++,q);\n              q+=GetPixelChannels(image);\n            }\n            if ((image->columns % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      else\n        {\n          size_t\n            bytes_per_pixel;\n\n          bytes_per_pixel=3;\n          if (image->alpha_trait != UndefinedPixelTrait)\n            bytes_per_pixel++;\n          if (bytes_per_line == 0)\n            bytes_per_line=bytes_per_pixel*image->columns;\n          length=image->rows*(bytes_per_line+bytes_per_line % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (image->alpha_trait != UndefinedPixelTrait)\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n              if (sun_info.type == RT_STANDARD)\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                }\n              else\n                {\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                }\n              if (image->colors != 0)\n                {\n                  SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelRed(image,q)].red),q);\n                  SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelGreen(image,q)].green),q);\n                  SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelBlue(image,q)].blue),q);\n                }\n              q+=GetPixelChannels(image);\n            }\n            if (((bytes_per_pixel*image->columns) % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image,exception);\n    sun_pixels=(unsigned char *) RelinquishMagickMemory(sun_pixels);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    sun_info.magic=ReadBlobMSBLong(image);\n    if (sun_info.magic == 0x59a66a95)\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while (sun_info.magic == 0x59a66a95);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadSUNImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define RMT_EQUAL_RGB  1\n#define RMT_NONE  0\n#define RMT_RAW  2\n#define RT_STANDARD  1\n#define RT_ENCODED  2\n#define RT_FORMAT_RGB  3\n\n  typedef struct _SUNInfo\n  {\n    unsigned int\n      magic,\n      width,\n      height,\n      depth,\n      length,\n      type,\n      maptype,\n      maplength;\n  } SUNInfo;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_line,\n    extent,\n    height,\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  SUNInfo\n    sun_info;\n\n  unsigned char\n    *sun_data,\n    *sun_pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read SUN raster header.\n  */\n  (void) ResetMagickMemory(&sun_info,0,sizeof(sun_info));\n  sun_info.magic=ReadBlobMSBLong(image);\n  do\n  {\n    /*\n      Verify SUN identifier.\n    */\n    if (sun_info.magic != 0x59a66a95)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    sun_info.width=ReadBlobMSBLong(image);\n    sun_info.height=ReadBlobMSBLong(image);\n    sun_info.depth=ReadBlobMSBLong(image);\n    sun_info.length=ReadBlobMSBLong(image);\n    sun_info.type=ReadBlobMSBLong(image);\n    sun_info.maptype=ReadBlobMSBLong(image);\n    sun_info.maplength=ReadBlobMSBLong(image);\n    extent=sun_info.height*sun_info.width;\n    if ((sun_info.height != 0) && (sun_info.width != extent/sun_info.height))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.type != RT_STANDARD) && (sun_info.type != RT_ENCODED) &&\n        (sun_info.type != RT_FORMAT_RGB))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype == RMT_NONE) && (sun_info.maplength != 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.depth == 0) || (sun_info.depth > 32))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((sun_info.maptype != RMT_NONE) && (sun_info.maptype != RMT_EQUAL_RGB) &&\n        (sun_info.maptype != RMT_RAW))\n      ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    image->depth=sun_info.depth <= 8 ? sun_info.depth :\n      MAGICKCORE_QUANTUM_DEPTH;\n    if (sun_info.depth < 24)\n      {\n        size_t\n          one;\n\n        image->colors=sun_info.maplength;\n        one=1;\n        if (sun_info.maptype == RMT_NONE)\n          image->colors=one << sun_info.depth;\n        if (sun_info.maptype == RMT_EQUAL_RGB)\n          image->colors=sun_info.maplength/3;\n        if (AcquireImageColormap(image,image->colors,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n      }\n    switch (sun_info.maptype)\n    {\n      case RMT_NONE:\n        break;\n      case RMT_EQUAL_RGB:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].red=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].green=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        count=ReadBlob(image,image->colors,sun_colormap);\n        if (count != (ssize_t) image->colors)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        for (i=0; i < (ssize_t) image->colors; i++)\n          image->colormap[i].blue=(MagickRealType) ScaleCharToQuantum(\n            sun_colormap[i]);\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      case RMT_RAW:\n      {\n        unsigned char\n          *sun_colormap;\n\n        /*\n          Read SUN raster colormap.\n        */\n        sun_colormap=(unsigned char *) AcquireQuantumMemory(sun_info.maplength,\n          sizeof(*sun_colormap));\n        if (sun_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        count=ReadBlob(image,sun_info.maplength,sun_colormap);\n        if (count != (ssize_t) sun_info.maplength)\n          ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n        sun_colormap=(unsigned char *) RelinquishMagickMemory(sun_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    image->alpha_trait=sun_info.depth == 32 ? BlendPixelTrait :\n      UndefinedPixelTrait;\n    image->columns=sun_info.width;\n    image->rows=sun_info.height;\n    if (image_info->ping != MagickFalse)\n      {\n        (void) CloseBlob(image);\n        return(GetFirstImageInList(image));\n      }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    if ((sun_info.length*sizeof(*sun_data))/sizeof(*sun_data) !=\n        sun_info.length || !sun_info.length)\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((sun_info.type != RT_ENCODED) && \n        ((number_pixels*sun_info.depth) > (8*sun_info.length)))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    bytes_per_line=sun_info.width*sun_info.depth;\n    sun_data=(unsigned char *) AcquireQuantumMemory((size_t) MagickMax(\n      sun_info.length,bytes_per_line*sun_info.width),sizeof(*sun_data));\n    if (sun_data == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    count=(ssize_t) ReadBlob(image,sun_info.length,sun_data);\n    if (count != (ssize_t) sun_info.length)\n      ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n    height=sun_info.height;\n    if ((height == 0) || (sun_info.width == 0) || (sun_info.depth == 0) ||\n        ((bytes_per_line/sun_info.depth) != sun_info.width))\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    bytes_per_line+=15;\n    bytes_per_line<<=1;\n    if ((bytes_per_line >> 1) != (sun_info.width*sun_info.depth+15))\n      ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n    bytes_per_line>>=4;\n    sun_pixels=(unsigned char *) AcquireQuantumMemory(height,\n      bytes_per_line*sizeof(*sun_pixels));\n    if (sun_pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (sun_info.type == RT_ENCODED)\n      (void) DecodeImage(sun_data,sun_info.length,sun_pixels,bytes_per_line*\n        height);\n    else\n      {\n        if (sun_info.length > (height*bytes_per_line))\n          ThrowReaderException(ResourceLimitError,\"ImproperImageHeader\");\n        (void) CopyMagickMemory(sun_pixels,sun_data,sun_info.length);\n      }\n    sun_data=(unsigned char *) RelinquishMagickMemory(sun_data);\n    /*\n      Convert SUN raster image to pixel packets.\n    */\n    p=sun_pixels;\n    if (sun_info.depth == 1)\n      for (y=0; y < (ssize_t) image->rows; y++)\n      {\n        q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n          break;\n        for (x=0; x < ((ssize_t) image->columns-7); x+=8)\n        {\n          for (bit=7; bit >= 0; bit--)\n          {\n            SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 : 0x01),\n              q);\n            q+=GetPixelChannels(image);\n          }\n          p++;\n        }\n        if ((image->columns % 8) != 0)\n          {\n            for (bit=7; bit >= (int) (8-(image->columns % 8)); bit--)\n            {\n              SetPixelIndex(image,(Quantum) ((*p) & (0x01 << bit) ? 0x00 :\n                0x01),q);\n              q+=GetPixelChannels(image);\n            }\n            p++;\n          }\n        if ((((image->columns/8)+(image->columns % 8 ? 1 : 0)) % 2) != 0)\n          p++;\n        if (SyncAuthenticPixels(image,exception) == MagickFalse)\n          break;\n        if (image->previous == (Image *) NULL)\n          {\n            status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n              image->rows);\n            if (status == MagickFalse)\n              break;\n          }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        {\n          if (bytes_per_line == 0)\n            bytes_per_line=image->columns;\n          length=image->rows*(image->columns+image->columns % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelIndex(image,*p++,q);\n              q+=GetPixelChannels(image);\n            }\n            if ((image->columns % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n      else\n        {\n          size_t\n            bytes_per_pixel;\n\n          bytes_per_pixel=3;\n          if (image->alpha_trait != UndefinedPixelTrait)\n            bytes_per_pixel++;\n          if (bytes_per_line == 0)\n            bytes_per_line=bytes_per_pixel*image->columns;\n          length=image->rows*(bytes_per_line+bytes_per_line % 2);\n          if (((sun_info.type == RT_ENCODED) &&\n               (length > (bytes_per_line*image->rows))) ||\n              ((sun_info.type != RT_ENCODED) && (length > sun_info.length)))\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (Quantum *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              if (image->alpha_trait != UndefinedPixelTrait)\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n              if (sun_info.type == RT_STANDARD)\n                {\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                }\n              else\n                {\n                  SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n                  SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n                }\n              if (image->colors != 0)\n                {\n                  SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelRed(image,q)].red),q);\n                  SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelGreen(image,q)].green),q);\n                  SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                    GetPixelBlue(image,q)].blue),q);\n                }\n              q+=GetPixelChannels(image);\n            }\n            if (((bytes_per_pixel*image->columns) % 2) != 0)\n              p++;\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image,exception);\n    sun_pixels=(unsigned char *) RelinquishMagickMemory(sun_pixels);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    sun_info.magic=ReadBlobMSBLong(image);\n    if (sun_info.magic == 0x59a66a95)\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while (sun_info.magic == 0x59a66a95);\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/6b4aff0f117b978502ee5bcd6e753c17aec5a961", "file_name": "coders/sun.c", "vul_type": "cwe-125", "description": "Write a C function to read and process SUN raster images."}
{"func_name": "lexer_process_char_literal", "func_src_before": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "func_src_after": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "commit_link": "github.com/zherczeg/jerryscript/commit/03a8c630f015f63268639d3ed3bf82cff6fa77d8", "file_name": "jerry-core/parser/js/js-lexer.c", "vul_type": "cwe-476", "description": "In C, write a function to process character literals in a lexer, handling escape sequences and ensuring they don't exceed predefined limits."}
{"func_name": "save_page_edit", "func_src_before": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "func_src_after": "@app.route('/<page_name>/save', methods=['POST'])\ndef save_page_edit(page_name):\n    # grab the new content from the user\n    content = request.form.get('content')\n    # check if 'page_name' exists in the database\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    result = query.namedresult()\n    # if it doesn't exist, create a new page in the database\n    if len(result) < 1:\n        db.insert(\n            'page', {\n                'page_name': page_name\n            }\n        )\n    else:\n        pass\n    # now that we're certain that the page exists in the database, we again grab the query\n    # and insert new content in the database\n    query = db.query(\"select id from page where page_name = '%s'\" % page_name)\n    page_id = query.namedresult()[0].id\n    db.insert(\n        'page_content', {\n            'page_id': page_id,\n            'content': content,\n            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\", localtime())\n        }\n    )\n    return redirect(\"/%s\" % page_name)", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "In Python, write a Flask endpoint to save edited content for a given page, creating the page in the database if it doesn't exist."}
{"func_name": "dd_save_text", "func_src_before": "void dd_save_text(struct dump_dir *dd, const char *name, const char *data)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, strlen(data), dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "func_src_after": "void dd_save_text(struct dump_dir *dd, const char *name, const char *data)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot save text. '%s' is not a valid file name\", name);\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, strlen(data), dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function `dd_save_text` to save text data to a file within a directory structure, handling errors for directory access and file naming."}
{"func_name": "HPHP::SimpleParser::TryParse", "func_src_before": "  static bool TryParse(const char* inp, int length,\n                       TypedValue* buf, Variant& out,\n                       JSONContainerType container_type, bool is_tsimplejson) {\n    SimpleParser parser(inp, length, buf, container_type, is_tsimplejson);\n    bool ok = parser.parseValue();\n    parser.skipSpace();\n    if (!ok || parser.p != inp + length) {\n      // Unsupported, malformed, or trailing garbage. Release entire stack.\n      tvDecRefRange(buf, parser.top);\n      return false;\n    }\n    out = Variant::attach(*--parser.top);\n    return true;\n  }", "func_src_after": "  static bool TryParse(const char* inp, int length,\n                       TypedValue* buf, Variant& out,\n                       JSONContainerType container_type, bool is_tsimplejson) {\n    SimpleParser parser(inp, length, buf, container_type, is_tsimplejson);\n    bool ok = parser.parseValue();\n    if (!ok ||\n        (parser.skipSpace(), parser.p != inp + length)) {\n      // Unsupported, malformed, or trailing garbage. Release entire stack.\n      tvDecRefRange(buf, parser.top);\n      return false;\n    }\n    out = Variant::attach(*--parser.top);\n    return true;\n  }", "commit_link": "github.com/facebook/hhvm/commit/bd586671a3c22eb2f07e55f11b3ce64e1f7961e7", "file_name": "hphp/runtime/ext/json/JSON_parser.cpp", "vul_type": "cwe-125", "description": "Create a C++ function named `TryParse` that attempts to parse a JSON string into a typed value and handles errors."}
{"func_name": "initHeader", "func_src_before": "    def initHeader(self):\n        \"\"\"Initialize the IP header according to the IP format definition.\n\n        \"\"\"\n\n        # Ethernet header\n\n        # Retrieve remote MAC address\n        dstMacAddr = arpreq.arpreq(self.remoteIP)\n        if dstMacAddr is not None:\n            dstMacAddr = dstMacAddr.replace(':', '')\n            dstMacAddr = binascii.unhexlify(dstMacAddr)\n        else:\n            # Force ARP resolution\n            p = subprocess.Popen([\"/bin/ping\", \"-c1\", self.remoteIP])\n            p.wait()\n            time.sleep(0.1)\n\n            dstMacAddr = arpreq.arpreq(self.remoteIP)\n            if dstMacAddr is not None:\n                dstMacAddr = dstMacAddr.replace(':', '')\n                dstMacAddr = binascii.unhexlify(dstMacAddr)\n            else:\n                raise Exception(\"Cannot resolve IP address to a MAC address for IP: '{}'\".format(self.remoteIP))\n\n        # Retrieve local MAC address\n        srcMacAddr = self.get_interface_addr(bytes(self.interface, 'utf-8'))[1]\n\n        eth_dst = Field(name='eth.dst', domain=Raw(dstMacAddr))\n        eth_src = Field(name='eth.src', domain=Raw(srcMacAddr))\n        eth_type = Field(name='eth.type', domain=Raw(b\"\\x08\\x00\"))\n\n\n        # IP header\n\n        ip_ver = Field(\n            name='ip.version', domain=BitArray(\n                value=bitarray('0100')))  # IP Version 4\n        ip_ihl = Field(name='ip.hdr_len', domain=BitArray(bitarray('0000')))\n        ip_tos = Field(\n            name='ip.tos',\n            domain=Data(\n                dataType=BitArray(nbBits=8),\n                originalValue=bitarray('00000000'),\n                svas=SVAS.PERSISTENT))\n        ip_tot_len = Field(\n            name='ip.len', domain=BitArray(bitarray('0000000000000000')))\n        ip_id = Field(name='ip.id', domain=BitArray(nbBits=16))\n        ip_flags = Field(name='ip.flags', domain=Data(dataType=BitArray(nbBits=3), originalValue=bitarray('000'), svas=SVAS.PERSISTENT))\n        ip_frag_off = Field(name='ip.fragment', domain=Data(dataType=BitArray(nbBits=13), originalValue=bitarray('0000000000000'), svas=SVAS.PERSISTENT))\n        ip_ttl = Field(name='ip.ttl', domain=Data(dataType=BitArray(nbBits=8), originalValue=bitarray('01000000'), svas=SVAS.PERSISTENT))\n        ip_proto = Field(name='ip.proto', domain=Integer(value=self.upperProtocol, unitSize=AbstractType.UNITSIZE_8, endianness=AbstractType.ENDIAN_BIG, sign=AbstractType.SIGN_UNSIGNED))\n        ip_checksum = Field(name='ip.checksum', domain=BitArray(bitarray('0000000000000000')))\n        ip_saddr = Field(name='ip.src', domain=IPv4(self.localIP))\n        ip_daddr = Field(\n            name='ip.dst', domain=IPv4(self.remoteIP))\n        ip_payload = Field(name='ip.payload', domain=Raw())\n\n        ip_ihl.domain = Size([ip_ver,\n                              ip_ihl,\n                              ip_tos,\n                              ip_tot_len,\n                              ip_id, ip_flags,\n                              ip_frag_off,\n                              ip_ttl, ip_proto,\n                              ip_checksum,\n                              ip_saddr,\n                              ip_daddr], dataType=BitArray(nbBits=4), factor=1/float(32))\n        ip_tot_len.domain = Size([ip_ver,\n                                  ip_ihl,\n                                  ip_tos,\n                                  ip_tot_len,\n                                  ip_id,\n                                  ip_flags,\n                                  ip_frag_off,\n                                  ip_ttl,\n                                  ip_proto,\n                                  ip_checksum,\n                                  ip_saddr,\n                                  ip_daddr,\n                                  ip_payload], dataType=Integer(unitSize=AbstractType.UNITSIZE_16, sign=AbstractType.SIGN_UNSIGNED), factor=1/float(8))\n        ip_checksum.domain = InternetChecksum(fields=[ip_ver,\n                                                      ip_ihl,\n                                                      ip_tos,\n                                                      ip_tot_len,\n                                                      ip_id,\n                                                      ip_flags,\n                                                      ip_frag_off,\n                                                      ip_ttl,\n                                                      ip_proto,\n                                                      ip_checksum,\n                                                      ip_saddr,\n                                                      ip_daddr], dataType=Raw(nbBytes=2, unitSize=AbstractType.UNITSIZE_16))\n        \n        self.header = Symbol(name='Ethernet layer', fields=[eth_dst,\n                                                            eth_src,\n                                                            eth_type,\n                                                            ip_ver,\n                                                            ip_ihl,\n                                                            ip_tos,\n                                                            ip_tot_len,\n                                                            ip_id,\n                                                            ip_flags,\n                                                            ip_frag_off,\n                                                            ip_ttl,\n                                                            ip_proto,\n                                                            ip_checksum,\n                                                            ip_saddr,\n                                                            ip_daddr,\n                                                            ip_payload])", "func_src_after": "    def initHeader(self):\n        \"\"\"Initialize the IP header according to the IP format definition.\n\n        \"\"\"\n\n        # Ethernet header\n\n        # Retrieve remote MAC address\n        dstMacAddr = arpreq.arpreq(self.remoteIP)\n        if dstMacAddr is not None:\n            dstMacAddr = dstMacAddr.replace(':', '')\n            dstMacAddr = binascii.unhexlify(dstMacAddr)\n        else:\n            # Force ARP resolution\n            p = subprocess.Popen(\"ping -c1 {}\".format(self.remoteIP), shell=True)\n            p.wait()\n            time.sleep(0.1)\n\n            dstMacAddr = arpreq.arpreq(self.remoteIP)\n            if dstMacAddr is not None:\n                dstMacAddr = dstMacAddr.replace(':', '')\n                dstMacAddr = binascii.unhexlify(dstMacAddr)\n            else:\n                raise Exception(\"Cannot resolve IP address to a MAC address for IP: '{}'\".format(self.remoteIP))\n\n        # Retrieve local MAC address\n        srcMacAddr = self.get_interface_addr(bytes(self.interface, 'utf-8'))[1]\n\n        eth_dst = Field(name='eth.dst', domain=Raw(dstMacAddr))\n        eth_src = Field(name='eth.src', domain=Raw(srcMacAddr))\n        eth_type = Field(name='eth.type', domain=Raw(b\"\\x08\\x00\"))\n\n\n        # IP header\n\n        ip_ver = Field(\n            name='ip.version', domain=BitArray(\n                value=bitarray('0100')))  # IP Version 4\n        ip_ihl = Field(name='ip.hdr_len', domain=BitArray(bitarray('0000')))\n        ip_tos = Field(\n            name='ip.tos',\n            domain=Data(\n                dataType=BitArray(nbBits=8),\n                originalValue=bitarray('00000000'),\n                svas=SVAS.PERSISTENT))\n        ip_tot_len = Field(\n            name='ip.len', domain=BitArray(bitarray('0000000000000000')))\n        ip_id = Field(name='ip.id', domain=BitArray(nbBits=16))\n        ip_flags = Field(name='ip.flags', domain=Data(dataType=BitArray(nbBits=3), originalValue=bitarray('000'), svas=SVAS.PERSISTENT))\n        ip_frag_off = Field(name='ip.fragment', domain=Data(dataType=BitArray(nbBits=13), originalValue=bitarray('0000000000000'), svas=SVAS.PERSISTENT))\n        ip_ttl = Field(name='ip.ttl', domain=Data(dataType=BitArray(nbBits=8), originalValue=bitarray('01000000'), svas=SVAS.PERSISTENT))\n        ip_proto = Field(name='ip.proto', domain=Integer(value=self.upperProtocol, unitSize=AbstractType.UNITSIZE_8, endianness=AbstractType.ENDIAN_BIG, sign=AbstractType.SIGN_UNSIGNED))\n        ip_checksum = Field(name='ip.checksum', domain=BitArray(bitarray('0000000000000000')))\n        ip_saddr = Field(name='ip.src', domain=IPv4(self.localIP))\n        ip_daddr = Field(\n            name='ip.dst', domain=IPv4(self.remoteIP))\n        ip_payload = Field(name='ip.payload', domain=Raw())\n\n        ip_ihl.domain = Size([ip_ver,\n                              ip_ihl,\n                              ip_tos,\n                              ip_tot_len,\n                              ip_id, ip_flags,\n                              ip_frag_off,\n                              ip_ttl, ip_proto,\n                              ip_checksum,\n                              ip_saddr,\n                              ip_daddr], dataType=BitArray(nbBits=4), factor=1/float(32))\n        ip_tot_len.domain = Size([ip_ver,\n                                  ip_ihl,\n                                  ip_tos,\n                                  ip_tot_len,\n                                  ip_id,\n                                  ip_flags,\n                                  ip_frag_off,\n                                  ip_ttl,\n                                  ip_proto,\n                                  ip_checksum,\n                                  ip_saddr,\n                                  ip_daddr,\n                                  ip_payload], dataType=Integer(unitSize=AbstractType.UNITSIZE_16, sign=AbstractType.SIGN_UNSIGNED), factor=1/float(8))\n        ip_checksum.domain = InternetChecksum(fields=[ip_ver,\n                                                      ip_ihl,\n                                                      ip_tos,\n                                                      ip_tot_len,\n                                                      ip_id,\n                                                      ip_flags,\n                                                      ip_frag_off,\n                                                      ip_ttl,\n                                                      ip_proto,\n                                                      ip_checksum,\n                                                      ip_saddr,\n                                                      ip_daddr], dataType=Raw(nbBytes=2, unitSize=AbstractType.UNITSIZE_16))\n        \n        self.header = Symbol(name='Ethernet layer', fields=[eth_dst,\n                                                            eth_src,\n                                                            eth_type,\n                                                            ip_ver,\n                                                            ip_ihl,\n                                                            ip_tos,\n                                                            ip_tot_len,\n                                                            ip_id,\n                                                            ip_flags,\n                                                            ip_frag_off,\n                                                            ip_ttl,\n                                                            ip_proto,\n                                                            ip_checksum,\n                                                            ip_saddr,\n                                                            ip_daddr,\n                                                            ip_payload])", "commit_link": "github.com/netzob/netzob/commit/557abf64867d715497979b029efedbd2777b912e", "file_name": "src/netzob/Simulator/Channels/RawEthernetClient.py", "vul_type": "cwe-078", "description": "In Python, write a method to initialize an Ethernet and IP header with ARP resolution and field definitions."}
{"func_name": "AdaptiveThresholdImage", "func_src_before": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const ssize_t offset,\n  ExceptionInfo *exception)\n{\n#define ThresholdImageTag  \"Threshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickPixelPacket\n    zero;\n\n  MagickRealType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(threshold_image,DirectClass) == MagickFalse)\n    {\n      InheritException(exception,&threshold_image->exception);\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Local adaptive threshold.\n  */\n  status=MagickTrue;\n  progress=0;\n  GetMagickPixelPacket(image,&zero);\n  number_pixels=(MagickRealType) (width*height);\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    MagickBooleanType\n      sync;\n\n    MagickPixelPacket\n      channel_bias,\n      channel_sum;\n\n    register const IndexPacket\n      *magick_restrict indexes;\n\n    register const PixelPacket\n      *magick_restrict p,\n      *magick_restrict r;\n\n    register IndexPacket\n      *magick_restrict threshold_indexes;\n\n    register PixelPacket\n      *magick_restrict q;\n\n    register ssize_t\n      x;\n\n    ssize_t\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      height/2L,image->columns+width,height,exception);\n    q=GetCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,1,\n      exception);\n    if ((p == (const PixelPacket *) NULL) || (q == (PixelPacket *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    indexes=GetCacheViewVirtualIndexQueue(image_view);\n    threshold_indexes=GetCacheViewAuthenticIndexQueue(threshold_view);\n    channel_bias=zero;\n    channel_sum=zero;\n    r=p;\n    for (v=0; v < (ssize_t) height; v++)\n    {\n      for (u=0; u < (ssize_t) width; u++)\n      {\n        if (u == (ssize_t) (width-1))\n          {\n            channel_bias.red+=r[u].red;\n            channel_bias.green+=r[u].green;\n            channel_bias.blue+=r[u].blue;\n            channel_bias.opacity+=r[u].opacity;\n            if (image->colorspace == CMYKColorspace)\n              channel_bias.index=(MagickRealType)\n                GetPixelIndex(indexes+(r-p)+u);\n          }\n        channel_sum.red+=r[u].red;\n        channel_sum.green+=r[u].green;\n        channel_sum.blue+=r[u].blue;\n        channel_sum.opacity+=r[u].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+(r-p)+u);\n      }\n      r+=image->columns+width;\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      MagickPixelPacket\n        mean;\n\n      mean=zero;\n      r=p;\n      channel_sum.red-=channel_bias.red;\n      channel_sum.green-=channel_bias.green;\n      channel_sum.blue-=channel_bias.blue;\n      channel_sum.opacity-=channel_bias.opacity;\n      channel_sum.index-=channel_bias.index;\n      channel_bias=zero;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        channel_bias.red+=r[0].red;\n        channel_bias.green+=r[0].green;\n        channel_bias.blue+=r[0].blue;\n        channel_bias.opacity+=r[0].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_bias.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+0);\n        channel_sum.red+=r[width-1].red;\n        channel_sum.green+=r[width-1].green;\n        channel_sum.blue+=r[width-1].blue;\n        channel_sum.opacity+=r[width-1].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+\n            width-1);\n        r+=image->columns+width;\n      }\n      mean.red=(MagickRealType) (channel_sum.red/number_pixels+offset);\n      mean.green=(MagickRealType) (channel_sum.green/number_pixels+offset);\n      mean.blue=(MagickRealType) (channel_sum.blue/number_pixels+offset);\n      mean.opacity=(MagickRealType) (channel_sum.opacity/number_pixels+offset);\n      if (image->colorspace == CMYKColorspace)\n        mean.index=(MagickRealType) (channel_sum.index/number_pixels+offset);\n      SetPixelRed(q,((MagickRealType) GetPixelRed(q) <= mean.red) ?\n        0 : QuantumRange);\n      SetPixelGreen(q,((MagickRealType) GetPixelGreen(q) <= mean.green) ?\n        0 : QuantumRange);\n      SetPixelBlue(q,((MagickRealType) GetPixelBlue(q) <= mean.blue) ?\n        0 : QuantumRange);\n      SetPixelOpacity(q,((MagickRealType) GetPixelOpacity(q) <= mean.opacity) ?\n        0 : QuantumRange);\n      if (image->colorspace == CMYKColorspace)\n        SetPixelIndex(threshold_indexes+x,(((MagickRealType) GetPixelIndex(\n          threshold_indexes+x) <= mean.index) ? 0 : QuantumRange));\n      p++;\n      q++;\n    }\n    sync=SyncCacheViewAuthenticPixels(threshold_view,exception);\n    if (sync == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,ThresholdImageTag,progress,image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "func_src_after": "MagickExport Image *AdaptiveThresholdImage(const Image *image,\n  const size_t width,const size_t height,const ssize_t offset,\n  ExceptionInfo *exception)\n{\n#define ThresholdImageTag  \"Threshold/Image\"\n\n  CacheView\n    *image_view,\n    *threshold_view;\n\n  Image\n    *threshold_image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  MagickPixelPacket\n    zero;\n\n  MagickRealType\n    number_pixels;\n\n  ssize_t\n    y;\n\n  assert(image != (const Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  threshold_image=CloneImage(image,0,0,MagickTrue,exception);\n  if (threshold_image == (Image *) NULL)\n    return((Image *) NULL);\n  if (width == 0)\n    return(threshold_image);\n  if (SetImageStorageClass(threshold_image,DirectClass) == MagickFalse)\n    {\n      InheritException(exception,&threshold_image->exception);\n      threshold_image=DestroyImage(threshold_image);\n      return((Image *) NULL);\n    }\n  /*\n    Local adaptive threshold.\n  */\n  status=MagickTrue;\n  progress=0;\n  GetMagickPixelPacket(image,&zero);\n  number_pixels=(MagickRealType) (width*height);\n  image_view=AcquireVirtualCacheView(image,exception);\n  threshold_view=AcquireAuthenticCacheView(threshold_image,exception);\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(image,threshold_image,image->rows,1)\n#endif\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    MagickBooleanType\n      sync;\n\n    MagickPixelPacket\n      channel_bias,\n      channel_sum;\n\n    register const IndexPacket\n      *magick_restrict indexes;\n\n    register const PixelPacket\n      *magick_restrict p,\n      *magick_restrict r;\n\n    register IndexPacket\n      *magick_restrict threshold_indexes;\n\n    register PixelPacket\n      *magick_restrict q;\n\n    register ssize_t\n      x;\n\n    ssize_t\n      u,\n      v;\n\n    if (status == MagickFalse)\n      continue;\n    p=GetCacheViewVirtualPixels(image_view,-((ssize_t) width/2L),y-(ssize_t)\n      height/2L,image->columns+width,height,exception);\n    q=GetCacheViewAuthenticPixels(threshold_view,0,y,threshold_image->columns,1,\n      exception);\n    if ((p == (const PixelPacket *) NULL) || (q == (PixelPacket *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    indexes=GetCacheViewVirtualIndexQueue(image_view);\n    threshold_indexes=GetCacheViewAuthenticIndexQueue(threshold_view);\n    channel_bias=zero;\n    channel_sum=zero;\n    r=p;\n    for (v=0; v < (ssize_t) height; v++)\n    {\n      for (u=0; u < (ssize_t) width; u++)\n      {\n        if (u == (ssize_t) (width-1))\n          {\n            channel_bias.red+=r[u].red;\n            channel_bias.green+=r[u].green;\n            channel_bias.blue+=r[u].blue;\n            channel_bias.opacity+=r[u].opacity;\n            if (image->colorspace == CMYKColorspace)\n              channel_bias.index=(MagickRealType)\n                GetPixelIndex(indexes+(r-p)+u);\n          }\n        channel_sum.red+=r[u].red;\n        channel_sum.green+=r[u].green;\n        channel_sum.blue+=r[u].blue;\n        channel_sum.opacity+=r[u].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+(r-p)+u);\n      }\n      r+=image->columns+width;\n    }\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      MagickPixelPacket\n        mean;\n\n      mean=zero;\n      r=p;\n      channel_sum.red-=channel_bias.red;\n      channel_sum.green-=channel_bias.green;\n      channel_sum.blue-=channel_bias.blue;\n      channel_sum.opacity-=channel_bias.opacity;\n      channel_sum.index-=channel_bias.index;\n      channel_bias=zero;\n      for (v=0; v < (ssize_t) height; v++)\n      {\n        channel_bias.red+=r[0].red;\n        channel_bias.green+=r[0].green;\n        channel_bias.blue+=r[0].blue;\n        channel_bias.opacity+=r[0].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_bias.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+0);\n        channel_sum.red+=r[width-1].red;\n        channel_sum.green+=r[width-1].green;\n        channel_sum.blue+=r[width-1].blue;\n        channel_sum.opacity+=r[width-1].opacity;\n        if (image->colorspace == CMYKColorspace)\n          channel_sum.index=(MagickRealType) GetPixelIndex(indexes+x+(r-p)+\n            width-1);\n        r+=image->columns+width;\n      }\n      mean.red=(MagickRealType) (channel_sum.red/number_pixels+offset);\n      mean.green=(MagickRealType) (channel_sum.green/number_pixels+offset);\n      mean.blue=(MagickRealType) (channel_sum.blue/number_pixels+offset);\n      mean.opacity=(MagickRealType) (channel_sum.opacity/number_pixels+offset);\n      if (image->colorspace == CMYKColorspace)\n        mean.index=(MagickRealType) (channel_sum.index/number_pixels+offset);\n      SetPixelRed(q,((MagickRealType) GetPixelRed(q) <= mean.red) ?\n        0 : QuantumRange);\n      SetPixelGreen(q,((MagickRealType) GetPixelGreen(q) <= mean.green) ?\n        0 : QuantumRange);\n      SetPixelBlue(q,((MagickRealType) GetPixelBlue(q) <= mean.blue) ?\n        0 : QuantumRange);\n      SetPixelOpacity(q,((MagickRealType) GetPixelOpacity(q) <= mean.opacity) ?\n        0 : QuantumRange);\n      if (image->colorspace == CMYKColorspace)\n        SetPixelIndex(threshold_indexes+x,(((MagickRealType) GetPixelIndex(\n          threshold_indexes+x) <= mean.index) ? 0 : QuantumRange));\n      p++;\n      q++;\n    }\n    sync=SyncCacheViewAuthenticPixels(threshold_view,exception);\n    if (sync == MagickFalse)\n      status=MagickFalse;\n    if (image->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(image,ThresholdImageTag,progress,image->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  threshold_view=DestroyCacheView(threshold_view);\n  image_view=DestroyCacheView(image_view);\n  if (status == MagickFalse)\n    threshold_image=DestroyImage(threshold_image);\n  return(threshold_image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick6/commit/55e6dc49f1a381d9d511ee2f888fdc3e3c3e3953", "file_name": "magick/threshold.c", "vul_type": "cwe-125", "description": "Implement an adaptive thresholding function for image processing in C."}
{"func_name": "valid_id", "func_src_before": "def valid_id(opts, id_):\n    '''\n    Returns if the passed id is valid\n    '''\n    try:\n        return bool(clean_path(opts['pki_dir'], id_)) and clean_id(id_)\n    except (AttributeError, KeyError, TypeError) as e:\n        return False", "func_src_after": "def valid_id(opts, id_):\n    '''\n    Returns if the passed id is valid\n    '''\n    try:\n        if any(x in id_ for x in ('/', '\\\\', '\\0')):\n            return False\n        return bool(clean_path(opts['pki_dir'], id_))\n    except (AttributeError, KeyError, TypeError):\n        return False", "commit_link": "github.com/saltstack/salt/commit/80d90307b07b3703428ecbb7c8bb468e28a9ae6d", "file_name": "salt/utils/verify.py", "vul_type": "cwe-022", "description": "Write a Python function named `valid_id` that checks the validity of an identifier based on certain conditions and directory path options."}
{"func_name": "start", "func_src_before": "def start():\n    print(\"[*] Starting backdoor process\")\n    print(\"[*] Decompressing target to tmp directory...\")\n    #subprocess.call(\"jar -x %s\" % target, shell=True)\n    with zipfile.ZipFile(target, 'r') as zip:\n        zip.extractall(\"tmp\")\n    print(\"[*] Target dumped to tmp directory\")\n\n    print(\"[*] Modifying manifest file...\")\n    oldmain=\"\"\n    man = open(\"tmp/META-INF/MANIFEST.MF\",\"r\").read()\n    with open(\"tmp/META-INF/MANIFEST.MF\",\"w\") as f:\n        for l in man.split(\"\\n\"):\n            if \"Main-Class\" in l:\n                oldmain=l[12:]\n                f.write(\"Main-Class: %s\\n\" % \"Backdoor\")\n            else:\n                f.write(\"%s\\n\" % l)\n    print(\"[*] Manifest file modified\")\n    \n    print(\"[*] Modifying provided backdoor...\")\n    inmain=False\n    level=0\n    bd=open(backdoor, \"r\").read()\n    with open(\"tmp/%s\" % backdoor,'w') as f:\n        for l in bd.split(\"\\n\"):\n            if \"main(\" in l:\n                inmain=True\n                f.write(l)\n            elif \"}\" in l and level<2 and inmain:\n                f.write(\"%s.main(args);}\" % oldmain)\n                inmain=False\n            elif \"}\" in l and level>1 and inmain:\n                level-=1\n                f.write(l)\n            elif \"{\" in l and inmain:\n                level+=1\n                f.write(l)\n            else:\n                f.write(l)\n    print(\"[*] Provided backdoor successfully modified\")\n\n    print(\"[*] Compiling modified backdoor...\")\n    if subprocess.call(\"javac -cp tmp/ tmp/%s\" % backdoor, shell=True) != 0:\n        print(\"[!] Error compiling %s\" % backdoor)\n    print(\"[*] Compiled modified backdoor\")\n                \n    if(len(oldmain)<1):\n        print(\"[!] Main-Class manifest attribute not found\")\n    else:\n        print(\"[*] Repackaging target jar file...\")\n        createZip(\"tmp\",outfile)\n        print(\"[*] Target jar successfully repackaged\")\n    shutil.rmtree('tmp/')", "func_src_after": "def start():\n    print(\"[*] Starting backdoor process\")\n    print(\"[*] Decompressing target to tmp directory...\")\n    #subprocess.call(\"jar -x %s\" % target, shell=True)\n    with zipfile.ZipFile(target, 'r') as zip:\n        zip.extractall(\"tmp\")\n    print(\"[*] Target dumped to tmp directory\")\n\n    print(\"[*] Modifying manifest file...\")\n    oldmain=\"\"\n    man = open(\"tmp/META-INF/MANIFEST.MF\",\"r\").read()\n    with open(\"tmp/META-INF/MANIFEST.MF\",\"w\") as f:\n        for l in man.split(\"\\n\"):\n            if \"Main-Class\" in l:\n                oldmain=l[12:]\n                f.write(\"Main-Class: %s\\n\" % \"Backdoor\")\n            else:\n                f.write(\"%s\\n\" % l)\n    print(\"[*] Manifest file modified\")\n    \n    print(\"[*] Modifying provided backdoor...\")\n    inmain=False\n    level=0\n    bd=open(backdoor, \"r\").read()\n    with open(\"tmp/%s\" % backdoor,'w') as f:\n        for l in bd.split(\"\\n\"):\n            if \"main(\" in l:\n                inmain=True\n                f.write(l)\n            elif \"}\" in l and level<2 and inmain:\n                f.write(\"%s.main(args);}\" % oldmain)\n                inmain=False\n            elif \"}\" in l and level>1 and inmain:\n                level-=1\n                f.write(l)\n            elif \"{\" in l and inmain:\n                level+=1\n                f.write(l)\n            else:\n                f.write(l)\n    print(\"[*] Provided backdoor successfully modified\")\n\n    print(\"[*] Compiling modified backdoor...\")\n    #if subprocess.call(\"javac -cp tmp/ tmp/%s\" % backdoor, shell=True) != 0:\n    if subprocess.call(['javac','-cp','tmp/','tmp/%s'%backdoor],shell=False) != 0:\n        print(\"[!] Error compiling %s\" % backdoor)\n    print(\"[*] Compiled modified backdoor\")\n                \n    if(len(oldmain)<1):\n        print(\"[!] Main-Class manifest attribute not found\")\n    else:\n        print(\"[*] Repackaging target jar file...\")\n        createZip(\"tmp\",outfile)\n        print(\"[*] Target jar successfully repackaged\")\n    shutil.rmtree('tmp/')", "commit_link": "github.com/Atticuss/ajar/commit/5ed8aba271ad20e6168f2e3bd6c25ba89b84484f", "file_name": "ajar.py", "vul_type": "cwe-078", "description": "Write a Python function to inject a backdoor into a Java application by modifying its manifest and main class, then recompiling and repackaging it."}
{"func_name": "cancelFollow", "func_src_before": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%d;\"%(userid,friendid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def cancelFollow(self,userid,friendid):\n        sqlText=\"delete from friends where userid=%d and friendid=%s;\"\n        params=[userid,friendid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `cancelFollow` that removes a friend connection from a database using SQL."}
{"func_name": "get_user", "func_src_before": "    def get_user(self):\n        if not hasattr(self, '_user'):\n            qs = \"select * from account_access where access_token = '%s'\" % self.access_token\n            result = self.db.get(qs)\n            if result:\n                self._user = result\n            else:\n                self._user = None\n        \n        return self._user", "func_src_after": "    def get_user(self):\n        if not hasattr(self, '_user'):\n            qs = \"select * from account_access where access_token = %s\"\n            result = self.db.get(qs, self.access_token)\n            if result:\n                self._user = result\n            else:\n                self._user = None\n        \n        return self._user", "commit_link": "github.com/bonbondirac/tsunami/commit/396cc394bd6daaf0ee9c16b1b55a4082eeaac208", "file_name": "src/auth.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch a user from a database using an access token, with and without string formatting."}
{"func_name": "bin_symbols", "func_src_before": "static int bin_symbols(RCore *r, int mode, ut64 laddr, int va, ut64 at, const char *name, bool exponly, const char *args) {\n\tRBinInfo *info = r_bin_get_info (r->bin);\n\tRList *entries = r_bin_get_entries (r->bin);\n\tRBinSymbol *symbol;\n\tRBinAddr *entry;\n\tRListIter *iter;\n\tbool firstexp = true;\n\tbool printHere = false;\n\tint i = 0, lastfs = 's';\n\tbool bin_demangle = r_config_get_i (r->config, \"bin.demangle\");\n\tif (!info) {\n\t\treturn 0;\n\t}\n\n\tif (args && *args == '.') {\n\t\tprintHere = true;\n\t}\n\n\tbool is_arm = info && info->arch && !strncmp (info->arch, \"arm\", 3);\n\tconst char *lang = bin_demangle ? r_config_get (r->config, \"bin.lang\") : NULL;\n\n\tRList *symbols = r_bin_get_symbols (r->bin);\n\tr_spaces_push (&r->anal->meta_spaces, \"bin\");\n\n\tif (IS_MODE_JSON (mode) && !printHere) {\n\t\tr_cons_printf (\"[\");\n\t} else if (IS_MODE_SET (mode)) {\n\t\tr_flag_space_set (r->flags, R_FLAGS_FS_SYMBOLS);\n\t} else if (!at && exponly) {\n\t\tif (IS_MODE_RAD (mode)) {\n\t\t\tr_cons_printf (\"fs exports\\n\");\n\t\t} else if (IS_MODE_NORMAL (mode)) {\n\t\t\tr_cons_printf (printHere ? \"\" : \"[Exports]\\n\");\n\t\t}\n\t} else if (!at && !exponly) {\n\t\tif (IS_MODE_RAD (mode)) {\n\t\t\tr_cons_printf (\"fs symbols\\n\");\n\t\t} else if (IS_MODE_NORMAL (mode)) {\n\t\t\tr_cons_printf (printHere ? \"\" : \"[Symbols]\\n\");\n\t\t}\n\t}\n\tif (IS_MODE_NORMAL (mode)) {\n\t\tr_cons_printf (\"Num Paddr      Vaddr      Bind     Type Size Name\\n\");\n\t}\n\n\n\tsize_t count = 0;\n\tr_list_foreach (symbols, iter, symbol) {\n\t\tif (!symbol->name) {\n\t\t\tcontinue;\n\t\t}\n\t\tchar *r_symbol_name = r_str_escape_utf8 (symbol->name, false, true);\n\t\tut64 addr = compute_addr (r->bin, symbol->paddr, symbol->vaddr, va);\n\t\tint len = symbol->size ? symbol->size : 32;\n\t\tSymName sn = {0};\n\n\t\tif (exponly && !isAnExport (symbol)) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (name && strcmp (r_symbol_name, name)) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (at && (!symbol->size || !is_in_range (at, addr, symbol->size))) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif ((printHere && !is_in_range (r->offset, symbol->paddr, len))\n\t\t\t\t&& (printHere && !is_in_range (r->offset, addr, len))) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tcount ++;\n\t\tsnInit (r, &sn, symbol, lang);\n\n\t\tif (IS_MODE_SET (mode) && (is_section_symbol (symbol) || is_file_symbol (symbol))) {\n\t\t\t/*\n\t\t\t * Skip section symbols because they will have their own flag.\n\t\t\t * Skip also file symbols because not useful for now.\n\t\t\t */\n\t\t} else if (IS_MODE_SET (mode) && is_special_symbol (symbol)) {\n\t\t\tif (is_arm) {\n\t\t\t\thandle_arm_special_symbol (r, symbol, va);\n\t\t\t}\n\t\t} else if (IS_MODE_SET (mode)) {\n\t\t\t// TODO: provide separate API in RBinPlugin to let plugins handle anal hints/metadata\n\t\t\tif (is_arm) {\n\t\t\t\thandle_arm_symbol (r, symbol, info, va);\n\t\t\t}\n\t\t\tselect_flag_space (r, symbol);\n\t\t\t/* If that's a Classed symbol (method or so) */\n\t\t\tif (sn.classname) {\n\t\t\t\tRFlagItem *fi = r_flag_get (r->flags, sn.methflag);\n\t\t\t\tif (r->bin->prefix) {\n\t\t\t\t\tchar *prname = r_str_newf (\"%s.%s\", r->bin->prefix, sn.methflag);\n\t\t\t\t\tr_name_filter (sn.methflag, -1);\n\t\t\t\t\tfree (sn.methflag);\n\t\t\t\t\tsn.methflag = prname;\n\t\t\t\t}\n\t\t\t\tif (fi) {\n\t\t\t\t\tr_flag_item_set_realname (fi, sn.methname);\n\t\t\t\t\tif ((fi->offset - r->flags->base) == addr) {\n\t\t\t\t//\t\tchar *comment = fi->comment ? strdup (fi->comment) : NULL;\n\t\t\t\t\t\tr_flag_unset (r->flags, fi);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfi = r_flag_set (r->flags, sn.methflag, addr, symbol->size);\n\t\t\t\t\tchar *comment = fi->comment ? strdup (fi->comment) : NULL;\n\t\t\t\t\tif (comment) {\n\t\t\t\t\t\tr_flag_item_set_comment (fi, comment);\n\t\t\t\t\t\tR_FREE (comment);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst char *n = sn.demname ? sn.demname : sn.name;\n\t\t\t\tconst char *fn = sn.demflag ? sn.demflag : sn.nameflag;\n\t\t\t\tchar *fnp = (r->bin->prefix) ?\n\t\t\t\t\tr_str_newf (\"%s.%s\", r->bin->prefix, fn):\n\t\t\t\t\tstrdup (fn);\n\t\t\t\tRFlagItem *fi = r_flag_set (r->flags, fnp, addr, symbol->size);\n\t\t\t\tif (fi) {\n\t\t\t\t\tr_flag_item_set_realname (fi, n);\n\t\t\t\t\tfi->demangled = (bool)(size_t)sn.demname;\n\t\t\t\t} else {\n\t\t\t\t\tif (fn) {\n\t\t\t\t\t\teprintf (\"[Warning] Can't find flag (%s)\\n\", fn);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfree (fnp);\n\t\t\t}\n\t\t\tif (sn.demname) {\n\t\t\t\tr_meta_add (r->anal, R_META_TYPE_COMMENT,\n\t\t\t\t\taddr, symbol->size, sn.demname);\n\t\t\t}\n\t\t\tr_flag_space_pop (r->flags);\n\t\t} else if (IS_MODE_JSON (mode)) {\n\t\t\tchar *str = r_str_escape_utf8_for_json (r_symbol_name, -1);\n\t\t\t// str = r_str_replace (str, \"\\\"\", \"\\\\\\\"\", 1);\n\t\t\tr_cons_printf (\"%s{\\\"name\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"demname\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"flagname\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"ordinal\\\":%d,\"\n\t\t\t\t\"\\\"bind\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"size\\\":%d,\"\n\t\t\t\t\"\\\"type\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"vaddr\\\":%\"PFMT64d\",\"\n\t\t\t\t\"\\\"paddr\\\":%\"PFMT64d\"}\",\n\t\t\t\t((exponly && firstexp) || printHere) ? \"\" : (iter->p ? \",\" : \"\"),\n\t\t\t\tstr,\n\t\t\t\tsn.demname? sn.demname: \"\",\n\t\t\t\tsn.nameflag,\n\t\t\t\tsymbol->ordinal,\n\t\t\t\tsymbol->bind,\n\t\t\t\t(int)symbol->size,\n\t\t\t\tsymbol->type,\n\t\t\t\t(ut64)addr, (ut64)symbol->paddr);\n\t\t\tfree (str);\n\t\t} else if (IS_MODE_SIMPLE (mode)) {\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tr_cons_printf (\"0x%08\"PFMT64x\" %d %s\\n\",\n\t\t\t\taddr, (int)symbol->size, name);\n\t\t} else if (IS_MODE_SIMPLEST (mode)) {\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tr_cons_printf (\"%s\\n\", name);\n\t\t} else if (IS_MODE_RAD (mode)) {\n\t\t\t/* Skip special symbols because we do not flag them and\n\t\t\t * they shouldn't be printed in the rad format either */\n\t\t\tif (is_special_symbol (symbol)) {\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tRBinFile *binfile;\n\t\t\tRBinPlugin *plugin;\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tif (!name) {\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tif (!strncmp (name, \"imp.\", 4)) {\n\t\t\t\tif (lastfs != 'i') {\n\t\t\t\t\tr_cons_printf (\"fs imports\\n\");\n\t\t\t\t}\n\t\t\t\tlastfs = 'i';\n\t\t\t} else {\n\t\t\t\tif (lastfs != 's') {\n\t\t\t\t\tconst char *fs = exponly? \"exports\": \"symbols\";\n\t\t\t\t\tr_cons_printf (\"fs %s\\n\", fs);\n\t\t\t\t}\n\t\t\t\tlastfs = 's';\n\t\t\t}\n\t\t\tif (r->bin->prefix || *name) { // we don't want unnamed symbol flags\n\t\t\t\tchar *flagname = construct_symbol_flagname (\"sym\", name, MAXFLAG_LEN_DEFAULT);\n\t\t\t\tif (!flagname) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"f %s%s%s %u 0x%08\" PFMT64x \"\\\"\\n\",\n\t\t\t\t\tr->bin->prefix ? r->bin->prefix : \"\", r->bin->prefix ? \".\" : \"\",\n\t\t\t\t\tflagname, symbol->size, addr);\n\t\t\t\tfree (flagname);\n\t\t\t}\n\t\t\tbinfile = r_bin_cur (r->bin);\n\t\t\tplugin = r_bin_file_cur_plugin (binfile);\n\t\t\tif (plugin && plugin->name) {\n\t\t\t\tif (r_str_startswith (plugin->name, \"pe\")) {\n\t\t\t\t\tchar *module = strdup (r_symbol_name);\n\t\t\t\t\tchar *p = strstr (module, \".dll_\");\n\t\t\t\t\tif (p && strstr (module, \"imp.\")) {\n\t\t\t\t\t\tchar *symname = __filterShell (p + 5);\n\t\t\t\t\t\tchar *m = __filterShell (module);\n\t\t\t\t\t\t*p = 0;\n\t\t\t\t\t\tif (r->bin->prefix) {\n\t\t\t\t\t\t\tr_cons_printf (\"\\\"k bin/pe/%s/%d=%s.%s\\\"\\n\",\n\t\t\t\t\t\t\t\tmodule, symbol->ordinal, r->bin->prefix, symname);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tr_cons_printf (\"\\\"k bin/pe/%s/%d=%s\\\"\\n\",\n\t\t\t\t\t\t\t\tmodule, symbol->ordinal, symname);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfree (symname);\n\t\t\t\t\t\tfree (m);\n\t\t\t\t\t}\n\t\t\t\t\tfree (module);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tconst char *bind = symbol->bind? symbol->bind: \"NONE\";\n\t\t\tconst char *type = symbol->type? symbol->type: \"NONE\";\n\t\t\tconst char *name = r_str_get (sn.demname? sn.demname: r_symbol_name);\n\t\t\t// const char *fwd = r_str_get (symbol->forwarder);\n\t\t\tr_cons_printf (\"%03u\", symbol->ordinal);\n\t\t\tif (symbol->paddr == UT64_MAX) {\n\t\t\t\tr_cons_printf (\" ----------\");\n\t\t\t} else {\n\t\t\t\tr_cons_printf (\" 0x%08\"PFMT64x, symbol->paddr);\n\t\t\t}\n\t\t\tr_cons_printf (\" 0x%08\"PFMT64x\" %6s %6s %4d%s%s\\n\",\n\t\t\t               addr, bind, type, symbol->size, *name? \" \": \"\", name);\n\t\t}\nnext:\n\t\tsnFini (&sn);\n\t\ti++;\n\t\tfree (r_symbol_name);\n\t\tif (exponly && firstexp) {\n\t\t\tfirstexp = false;\n\t\t}\n\t\tif (printHere) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (count == 0 && IS_MODE_JSON (mode)) {\n\t\tr_cons_printf (\"{}\");\n\t}\n\n\n\t//handle thumb and arm for entry point since they are not present in symbols\n\tif (is_arm) {\n\t\tr_list_foreach (entries, iter, entry) {\n\t\t\tif (IS_MODE_SET (mode)) {\n\t\t\t\thandle_arm_entry (r, entry, info, va);\n\t\t\t}\n\t\t}\n\t}\n\tif (IS_MODE_JSON (mode) && !printHere) {\n\t\tr_cons_printf (\"]\");\n\t}\n\n\tr_spaces_pop (&r->anal->meta_spaces);\n\treturn true;\n}", "func_src_after": "static int bin_symbols(RCore *r, int mode, ut64 laddr, int va, ut64 at, const char *name, bool exponly, const char *args) {\n\tRBinInfo *info = r_bin_get_info (r->bin);\n\tRList *entries = r_bin_get_entries (r->bin);\n\tRBinSymbol *symbol;\n\tRBinAddr *entry;\n\tRListIter *iter;\n\tbool firstexp = true;\n\tbool printHere = false;\n\tint i = 0, lastfs = 's';\n\tbool bin_demangle = r_config_get_i (r->config, \"bin.demangle\");\n\tif (!info) {\n\t\treturn 0;\n\t}\n\n\tif (args && *args == '.') {\n\t\tprintHere = true;\n\t}\n\n\tbool is_arm = info && info->arch && !strncmp (info->arch, \"arm\", 3);\n\tconst char *lang = bin_demangle ? r_config_get (r->config, \"bin.lang\") : NULL;\n\n\tRList *symbols = r_bin_get_symbols (r->bin);\n\tr_spaces_push (&r->anal->meta_spaces, \"bin\");\n\n\tif (IS_MODE_JSON (mode) && !printHere) {\n\t\tr_cons_printf (\"[\");\n\t} else if (IS_MODE_SET (mode)) {\n\t\tr_flag_space_set (r->flags, R_FLAGS_FS_SYMBOLS);\n\t} else if (!at && exponly) {\n\t\tif (IS_MODE_RAD (mode)) {\n\t\t\tr_cons_printf (\"fs exports\\n\");\n\t\t} else if (IS_MODE_NORMAL (mode)) {\n\t\t\tr_cons_printf (printHere ? \"\" : \"[Exports]\\n\");\n\t\t}\n\t} else if (!at && !exponly) {\n\t\tif (IS_MODE_RAD (mode)) {\n\t\t\tr_cons_printf (\"fs symbols\\n\");\n\t\t} else if (IS_MODE_NORMAL (mode)) {\n\t\t\tr_cons_printf (printHere ? \"\" : \"[Symbols]\\n\");\n\t\t}\n\t}\n\tif (IS_MODE_NORMAL (mode)) {\n\t\tr_cons_printf (\"Num Paddr      Vaddr      Bind     Type Size Name\\n\");\n\t}\n\n\n\tsize_t count = 0;\n\tr_list_foreach (symbols, iter, symbol) {\n\t\tif (!symbol->name) {\n\t\t\tcontinue;\n\t\t}\n\t\tchar *r_symbol_name = r_str_escape_utf8 (symbol->name, false, true);\n\t\tut64 addr = compute_addr (r->bin, symbol->paddr, symbol->vaddr, va);\n\t\tint len = symbol->size ? symbol->size : 32;\n\t\tSymName sn = {0};\n\n\t\tif (exponly && !isAnExport (symbol)) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (name && strcmp (r_symbol_name, name)) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif (at && (!symbol->size || !is_in_range (at, addr, symbol->size))) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tif ((printHere && !is_in_range (r->offset, symbol->paddr, len))\n\t\t\t\t&& (printHere && !is_in_range (r->offset, addr, len))) {\n\t\t\tfree (r_symbol_name);\n\t\t\tcontinue;\n\t\t}\n\t\tcount ++;\n\t\tsnInit (r, &sn, symbol, lang);\n\n\t\tif (IS_MODE_SET (mode) && (is_section_symbol (symbol) || is_file_symbol (symbol))) {\n\t\t\t/*\n\t\t\t * Skip section symbols because they will have their own flag.\n\t\t\t * Skip also file symbols because not useful for now.\n\t\t\t */\n\t\t} else if (IS_MODE_SET (mode) && is_special_symbol (symbol)) {\n\t\t\tif (is_arm) {\n\t\t\t\thandle_arm_special_symbol (r, symbol, va);\n\t\t\t}\n\t\t} else if (IS_MODE_SET (mode)) {\n\t\t\t// TODO: provide separate API in RBinPlugin to let plugins handle anal hints/metadata\n\t\t\tif (is_arm) {\n\t\t\t\thandle_arm_symbol (r, symbol, info, va);\n\t\t\t}\n\t\t\tselect_flag_space (r, symbol);\n\t\t\t/* If that's a Classed symbol (method or so) */\n\t\t\tif (sn.classname) {\n\t\t\t\tRFlagItem *fi = r_flag_get (r->flags, sn.methflag);\n\t\t\t\tif (r->bin->prefix) {\n\t\t\t\t\tchar *prname = r_str_newf (\"%s.%s\", r->bin->prefix, sn.methflag);\n\t\t\t\t\tr_name_filter (sn.methflag, -1);\n\t\t\t\t\tfree (sn.methflag);\n\t\t\t\t\tsn.methflag = prname;\n\t\t\t\t}\n\t\t\t\tif (fi) {\n\t\t\t\t\tr_flag_item_set_realname (fi, sn.methname);\n\t\t\t\t\tif ((fi->offset - r->flags->base) == addr) {\n\t\t\t\t//\t\tchar *comment = fi->comment ? strdup (fi->comment) : NULL;\n\t\t\t\t\t\tr_flag_unset (r->flags, fi);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tfi = r_flag_set (r->flags, sn.methflag, addr, symbol->size);\n\t\t\t\t\tchar *comment = fi->comment ? strdup (fi->comment) : NULL;\n\t\t\t\t\tif (comment) {\n\t\t\t\t\t\tr_flag_item_set_comment (fi, comment);\n\t\t\t\t\t\tR_FREE (comment);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tconst char *n = sn.demname ? sn.demname : sn.name;\n\t\t\t\tconst char *fn = sn.demflag ? sn.demflag : sn.nameflag;\n\t\t\t\tchar *fnp = (r->bin->prefix) ?\n\t\t\t\t\tr_str_newf (\"%s.%s\", r->bin->prefix, fn):\n\t\t\t\t\tstrdup (fn);\n\t\t\t\tRFlagItem *fi = r_flag_set (r->flags, fnp, addr, symbol->size);\n\t\t\t\tif (fi) {\n\t\t\t\t\tr_flag_item_set_realname (fi, n);\n\t\t\t\t\tfi->demangled = (bool)(size_t)sn.demname;\n\t\t\t\t} else {\n\t\t\t\t\tif (fn) {\n\t\t\t\t\t\teprintf (\"[Warning] Can't find flag (%s)\\n\", fn);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfree (fnp);\n\t\t\t}\n\t\t\tif (sn.demname) {\n\t\t\t\tr_meta_add (r->anal, R_META_TYPE_COMMENT,\n\t\t\t\t\taddr, symbol->size, sn.demname);\n\t\t\t}\n\t\t\tr_flag_space_pop (r->flags);\n\t\t} else if (IS_MODE_JSON (mode)) {\n\t\t\tchar *str = r_str_escape_utf8_for_json (r_symbol_name, -1);\n\t\t\t// str = r_str_replace (str, \"\\\"\", \"\\\\\\\"\", 1);\n\t\t\tr_cons_printf (\"%s{\\\"name\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"demname\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"flagname\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"ordinal\\\":%d,\"\n\t\t\t\t\"\\\"bind\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"size\\\":%d,\"\n\t\t\t\t\"\\\"type\\\":\\\"%s\\\",\"\n\t\t\t\t\"\\\"vaddr\\\":%\"PFMT64d\",\"\n\t\t\t\t\"\\\"paddr\\\":%\"PFMT64d\"}\",\n\t\t\t\t((exponly && firstexp) || printHere) ? \"\" : (iter->p ? \",\" : \"\"),\n\t\t\t\tstr,\n\t\t\t\tsn.demname? sn.demname: \"\",\n\t\t\t\tsn.nameflag,\n\t\t\t\tsymbol->ordinal,\n\t\t\t\tsymbol->bind,\n\t\t\t\t(int)symbol->size,\n\t\t\t\tsymbol->type,\n\t\t\t\t(ut64)addr, (ut64)symbol->paddr);\n\t\t\tfree (str);\n\t\t} else if (IS_MODE_SIMPLE (mode)) {\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tr_cons_printf (\"0x%08\"PFMT64x\" %d %s\\n\",\n\t\t\t\taddr, (int)symbol->size, name);\n\t\t} else if (IS_MODE_SIMPLEST (mode)) {\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tr_cons_printf (\"%s\\n\", name);\n\t\t} else if (IS_MODE_RAD (mode)) {\n\t\t\t/* Skip special symbols because we do not flag them and\n\t\t\t * they shouldn't be printed in the rad format either */\n\t\t\tif (is_special_symbol (symbol)) {\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tRBinFile *binfile;\n\t\t\tRBinPlugin *plugin;\n\t\t\tconst char *name = sn.demname? sn.demname: r_symbol_name;\n\t\t\tif (!name) {\n\t\t\t\tgoto next;\n\t\t\t}\n\t\t\tif (!strncmp (name, \"imp.\", 4)) {\n\t\t\t\tif (lastfs != 'i') {\n\t\t\t\t\tr_cons_printf (\"fs imports\\n\");\n\t\t\t\t}\n\t\t\t\tlastfs = 'i';\n\t\t\t} else {\n\t\t\t\tif (lastfs != 's') {\n\t\t\t\t\tconst char *fs = exponly? \"exports\": \"symbols\";\n\t\t\t\t\tr_cons_printf (\"fs %s\\n\", fs);\n\t\t\t\t}\n\t\t\t\tlastfs = 's';\n\t\t\t}\n\t\t\tif (r->bin->prefix || *name) { // we don't want unnamed symbol flags\n\t\t\t\tchar *flagname = construct_symbol_flagname (\"sym\", name, MAXFLAG_LEN_DEFAULT);\n\t\t\t\tif (!flagname) {\n\t\t\t\t\tgoto next;\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"f %s%s%s %u 0x%08\" PFMT64x \"\\\"\\n\",\n\t\t\t\t\tr->bin->prefix ? r->bin->prefix : \"\", r->bin->prefix ? \".\" : \"\",\n\t\t\t\t\tflagname, symbol->size, addr);\n\t\t\t\tfree (flagname);\n\t\t\t}\n\t\t\tbinfile = r_bin_cur (r->bin);\n\t\t\tplugin = r_bin_file_cur_plugin (binfile);\n\t\t\tif (plugin && plugin->name) {\n\t\t\t\tif (r_str_startswith (plugin->name, \"pe\")) {\n\t\t\t\t\tchar *module = strdup (r_symbol_name);\n\t\t\t\t\tchar *p = strstr (module, \".dll_\");\n\t\t\t\t\tif (p && strstr (module, \"imp.\")) {\n\t\t\t\t\t\tchar *symname = __filterShell (p + 5);\n\t\t\t\t\t\tchar *m = __filterShell (module);\n\t\t\t\t\t\t*p = 0;\n\t\t\t\t\t\tif (r->bin->prefix) {\n\t\t\t\t\t\t\tr_cons_printf (\"k bin/pe/%s/%d=%s.%s\\n\",\n\t\t\t\t\t\t\t\tmodule, symbol->ordinal, r->bin->prefix, symname);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tr_cons_printf (\"k bin/pe/%s/%d=%s\\n\",\n\t\t\t\t\t\t\t\tmodule, symbol->ordinal, symname);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfree (symname);\n\t\t\t\t\t\tfree (m);\n\t\t\t\t\t}\n\t\t\t\t\tfree (module);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tconst char *bind = symbol->bind? symbol->bind: \"NONE\";\n\t\t\tconst char *type = symbol->type? symbol->type: \"NONE\";\n\t\t\tconst char *name = r_str_get (sn.demname? sn.demname: r_symbol_name);\n\t\t\t// const char *fwd = r_str_get (symbol->forwarder);\n\t\t\tr_cons_printf (\"%03u\", symbol->ordinal);\n\t\t\tif (symbol->paddr == UT64_MAX) {\n\t\t\t\tr_cons_printf (\" ----------\");\n\t\t\t} else {\n\t\t\t\tr_cons_printf (\" 0x%08\"PFMT64x, symbol->paddr);\n\t\t\t}\n\t\t\tr_cons_printf (\" 0x%08\"PFMT64x\" %6s %6s %4d%s%s\\n\",\n\t\t\t               addr, bind, type, symbol->size, *name? \" \": \"\", name);\n\t\t}\nnext:\n\t\tsnFini (&sn);\n\t\ti++;\n\t\tfree (r_symbol_name);\n\t\tif (exponly && firstexp) {\n\t\t\tfirstexp = false;\n\t\t}\n\t\tif (printHere) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (count == 0 && IS_MODE_JSON (mode)) {\n\t\tr_cons_printf (\"{}\");\n\t}\n\n\n\t//handle thumb and arm for entry point since they are not present in symbols\n\tif (is_arm) {\n\t\tr_list_foreach (entries, iter, entry) {\n\t\t\tif (IS_MODE_SET (mode)) {\n\t\t\t\thandle_arm_entry (r, entry, info, va);\n\t\t\t}\n\t\t}\n\t}\n\tif (IS_MODE_JSON (mode) && !printHere) {\n\t\tr_cons_printf (\"]\");\n\t}\n\n\tr_spaces_pop (&r->anal->meta_spaces);\n\treturn true;\n}", "commit_link": "github.com/radareorg/radare2/commit/5411543a310a470b1257fb93273cdd6e8dfcb3af", "file_name": "libr/core/cbin.c", "vul_type": "cwe-078", "description": "Write a C function to process and print binary symbols in various formats based on the given mode."}
{"func_name": "saa7164_bus_get", "func_src_before": "int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,\n\tvoid *buf, int peekonly)\n{\n\tstruct tmComResBusInfo *bus = &dev->bus;\n\tu32 bytes_to_read, write_distance, curr_grp, curr_gwp,\n\t\tnew_grp, buf_size, space_rem;\n\tstruct tmComResInfo msg_tmp;\n\tint ret = SAA_ERR_BAD_PARAMETER;\n\n\tsaa7164_bus_verify(dev);\n\n\tif (msg == NULL)\n\t\treturn ret;\n\n\tif (msg->size > dev->bus.m_wMaxReqSize) {\n\t\tprintk(KERN_ERR \"%s() Exceeded dev->bus.m_wMaxReqSize\\n\",\n\t\t\t__func__);\n\t\treturn ret;\n\t}\n\n\tif ((peekonly == 0) && (msg->size > 0) && (buf == NULL)) {\n\t\tprintk(KERN_ERR\n\t\t\t\"%s() Missing msg buf, size should be %d bytes\\n\",\n\t\t\t__func__, msg->size);\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&bus->lock);\n\n\t/* Peek the bus to see if a msg exists, if it's not what we're expecting\n\t * then return cleanly else read the message from the bus.\n\t */\n\tcurr_gwp = saa7164_readl(bus->m_dwGetWritePos);\n\tcurr_grp = saa7164_readl(bus->m_dwGetReadPos);\n\n\tif (curr_gwp == curr_grp) {\n\t\tret = SAA_ERR_EMPTY;\n\t\tgoto out;\n\t}\n\n\tbytes_to_read = sizeof(*msg);\n\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() No message/response found\\n\", __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, space_rem);\n\t\tmemcpy_fromio((u8 *)&msg_tmp + space_rem, bus->m_pdwGetRing,\n\t\t\tbytes_to_read - space_rem);\n\n\t} else {\n\t\t/* No wrapping */\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, bytes_to_read);\n\t}\n\t/* Convert from little endian to CPU */\n\tmsg_tmp.size = le16_to_cpu((__force __le16)msg_tmp.size);\n\tmsg_tmp.command = le32_to_cpu((__force __le32)msg_tmp.command);\n\tmsg_tmp.controlselector = le16_to_cpu((__force __le16)msg_tmp.controlselector);\n\tmemcpy(msg, &msg_tmp, sizeof(*msg));\n\n\t/* No need to update the read positions, because this was a peek */\n\t/* If the caller specifically want to peek, return */\n\tif (peekonly) {\n\t\tgoto peekout;\n\t}\n\n\t/* Check if the command/response matches what is expected */\n\tif ((msg_tmp.id != msg->id) || (msg_tmp.command != msg->command) ||\n\t\t(msg_tmp.controlselector != msg->controlselector) ||\n\t\t(msg_tmp.seqno != msg->seqno) || (msg_tmp.size != msg->size)) {\n\n\t\tprintk(KERN_ERR \"%s() Unexpected msg miss-match\\n\", __func__);\n\t\tsaa7164_bus_dumpmsg(dev, msg, buf);\n\t\tsaa7164_bus_dumpmsg(dev, &msg_tmp, NULL);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Get the actual command and response from the bus */\n\tbuf_size = msg->size;\n\n\tbytes_to_read = sizeof(*msg) + msg->size;\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() Invalid bus state, missing msg or mangled ring, faulty H/W / bad code?\\n\",\n\t\t       __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tif (space_rem < sizeof(*msg)) {\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + sizeof(*msg) -\n\t\t\t\t\tspace_rem, buf_size);\n\n\t\t} else if (space_rem == sizeof(*msg)) {\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing, buf_size);\n\t\t} else {\n\t\t\t/* Additional data wraps around the ring */\n\t\t\tif (buf) {\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp +\n\t\t\t\t\tsizeof(*msg), space_rem - sizeof(*msg));\n\t\t\t\tmemcpy_fromio(buf + space_rem - sizeof(*msg),\n\t\t\t\t\tbus->m_pdwGetRing, bytes_to_read -\n\t\t\t\t\tspace_rem);\n\t\t\t}\n\n\t\t}\n\n\t} else {\n\t\t/* No wrapping */\n\t\tif (buf)\n\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp + sizeof(*msg),\n\t\t\t\tbuf_size);\n\t}\n\n\t/* Update the read positions, adjusting the ring */\n\tsaa7164_writel(bus->m_dwGetReadPos, new_grp);\n\npeekout:\n\tret = SAA_OK;\nout:\n\tmutex_unlock(&bus->lock);\n\tsaa7164_bus_verify(dev);\n\treturn ret;\n}", "func_src_after": "int saa7164_bus_get(struct saa7164_dev *dev, struct tmComResInfo* msg,\n\tvoid *buf, int peekonly)\n{\n\tstruct tmComResBusInfo *bus = &dev->bus;\n\tu32 bytes_to_read, write_distance, curr_grp, curr_gwp,\n\t\tnew_grp, buf_size, space_rem;\n\tstruct tmComResInfo msg_tmp;\n\tint ret = SAA_ERR_BAD_PARAMETER;\n\n\tsaa7164_bus_verify(dev);\n\n\tif (msg == NULL)\n\t\treturn ret;\n\n\tif (msg->size > dev->bus.m_wMaxReqSize) {\n\t\tprintk(KERN_ERR \"%s() Exceeded dev->bus.m_wMaxReqSize\\n\",\n\t\t\t__func__);\n\t\treturn ret;\n\t}\n\n\tif ((peekonly == 0) && (msg->size > 0) && (buf == NULL)) {\n\t\tprintk(KERN_ERR\n\t\t\t\"%s() Missing msg buf, size should be %d bytes\\n\",\n\t\t\t__func__, msg->size);\n\t\treturn ret;\n\t}\n\n\tmutex_lock(&bus->lock);\n\n\t/* Peek the bus to see if a msg exists, if it's not what we're expecting\n\t * then return cleanly else read the message from the bus.\n\t */\n\tcurr_gwp = saa7164_readl(bus->m_dwGetWritePos);\n\tcurr_grp = saa7164_readl(bus->m_dwGetReadPos);\n\n\tif (curr_gwp == curr_grp) {\n\t\tret = SAA_ERR_EMPTY;\n\t\tgoto out;\n\t}\n\n\tbytes_to_read = sizeof(*msg);\n\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() No message/response found\\n\", __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, space_rem);\n\t\tmemcpy_fromio((u8 *)&msg_tmp + space_rem, bus->m_pdwGetRing,\n\t\t\tbytes_to_read - space_rem);\n\n\t} else {\n\t\t/* No wrapping */\n\t\tmemcpy_fromio(&msg_tmp, bus->m_pdwGetRing + curr_grp, bytes_to_read);\n\t}\n\t/* Convert from little endian to CPU */\n\tmsg_tmp.size = le16_to_cpu((__force __le16)msg_tmp.size);\n\tmsg_tmp.command = le32_to_cpu((__force __le32)msg_tmp.command);\n\tmsg_tmp.controlselector = le16_to_cpu((__force __le16)msg_tmp.controlselector);\n\n\t/* No need to update the read positions, because this was a peek */\n\t/* If the caller specifically want to peek, return */\n\tif (peekonly) {\n\t\tmemcpy(msg, &msg_tmp, sizeof(*msg));\n\t\tgoto peekout;\n\t}\n\n\t/* Check if the command/response matches what is expected */\n\tif ((msg_tmp.id != msg->id) || (msg_tmp.command != msg->command) ||\n\t\t(msg_tmp.controlselector != msg->controlselector) ||\n\t\t(msg_tmp.seqno != msg->seqno) || (msg_tmp.size != msg->size)) {\n\n\t\tprintk(KERN_ERR \"%s() Unexpected msg miss-match\\n\", __func__);\n\t\tsaa7164_bus_dumpmsg(dev, msg, buf);\n\t\tsaa7164_bus_dumpmsg(dev, &msg_tmp, NULL);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Get the actual command and response from the bus */\n\tbuf_size = msg->size;\n\n\tbytes_to_read = sizeof(*msg) + msg->size;\n\t/* Calculate write distance to current read position */\n\twrite_distance = 0;\n\tif (curr_gwp >= curr_grp)\n\t\t/* Write doesn't wrap around the ring */\n\t\twrite_distance = curr_gwp - curr_grp;\n\telse\n\t\t/* Write wraps around the ring */\n\t\twrite_distance = curr_gwp + bus->m_dwSizeGetRing - curr_grp;\n\n\tif (bytes_to_read > write_distance) {\n\t\tprintk(KERN_ERR \"%s() Invalid bus state, missing msg or mangled ring, faulty H/W / bad code?\\n\",\n\t\t       __func__);\n\t\tret = SAA_ERR_INVALID_COMMAND;\n\t\tgoto out;\n\t}\n\n\t/* Calculate the new read position */\n\tnew_grp = curr_grp + bytes_to_read;\n\tif (new_grp > bus->m_dwSizeGetRing) {\n\n\t\t/* Ring wraps */\n\t\tnew_grp -= bus->m_dwSizeGetRing;\n\t\tspace_rem = bus->m_dwSizeGetRing - curr_grp;\n\n\t\tif (space_rem < sizeof(*msg)) {\n\t\t\t/* msg wraps around the ring */\n\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, space_rem);\n\t\t\tmemcpy_fromio((u8 *)msg + space_rem, bus->m_pdwGetRing,\n\t\t\t\tsizeof(*msg) - space_rem);\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + sizeof(*msg) -\n\t\t\t\t\tspace_rem, buf_size);\n\n\t\t} else if (space_rem == sizeof(*msg)) {\n\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n\t\t\tif (buf)\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing, buf_size);\n\t\t} else {\n\t\t\t/* Additional data wraps around the ring */\n\t\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n\t\t\tif (buf) {\n\t\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp +\n\t\t\t\t\tsizeof(*msg), space_rem - sizeof(*msg));\n\t\t\t\tmemcpy_fromio(buf + space_rem - sizeof(*msg),\n\t\t\t\t\tbus->m_pdwGetRing, bytes_to_read -\n\t\t\t\t\tspace_rem);\n\t\t\t}\n\n\t\t}\n\n\t} else {\n\t\t/* No wrapping */\n\t\tmemcpy_fromio(msg, bus->m_pdwGetRing + curr_grp, sizeof(*msg));\n\t\tif (buf)\n\t\t\tmemcpy_fromio(buf, bus->m_pdwGetRing + curr_grp + sizeof(*msg),\n\t\t\t\tbuf_size);\n\t}\n\t/* Convert from little endian to CPU */\n\tmsg->size = le16_to_cpu((__force __le16)msg->size);\n\tmsg->command = le32_to_cpu((__force __le32)msg->command);\n\tmsg->controlselector = le16_to_cpu((__force __le16)msg->controlselector);\n\n\t/* Update the read positions, adjusting the ring */\n\tsaa7164_writel(bus->m_dwGetReadPos, new_grp);\n\npeekout:\n\tret = SAA_OK;\nout:\n\tmutex_unlock(&bus->lock);\n\tsaa7164_bus_verify(dev);\n\treturn ret;\n}", "commit_link": "github.com/stoth68000/media-tree/commit/354dd3924a2e43806774953de536257548b5002c", "file_name": "drivers/media/pci/saa7164/saa7164-bus.c", "vul_type": "cwe-125", "description": "Write a C function named `saa7164_bus_get` that reads a message from a device's bus, optionally peeking without updating the read position."}
{"func_name": "lookup_assets", "func_src_before": "@app.route('/lookup_assets')\ndef lookup_assets():\n    start = request.args.get('start')\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT aname FROM assets WHERE aname LIKE '\"+start+\"%'\"\n    cur.execute(query)\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "func_src_after": "@app.route('/lookup_assets')\ndef lookup_assets():\n    start = request.args.get('start')\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"SELECT aname FROM assets WHERE aname LIKE %s\"\n    cur.execute(query, (start+'%',))\n    results = cur.fetchall()\n    con.close()\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint to search for asset names starting with a given string using psycopg2 for database access."}
{"func_name": "multiSelect", "func_src_before": "static int multiSelect(\n  Parse *pParse,        /* Parsing context */\n  Select *p,            /* The right-most of SELECTs to be coded */\n  SelectDest *pDest     /* What to do with query results */\n){\n  int rc = SQLITE_OK;   /* Success code from a subroutine */\n  Select *pPrior;       /* Another SELECT immediately to our left */\n  Vdbe *v;              /* Generate code to this VDBE */\n  SelectDest dest;      /* Alternative data destination */\n  Select *pDelete = 0;  /* Chain of simple selects to delete */\n  sqlite3 *db;          /* Database connection */\n\n  /* Make sure there is no ORDER BY or LIMIT clause on prior SELECTs.  Only\n  ** the last (right-most) SELECT in the series may have an ORDER BY or LIMIT.\n  */\n  assert( p && p->pPrior );  /* Calling function guarantees this much */\n  assert( (p->selFlags & SF_Recursive)==0 || p->op==TK_ALL || p->op==TK_UNION );\n  assert( p->selFlags & SF_Compound );\n  db = pParse->db;\n  pPrior = p->pPrior;\n  dest = *pDest;\n  if( pPrior->pOrderBy || pPrior->pLimit ){\n    sqlite3ErrorMsg(pParse,\"%s clause should come after %s not before\",\n      pPrior->pOrderBy!=0 ? \"ORDER BY\" : \"LIMIT\", selectOpName(p->op));\n    rc = 1;\n    goto multi_select_end;\n  }\n\n  v = sqlite3GetVdbe(pParse);\n  assert( v!=0 );  /* The VDBE already created by calling function */\n\n  /* Create the destination temporary table if necessary\n  */\n  if( dest.eDest==SRT_EphemTab ){\n    assert( p->pEList );\n    sqlite3VdbeAddOp2(v, OP_OpenEphemeral, dest.iSDParm, p->pEList->nExpr);\n    dest.eDest = SRT_Table;\n  }\n\n  /* Special handling for a compound-select that originates as a VALUES clause.\n  */\n  if( p->selFlags & SF_MultiValue ){\n    rc = multiSelectValues(pParse, p, &dest);\n    if( rc>=0 ) goto multi_select_end;\n    rc = SQLITE_OK;\n  }\n\n  /* Make sure all SELECTs in the statement have the same number of elements\n  ** in their result sets.\n  */\n  assert( p->pEList && pPrior->pEList );\n  assert( p->pEList->nExpr==pPrior->pEList->nExpr );\n\n#ifndef SQLITE_OMIT_CTE\n  if( p->selFlags & SF_Recursive ){\n    generateWithRecursiveQuery(pParse, p, &dest);\n  }else\n#endif\n\n  /* Compound SELECTs that have an ORDER BY clause are handled separately.\n  */\n  if( p->pOrderBy ){\n    return multiSelectOrderBy(pParse, p, pDest);\n  }else{\n\n#ifndef SQLITE_OMIT_EXPLAIN\n    if( pPrior->pPrior==0 ){\n      ExplainQueryPlan((pParse, 1, \"COMPOUND QUERY\"));\n      ExplainQueryPlan((pParse, 1, \"LEFT-MOST SUBQUERY\"));\n    }\n#endif\n\n    /* Generate code for the left and right SELECT statements.\n    */\n    switch( p->op ){\n      case TK_ALL: {\n        int addr = 0;\n        int nLimit;\n        assert( !pPrior->pLimit );\n        pPrior->iLimit = p->iLimit;\n        pPrior->iOffset = p->iOffset;\n        pPrior->pLimit = p->pLimit;\n        rc = sqlite3Select(pParse, pPrior, &dest);\n        p->pLimit = 0;\n        if( rc ){\n          goto multi_select_end;\n        }\n        p->pPrior = 0;\n        p->iLimit = pPrior->iLimit;\n        p->iOffset = pPrior->iOffset;\n        if( p->iLimit ){\n          addr = sqlite3VdbeAddOp1(v, OP_IfNot, p->iLimit); VdbeCoverage(v);\n          VdbeComment((v, \"Jump ahead if LIMIT reached\"));\n          if( p->iOffset ){\n            sqlite3VdbeAddOp3(v, OP_OffsetLimit,\n                              p->iLimit, p->iOffset+1, p->iOffset);\n          }\n        }\n        ExplainQueryPlan((pParse, 1, \"UNION ALL\"));\n        rc = sqlite3Select(pParse, p, &dest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        if( pPrior->pLimit\n         && sqlite3ExprIsInteger(pPrior->pLimit->pLeft, &nLimit)\n         && nLimit>0 && p->nSelectRow > sqlite3LogEst((u64)nLimit) \n        ){\n          p->nSelectRow = sqlite3LogEst((u64)nLimit);\n        }\n        if( addr ){\n          sqlite3VdbeJumpHere(v, addr);\n        }\n        break;\n      }\n      case TK_EXCEPT:\n      case TK_UNION: {\n        int unionTab;    /* Cursor number of the temp table holding result */\n        u8 op = 0;       /* One of the SRT_ operations to apply to self */\n        int priorOp;     /* The SRT_ operation to apply to prior selects */\n        Expr *pLimit;    /* Saved values of p->nLimit  */\n        int addr;\n        SelectDest uniondest;\n  \n        testcase( p->op==TK_EXCEPT );\n        testcase( p->op==TK_UNION );\n        priorOp = SRT_Union;\n        if( dest.eDest==priorOp ){\n          /* We can reuse a temporary table generated by a SELECT to our\n          ** right.\n          */\n          assert( p->pLimit==0 );      /* Not allowed on leftward elements */\n          unionTab = dest.iSDParm;\n        }else{\n          /* We will need to create our own temporary table to hold the\n          ** intermediate results.\n          */\n          unionTab = pParse->nTab++;\n          assert( p->pOrderBy==0 );\n          addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, unionTab, 0);\n          assert( p->addrOpenEphm[0] == -1 );\n          p->addrOpenEphm[0] = addr;\n          findRightmost(p)->selFlags |= SF_UsesEphemeral;\n          assert( p->pEList );\n        }\n  \n        /* Code the SELECT statements to our left\n        */\n        assert( !pPrior->pOrderBy );\n        sqlite3SelectDestInit(&uniondest, priorOp, unionTab);\n        rc = sqlite3Select(pParse, pPrior, &uniondest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT statement\n        */\n        if( p->op==TK_EXCEPT ){\n          op = SRT_Except;\n        }else{\n          assert( p->op==TK_UNION );\n          op = SRT_Union;\n        }\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        uniondest.eDest = op;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &uniondest);\n        testcase( rc!=SQLITE_OK );\n        /* Query flattening in sqlite3Select() might refill p->pOrderBy.\n        ** Be sure to delete p->pOrderBy, therefore, to avoid a memory leak. */\n        sqlite3ExprListDelete(db, p->pOrderBy);\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->pOrderBy = 0;\n        if( p->op==TK_UNION ){\n          p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n        p->iLimit = 0;\n        p->iOffset = 0;\n  \n        /* Convert the data in the temporary table into whatever form\n        ** it is that we currently need.\n        */\n        assert( unionTab==dest.iSDParm || dest.eDest!=priorOp );\n        if( dest.eDest!=priorOp ){\n          int iCont, iBreak, iStart;\n          assert( p->pEList );\n          iBreak = sqlite3VdbeMakeLabel(pParse);\n          iCont = sqlite3VdbeMakeLabel(pParse);\n          computeLimitRegisters(pParse, p, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Rewind, unionTab, iBreak); VdbeCoverage(v);\n          iStart = sqlite3VdbeCurrentAddr(v);\n          selectInnerLoop(pParse, p, unionTab,\n                          0, 0, &dest, iCont, iBreak);\n          sqlite3VdbeResolveLabel(v, iCont);\n          sqlite3VdbeAddOp2(v, OP_Next, unionTab, iStart); VdbeCoverage(v);\n          sqlite3VdbeResolveLabel(v, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Close, unionTab, 0);\n        }\n        break;\n      }\n      default: assert( p->op==TK_INTERSECT ); {\n        int tab1, tab2;\n        int iCont, iBreak, iStart;\n        Expr *pLimit;\n        int addr;\n        SelectDest intersectdest;\n        int r1;\n  \n        /* INTERSECT is different from the others since it requires\n        ** two temporary tables.  Hence it has its own case.  Begin\n        ** by allocating the tables we will need.\n        */\n        tab1 = pParse->nTab++;\n        tab2 = pParse->nTab++;\n        assert( p->pOrderBy==0 );\n  \n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab1, 0);\n        assert( p->addrOpenEphm[0] == -1 );\n        p->addrOpenEphm[0] = addr;\n        findRightmost(p)->selFlags |= SF_UsesEphemeral;\n        assert( p->pEList );\n  \n        /* Code the SELECTs to our left into temporary table \"tab1\".\n        */\n        sqlite3SelectDestInit(&intersectdest, SRT_Union, tab1);\n        rc = sqlite3Select(pParse, pPrior, &intersectdest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT into temporary table \"tab2\"\n        */\n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab2, 0);\n        assert( p->addrOpenEphm[1] == -1 );\n        p->addrOpenEphm[1] = addr;\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        intersectdest.iSDParm = tab2;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &intersectdest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        if( p->nSelectRow>pPrior->nSelectRow ){\n          p->nSelectRow = pPrior->nSelectRow;\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n  \n        /* Generate code to take the intersection of the two temporary\n        ** tables.\n        */\n        assert( p->pEList );\n        iBreak = sqlite3VdbeMakeLabel(pParse);\n        iCont = sqlite3VdbeMakeLabel(pParse);\n        computeLimitRegisters(pParse, p, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Rewind, tab1, iBreak); VdbeCoverage(v);\n        r1 = sqlite3GetTempReg(pParse);\n        iStart = sqlite3VdbeAddOp2(v, OP_RowData, tab1, r1);\n        sqlite3VdbeAddOp4Int(v, OP_NotFound, tab2, iCont, r1, 0);\n        VdbeCoverage(v);\n        sqlite3ReleaseTempReg(pParse, r1);\n        selectInnerLoop(pParse, p, tab1,\n                        0, 0, &dest, iCont, iBreak);\n        sqlite3VdbeResolveLabel(v, iCont);\n        sqlite3VdbeAddOp2(v, OP_Next, tab1, iStart); VdbeCoverage(v);\n        sqlite3VdbeResolveLabel(v, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Close, tab2, 0);\n        sqlite3VdbeAddOp2(v, OP_Close, tab1, 0);\n        break;\n      }\n    }\n  \n  #ifndef SQLITE_OMIT_EXPLAIN\n    if( p->pNext==0 ){\n      ExplainQueryPlanPop(pParse);\n    }\n  #endif\n  }\n  \n  /* Compute collating sequences used by \n  ** temporary tables needed to implement the compound select.\n  ** Attach the KeyInfo structure to all temporary tables.\n  **\n  ** This section is run by the right-most SELECT statement only.\n  ** SELECT statements to the left always skip this part.  The right-most\n  ** SELECT might also skip this part if it has no ORDER BY clause and\n  ** no temp tables are required.\n  */\n  if( p->selFlags & SF_UsesEphemeral ){\n    int i;                        /* Loop counter */\n    KeyInfo *pKeyInfo;            /* Collating sequence for the result set */\n    Select *pLoop;                /* For looping through SELECT statements */\n    CollSeq **apColl;             /* For looping through pKeyInfo->aColl[] */\n    int nCol;                     /* Number of columns in result set */\n\n    assert( p->pNext==0 );\n    nCol = p->pEList->nExpr;\n    pKeyInfo = sqlite3KeyInfoAlloc(db, nCol, 1);\n    if( !pKeyInfo ){\n      rc = SQLITE_NOMEM_BKPT;\n      goto multi_select_end;\n    }\n    for(i=0, apColl=pKeyInfo->aColl; i<nCol; i++, apColl++){\n      *apColl = multiSelectCollSeq(pParse, p, i);\n      if( 0==*apColl ){\n        *apColl = db->pDfltColl;\n      }\n    }\n\n    for(pLoop=p; pLoop; pLoop=pLoop->pPrior){\n      for(i=0; i<2; i++){\n        int addr = pLoop->addrOpenEphm[i];\n        if( addr<0 ){\n          /* If [0] is unused then [1] is also unused.  So we can\n          ** always safely abort as soon as the first unused slot is found */\n          assert( pLoop->addrOpenEphm[1]<0 );\n          break;\n        }\n        sqlite3VdbeChangeP2(v, addr, nCol);\n        sqlite3VdbeChangeP4(v, addr, (char*)sqlite3KeyInfoRef(pKeyInfo),\n                            P4_KEYINFO);\n        pLoop->addrOpenEphm[i] = -1;\n      }\n    }\n    sqlite3KeyInfoUnref(pKeyInfo);\n  }\n\nmulti_select_end:\n  pDest->iSdst = dest.iSdst;\n  pDest->nSdst = dest.nSdst;\n  sqlite3SelectDelete(db, pDelete);\n  return rc;\n}", "func_src_after": "static int multiSelect(\n  Parse *pParse,        /* Parsing context */\n  Select *p,            /* The right-most of SELECTs to be coded */\n  SelectDest *pDest     /* What to do with query results */\n){\n  int rc = SQLITE_OK;   /* Success code from a subroutine */\n  Select *pPrior;       /* Another SELECT immediately to our left */\n  Vdbe *v;              /* Generate code to this VDBE */\n  SelectDest dest;      /* Alternative data destination */\n  Select *pDelete = 0;  /* Chain of simple selects to delete */\n  sqlite3 *db;          /* Database connection */\n\n  /* Make sure there is no ORDER BY or LIMIT clause on prior SELECTs.  Only\n  ** the last (right-most) SELECT in the series may have an ORDER BY or LIMIT.\n  */\n  assert( p && p->pPrior );  /* Calling function guarantees this much */\n  assert( (p->selFlags & SF_Recursive)==0 || p->op==TK_ALL || p->op==TK_UNION );\n  assert( p->selFlags & SF_Compound );\n  db = pParse->db;\n  pPrior = p->pPrior;\n  dest = *pDest;\n  if( pPrior->pOrderBy || pPrior->pLimit ){\n    sqlite3ErrorMsg(pParse,\"%s clause should come after %s not before\",\n      pPrior->pOrderBy!=0 ? \"ORDER BY\" : \"LIMIT\", selectOpName(p->op));\n    rc = 1;\n    goto multi_select_end;\n  }\n\n  v = sqlite3GetVdbe(pParse);\n  assert( v!=0 );  /* The VDBE already created by calling function */\n\n  /* Create the destination temporary table if necessary\n  */\n  if( dest.eDest==SRT_EphemTab ){\n    assert( p->pEList );\n    sqlite3VdbeAddOp2(v, OP_OpenEphemeral, dest.iSDParm, p->pEList->nExpr);\n    dest.eDest = SRT_Table;\n  }\n\n  /* Special handling for a compound-select that originates as a VALUES clause.\n  */\n  if( p->selFlags & SF_MultiValue ){\n    rc = multiSelectValues(pParse, p, &dest);\n    if( rc>=0 ) goto multi_select_end;\n    rc = SQLITE_OK;\n  }\n\n  /* Make sure all SELECTs in the statement have the same number of elements\n  ** in their result sets.\n  */\n  assert( p->pEList && pPrior->pEList );\n  assert( p->pEList->nExpr==pPrior->pEList->nExpr );\n\n#ifndef SQLITE_OMIT_CTE\n  if( p->selFlags & SF_Recursive ){\n    generateWithRecursiveQuery(pParse, p, &dest);\n  }else\n#endif\n\n  /* Compound SELECTs that have an ORDER BY clause are handled separately.\n  */\n  if( p->pOrderBy ){\n    return multiSelectOrderBy(pParse, p, pDest);\n  }else{\n\n#ifndef SQLITE_OMIT_EXPLAIN\n    if( pPrior->pPrior==0 ){\n      ExplainQueryPlan((pParse, 1, \"COMPOUND QUERY\"));\n      ExplainQueryPlan((pParse, 1, \"LEFT-MOST SUBQUERY\"));\n    }\n#endif\n\n    /* Generate code for the left and right SELECT statements.\n    */\n    switch( p->op ){\n      case TK_ALL: {\n        int addr = 0;\n        int nLimit;\n        assert( !pPrior->pLimit );\n        pPrior->iLimit = p->iLimit;\n        pPrior->iOffset = p->iOffset;\n        pPrior->pLimit = p->pLimit;\n        rc = sqlite3Select(pParse, pPrior, &dest);\n        p->pLimit = 0;\n        if( rc ){\n          goto multi_select_end;\n        }\n        p->pPrior = 0;\n        p->iLimit = pPrior->iLimit;\n        p->iOffset = pPrior->iOffset;\n        if( p->iLimit ){\n          addr = sqlite3VdbeAddOp1(v, OP_IfNot, p->iLimit); VdbeCoverage(v);\n          VdbeComment((v, \"Jump ahead if LIMIT reached\"));\n          if( p->iOffset ){\n            sqlite3VdbeAddOp3(v, OP_OffsetLimit,\n                              p->iLimit, p->iOffset+1, p->iOffset);\n          }\n        }\n        ExplainQueryPlan((pParse, 1, \"UNION ALL\"));\n        rc = sqlite3Select(pParse, p, &dest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        if( pPrior->pLimit\n         && sqlite3ExprIsInteger(pPrior->pLimit->pLeft, &nLimit)\n         && nLimit>0 && p->nSelectRow > sqlite3LogEst((u64)nLimit) \n        ){\n          p->nSelectRow = sqlite3LogEst((u64)nLimit);\n        }\n        if( addr ){\n          sqlite3VdbeJumpHere(v, addr);\n        }\n        break;\n      }\n      case TK_EXCEPT:\n      case TK_UNION: {\n        int unionTab;    /* Cursor number of the temp table holding result */\n        u8 op = 0;       /* One of the SRT_ operations to apply to self */\n        int priorOp;     /* The SRT_ operation to apply to prior selects */\n        Expr *pLimit;    /* Saved values of p->nLimit  */\n        int addr;\n        SelectDest uniondest;\n  \n        testcase( p->op==TK_EXCEPT );\n        testcase( p->op==TK_UNION );\n        priorOp = SRT_Union;\n        if( dest.eDest==priorOp ){\n          /* We can reuse a temporary table generated by a SELECT to our\n          ** right.\n          */\n          assert( p->pLimit==0 );      /* Not allowed on leftward elements */\n          unionTab = dest.iSDParm;\n        }else{\n          /* We will need to create our own temporary table to hold the\n          ** intermediate results.\n          */\n          unionTab = pParse->nTab++;\n          assert( p->pOrderBy==0 );\n          addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, unionTab, 0);\n          assert( p->addrOpenEphm[0] == -1 );\n          p->addrOpenEphm[0] = addr;\n          findRightmost(p)->selFlags |= SF_UsesEphemeral;\n          assert( p->pEList );\n        }\n  \n        /* Code the SELECT statements to our left\n        */\n        assert( !pPrior->pOrderBy );\n        sqlite3SelectDestInit(&uniondest, priorOp, unionTab);\n        rc = sqlite3Select(pParse, pPrior, &uniondest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT statement\n        */\n        if( p->op==TK_EXCEPT ){\n          op = SRT_Except;\n        }else{\n          assert( p->op==TK_UNION );\n          op = SRT_Union;\n        }\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        uniondest.eDest = op;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &uniondest);\n        testcase( rc!=SQLITE_OK );\n        /* Query flattening in sqlite3Select() might refill p->pOrderBy.\n        ** Be sure to delete p->pOrderBy, therefore, to avoid a memory leak. */\n        sqlite3ExprListDelete(db, p->pOrderBy);\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        p->pOrderBy = 0;\n        if( p->op==TK_UNION ){\n          p->nSelectRow = sqlite3LogEstAdd(p->nSelectRow, pPrior->nSelectRow);\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n        p->iLimit = 0;\n        p->iOffset = 0;\n  \n        /* Convert the data in the temporary table into whatever form\n        ** it is that we currently need.\n        */\n        assert( unionTab==dest.iSDParm || dest.eDest!=priorOp );\n        if( dest.eDest!=priorOp ){\n          int iCont, iBreak, iStart;\n          assert( p->pEList );\n          iBreak = sqlite3VdbeMakeLabel(pParse);\n          iCont = sqlite3VdbeMakeLabel(pParse);\n          computeLimitRegisters(pParse, p, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Rewind, unionTab, iBreak); VdbeCoverage(v);\n          iStart = sqlite3VdbeCurrentAddr(v);\n          selectInnerLoop(pParse, p, unionTab,\n                          0, 0, &dest, iCont, iBreak);\n          sqlite3VdbeResolveLabel(v, iCont);\n          sqlite3VdbeAddOp2(v, OP_Next, unionTab, iStart); VdbeCoverage(v);\n          sqlite3VdbeResolveLabel(v, iBreak);\n          sqlite3VdbeAddOp2(v, OP_Close, unionTab, 0);\n        }\n        break;\n      }\n      default: assert( p->op==TK_INTERSECT ); {\n        int tab1, tab2;\n        int iCont, iBreak, iStart;\n        Expr *pLimit;\n        int addr;\n        SelectDest intersectdest;\n        int r1;\n  \n        /* INTERSECT is different from the others since it requires\n        ** two temporary tables.  Hence it has its own case.  Begin\n        ** by allocating the tables we will need.\n        */\n        tab1 = pParse->nTab++;\n        tab2 = pParse->nTab++;\n        assert( p->pOrderBy==0 );\n  \n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab1, 0);\n        assert( p->addrOpenEphm[0] == -1 );\n        p->addrOpenEphm[0] = addr;\n        findRightmost(p)->selFlags |= SF_UsesEphemeral;\n        assert( p->pEList );\n  \n        /* Code the SELECTs to our left into temporary table \"tab1\".\n        */\n        sqlite3SelectDestInit(&intersectdest, SRT_Union, tab1);\n        rc = sqlite3Select(pParse, pPrior, &intersectdest);\n        if( rc ){\n          goto multi_select_end;\n        }\n  \n        /* Code the current SELECT into temporary table \"tab2\"\n        */\n        addr = sqlite3VdbeAddOp2(v, OP_OpenEphemeral, tab2, 0);\n        assert( p->addrOpenEphm[1] == -1 );\n        p->addrOpenEphm[1] = addr;\n        p->pPrior = 0;\n        pLimit = p->pLimit;\n        p->pLimit = 0;\n        intersectdest.iSDParm = tab2;\n        ExplainQueryPlan((pParse, 1, \"%s USING TEMP B-TREE\",\n                          selectOpName(p->op)));\n        rc = sqlite3Select(pParse, p, &intersectdest);\n        testcase( rc!=SQLITE_OK );\n        pDelete = p->pPrior;\n        p->pPrior = pPrior;\n        if( p->nSelectRow>pPrior->nSelectRow ){\n          p->nSelectRow = pPrior->nSelectRow;\n        }\n        sqlite3ExprDelete(db, p->pLimit);\n        p->pLimit = pLimit;\n  \n        /* Generate code to take the intersection of the two temporary\n        ** tables.\n        */\n        assert( p->pEList );\n        iBreak = sqlite3VdbeMakeLabel(pParse);\n        iCont = sqlite3VdbeMakeLabel(pParse);\n        computeLimitRegisters(pParse, p, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Rewind, tab1, iBreak); VdbeCoverage(v);\n        r1 = sqlite3GetTempReg(pParse);\n        iStart = sqlite3VdbeAddOp2(v, OP_RowData, tab1, r1);\n        sqlite3VdbeAddOp4Int(v, OP_NotFound, tab2, iCont, r1, 0);\n        VdbeCoverage(v);\n        sqlite3ReleaseTempReg(pParse, r1);\n        selectInnerLoop(pParse, p, tab1,\n                        0, 0, &dest, iCont, iBreak);\n        sqlite3VdbeResolveLabel(v, iCont);\n        sqlite3VdbeAddOp2(v, OP_Next, tab1, iStart); VdbeCoverage(v);\n        sqlite3VdbeResolveLabel(v, iBreak);\n        sqlite3VdbeAddOp2(v, OP_Close, tab2, 0);\n        sqlite3VdbeAddOp2(v, OP_Close, tab1, 0);\n        break;\n      }\n    }\n  \n  #ifndef SQLITE_OMIT_EXPLAIN\n    if( p->pNext==0 ){\n      ExplainQueryPlanPop(pParse);\n    }\n  #endif\n  }\n  if( pParse->nErr ) goto multi_select_end;\n  \n  /* Compute collating sequences used by \n  ** temporary tables needed to implement the compound select.\n  ** Attach the KeyInfo structure to all temporary tables.\n  **\n  ** This section is run by the right-most SELECT statement only.\n  ** SELECT statements to the left always skip this part.  The right-most\n  ** SELECT might also skip this part if it has no ORDER BY clause and\n  ** no temp tables are required.\n  */\n  if( p->selFlags & SF_UsesEphemeral ){\n    int i;                        /* Loop counter */\n    KeyInfo *pKeyInfo;            /* Collating sequence for the result set */\n    Select *pLoop;                /* For looping through SELECT statements */\n    CollSeq **apColl;             /* For looping through pKeyInfo->aColl[] */\n    int nCol;                     /* Number of columns in result set */\n\n    assert( p->pNext==0 );\n    nCol = p->pEList->nExpr;\n    pKeyInfo = sqlite3KeyInfoAlloc(db, nCol, 1);\n    if( !pKeyInfo ){\n      rc = SQLITE_NOMEM_BKPT;\n      goto multi_select_end;\n    }\n    for(i=0, apColl=pKeyInfo->aColl; i<nCol; i++, apColl++){\n      *apColl = multiSelectCollSeq(pParse, p, i);\n      if( 0==*apColl ){\n        *apColl = db->pDfltColl;\n      }\n    }\n\n    for(pLoop=p; pLoop; pLoop=pLoop->pPrior){\n      for(i=0; i<2; i++){\n        int addr = pLoop->addrOpenEphm[i];\n        if( addr<0 ){\n          /* If [0] is unused then [1] is also unused.  So we can\n          ** always safely abort as soon as the first unused slot is found */\n          assert( pLoop->addrOpenEphm[1]<0 );\n          break;\n        }\n        sqlite3VdbeChangeP2(v, addr, nCol);\n        sqlite3VdbeChangeP4(v, addr, (char*)sqlite3KeyInfoRef(pKeyInfo),\n                            P4_KEYINFO);\n        pLoop->addrOpenEphm[i] = -1;\n      }\n    }\n    sqlite3KeyInfoUnref(pKeyInfo);\n  }\n\nmulti_select_end:\n  pDest->iSdst = dest.iSdst;\n  pDest->nSdst = dest.nSdst;\n  sqlite3SelectDelete(db, pDelete);\n  return rc;\n}", "commit_link": "github.com/sqlite/sqlite/commit/8428b3b437569338a9d1e10c4cd8154acbe33089", "file_name": "src/select.c", "vul_type": "cwe-476", "description": "Write a function in C for SQLite that handles the execution of compound SELECT queries with specific handling for UNION, INTERSECT, and EXCEPT operations."}
{"func_name": "handle_eac3", "func_src_before": "static int handle_eac3(MOVMuxContext *mov, AVPacket *pkt, MOVTrack *track)\n{\n    AC3HeaderInfo *hdr = NULL;\n    struct eac3_info *info;\n    int num_blocks, ret;\n\n    if (!track->eac3_priv && !(track->eac3_priv = av_mallocz(sizeof(*info))))\n        return AVERROR(ENOMEM);\n    info = track->eac3_priv;\n\n    if (avpriv_ac3_parse_header(&hdr, pkt->data, pkt->size) < 0) {\n        /* drop the packets until we see a good one */\n        if (!track->entry) {\n            av_log(mov, AV_LOG_WARNING, \"Dropping invalid packet from start of the stream\\n\");\n            ret = 0;\n        } else\n            ret = AVERROR_INVALIDDATA;\n        goto end;\n    }\n\n    info->data_rate = FFMAX(info->data_rate, hdr->bit_rate / 1000);\n    num_blocks = hdr->num_blocks;\n\n    if (!info->ec3_done) {\n        /* AC-3 substream must be the first one */\n        if (hdr->bitstream_id <= 10 && hdr->substreamid != 0) {\n            ret = AVERROR(EINVAL);\n            goto end;\n        }\n\n        /* this should always be the case, given that our AC-3 parser\n         * concatenates dependent frames to their independent parent */\n        if (hdr->frame_type == EAC3_FRAME_TYPE_INDEPENDENT) {\n            /* substream ids must be incremental */\n            if (hdr->substreamid > info->num_ind_sub + 1) {\n                ret = AVERROR(EINVAL);\n                goto end;\n            }\n\n            if (hdr->substreamid == info->num_ind_sub + 1) {\n                //info->num_ind_sub++;\n                avpriv_request_sample(track->par, \"Multiple independent substreams\");\n                ret = AVERROR_PATCHWELCOME;\n                goto end;\n            } else if (hdr->substreamid < info->num_ind_sub ||\n                       hdr->substreamid == 0 && info->substream[0].bsid) {\n                info->ec3_done = 1;\n                goto concatenate;\n            }\n        } else {\n            if (hdr->substreamid != 0) {\n                avpriv_request_sample(mov->fc, \"Multiple non EAC3 independent substreams\");\n                ret = AVERROR_PATCHWELCOME;\n                goto end;\n            }\n        }\n\n        /* fill the info needed for the \"dec3\" atom */\n        info->substream[hdr->substreamid].fscod = hdr->sr_code;\n        info->substream[hdr->substreamid].bsid  = hdr->bitstream_id;\n        info->substream[hdr->substreamid].bsmod = hdr->bitstream_mode;\n        info->substream[hdr->substreamid].acmod = hdr->channel_mode;\n        info->substream[hdr->substreamid].lfeon = hdr->lfe_on;\n\n        /* Parse dependent substream(s), if any */\n        if (pkt->size != hdr->frame_size) {\n            int cumul_size = hdr->frame_size;\n            int parent = hdr->substreamid;\n\n            while (cumul_size != pkt->size) {\n                GetBitContext gbc;\n                int i;\n                ret = avpriv_ac3_parse_header(&hdr, pkt->data + cumul_size, pkt->size - cumul_size);\n                if (ret < 0)\n                    goto end;\n                if (hdr->frame_type != EAC3_FRAME_TYPE_DEPENDENT) {\n                    ret = AVERROR(EINVAL);\n                    goto end;\n                }\n                info->substream[parent].num_dep_sub++;\n                ret /= 8;\n\n                /* header is parsed up to lfeon, but custom channel map may be needed */\n                init_get_bits8(&gbc, pkt->data + cumul_size + ret, pkt->size - cumul_size - ret);\n                /* skip bsid */\n                skip_bits(&gbc, 5);\n                /* skip volume control params */\n                for (i = 0; i < (hdr->channel_mode ? 1 : 2); i++) {\n                    skip_bits(&gbc, 5); // skip dialog normalization\n                    if (get_bits1(&gbc)) {\n                        skip_bits(&gbc, 8); // skip compression gain word\n                    }\n                }\n                /* get the dependent stream channel map, if exists */\n                if (get_bits1(&gbc))\n                    info->substream[parent].chan_loc |= (get_bits(&gbc, 16) >> 5) & 0x1f;\n                else\n                    info->substream[parent].chan_loc |= hdr->channel_mode;\n                cumul_size += hdr->frame_size;\n            }\n        }\n    }\n\nconcatenate:\n    if (!info->num_blocks && num_blocks == 6) {\n        ret = pkt->size;\n        goto end;\n    }\n    else if (info->num_blocks + num_blocks > 6) {\n        ret = AVERROR_INVALIDDATA;\n        goto end;\n    }\n\n    if (!info->num_blocks) {\n        ret = av_packet_ref(&info->pkt, pkt);\n        if (!ret)\n            info->num_blocks = num_blocks;\n        goto end;\n    } else {\n        if ((ret = av_grow_packet(&info->pkt, pkt->size)) < 0)\n            goto end;\n        memcpy(info->pkt.data + info->pkt.size - pkt->size, pkt->data, pkt->size);\n        info->num_blocks += num_blocks;\n        info->pkt.duration += pkt->duration;\n        if ((ret = av_copy_packet_side_data(&info->pkt, pkt)) < 0)\n            goto end;\n        if (info->num_blocks != 6)\n            goto end;\n        av_packet_unref(pkt);\n        av_packet_move_ref(pkt, &info->pkt);\n        info->num_blocks = 0;\n    }\n    ret = pkt->size;\n\nend:\n    av_free(hdr);\n\n    return ret;\n}", "func_src_after": "static int handle_eac3(MOVMuxContext *mov, AVPacket *pkt, MOVTrack *track)\n{\n    AC3HeaderInfo *hdr = NULL;\n    struct eac3_info *info;\n    int num_blocks, ret;\n\n    if (!track->eac3_priv && !(track->eac3_priv = av_mallocz(sizeof(*info))))\n        return AVERROR(ENOMEM);\n    info = track->eac3_priv;\n\n    if (avpriv_ac3_parse_header(&hdr, pkt->data, pkt->size) < 0) {\n        /* drop the packets until we see a good one */\n        if (!track->entry) {\n            av_log(mov, AV_LOG_WARNING, \"Dropping invalid packet from start of the stream\\n\");\n            ret = 0;\n        } else\n            ret = AVERROR_INVALIDDATA;\n        goto end;\n    }\n\n    info->data_rate = FFMAX(info->data_rate, hdr->bit_rate / 1000);\n    num_blocks = hdr->num_blocks;\n\n    if (!info->ec3_done) {\n        /* AC-3 substream must be the first one */\n        if (hdr->bitstream_id <= 10 && hdr->substreamid != 0) {\n            ret = AVERROR(EINVAL);\n            goto end;\n        }\n\n        /* this should always be the case, given that our AC-3 parser\n         * concatenates dependent frames to their independent parent */\n        if (hdr->frame_type == EAC3_FRAME_TYPE_INDEPENDENT) {\n            /* substream ids must be incremental */\n            if (hdr->substreamid > info->num_ind_sub + 1) {\n                ret = AVERROR(EINVAL);\n                goto end;\n            }\n\n            if (hdr->substreamid == info->num_ind_sub + 1) {\n                //info->num_ind_sub++;\n                avpriv_request_sample(mov->fc, \"Multiple independent substreams\");\n                ret = AVERROR_PATCHWELCOME;\n                goto end;\n            } else if (hdr->substreamid < info->num_ind_sub ||\n                       hdr->substreamid == 0 && info->substream[0].bsid) {\n                info->ec3_done = 1;\n                goto concatenate;\n            }\n        } else {\n            if (hdr->substreamid != 0) {\n                avpriv_request_sample(mov->fc, \"Multiple non EAC3 independent substreams\");\n                ret = AVERROR_PATCHWELCOME;\n                goto end;\n            }\n        }\n\n        /* fill the info needed for the \"dec3\" atom */\n        info->substream[hdr->substreamid].fscod = hdr->sr_code;\n        info->substream[hdr->substreamid].bsid  = hdr->bitstream_id;\n        info->substream[hdr->substreamid].bsmod = hdr->bitstream_mode;\n        info->substream[hdr->substreamid].acmod = hdr->channel_mode;\n        info->substream[hdr->substreamid].lfeon = hdr->lfe_on;\n\n        /* Parse dependent substream(s), if any */\n        if (pkt->size != hdr->frame_size) {\n            int cumul_size = hdr->frame_size;\n            int parent = hdr->substreamid;\n\n            while (cumul_size != pkt->size) {\n                GetBitContext gbc;\n                int i;\n                ret = avpriv_ac3_parse_header(&hdr, pkt->data + cumul_size, pkt->size - cumul_size);\n                if (ret < 0)\n                    goto end;\n                if (hdr->frame_type != EAC3_FRAME_TYPE_DEPENDENT) {\n                    ret = AVERROR(EINVAL);\n                    goto end;\n                }\n                info->substream[parent].num_dep_sub++;\n                ret /= 8;\n\n                /* header is parsed up to lfeon, but custom channel map may be needed */\n                init_get_bits8(&gbc, pkt->data + cumul_size + ret, pkt->size - cumul_size - ret);\n                /* skip bsid */\n                skip_bits(&gbc, 5);\n                /* skip volume control params */\n                for (i = 0; i < (hdr->channel_mode ? 1 : 2); i++) {\n                    skip_bits(&gbc, 5); // skip dialog normalization\n                    if (get_bits1(&gbc)) {\n                        skip_bits(&gbc, 8); // skip compression gain word\n                    }\n                }\n                /* get the dependent stream channel map, if exists */\n                if (get_bits1(&gbc))\n                    info->substream[parent].chan_loc |= (get_bits(&gbc, 16) >> 5) & 0x1f;\n                else\n                    info->substream[parent].chan_loc |= hdr->channel_mode;\n                cumul_size += hdr->frame_size;\n            }\n        }\n    }\n\nconcatenate:\n    if (!info->num_blocks && num_blocks == 6) {\n        ret = pkt->size;\n        goto end;\n    }\n    else if (info->num_blocks + num_blocks > 6) {\n        ret = AVERROR_INVALIDDATA;\n        goto end;\n    }\n\n    if (!info->num_blocks) {\n        ret = av_packet_ref(&info->pkt, pkt);\n        if (!ret)\n            info->num_blocks = num_blocks;\n        goto end;\n    } else {\n        if ((ret = av_grow_packet(&info->pkt, pkt->size)) < 0)\n            goto end;\n        memcpy(info->pkt.data + info->pkt.size - pkt->size, pkt->data, pkt->size);\n        info->num_blocks += num_blocks;\n        info->pkt.duration += pkt->duration;\n        if ((ret = av_copy_packet_side_data(&info->pkt, pkt)) < 0)\n            goto end;\n        if (info->num_blocks != 6)\n            goto end;\n        av_packet_unref(pkt);\n        av_packet_move_ref(pkt, &info->pkt);\n        info->num_blocks = 0;\n    }\n    ret = pkt->size;\n\nend:\n    av_free(hdr);\n\n    return ret;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/95556e27e2c1d56d9e18f5db34d6f756f3011148", "file_name": "libavformat/movenc.c", "vul_type": "cwe-125", "description": "Write a C function named `handle_eac3` that processes E-AC-3 audio packets for a multimedia container."}
{"func_name": "fpm_log_write", "func_src_before": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "func_src_after": "int fpm_log_write(char *log_format) /* {{{ */\n{\n\tchar *s, *b;\n\tchar buffer[FPM_LOG_BUFFER+1];\n\tint token, test;\n\tsize_t len, len2;\n\tstruct fpm_scoreboard_proc_s proc, *proc_p;\n\tstruct fpm_scoreboard_s *scoreboard;\n\tchar tmp[129];\n\tchar format[129];\n\ttime_t now_epoch;\n#ifdef HAVE_TIMES\n\tclock_t tms_total;\n#endif\n\n\tif (!log_format && (!fpm_log_format || fpm_log_fd == -1)) {\n\t\treturn -1;\n\t}\n\n\tif (!log_format) {\n\t\tlog_format = fpm_log_format;\n\t\ttest = 0;\n\t} else {\n\t\ttest = 1;\n\t}\n\n\tnow_epoch = time(NULL);\n\n\tif (!test) {\n\t\tscoreboard = fpm_scoreboard_get();\n\t\tif (!scoreboard) {\n\t\t\tzlog(ZLOG_WARNING, \"unable to get scoreboard while preparing the access log\");\n\t\t\treturn -1;\n\t\t}\n\t\tproc_p = fpm_scoreboard_proc_acquire(NULL, -1, 0);\n\t\tif (!proc_p) {\n\t\t\tzlog(ZLOG_WARNING, \"[pool %s] Unable to acquire shm slot while preparing the access log\", scoreboard->pool);\n\t\t\treturn -1;\n\t\t}\n\t\tproc = *proc_p;\n\t\tfpm_scoreboard_proc_release(proc_p);\n\t}\n\n\ttoken = 0;\n\n\tmemset(buffer, '\\0', sizeof(buffer));\n\tb = buffer;\n\tlen = 0;\n\n\n\ts = log_format;\n\n\twhile (*s != '\\0') {\n\t\t/* Test is we have place for 1 more char. */\n\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!token && *s == '%') {\n\t\t\ttoken = 1;\n\t\t\tmemset(format, '\\0', sizeof(format)); /* reset format */\n\t\t\ts++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (token) {\n\t\t\ttoken = 0;\n\t\t\tlen2 = 0;\n\t\t\tswitch (*s) {\n\n\t\t\t\tcase '%': /* '%' */\n\t\t\t\t\t*b = '%';\n\t\t\t\t\tlen2 = 1;\n\t\t\t\t\tbreak;\n\n#ifdef HAVE_TIMES\n\t\t\t\tcase 'C': /* %CPU */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"total\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cutime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"user\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_utime + proc.last_request_cpu.tms_cutime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else if (!strcasecmp(format, \"system\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\ttms_total = proc.last_request_cpu.tms_stime + proc.last_request_cpu.tms_cstime;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'total', 'user' or 'system' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.2f\", tms_total / fpm_scoreboard_get_tick() / (proc.cpu_duration.tv_sec + proc.cpu_duration.tv_usec / 1000000.) * 100.);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n#endif\n\n\t\t\t\tcase 'd': /* duration \u00b5s */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"seconds\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec + proc.duration.tv_usec / 1000000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* miliseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"miliseconds\") || !strcasecmp(format, \"mili\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%.3f\", proc.duration.tv_sec * 1000. + proc.duration.tv_usec / 1000.);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* microseconds */\n\t\t\t\t\t} else if (!strcasecmp(format, \"microseconds\") || !strcasecmp(format, \"micro\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.duration.tv_sec * 1000000UL + proc.duration.tv_usec);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'seconds', 'mili', 'miliseconds', 'micro' or 'microseconds' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'e': /* fastcgi env  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the environment variable must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tchar *env = fcgi_getenv((fcgi_request*) SG(server_context), format, strlen(format));\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", env ? env : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'f': /* script */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\",  *proc.script_filename ? proc.script_filename : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'l': /* content length */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.content_length);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'm': /* method */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.request_method ? proc.request_method : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'M': /* memory */\n\t\t\t\t\t/* seconds */\n\t\t\t\t\tif (format[0] == '\\0' || !strcasecmp(format, \"bytes\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%zu\", proc.memory);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* kilobytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"kilobytes\") || !strcasecmp(format, \"kilo\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t/* megabytes */\n\t\t\t\t\t} else if (!strcasecmp(format, \"megabytes\") || !strcasecmp(format, \"mega\")) {\n\t\t\t\t\t\tif (!test) {\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%lu\", proc.memory / 1024 / 1024);\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"only 'bytes', 'kilo', 'kilobytes', 'mega' or 'megabytes' are allowed as a modifier for %%%c ('%s')\", *s, format);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'n': /* pool name */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", scoreboard->pool[0] ? scoreboard->pool : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'o': /* header output  */\n\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\tzlog(ZLOG_WARNING, \"the name of the header must be set between embraces for %%%c\", *s);\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tsapi_header_struct *h;\n\t\t\t\t\t\tzend_llist_position pos;\n\t\t\t\t\t\tsapi_headers_struct *sapi_headers = &SG(sapi_headers);\n\t\t\t\t\t\tsize_t format_len = strlen(format);\n\n\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_first_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\twhile (h) {\n\t\t\t\t\t\t\tchar *header;\n\t\t\t\t\t\t\tif (!h->header_len) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif (!strstr(h->header, format)) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t/* test if enought char after the header name + ': ' */\n\t\t\t\t\t\t\tif (h->header_len <= format_len + 2) {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (h->header[format_len] != ':' || h->header[format_len + 1] != ' ') {\n\t\t\t\t\t\t\t\th = (sapi_header_struct*)zend_llist_get_next_ex(&sapi_headers->headers, &pos);\n\t\t\t\t\t\t\t\tcontinue;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\theader = h->header + format_len + 2;\n\t\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", header && *header ? header : \"-\");\n\n\t\t\t\t\t\t\t/* found, done */\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (!len2) {\n\t\t\t\t\t\t\tlen2 = 1;\n\t\t\t\t\t\t\t*b = '-';\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'p': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getpid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'P': /* PID */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%ld\", (long)getppid());\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'q': /* query_string */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.query_string);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'Q': /* '?' */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", *proc.query_string  ? \"?\" : \"\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'r': /* request URI */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.request_uri);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'R': /* remote IP address */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tconst char *tmp = fcgi_get_last_client_ip();\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp ? tmp : \"-\");\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 's': /* status */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%d\", SG(sapi_headers).http_response_code);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'T':\n\t\t\t\tcase 't': /* time */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\ttime_t *t;\n\t\t\t\t\t\tif (*s == 't') {\n\t\t\t\t\t\t\tt = &proc.accepted_epoch;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tt = &now_epoch;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (format[0] == '\\0') {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, \"%d/%b/%Y:%H:%M:%S %z\", localtime(t));\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tstrftime(tmp, sizeof(tmp) - 1, format, localtime(t));\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", tmp);\n\t\t\t\t\t}\n\t\t\t\t\tformat[0] = '\\0';\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'u': /* remote user */\n\t\t\t\t\tif (!test) {\n\t\t\t\t\t\tlen2 = snprintf(b, FPM_LOG_BUFFER - len, \"%s\", proc.auth_user);\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase '{': /* complex var */\n\t\t\t\t\ttoken = 1;\n\t\t\t\t\t{\n\t\t\t\t\t\tchar *start;\n\t\t\t\t\t\tsize_t l;\n\n\t\t\t\t\t\tstart = ++s;\n\n\t\t\t\t\t\twhile (*s != '\\0') {\n\t\t\t\t\t\t\tif (*s == '}') {\n\t\t\t\t\t\t\t\tl = s - start;\n\n\t\t\t\t\t\t\t\tif (l >= sizeof(format) - 1) {\n\t\t\t\t\t\t\t\t\tl = sizeof(format) - 1;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tmemcpy(format, start, l);\n\t\t\t\t\t\t\t\tformat[l] = '\\0';\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ts++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif (s[1] == '\\0') {\n\t\t\t\t\t\t\tzlog(ZLOG_WARNING, \"missing closing embrace in the access.format\");\n\t\t\t\t\t\t\treturn -1;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tzlog(ZLOG_WARNING, \"Invalid token in the access.format (%%%c)\", *s);\n\t\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (*s != '}' && format[0] != '\\0') {\n\t\t\t\tzlog(ZLOG_WARNING, \"embrace is not allowed for modifier %%%c\", *s);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ts++;\n\t\t\tif (!test) {\n\t\t\t\tb += len2;\n\t\t\t\tlen += len2;\n\t\t\t}\n\t\t\tif (len >= FPM_LOG_BUFFER) {\n\t\t\t\tzlog(ZLOG_NOTICE, \"the log buffer is full (%d). The access log request has been truncated.\", FPM_LOG_BUFFER);\n\t\t\t\tlen = FPM_LOG_BUFFER;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (!test) {\n\t\t\t// push the normal char to the output buffer\n\t\t\t*b = *s;\n\t\t\tb++;\n\t\t\tlen++;\n\t\t}\n\t\ts++;\n\t}\n\n\tif (!test && strlen(buffer) > 0) {\n\t\tbuffer[len] = '\\n';\n\t\twrite(fpm_log_fd, buffer, len + 1);\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/php/php-src/commit/2721a0148649e07ed74468f097a28899741eb58f", "file_name": "sapi/fpm/fpm/fpm_log.c", "vul_type": "cwe-125", "description": "Write a C function named `fpm_log_write` that processes a log format string and writes the formatted log entry to a file."}
{"func_name": "dnxhd_decode_header", "func_src_before": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n                               const uint8_t *buf, int buf_size,\n                               int first_field)\n{\n    int i, cid, ret;\n    int old_bit_depth = ctx->bit_depth, bitdepth;\n    uint64_t header_prefix;\n    if (buf_size < 0x280) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < 640).\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    header_prefix = ff_dnxhd_parse_header_prefix(buf);\n    if (header_prefix == 0) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"unknown header 0x%02X 0x%02X 0x%02X 0x%02X 0x%02X\\n\",\n               buf[0], buf[1], buf[2], buf[3], buf[4]);\n        return AVERROR_INVALIDDATA;\n    }\n    if (buf[5] & 2) { /* interlaced */\n        ctx->cur_field = buf[5] & 1;\n        frame->interlaced_frame = 1;\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n    } else {\n        ctx->cur_field = 0;\n    }\n    ctx->mbaff = (buf[0x6] >> 5) & 1;\n\n    ctx->height = AV_RB16(buf + 0x18);\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n    switch(buf[0x21] >> 5) {\n    case 1: bitdepth = 8; break;\n    case 2: bitdepth = 10; break;\n    case 3: bitdepth = 12; break;\n    default:\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"Unknown bitdepth indicator (%d)\\n\", buf[0x21] >> 5);\n        return AVERROR_INVALIDDATA;\n    }\n\n    cid = AV_RB32(buf + 0x28);\n\n    ctx->avctx->profile = dnxhd_get_profile(cid);\n\n    if ((ret = dnxhd_init_vlc(ctx, cid, bitdepth)) < 0)\n        return ret;\n    if (ctx->mbaff && ctx->cid_table->cid != 1260)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive MB interlace flag in an unsupported profile.\\n\");\n\n    ctx->act = buf[0x2C] & 7;\n    if (ctx->act && ctx->cid_table->cid != 1256 && ctx->cid_table->cid != 1270)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive color transform in an unsupported profile.\\n\");\n\n    ctx->is_444 = (buf[0x2C] >> 6) & 1;\n    if (ctx->is_444) {\n        if (bitdepth == 8) {\n            avpriv_request_sample(ctx->avctx, \"4:4:4 8 bits\");\n            return AVERROR_INVALIDDATA;\n        } else if (bitdepth == 10) {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P10\n                                    : AV_PIX_FMT_GBRP10;\n        } else {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_12_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P12\n                                    : AV_PIX_FMT_GBRP12;\n        }\n    } else if (bitdepth == 12) {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_12;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P12;\n    } else if (bitdepth == 10) {\n        if (ctx->avctx->profile == FF_PROFILE_DNXHR_HQX)\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n        else\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n    } else {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P;\n    }\n\n    ctx->avctx->bits_per_raw_sample = ctx->bit_depth = bitdepth;\n    if (ctx->bit_depth != old_bit_depth) {\n        ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n        ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n        ff_init_scantable(ctx->idsp.idct_permutation, &ctx->scantable,\n                          ff_zigzag_direct);\n    }\n\n    // make sure profile size constraints are respected\n    // DNx100 allows 1920->1440 and 1280->960 subsampling\n    if (ctx->width != ctx->cid_table->width &&\n        ctx->cid_table->width != DNXHD_VARIABLE) {\n        av_reduce(&ctx->avctx->sample_aspect_ratio.num,\n                  &ctx->avctx->sample_aspect_ratio.den,\n                  ctx->width, ctx->cid_table->width, 255);\n        ctx->width = ctx->cid_table->width;\n    }\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size (%d < %u).\\n\",\n               buf_size, ctx->cid_table->coding_unit_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ctx->mb_width  = (ctx->width + 15)>> 4;\n    ctx->mb_height = AV_RB16(buf + 0x16c);\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n        ctx->height <<= 1;\n\n    av_log(ctx->avctx, AV_LOG_VERBOSE, \"%dx%d, 4:%s %d bits, MBAFF=%d ACT=%d\\n\",\n           ctx->width, ctx->height, ctx->is_444 ? \"4:4\" : \"2:2\",\n           ctx->bit_depth, ctx->mbaff, ctx->act);\n\n    // Newer format supports variable mb_scan_index sizes\n    if (ctx->mb_height > 68 && ff_dnxhd_check_header_prefix_hr(header_prefix)) {\n        ctx->data_offset = 0x170 + (ctx->mb_height << 2);\n    } else {\n        if (ctx->mb_height > 68 ||\n            (ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"mb height too big: %d\\n\", ctx->mb_height);\n            return AVERROR_INVALIDDATA;\n        }\n        ctx->data_offset = 0x280;\n    }\n\n    if (buf_size < ctx->data_offset) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < %d).\\n\", buf_size, ctx->data_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (ctx->mb_height > FF_ARRAY_ELEMS(ctx->mb_scan_index)) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"mb_height too big (%d > %\"SIZE_SPECIFIER\").\\n\", ctx->mb_height, FF_ARRAY_ELEMS(ctx->mb_scan_index));\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < ctx->mb_height; i++) {\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n        ff_dlog(ctx->avctx, \"mb scan index %d, pos %d: %\"PRIu32\"\\n\",\n                i, 0x170 + (i << 2), ctx->mb_scan_index[i]);\n        if (buf_size - ctx->data_offset < ctx->mb_scan_index[i]) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"invalid mb scan index (%\"PRIu32\" vs %u).\\n\",\n                   ctx->mb_scan_index[i], buf_size - ctx->data_offset);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    return 0;\n}", "func_src_after": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n                               const uint8_t *buf, int buf_size,\n                               int first_field)\n{\n    int i, cid, ret;\n    int old_bit_depth = ctx->bit_depth, bitdepth;\n    uint64_t header_prefix;\n    if (buf_size < 0x280) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < 640).\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    header_prefix = ff_dnxhd_parse_header_prefix(buf);\n    if (header_prefix == 0) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"unknown header 0x%02X 0x%02X 0x%02X 0x%02X 0x%02X\\n\",\n               buf[0], buf[1], buf[2], buf[3], buf[4]);\n        return AVERROR_INVALIDDATA;\n    }\n    if (buf[5] & 2) { /* interlaced */\n        ctx->cur_field = buf[5] & 1;\n        frame->interlaced_frame = 1;\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n    } else {\n        ctx->cur_field = 0;\n    }\n    ctx->mbaff = (buf[0x6] >> 5) & 1;\n\n    ctx->height = AV_RB16(buf + 0x18);\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n    switch(buf[0x21] >> 5) {\n    case 1: bitdepth = 8; break;\n    case 2: bitdepth = 10; break;\n    case 3: bitdepth = 12; break;\n    default:\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"Unknown bitdepth indicator (%d)\\n\", buf[0x21] >> 5);\n        return AVERROR_INVALIDDATA;\n    }\n\n    cid = AV_RB32(buf + 0x28);\n\n    ctx->avctx->profile = dnxhd_get_profile(cid);\n\n    if ((ret = dnxhd_init_vlc(ctx, cid, bitdepth)) < 0)\n        return ret;\n    if (ctx->mbaff && ctx->cid_table->cid != 1260)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive MB interlace flag in an unsupported profile.\\n\");\n\n    ctx->act = buf[0x2C] & 7;\n    if (ctx->act && ctx->cid_table->cid != 1256 && ctx->cid_table->cid != 1270)\n        av_log(ctx->avctx, AV_LOG_WARNING,\n               \"Adaptive color transform in an unsupported profile.\\n\");\n\n    ctx->is_444 = (buf[0x2C] >> 6) & 1;\n    if (ctx->is_444) {\n        if (bitdepth == 8) {\n            avpriv_request_sample(ctx->avctx, \"4:4:4 8 bits\");\n            return AVERROR_INVALIDDATA;\n        } else if (bitdepth == 10) {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P10\n                                    : AV_PIX_FMT_GBRP10;\n        } else {\n            ctx->decode_dct_block = dnxhd_decode_dct_block_12_444;\n            ctx->pix_fmt = ctx->act ? AV_PIX_FMT_YUV444P12\n                                    : AV_PIX_FMT_GBRP12;\n        }\n    } else if (bitdepth == 12) {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_12;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P12;\n    } else if (bitdepth == 10) {\n        if (ctx->avctx->profile == FF_PROFILE_DNXHR_HQX)\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n        else\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n    } else {\n        ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n        ctx->pix_fmt = AV_PIX_FMT_YUV422P;\n    }\n\n    ctx->avctx->bits_per_raw_sample = ctx->bit_depth = bitdepth;\n    if (ctx->bit_depth != old_bit_depth) {\n        ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n        ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n        ff_init_scantable(ctx->idsp.idct_permutation, &ctx->scantable,\n                          ff_zigzag_direct);\n    }\n\n    // make sure profile size constraints are respected\n    // DNx100 allows 1920->1440 and 1280->960 subsampling\n    if (ctx->width != ctx->cid_table->width &&\n        ctx->cid_table->width != DNXHD_VARIABLE) {\n        av_reduce(&ctx->avctx->sample_aspect_ratio.num,\n                  &ctx->avctx->sample_aspect_ratio.den,\n                  ctx->width, ctx->cid_table->width, 255);\n        ctx->width = ctx->cid_table->width;\n    }\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size (%d < %u).\\n\",\n               buf_size, ctx->cid_table->coding_unit_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ctx->mb_width  = (ctx->width + 15)>> 4;\n    ctx->mb_height = AV_RB16(buf + 0x16c);\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n        ctx->height <<= 1;\n\n    av_log(ctx->avctx, AV_LOG_VERBOSE, \"%dx%d, 4:%s %d bits, MBAFF=%d ACT=%d\\n\",\n           ctx->width, ctx->height, ctx->is_444 ? \"4:4\" : \"2:2\",\n           ctx->bit_depth, ctx->mbaff, ctx->act);\n\n    // Newer format supports variable mb_scan_index sizes\n    if (ctx->mb_height > 68 && ff_dnxhd_check_header_prefix_hr(header_prefix)) {\n        ctx->data_offset = 0x170 + (ctx->mb_height << 2);\n    } else {\n        if (ctx->mb_height > 68) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"mb height too big: %d\\n\", ctx->mb_height);\n            return AVERROR_INVALIDDATA;\n        }\n        ctx->data_offset = 0x280;\n    }\n    if ((ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n                \"mb height too big: %d\\n\", ctx->mb_height);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (buf_size < ctx->data_offset) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"buffer too small (%d < %d).\\n\", buf_size, ctx->data_offset);\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (ctx->mb_height > FF_ARRAY_ELEMS(ctx->mb_scan_index)) {\n        av_log(ctx->avctx, AV_LOG_ERROR,\n               \"mb_height too big (%d > %\"SIZE_SPECIFIER\").\\n\", ctx->mb_height, FF_ARRAY_ELEMS(ctx->mb_scan_index));\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i < ctx->mb_height; i++) {\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n        ff_dlog(ctx->avctx, \"mb scan index %d, pos %d: %\"PRIu32\"\\n\",\n                i, 0x170 + (i << 2), ctx->mb_scan_index[i]);\n        if (buf_size - ctx->data_offset < ctx->mb_scan_index[i]) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"invalid mb scan index (%\"PRIu32\" vs %u).\\n\",\n                   ctx->mb_scan_index[i], buf_size - ctx->data_offset);\n            return AVERROR_INVALIDDATA;\n        }\n    }\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/296debd213bd6dce7647cedd34eb64e5b94cdc92", "file_name": "libavcodec/dnxhddec.c", "vul_type": "cwe-125", "description": "Write a C function named `dnxhd_decode_header` that decodes the header of a DNxHD video frame."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw - SQL Injection\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/rwolf527/crimemap/commit/50b0695e0b4c46165e6146f6fac4cd6871d9fdf6", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function that adds user input to a database with a deliberate SQL injection vulnerability."}
{"func_name": "mwifiex_ret_wmm_get_status", "func_src_before": "int mwifiex_ret_wmm_get_status(struct mwifiex_private *priv,\n\t\t\t       const struct host_cmd_ds_command *resp)\n{\n\tu8 *curr = (u8 *) &resp->params.get_wmm_status;\n\tuint16_t resp_len = le16_to_cpu(resp->size), tlv_len;\n\tint mask = IEEE80211_WMM_IE_AP_QOSINFO_PARAM_SET_CNT_MASK;\n\tbool valid = true;\n\n\tstruct mwifiex_ie_types_data *tlv_hdr;\n\tstruct mwifiex_ie_types_wmm_queue_status *tlv_wmm_qstatus;\n\tstruct ieee_types_wmm_parameter *wmm_param_ie = NULL;\n\tstruct mwifiex_wmm_ac_status *ac_status;\n\n\tmwifiex_dbg(priv->adapter, INFO,\n\t\t    \"info: WMM: WMM_GET_STATUS cmdresp received: %d\\n\",\n\t\t    resp_len);\n\n\twhile ((resp_len >= sizeof(tlv_hdr->header)) && valid) {\n\t\ttlv_hdr = (struct mwifiex_ie_types_data *) curr;\n\t\ttlv_len = le16_to_cpu(tlv_hdr->header.len);\n\n\t\tif (resp_len < tlv_len + sizeof(tlv_hdr->header))\n\t\t\tbreak;\n\n\t\tswitch (le16_to_cpu(tlv_hdr->header.type)) {\n\t\tcase TLV_TYPE_WMMQSTATUS:\n\t\t\ttlv_wmm_qstatus =\n\t\t\t\t(struct mwifiex_ie_types_wmm_queue_status *)\n\t\t\t\ttlv_hdr;\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"QSTATUS TLV: %d, %d, %d\\n\",\n\t\t\t\t    tlv_wmm_qstatus->queue_index,\n\t\t\t\t    tlv_wmm_qstatus->flow_required,\n\t\t\t\t    tlv_wmm_qstatus->disabled);\n\n\t\t\tac_status = &priv->wmm.ac_status[tlv_wmm_qstatus->\n\t\t\t\t\t\t\t queue_index];\n\t\t\tac_status->disabled = tlv_wmm_qstatus->disabled;\n\t\t\tac_status->flow_required =\n\t\t\t\t\t\ttlv_wmm_qstatus->flow_required;\n\t\t\tac_status->flow_created = tlv_wmm_qstatus->flow_created;\n\t\t\tbreak;\n\n\t\tcase WLAN_EID_VENDOR_SPECIFIC:\n\t\t\t/*\n\t\t\t * Point the regular IEEE IE 2 bytes into the Marvell IE\n\t\t\t *   and setup the IEEE IE type and length byte fields\n\t\t\t */\n\n\t\t\twmm_param_ie =\n\t\t\t\t(struct ieee_types_wmm_parameter *) (curr +\n\t\t\t\t\t\t\t\t    2);\n\t\t\twmm_param_ie->vend_hdr.len = (u8) tlv_len;\n\t\t\twmm_param_ie->vend_hdr.element_id =\n\t\t\t\t\t\tWLAN_EID_VENDOR_SPECIFIC;\n\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"WMM Parameter Set Count: %d\\n\",\n\t\t\t\t    wmm_param_ie->qos_info_bitmap & mask);\n\n\t\t\tmemcpy((u8 *) &priv->curr_bss_params.bss_descriptor.\n\t\t\t       wmm_ie, wmm_param_ie,\n\t\t\t       wmm_param_ie->vend_hdr.len + 2);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tvalid = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcurr += (tlv_len + sizeof(tlv_hdr->header));\n\t\tresp_len -= (tlv_len + sizeof(tlv_hdr->header));\n\t}\n\n\tmwifiex_wmm_setup_queue_priorities(priv, wmm_param_ie);\n\tmwifiex_wmm_setup_ac_downgrade(priv);\n\n\treturn 0;\n}", "func_src_after": "int mwifiex_ret_wmm_get_status(struct mwifiex_private *priv,\n\t\t\t       const struct host_cmd_ds_command *resp)\n{\n\tu8 *curr = (u8 *) &resp->params.get_wmm_status;\n\tuint16_t resp_len = le16_to_cpu(resp->size), tlv_len;\n\tint mask = IEEE80211_WMM_IE_AP_QOSINFO_PARAM_SET_CNT_MASK;\n\tbool valid = true;\n\n\tstruct mwifiex_ie_types_data *tlv_hdr;\n\tstruct mwifiex_ie_types_wmm_queue_status *tlv_wmm_qstatus;\n\tstruct ieee_types_wmm_parameter *wmm_param_ie = NULL;\n\tstruct mwifiex_wmm_ac_status *ac_status;\n\n\tmwifiex_dbg(priv->adapter, INFO,\n\t\t    \"info: WMM: WMM_GET_STATUS cmdresp received: %d\\n\",\n\t\t    resp_len);\n\n\twhile ((resp_len >= sizeof(tlv_hdr->header)) && valid) {\n\t\ttlv_hdr = (struct mwifiex_ie_types_data *) curr;\n\t\ttlv_len = le16_to_cpu(tlv_hdr->header.len);\n\n\t\tif (resp_len < tlv_len + sizeof(tlv_hdr->header))\n\t\t\tbreak;\n\n\t\tswitch (le16_to_cpu(tlv_hdr->header.type)) {\n\t\tcase TLV_TYPE_WMMQSTATUS:\n\t\t\ttlv_wmm_qstatus =\n\t\t\t\t(struct mwifiex_ie_types_wmm_queue_status *)\n\t\t\t\ttlv_hdr;\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"QSTATUS TLV: %d, %d, %d\\n\",\n\t\t\t\t    tlv_wmm_qstatus->queue_index,\n\t\t\t\t    tlv_wmm_qstatus->flow_required,\n\t\t\t\t    tlv_wmm_qstatus->disabled);\n\n\t\t\tac_status = &priv->wmm.ac_status[tlv_wmm_qstatus->\n\t\t\t\t\t\t\t queue_index];\n\t\t\tac_status->disabled = tlv_wmm_qstatus->disabled;\n\t\t\tac_status->flow_required =\n\t\t\t\t\t\ttlv_wmm_qstatus->flow_required;\n\t\t\tac_status->flow_created = tlv_wmm_qstatus->flow_created;\n\t\t\tbreak;\n\n\t\tcase WLAN_EID_VENDOR_SPECIFIC:\n\t\t\t/*\n\t\t\t * Point the regular IEEE IE 2 bytes into the Marvell IE\n\t\t\t *   and setup the IEEE IE type and length byte fields\n\t\t\t */\n\n\t\t\twmm_param_ie =\n\t\t\t\t(struct ieee_types_wmm_parameter *) (curr +\n\t\t\t\t\t\t\t\t    2);\n\t\t\twmm_param_ie->vend_hdr.len = (u8) tlv_len;\n\t\t\twmm_param_ie->vend_hdr.element_id =\n\t\t\t\t\t\tWLAN_EID_VENDOR_SPECIFIC;\n\n\t\t\tmwifiex_dbg(priv->adapter, CMD,\n\t\t\t\t    \"info: CMD_RESP: WMM_GET_STATUS:\\t\"\n\t\t\t\t    \"WMM Parameter Set Count: %d\\n\",\n\t\t\t\t    wmm_param_ie->qos_info_bitmap & mask);\n\n\t\t\tif (wmm_param_ie->vend_hdr.len + 2 >\n\t\t\t\tsizeof(struct ieee_types_wmm_parameter))\n\t\t\t\tbreak;\n\n\t\t\tmemcpy((u8 *) &priv->curr_bss_params.bss_descriptor.\n\t\t\t       wmm_ie, wmm_param_ie,\n\t\t\t       wmm_param_ie->vend_hdr.len + 2);\n\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tvalid = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tcurr += (tlv_len + sizeof(tlv_hdr->header));\n\t\tresp_len -= (tlv_len + sizeof(tlv_hdr->header));\n\t}\n\n\tmwifiex_wmm_setup_queue_priorities(priv, wmm_param_ie);\n\tmwifiex_wmm_setup_ac_downgrade(priv);\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/3a9b153c5591548612c3955c9600a98150c81875", "file_name": "drivers/net/wireless/marvell/mwifiex/wmm.c", "vul_type": "cwe-787", "description": "Write a C function named `mwifiex_ret_wmm_get_status` that processes a WMM (Wireless Multimedia) status response for a WiFi device."}
{"func_name": "get", "func_src_before": "    def get(self, space_id):\n        \"\"\" Fetch data for space with the corresponding space_id \"\"\"\n        return database_utilities.execute_query(\n            f\"\"\"select * from spaces where space_id = '{space_id}'\"\"\")", "func_src_after": "    def get(self, space_id):\n        \"\"\" Fetch data for space with the corresponding space_id \"\"\"\n        return database_utilities.execute_query(\n            f\"\"\"select * from spaces where space_id = %s\"\"\", (space_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/spaces.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve data from a database table 'spaces' using a provided 'space_id'."}
{"func_name": "view_page_history", "func_src_before": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = '%s'\" % page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "func_src_after": "@app.route('/<page_name>/history')\ndef view_page_history(page_name):\n    query = db.query(\"select page_content.timestamp, page_content.id from page, page_content where page.id = page_content.page_id and page.page_name = $1\", page_name)\n    page_histories = query.namedresult()\n\n    return render_template(\n        'page_history.html',\n        page_name = page_name,\n        page_histories = page_histories\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to display the history of a webpage using a template, with SQL query parameterization differing between string formatting and using placeholders."}
{"func_name": "mpol_parse_str", "func_src_before": "int mpol_parse_str(char *str, struct mempolicy **mpol)\n{\n\tstruct mempolicy *new = NULL;\n\tunsigned short mode_flags;\n\tnodemask_t nodes;\n\tchar *nodelist = strchr(str, ':');\n\tchar *flags = strchr(str, '=');\n\tint err = 1, mode;\n\n\tif (flags)\n\t\t*flags++ = '\\0';\t/* terminate mode string */\n\n\tif (nodelist) {\n\t\t/* NUL-terminate mode or flags string */\n\t\t*nodelist++ = '\\0';\n\t\tif (nodelist_parse(nodelist, nodes))\n\t\t\tgoto out;\n\t\tif (!nodes_subset(nodes, node_states[N_MEMORY]))\n\t\t\tgoto out;\n\t} else\n\t\tnodes_clear(nodes);\n\n\tmode = match_string(policy_modes, MPOL_MAX, str);\n\tif (mode < 0)\n\t\tgoto out;\n\n\tswitch (mode) {\n\tcase MPOL_PREFERRED:\n\t\t/*\n\t\t * Insist on a nodelist of one node only\n\t\t */\n\t\tif (nodelist) {\n\t\t\tchar *rest = nodelist;\n\t\t\twhile (isdigit(*rest))\n\t\t\t\trest++;\n\t\t\tif (*rest)\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\t\t/*\n\t\t * Default to online nodes with memory if no nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tnodes = node_states[N_MEMORY];\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\t\t/*\n\t\t * Don't allow a nodelist;  mpol_new() checks flags\n\t\t */\n\t\tif (nodelist)\n\t\t\tgoto out;\n\t\tmode = MPOL_PREFERRED;\n\t\tbreak;\n\tcase MPOL_DEFAULT:\n\t\t/*\n\t\t * Insist on a empty nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\terr = 0;\n\t\tgoto out;\n\tcase MPOL_BIND:\n\t\t/*\n\t\t * Insist on a nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tgoto out;\n\t}\n\n\tmode_flags = 0;\n\tif (flags) {\n\t\t/*\n\t\t * Currently, we only support two mutually exclusive\n\t\t * mode flags.\n\t\t */\n\t\tif (!strcmp(flags, \"static\"))\n\t\t\tmode_flags |= MPOL_F_STATIC_NODES;\n\t\telse if (!strcmp(flags, \"relative\"))\n\t\t\tmode_flags |= MPOL_F_RELATIVE_NODES;\n\t\telse\n\t\t\tgoto out;\n\t}\n\n\tnew = mpol_new(mode, mode_flags, &nodes);\n\tif (IS_ERR(new))\n\t\tgoto out;\n\n\t/*\n\t * Save nodes for mpol_to_str() to show the tmpfs mount options\n\t * for /proc/mounts, /proc/pid/mounts and /proc/pid/mountinfo.\n\t */\n\tif (mode != MPOL_PREFERRED)\n\t\tnew->v.nodes = nodes;\n\telse if (nodelist)\n\t\tnew->v.preferred_node = first_node(nodes);\n\telse\n\t\tnew->flags |= MPOL_F_LOCAL;\n\n\t/*\n\t * Save nodes for contextualization: this will be used to \"clone\"\n\t * the mempolicy in a specific context [cpuset] at a later time.\n\t */\n\tnew->w.user_nodemask = nodes;\n\n\terr = 0;\n\nout:\n\t/* Restore string for error message */\n\tif (nodelist)\n\t\t*--nodelist = ':';\n\tif (flags)\n\t\t*--flags = '=';\n\tif (!err)\n\t\t*mpol = new;\n\treturn err;\n}", "func_src_after": "int mpol_parse_str(char *str, struct mempolicy **mpol)\n{\n\tstruct mempolicy *new = NULL;\n\tunsigned short mode_flags;\n\tnodemask_t nodes;\n\tchar *nodelist = strchr(str, ':');\n\tchar *flags = strchr(str, '=');\n\tint err = 1, mode;\n\n\tif (flags)\n\t\t*flags++ = '\\0';\t/* terminate mode string */\n\n\tif (nodelist) {\n\t\t/* NUL-terminate mode or flags string */\n\t\t*nodelist++ = '\\0';\n\t\tif (nodelist_parse(nodelist, nodes))\n\t\t\tgoto out;\n\t\tif (!nodes_subset(nodes, node_states[N_MEMORY]))\n\t\t\tgoto out;\n\t} else\n\t\tnodes_clear(nodes);\n\n\tmode = match_string(policy_modes, MPOL_MAX, str);\n\tif (mode < 0)\n\t\tgoto out;\n\n\tswitch (mode) {\n\tcase MPOL_PREFERRED:\n\t\t/*\n\t\t * Insist on a nodelist of one node only, although later\n\t\t * we use first_node(nodes) to grab a single node, so here\n\t\t * nodelist (or nodes) cannot be empty.\n\t\t */\n\t\tif (nodelist) {\n\t\t\tchar *rest = nodelist;\n\t\t\twhile (isdigit(*rest))\n\t\t\t\trest++;\n\t\t\tif (*rest)\n\t\t\t\tgoto out;\n\t\t\tif (nodes_empty(nodes))\n\t\t\t\tgoto out;\n\t\t}\n\t\tbreak;\n\tcase MPOL_INTERLEAVE:\n\t\t/*\n\t\t * Default to online nodes with memory if no nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tnodes = node_states[N_MEMORY];\n\t\tbreak;\n\tcase MPOL_LOCAL:\n\t\t/*\n\t\t * Don't allow a nodelist;  mpol_new() checks flags\n\t\t */\n\t\tif (nodelist)\n\t\t\tgoto out;\n\t\tmode = MPOL_PREFERRED;\n\t\tbreak;\n\tcase MPOL_DEFAULT:\n\t\t/*\n\t\t * Insist on a empty nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\terr = 0;\n\t\tgoto out;\n\tcase MPOL_BIND:\n\t\t/*\n\t\t * Insist on a nodelist\n\t\t */\n\t\tif (!nodelist)\n\t\t\tgoto out;\n\t}\n\n\tmode_flags = 0;\n\tif (flags) {\n\t\t/*\n\t\t * Currently, we only support two mutually exclusive\n\t\t * mode flags.\n\t\t */\n\t\tif (!strcmp(flags, \"static\"))\n\t\t\tmode_flags |= MPOL_F_STATIC_NODES;\n\t\telse if (!strcmp(flags, \"relative\"))\n\t\t\tmode_flags |= MPOL_F_RELATIVE_NODES;\n\t\telse\n\t\t\tgoto out;\n\t}\n\n\tnew = mpol_new(mode, mode_flags, &nodes);\n\tif (IS_ERR(new))\n\t\tgoto out;\n\n\t/*\n\t * Save nodes for mpol_to_str() to show the tmpfs mount options\n\t * for /proc/mounts, /proc/pid/mounts and /proc/pid/mountinfo.\n\t */\n\tif (mode != MPOL_PREFERRED)\n\t\tnew->v.nodes = nodes;\n\telse if (nodelist)\n\t\tnew->v.preferred_node = first_node(nodes);\n\telse\n\t\tnew->flags |= MPOL_F_LOCAL;\n\n\t/*\n\t * Save nodes for contextualization: this will be used to \"clone\"\n\t * the mempolicy in a specific context [cpuset] at a later time.\n\t */\n\tnew->w.user_nodemask = nodes;\n\n\terr = 0;\n\nout:\n\t/* Restore string for error message */\n\tif (nodelist)\n\t\t*--nodelist = ':';\n\tif (flags)\n\t\t*--flags = '=';\n\tif (!err)\n\t\t*mpol = new;\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/aa9f7d5172fac9bf1f09e678c35e287a40a7b7dd", "file_name": "mm/mempolicy.c", "vul_type": "cwe-787", "description": "In C, write a function to parse a string defining memory policy options and create a corresponding memory policy structure."}
{"func_name": "get_uncompressed_data", "func_src_before": "get_uncompressed_data(struct archive_read *a, const void **buff, size_t size,\n    size_t minimum)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tssize_t bytes_avail;\n\n\tif (zip->codec == _7Z_COPY && zip->codec2 == (unsigned long)-1) {\n\t\t/* Copy mode. */\n\n\t\t*buff = __archive_read_ahead(a, minimum, &bytes_avail);\n\t\tif (bytes_avail <= 0) {\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Truncated 7-Zip file data\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif ((size_t)bytes_avail >\n\t\t    zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\tif ((size_t)bytes_avail > size)\n\t\t\tbytes_avail = (ssize_t)size;\n\n\t\tzip->pack_stream_bytes_unconsumed = bytes_avail;\n\t} else if (zip->uncompressed_buffer_pointer == NULL) {\n\t\t/* Decompression has failed. */\n\t\tarchive_set_error(&(a->archive),\n\t\t    ARCHIVE_ERRNO_MISC, \"Damaged 7-Zip archive\");\n\t\treturn (ARCHIVE_FATAL);\n\t} else {\n\t\t/* Packed mode. */\n\t\tif (minimum > zip->uncompressed_buffer_bytes_remaining) {\n\t\t\t/*\n\t\t\t * If remaining uncompressed data size is less than\n\t\t\t * the minimum size, fill the buffer up to the\n\t\t\t * minimum size.\n\t\t\t */\n\t\t\tif (extract_pack_stream(a, minimum) < 0)\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif (size > zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\telse\n\t\t\tbytes_avail = (ssize_t)size;\n\t\t*buff = zip->uncompressed_buffer_pointer;\n\t\tzip->uncompressed_buffer_pointer += bytes_avail;\n\t}\n\tzip->uncompressed_buffer_bytes_remaining -= bytes_avail;\n\treturn (bytes_avail);\n}", "func_src_after": "get_uncompressed_data(struct archive_read *a, const void **buff, size_t size,\n    size_t minimum)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tssize_t bytes_avail;\n\n\tif (zip->codec == _7Z_COPY && zip->codec2 == (unsigned long)-1) {\n\t\t/* Copy mode. */\n\n\t\t/*\n\t\t * Note: '1' here is a performance optimization.\n\t\t * Recall that the decompression layer returns a count of\n\t\t * available bytes; asking for more than that forces the\n\t\t * decompressor to combine reads by copying data.\n\t\t */\n\t\t*buff = __archive_read_ahead(a, 1, &bytes_avail);\n\t\tif (bytes_avail <= 0) {\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Truncated 7-Zip file data\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif ((size_t)bytes_avail >\n\t\t    zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\tif ((size_t)bytes_avail > size)\n\t\t\tbytes_avail = (ssize_t)size;\n\n\t\tzip->pack_stream_bytes_unconsumed = bytes_avail;\n\t} else if (zip->uncompressed_buffer_pointer == NULL) {\n\t\t/* Decompression has failed. */\n\t\tarchive_set_error(&(a->archive),\n\t\t    ARCHIVE_ERRNO_MISC, \"Damaged 7-Zip archive\");\n\t\treturn (ARCHIVE_FATAL);\n\t} else {\n\t\t/* Packed mode. */\n\t\tif (minimum > zip->uncompressed_buffer_bytes_remaining) {\n\t\t\t/*\n\t\t\t * If remaining uncompressed data size is less than\n\t\t\t * the minimum size, fill the buffer up to the\n\t\t\t * minimum size.\n\t\t\t */\n\t\t\tif (extract_pack_stream(a, minimum) < 0)\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tif (size > zip->uncompressed_buffer_bytes_remaining)\n\t\t\tbytes_avail = (ssize_t)\n\t\t\t    zip->uncompressed_buffer_bytes_remaining;\n\t\telse\n\t\t\tbytes_avail = (ssize_t)size;\n\t\t*buff = zip->uncompressed_buffer_pointer;\n\t\tzip->uncompressed_buffer_pointer += bytes_avail;\n\t}\n\tzip->uncompressed_buffer_bytes_remaining -= bytes_avail;\n\treturn (bytes_avail);\n}", "commit_link": "github.com/libarchive/libarchive/commit/65a23f5dbee4497064e9bb467f81138a62b0dae1", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-125", "description": "In C, write a function to retrieve uncompressed data from a 7-Zip archive, handling both copy and packed modes."}
{"func_name": "voutf", "func_src_before": "static void voutf(struct GlobalConfig *config,\n                  const char *prefix,\n                  const char *fmt,\n                  va_list ap)\n{\n  size_t width = (79 - strlen(prefix));\n  if(!config->mute) {\n    size_t len;\n    char *ptr;\n    char *print_buffer;\n\n    print_buffer = curlx_mvaprintf(fmt, ap);\n    if(!print_buffer)\n      return;\n    len = strlen(print_buffer);\n\n    ptr = print_buffer;\n    while(len > 0) {\n      fputs(prefix, config->errors);\n\n      if(len > width) {\n        size_t cut = width-1;\n\n        while(!ISSPACE(ptr[cut]) && cut) {\n          cut--;\n        }\n        if(0 == cut)\n          /* not a single cutting position was found, just cut it at the\n             max text width then! */\n          cut = width-1;\n\n        (void)fwrite(ptr, cut + 1, 1, config->errors);\n        fputs(\"\\n\", config->errors);\n        ptr += cut + 1; /* skip the space too */\n        len -= cut;\n      }\n      else {\n        fputs(ptr, config->errors);\n        len = 0;\n      }\n    }\n    curl_free(print_buffer);\n  }\n}", "func_src_after": "static void voutf(struct GlobalConfig *config,\n                  const char *prefix,\n                  const char *fmt,\n                  va_list ap)\n{\n  size_t width = (79 - strlen(prefix));\n  if(!config->mute) {\n    size_t len;\n    char *ptr;\n    char *print_buffer;\n\n    print_buffer = curlx_mvaprintf(fmt, ap);\n    if(!print_buffer)\n      return;\n    len = strlen(print_buffer);\n\n    ptr = print_buffer;\n    while(len > 0) {\n      fputs(prefix, config->errors);\n\n      if(len > width) {\n        size_t cut = width-1;\n\n        while(!ISSPACE(ptr[cut]) && cut) {\n          cut--;\n        }\n        if(0 == cut)\n          /* not a single cutting position was found, just cut it at the\n             max text width then! */\n          cut = width-1;\n\n        (void)fwrite(ptr, cut + 1, 1, config->errors);\n        fputs(\"\\n\", config->errors);\n        ptr += cut + 1; /* skip the space too */\n        len -= cut + 1;\n      }\n      else {\n        fputs(ptr, config->errors);\n        len = 0;\n      }\n    }\n    curl_free(print_buffer);\n  }\n}", "commit_link": "github.com/curl/curl/commit/d530e92f59ae9bb2d47066c3c460b25d2ffeb211", "file_name": "src/tool_msgs.c", "vul_type": "cwe-125", "description": "Write a C function named `voutf` that formats and outputs a string with a prefix to an error stream, wrapping lines to a maximum width."}
{"func_name": "build_board", "func_src_before": "def build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\" % game)\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)", "func_src_after": "def build_board(conn, game,size):\n    # we'll build the empty board, and then fill in with the move list that\n    # we get from the DB.\n    board = []\n    for i in range(size):\n        board.append([\"\"]*size)\n\n\n    # search for all moves that have happenend during this game.\n    cursor = conn.cursor()\n    cursor.execute(\"SELECT x,y,letter FROM moves WHERE gameID = %d;\", (game,))\n\n    counts = {\"X\":0, \"O\":0}\n    for move in cursor.fetchall():\n        (x,y,letter) = move\n\n        x = int(x)\n        y = int(y)\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert letter in \"XO\"\n\n        assert board[x][y] == \"\"\n        board[x][y] = letter\n\n        counts[letter] += 1\n\n    cursor.close()\n\n    assert counts[\"X\"] >= counts[\"O\"]\n    assert counts[\"X\"] <= counts[\"O\"]+1\n\n    if counts[\"X\"] == counts[\"O\"]:\n        nextPlayer = 0\n    else:\n        nextPlayer = 1\n    letter = \"XO\"[nextPlayer]\n\n    return (board,nextPlayer,letter)", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/common.py", "vul_type": "cwe-089", "description": "In Python, write a function to construct a tic-tac-toe board from a database, tracking the next player's turn based on move history."}
{"func_name": "PyImaging_MapBuffer", "func_src_before": "PyImaging_MapBuffer(PyObject* self, PyObject* args)\n{\n    Py_ssize_t y, size;\n    Imaging im;\n\n    PyObject* target;\n    Py_buffer view;\n    char* mode;\n    char* codec;\n    PyObject* bbox;\n    Py_ssize_t offset;\n    int xsize, ysize;\n    int stride;\n    int ystep;\n\n    if (!PyArg_ParseTuple(args, \"O(ii)sOn(sii)\", &target, &xsize, &ysize,\n                          &codec, &bbox, &offset, &mode, &stride, &ystep))\n        return NULL;\n\n    if (!PyImaging_CheckBuffer(target)) {\n        PyErr_SetString(PyExc_TypeError, \"expected string or buffer\");\n        return NULL;\n    }\n\n    if (stride <= 0) {\n        if (!strcmp(mode, \"L\") || !strcmp(mode, \"P\"))\n            stride = xsize;\n        else if (!strncmp(mode, \"I;16\", 4))\n            stride = xsize * 2;\n        else\n            stride = xsize * 4;\n    }\n\n    size = (Py_ssize_t) ysize * stride;\n\n    /* check buffer size */\n    if (PyImaging_GetBuffer(target, &view) < 0)\n        return NULL;\n\n    if (view.len < 0) {\n        PyErr_SetString(PyExc_ValueError, \"buffer has negative size\");\n        return NULL;\n    }\n    if (offset + size > view.len) {\n        PyErr_SetString(PyExc_ValueError, \"buffer is not large enough\");\n        return NULL;\n    }\n\n    im = ImagingNewPrologueSubtype(\n        mode, xsize, ysize, sizeof(ImagingBufferInstance)\n        );\n    if (!im)\n        return NULL;\n\n    /* setup file pointers */\n    if (ystep > 0)\n        for (y = 0; y < ysize; y++)\n            im->image[y] = (char*)view.buf + offset + y * stride;\n    else\n        for (y = 0; y < ysize; y++)\n            im->image[ysize-y-1] = (char*)view.buf + offset + y * stride;\n\n    im->destroy = mapping_destroy_buffer;\n\n    Py_INCREF(target);\n    ((ImagingBufferInstance*) im)->target = target;\n    ((ImagingBufferInstance*) im)->view = view;\n\n    if (!ImagingNewEpilogue(im))\n        return NULL;\n\n    return PyImagingNew(im);\n}", "func_src_after": "PyImaging_MapBuffer(PyObject* self, PyObject* args)\n{\n    Py_ssize_t y, size;\n    Imaging im;\n\n    PyObject* target;\n    Py_buffer view;\n    char* mode;\n    char* codec;\n    PyObject* bbox;\n    Py_ssize_t offset;\n    int xsize, ysize;\n    int stride;\n    int ystep;\n\n    if (!PyArg_ParseTuple(args, \"O(ii)sOn(sii)\", &target, &xsize, &ysize,\n                          &codec, &bbox, &offset, &mode, &stride, &ystep))\n        return NULL;\n\n    if (!PyImaging_CheckBuffer(target)) {\n        PyErr_SetString(PyExc_TypeError, \"expected string or buffer\");\n        return NULL;\n    }\n\n    if (stride <= 0) {\n        if (!strcmp(mode, \"L\") || !strcmp(mode, \"P\"))\n            stride = xsize;\n        else if (!strncmp(mode, \"I;16\", 4))\n            stride = xsize * 2;\n        else\n            stride = xsize * 4;\n    }\n\n    if (ysize > INT_MAX / stride) {\n        PyErr_SetString(PyExc_MemoryError, \"Integer overflow in ysize\");\n        return NULL;\n    }\n\n    size = (Py_ssize_t) ysize * stride;\n\n    if (offset > SIZE_MAX - size) {\n        PyErr_SetString(PyExc_MemoryError, \"Integer overflow in offset\");\n        return NULL;\n    }        \n\n    /* check buffer size */\n    if (PyImaging_GetBuffer(target, &view) < 0)\n        return NULL;\n\n    if (view.len < 0) {\n        PyErr_SetString(PyExc_ValueError, \"buffer has negative size\");\n        return NULL;\n    }\n    if (offset + size > view.len) {\n        PyErr_SetString(PyExc_ValueError, \"buffer is not large enough\");\n        return NULL;\n    }\n\n    im = ImagingNewPrologueSubtype(\n        mode, xsize, ysize, sizeof(ImagingBufferInstance)\n        );\n    if (!im)\n        return NULL;\n\n    /* setup file pointers */\n    if (ystep > 0)\n        for (y = 0; y < ysize; y++)\n            im->image[y] = (char*)view.buf + offset + y * stride;\n    else\n        for (y = 0; y < ysize; y++)\n            im->image[ysize-y-1] = (char*)view.buf + offset + y * stride;\n\n    im->destroy = mapping_destroy_buffer;\n\n    Py_INCREF(target);\n    ((ImagingBufferInstance*) im)->target = target;\n    ((ImagingBufferInstance*) im)->view = view;\n\n    if (!ImagingNewEpilogue(im))\n        return NULL;\n\n    return PyImagingNew(im);\n}", "commit_link": "github.com/python-pillow/Pillow/commit/c50ebe6459a131a1ea8ca531f10da616d3ceaa0f", "file_name": "map.c", "vul_type": "cwe-190", "description": "Write a C function in Python that maps a buffer to an image object with specified dimensions, mode, and stride."}
{"func_name": "main", "func_src_before": "def main():\n    global word\n    print(\"Starting script... press 'ctrl+c' in terminal to turn off\")\n    while True:\n        if pyperclip.paste() != word and len(pyperclip.paste().split())<5:\n            word = pyperclip.paste()\n            wordChc=False\n            req = requests.get(\"https://api-portal.dictionary.com/dcom/pageData/%s\" % word)\n            wordChcURB = False\n            reqURB=requests.get('https://api.urbandictionary.com/v0/define?term=%s' % word)\n            try:    \n                data = json.loads(req.text)['data']['content'][0]['entries'][0]['posBlocks'][0]['definitions']\n            except TypeError:\n                os.system('notify-send \"Cant find that word on dictionary.com!\"')\n                wordChc = True\n            except KeyError:\n                os.system('notify-send \"Cant find that word on dictionary.com!\"')\n                wordChc = True\n\n            if not wordChc:\n                definitions = []\n                try:\n                    for definition in data[:3]:\n                        definitions.append(cleanhtml(definition['definition']))\n                        definitions.append(\"------------\")\n                    os.system('notify-send \"definitions from dictionary.com:\\n{}\"'.format('\\n'.join(definitions)))\n                except KeyError:\n                    os.system('notify-send \"no results in dictionary.com\"')\n            try:    \n                dataURB = json.loads(reqURB.text)['list']\n            except TypeError:\n                os.system('notify-send \"Cant find that word on urbandictionary.com!\"' % word)\n                wordChcURB = True\n            except KeyError:\n                os.system('notify-send \"Cant find that word on urbandictionary.com!\"' % word)\n                wordChcURB = True\n\n            if not wordChcURB:    \n                definitionsURB = []\n                for definition in dataURB[:3]:\n                    definitionsURB.append(definition['definition'])\n                    definitionsURB.append(\"------------\")\n                os.system('notify-send \"definitions from urbandictionary.com:\\n{}\"'.format('\\n'.join(definitionsURB)))\n    os.system('notify-send \"Thank you for using define.py made by kelj0\"')", "func_src_after": "def main():\n    global word\n    print(\"Starting script... press 'ctrl+c' in terminal to turn off\")\n    while True:\n        if pyperclip.paste() != word and len(pyperclip.paste().split())<5:\n            word = pyperclip.paste()\n            wordChc=False\n            req = requests.get(\"https://api-portal.dictionary.com/dcom/pageData/%s\" % word)\n            wordChcURB = False\n            reqURB=requests.get('https://api.urbandictionary.com/v0/define?term=%s' % word)\n            try:    \n                data = json.loads(req.text)['data']['content'][0]['entries'][0]['posBlocks'][0]['definitions']\n            except TypeError:\n                os.system('notify-send \"Cant find |%s| on dictionary.com!\"' % word)\n                wordChc = True\n            except KeyError:\n                os.system('notify-send \"Cant find |%s| on dictionary.com!\"' % word)\n                wordChc = True\n\n            if not wordChc:\n                definitions = []\n                try:\n                    for definition in data[:3]:\n                        definitions.append(cleanhtml(definition['definition']))\n                        definitions.append(\"------------\")\n                    os.system('notify-send \"definitions from dictionary.com:[{}\\n{}\"'\\\n                    .format(word+\"]\\n------------\",'\\n'.join(definitions)))\n                except KeyError:\n                    os.system('notify-send \"no results in dictionary.com\"')\n            try:    \n                dataURB = json.loads(reqURB.text)['list']\n            except TypeError:\n                os.system('notify-send \"Cant find |%s| on urbandictionary.com!\"' % word)\n                wordChcURB = True\n            except KeyError:\n                os.system('notify-send \"Cant find |%s| on urbandictionary.com!\"' % word)\n                wordChcURB = True\n\n            if not wordChcURB:    \n                definitionsURB = []\n                for definition in dataURB[:3]:\n                    definitionsURB.append(definition['definition'])\n                    definitionsURB.append(\"------------\")\n                os.system('notify-send \"definitions from urbandictionary.com:[{}\\n{}\"'\\\n                .format(word+\"]\\n------------\",'\\n'.join(definitionsURB)))\n    os.system('notify-send \"Thank you for using define.py made by kelj0\"')", "commit_link": "github.com/kelj0/LearningPython/commit/2563088bf44f4d5e7f7d65f3c41f12fdaef4a1e4", "file_name": "SmallProjects/Define/define.py", "vul_type": "cwe-078", "description": "Write a Python script that continuously monitors the clipboard for new text and fetches definitions from Dictionary.com and UrbanDictionary.com if the text is a single word or a phrase with less than five words."}
{"func_name": "PlayerGeneric::~PlayerGeneric", "func_src_before": "PlayerGeneric::~PlayerGeneric()\n{\n\n\tif (player)\n\t{\n\t\tif (mixer && mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\t\n\tif (mixer)\n\t\tdelete mixer;\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "func_src_after": "PlayerGeneric::~PlayerGeneric()\n{\n\tif (mixer)\n\t\tdelete mixer;\n\n\tif (player)\n\t{\n\t\tif (mixer->isActive() && !mixer->isDeviceRemoved(player))\n\t\t\tmixer->removeDevice(player);\n\t\tdelete player;\n\t}\n\n\tdelete[] audioDriverName;\n\t\n\tdelete listener;\n}", "commit_link": "github.com/milkytracker/MilkyTracker/commit/7afd55c42ad80d01a339197a2d8b5461d214edaf", "file_name": "src/milkyplay/PlayerGeneric.cpp", "vul_type": "cwe-416", "description": "Write a C++ destructor for a class named `PlayerGeneric` that cleans up memory by deleting member pointers, ensuring that a `mixer` object is properly deactivated and devices are removed before deletion."}
{"func_name": "write_section", "func_src_before": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = section_data[key]\n            self.icinga_lines.append((\"%s%-45s%s\" % (self.indent, key, self.value_to_icinga(value))))\n        self.write_line(\"}\")", "func_src_after": "    def write_section(self, section_name, section_data):\n        self.write_line(\"\")\n        self.write_line(\"define %s {\" % section_name)\n        sorted_keys = section_data.keys()\n        sorted_keys.sort()\n        for key in sorted_keys:\n            value = self.value_to_icinga(section_data[key])\n            icinga_line = \"%s%-45s%s\" % (self.indent, key, value)\n\n            if \"\\n\" in icinga_line or \"}\" in icinga_line:\n                msg = \"Found forbidden newline or '}' character in section %r.\"\n                raise Exception(msg % section_name)\n\n            self.icinga_lines.append(icinga_line)\n        self.write_line(\"}\")", "commit_link": "github.com/Scout24/monitoring-config-generator/commit/a4b01b72d2e3d6ec2600c384a77f675fa9bbf6b7", "file_name": "src/main/python/monitoring_config_generator/MonitoringConfigGenerator.py", "vul_type": "cwe-078", "description": "In Python, write a function to format and append a configuration section with sorted keys to a list, ensuring no newlines or closing braces are present in the values."}
{"func_name": "parallel_process_irp_create", "func_src_before": "static UINT parallel_process_irp_create(PARALLEL_DEVICE* parallel, IRP* irp)\n{\n\tchar* path = NULL;\n\tint status;\n\tUINT32 PathLength;\n\tStream_Seek(irp->input, 28);\n\t/* DesiredAccess(4) AllocationSize(8), FileAttributes(4) */\n\t/* SharedAccess(4) CreateDisposition(4), CreateOptions(4) */\n\tStream_Read_UINT32(irp->input, PathLength);\n\tstatus = ConvertFromUnicode(CP_UTF8, 0, (WCHAR*)Stream_Pointer(irp->input), PathLength / 2,\n\t                            &path, 0, NULL, NULL);\n\n\tif (status < 1)\n\t\tif (!(path = (char*)calloc(1, 1)))\n\t\t{\n\t\t\tWLog_ERR(TAG, \"calloc failed!\");\n\t\t\treturn CHANNEL_RC_NO_MEMORY;\n\t\t}\n\n\tparallel->id = irp->devman->id_sequence++;\n\tparallel->file = open(parallel->path, O_RDWR);\n\n\tif (parallel->file < 0)\n\t{\n\t\tirp->IoStatus = STATUS_ACCESS_DENIED;\n\t\tparallel->id = 0;\n\t}\n\telse\n\t{\n\t\t/* all read and write operations should be non-blocking */\n\t\tif (fcntl(parallel->file, F_SETFL, O_NONBLOCK) == -1)\n\t\t{\n\t\t}\n\t}\n\n\tStream_Write_UINT32(irp->output, parallel->id);\n\tStream_Write_UINT8(irp->output, 0);\n\tfree(path);\n\treturn irp->Complete(irp);\n}", "func_src_after": "static UINT parallel_process_irp_create(PARALLEL_DEVICE* parallel, IRP* irp)\n{\n\tchar* path = NULL;\n\tint status;\n\tWCHAR* ptr;\n\tUINT32 PathLength;\n\tif (!Stream_SafeSeek(irp->input, 28))\n\t\treturn ERROR_INVALID_DATA;\n\t/* DesiredAccess(4) AllocationSize(8), FileAttributes(4) */\n\t/* SharedAccess(4) CreateDisposition(4), CreateOptions(4) */\n\tif (Stream_GetRemainingLength(irp->input) < 4)\n\t\treturn ERROR_INVALID_DATA;\n\tStream_Read_UINT32(irp->input, PathLength);\n\tptr = (WCHAR*)Stream_Pointer(irp->input);\n\tif (!Stream_SafeSeek(irp->input, PathLength))\n\t\treturn ERROR_INVALID_DATA;\n\tstatus = ConvertFromUnicode(CP_UTF8, 0, ptr, PathLength / 2, &path, 0, NULL, NULL);\n\n\tif (status < 1)\n\t\tif (!(path = (char*)calloc(1, 1)))\n\t\t{\n\t\t\tWLog_ERR(TAG, \"calloc failed!\");\n\t\t\treturn CHANNEL_RC_NO_MEMORY;\n\t\t}\n\n\tparallel->id = irp->devman->id_sequence++;\n\tparallel->file = open(parallel->path, O_RDWR);\n\n\tif (parallel->file < 0)\n\t{\n\t\tirp->IoStatus = STATUS_ACCESS_DENIED;\n\t\tparallel->id = 0;\n\t}\n\telse\n\t{\n\t\t/* all read and write operations should be non-blocking */\n\t\tif (fcntl(parallel->file, F_SETFL, O_NONBLOCK) == -1)\n\t\t{\n\t\t}\n\t}\n\n\tStream_Write_UINT32(irp->output, parallel->id);\n\tStream_Write_UINT8(irp->output, 0);\n\tfree(path);\n\treturn irp->Complete(irp);\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/795842f4096501fcefc1a7f535ccc8132feb31d7", "file_name": "channels/parallel/client/parallel_main.c", "vul_type": "cwe-125", "description": "Write a C function for handling the creation of an IRP (I/O Request Packet) for a parallel device, including path conversion and non-blocking file operations."}
{"func_name": "store_metadata", "func_src_before": "    def store_metadata(self, session, key, mType, value):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"UPDATE %s SET %s = %r WHERE identifier = '%s';\" %\n                 (self.table, mType, value, id)\n                 )\n        try:\n            self._query(query)\n        except:\n            return None\n        return value", "func_src_after": "    def store_metadata(self, session, key, mType, value):\n        if (self.idNormalizer is not None):\n            id = self.idNormalizer.process_string(session, id)\n        elif type(id) == unicode:\n            id = id.encode('utf-8')\n        else:\n            id = str(id)\n        self._openContainer(session)\n        query = (\"UPDATE %s SET %s = $1 WHERE identifier = $2;\" %\n                 (self.table, mType)\n                 )\n        args = (value, id)\n        try:\n            self._query(query, *args)\n        except:\n            return None\n        return value", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089", "description": "Write a Python function to update a database record's metadata field identified by a key, handling string normalization and query execution."}
{"func_name": "matchCurrentInput", "func_src_before": "matchCurrentInput(\n\t\tconst InString *input, int pos, const widechar *passInstructions, int passIC) {\n\tint k;\n\tint kk = pos;\n\tfor (k = passIC + 2; k < passIC + 2 + passInstructions[passIC + 1]; k++)\n\t\tif (input->chars[kk] == ENDSEGMENT || passInstructions[k] != input->chars[kk++])\n\t\t\treturn 0;\n\treturn 1;\n}", "func_src_after": "matchCurrentInput(\n\t\tconst InString *input, int pos, const widechar *passInstructions, int passIC) {\n\tint k;\n\tint kk = pos;\n\tfor (k = passIC + 2;\n\t\t\t((k < passIC + 2 + passInstructions[passIC + 1]) && (kk < input->length));\n\t\t\tk++)\n\t\tif (input->chars[kk] == ENDSEGMENT || passInstructions[k] != input->chars[kk++])\n\t\t\treturn 0;\n\treturn 1;\n}", "commit_link": "github.com/liblouis/liblouis/commit/5e4089659bb49b3095fa541fa6387b4c40d7396e", "file_name": "liblouis/lou_translateString.c", "vul_type": "cwe-125", "description": "Write a C function named `matchCurrentInput` that checks if a segment of an input string matches a sequence of pass instructions, starting at a given position."}
{"func_name": "_get_vvset_from_3par", "func_src_before": "    def _get_vvset_from_3par(self, volume_name):\n        \"\"\"Get Virtual Volume Set from 3PAR.\n\n        The only way to do this currently is to try and delete the volume\n        to get the error message.\n\n        NOTE(walter-boring): don't call this unless you know the volume is\n        already in a vvset!\n        \"\"\"\n        cmd = ['removevv', '-f', volume_name]\n        LOG.debug(\"Issuing remove command to find vvset name %s\" % cmd)\n        out = self._cli_run(cmd)\n        vvset_name = None\n        if out and len(out) > 1:\n            if out[1].startswith(\"Attempt to delete \"):\n                words = out[1].split(\" \")\n                vvset_name = words[len(words) - 1]\n\n        return vvset_name", "func_src_after": "    def _get_vvset_from_3par(self, volume_name):\n        \"\"\"Get Virtual Volume Set from 3PAR.\n\n        The only way to do this currently is to try and delete the volume\n        to get the error message.\n\n        NOTE(walter-boring): don't call this unless you know the volume is\n        already in a vvset!\n        \"\"\"\n        cmd = \"removevv -f %s\" % volume_name\n        LOG.debug(\"Issuing remove command to find vvset name %s\" % cmd)\n        out = self._cli_run(cmd, None)\n        vvset_name = None\n        if out and len(out) > 1:\n            if out[1].startswith(\"Attempt to delete \"):\n                words = out[1].split(\" \")\n                vvset_name = words[len(words) - 1]\n\n        return vvset_name", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to extract the name of a Virtual Volume Set by simulating the deletion of a volume in 3PAR and parsing the error message."}
{"func_name": "add_extra_args", "func_src_before": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "func_src_after": "    def add_extra_args(self, args=None):\n        \"\"\"Add more args depending on how known args are set.\"\"\"\n        parsed = vars(self.parse_known_args(args, nohelp=True)[0])\n\n        # find which image mode specified if any, and add additional arguments\n        image_mode = parsed.get('image_mode', None)\n        if image_mode is not None and image_mode != 'none':\n            self.add_image_args(image_mode)\n\n        # find which task specified if any, and add its specific arguments\n        task = parsed.get('task', None)\n        if task is not None:\n            self.add_task_args(task)\n        evaltask = parsed.get('evaltask', None)\n        if evaltask is not None:\n            self.add_task_args(evaltask)\n\n        # find which model specified if any, and add its specific arguments\n        model = parsed.get('model', None)\n        if model is not None:\n            self.add_model_subargs(model)\n\n        # reset parser-level defaults over any model-level defaults\n        try:\n            self.set_defaults(**self._defaults)\n        except AttributeError:\n            raise RuntimeError('Please file an issue on github that argparse '\n                               'got an attribute error when parsing.')", "commit_link": "github.com/freedombenLiu/ParlAI/commit/601668d569e1276e0b8bf2bf8fb43e391e10d170", "file_name": "parlai/core/params.py", "vul_type": "cwe-078", "description": "Write a Python function that extends argument parsing with additional arguments based on existing parsed arguments."}
{"func_name": "gmc_mmx", "func_src_before": "static void gmc_mmx(uint8_t *dst, uint8_t *src,\n                    int stride, int h, int ox, int oy,\n                    int dxx, int dxy, int dyx, int dyy,\n                    int shift, int r, int width, int height)\n{\n    const int w    = 8;\n    const int ix   = ox  >> (16 + shift);\n    const int iy   = oy  >> (16 + shift);\n    const int oxs  = ox  >> 4;\n    const int oys  = oy  >> 4;\n    const int dxxs = dxx >> 4;\n    const int dxys = dxy >> 4;\n    const int dyxs = dyx >> 4;\n    const int dyys = dyy >> 4;\n    const uint16_t r4[4]   = { r, r, r, r };\n    const uint16_t dxy4[4] = { dxys, dxys, dxys, dxys };\n    const uint16_t dyy4[4] = { dyys, dyys, dyys, dyys };\n    const uint64_t shift2  = 2 * shift;\n#define MAX_STRIDE 4096U\n#define MAX_H 8U\n    uint8_t edge_buf[(MAX_H + 1) * MAX_STRIDE];\n    int x, y;\n\n    const int dxw = (dxx - (1 << (16 + shift))) * (w - 1);\n    const int dyh = (dyy - (1 << (16 + shift))) * (h - 1);\n    const int dxh = dxy * (h - 1);\n    const int dyw = dyx * (w - 1);\n    int need_emu  =  (unsigned) ix >= width  - w || width < w ||\n                     (unsigned) iy >= height - h || height< h\n                     ;\n\n    if ( // non-constant fullpel offset (3% of blocks)\n        ((ox ^ (ox + dxw)) | (ox ^ (ox + dxh)) | (ox ^ (ox + dxw + dxh)) |\n         (oy ^ (oy + dyw)) | (oy ^ (oy + dyh)) | (oy ^ (oy + dyw + dyh))) >> (16 + shift) ||\n        // uses more than 16 bits of subpel mv (only at huge resolution)\n        (dxx | dxy | dyx | dyy) & 15 ||\n        (need_emu && (h > MAX_H || stride > MAX_STRIDE))) {\n        // FIXME could still use mmx for some of the rows\n        ff_gmc_c(dst, src, stride, h, ox, oy, dxx, dxy, dyx, dyy,\n                 shift, r, width, height);\n        return;\n    }\n\n    src += ix + iy * stride;\n    if (need_emu) {\n        ff_emulated_edge_mc_8(edge_buf, src, stride, stride, w + 1, h + 1, ix, iy, width, height);\n        src = edge_buf;\n    }\n\n    __asm__ volatile (\n        \"movd         %0, %%mm6         \\n\\t\"\n        \"pxor      %%mm7, %%mm7         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        :: \"r\" (1 << shift));\n\n    for (x = 0; x < w; x += 4) {\n        uint16_t dx4[4] = { oxs - dxys + dxxs * (x + 0),\n                            oxs - dxys + dxxs * (x + 1),\n                            oxs - dxys + dxxs * (x + 2),\n                            oxs - dxys + dxxs * (x + 3) };\n        uint16_t dy4[4] = { oys - dyys + dyxs * (x + 0),\n                            oys - dyys + dyxs * (x + 1),\n                            oys - dyys + dyxs * (x + 2),\n                            oys - dyys + dyxs * (x + 3) };\n\n        for (y = 0; y < h; y++) {\n            __asm__ volatile (\n                \"movq      %0, %%mm4    \\n\\t\"\n                \"movq      %1, %%mm5    \\n\\t\"\n                \"paddw     %2, %%mm4    \\n\\t\"\n                \"paddw     %3, %%mm5    \\n\\t\"\n                \"movq   %%mm4, %0       \\n\\t\"\n                \"movq   %%mm5, %1       \\n\\t\"\n                \"psrlw    $12, %%mm4    \\n\\t\"\n                \"psrlw    $12, %%mm5    \\n\\t\"\n                : \"+m\" (*dx4), \"+m\" (*dy4)\n                : \"m\" (*dxy4), \"m\" (*dyy4));\n\n            __asm__ volatile (\n                \"movq      %%mm6, %%mm2 \\n\\t\"\n                \"movq      %%mm6, %%mm1 \\n\\t\"\n                \"psubw     %%mm4, %%mm2 \\n\\t\"\n                \"psubw     %%mm5, %%mm1 \\n\\t\"\n                \"movq      %%mm2, %%mm0 \\n\\t\"\n                \"movq      %%mm4, %%mm3 \\n\\t\"\n                \"pmullw    %%mm1, %%mm0 \\n\\t\" // (s - dx) * (s - dy)\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // dx * dy\n                \"pmullw    %%mm5, %%mm2 \\n\\t\" // (s - dx) * dy\n                \"pmullw    %%mm4, %%mm1 \\n\\t\" // dx * (s - dy)\n\n                \"movd         %4, %%mm5 \\n\\t\"\n                \"movd         %3, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // src[1, 1] * dx * dy\n                \"pmullw    %%mm4, %%mm2 \\n\\t\" // src[0, 1] * (s - dx) * dy\n\n                \"movd         %2, %%mm5 \\n\\t\"\n                \"movd         %1, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm1 \\n\\t\" // src[1, 0] * dx * (s - dy)\n                \"pmullw    %%mm4, %%mm0 \\n\\t\" // src[0, 0] * (s - dx) * (s - dy)\n                \"paddw        %5, %%mm1 \\n\\t\"\n                \"paddw     %%mm3, %%mm2 \\n\\t\"\n                \"paddw     %%mm1, %%mm0 \\n\\t\"\n                \"paddw     %%mm2, %%mm0 \\n\\t\"\n\n                \"psrlw        %6, %%mm0 \\n\\t\"\n                \"packuswb  %%mm0, %%mm0 \\n\\t\"\n                \"movd      %%mm0, %0    \\n\\t\"\n\n                : \"=m\" (dst[x + y * stride])\n                : \"m\" (src[0]), \"m\" (src[1]),\n                  \"m\" (src[stride]), \"m\" (src[stride + 1]),\n                  \"m\" (*r4), \"m\" (shift2));\n            src += stride;\n        }\n        src += 4 - h * stride;\n    }\n}", "func_src_after": "static void gmc_mmx(uint8_t *dst, uint8_t *src,\n                    int stride, int h, int ox, int oy,\n                    int dxx, int dxy, int dyx, int dyy,\n                    int shift, int r, int width, int height)\n{\n    const int w    = 8;\n    const int ix   = ox  >> (16 + shift);\n    const int iy   = oy  >> (16 + shift);\n    const int oxs  = ox  >> 4;\n    const int oys  = oy  >> 4;\n    const int dxxs = dxx >> 4;\n    const int dxys = dxy >> 4;\n    const int dyxs = dyx >> 4;\n    const int dyys = dyy >> 4;\n    const uint16_t r4[4]   = { r, r, r, r };\n    const uint16_t dxy4[4] = { dxys, dxys, dxys, dxys };\n    const uint16_t dyy4[4] = { dyys, dyys, dyys, dyys };\n    const uint64_t shift2  = 2 * shift;\n#define MAX_STRIDE 4096U\n#define MAX_H 8U\n    uint8_t edge_buf[(MAX_H + 1) * MAX_STRIDE];\n    int x, y;\n\n    const int dxw = (dxx - (1 << (16 + shift))) * (w - 1);\n    const int dyh = (dyy - (1 << (16 + shift))) * (h - 1);\n    const int dxh = dxy * (h - 1);\n    const int dyw = dyx * (w - 1);\n    int need_emu  =  (unsigned) ix >= width  - w ||\n                     (unsigned) iy >= height - h;\n\n    if ( // non-constant fullpel offset (3% of blocks)\n        ((ox ^ (ox + dxw)) | (ox ^ (ox + dxh)) | (ox ^ (ox + dxw + dxh)) |\n         (oy ^ (oy + dyw)) | (oy ^ (oy + dyh)) | (oy ^ (oy + dyw + dyh))) >> (16 + shift) ||\n        // uses more than 16 bits of subpel mv (only at huge resolution)\n        (dxx | dxy | dyx | dyy) & 15 ||\n        (need_emu && (h > MAX_H || stride > MAX_STRIDE))) {\n        // FIXME could still use mmx for some of the rows\n        ff_gmc_c(dst, src, stride, h, ox, oy, dxx, dxy, dyx, dyy,\n                 shift, r, width, height);\n        return;\n    }\n\n    src += ix + iy * stride;\n    if (need_emu) {\n        ff_emulated_edge_mc_8(edge_buf, src, stride, stride, w + 1, h + 1, ix, iy, width, height);\n        src = edge_buf;\n    }\n\n    __asm__ volatile (\n        \"movd         %0, %%mm6         \\n\\t\"\n        \"pxor      %%mm7, %%mm7         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        \"punpcklwd %%mm6, %%mm6         \\n\\t\"\n        :: \"r\" (1 << shift));\n\n    for (x = 0; x < w; x += 4) {\n        uint16_t dx4[4] = { oxs - dxys + dxxs * (x + 0),\n                            oxs - dxys + dxxs * (x + 1),\n                            oxs - dxys + dxxs * (x + 2),\n                            oxs - dxys + dxxs * (x + 3) };\n        uint16_t dy4[4] = { oys - dyys + dyxs * (x + 0),\n                            oys - dyys + dyxs * (x + 1),\n                            oys - dyys + dyxs * (x + 2),\n                            oys - dyys + dyxs * (x + 3) };\n\n        for (y = 0; y < h; y++) {\n            __asm__ volatile (\n                \"movq      %0, %%mm4    \\n\\t\"\n                \"movq      %1, %%mm5    \\n\\t\"\n                \"paddw     %2, %%mm4    \\n\\t\"\n                \"paddw     %3, %%mm5    \\n\\t\"\n                \"movq   %%mm4, %0       \\n\\t\"\n                \"movq   %%mm5, %1       \\n\\t\"\n                \"psrlw    $12, %%mm4    \\n\\t\"\n                \"psrlw    $12, %%mm5    \\n\\t\"\n                : \"+m\" (*dx4), \"+m\" (*dy4)\n                : \"m\" (*dxy4), \"m\" (*dyy4));\n\n            __asm__ volatile (\n                \"movq      %%mm6, %%mm2 \\n\\t\"\n                \"movq      %%mm6, %%mm1 \\n\\t\"\n                \"psubw     %%mm4, %%mm2 \\n\\t\"\n                \"psubw     %%mm5, %%mm1 \\n\\t\"\n                \"movq      %%mm2, %%mm0 \\n\\t\"\n                \"movq      %%mm4, %%mm3 \\n\\t\"\n                \"pmullw    %%mm1, %%mm0 \\n\\t\" // (s - dx) * (s - dy)\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // dx * dy\n                \"pmullw    %%mm5, %%mm2 \\n\\t\" // (s - dx) * dy\n                \"pmullw    %%mm4, %%mm1 \\n\\t\" // dx * (s - dy)\n\n                \"movd         %4, %%mm5 \\n\\t\"\n                \"movd         %3, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm3 \\n\\t\" // src[1, 1] * dx * dy\n                \"pmullw    %%mm4, %%mm2 \\n\\t\" // src[0, 1] * (s - dx) * dy\n\n                \"movd         %2, %%mm5 \\n\\t\"\n                \"movd         %1, %%mm4 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm5 \\n\\t\"\n                \"punpcklbw %%mm7, %%mm4 \\n\\t\"\n                \"pmullw    %%mm5, %%mm1 \\n\\t\" // src[1, 0] * dx * (s - dy)\n                \"pmullw    %%mm4, %%mm0 \\n\\t\" // src[0, 0] * (s - dx) * (s - dy)\n                \"paddw        %5, %%mm1 \\n\\t\"\n                \"paddw     %%mm3, %%mm2 \\n\\t\"\n                \"paddw     %%mm1, %%mm0 \\n\\t\"\n                \"paddw     %%mm2, %%mm0 \\n\\t\"\n\n                \"psrlw        %6, %%mm0 \\n\\t\"\n                \"packuswb  %%mm0, %%mm0 \\n\\t\"\n                \"movd      %%mm0, %0    \\n\\t\"\n\n                : \"=m\" (dst[x + y * stride])\n                : \"m\" (src[0]), \"m\" (src[1]),\n                  \"m\" (src[stride]), \"m\" (src[stride + 1]),\n                  \"m\" (*r4), \"m\" (shift2));\n            src += stride;\n        }\n        src += 4 - h * stride;\n    }\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/58cf31cee7a456057f337b3102a03206d833d5e8", "file_name": "libavcodec/x86/mpegvideodsp.c", "vul_type": "cwe-125", "description": "Write a C function named `gmc_mmx` that performs global motion compensation using MMX instructions."}
{"func_name": "Exiv2::WebPImage::getHeaderOffset", "func_src_before": "    long WebPImage::getHeaderOffset(byte *data, long data_size,\n                                    byte *header, long header_size) {\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "func_src_after": "    long WebPImage::getHeaderOffset(byte* data, long data_size, byte* header, long header_size)\n    {\n        if (data_size < header_size) { return -1; }\n        long pos = -1;\n        for (long i=0; i < data_size - header_size; i++) {\n            if (memcmp(header, &data[i], header_size) == 0) {\n                pos = i;\n                break;\n            }\n        }\n        return pos;\n    }", "commit_link": "github.com/Exiv2/exiv2/commit/e925bc5addd881543fa503470c8a859e112cca62", "file_name": "src/webpimage.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that finds the position of a header within a block of data and returns the index, or -1 if not found."}
{"func_name": "get", "func_src_before": "    def get(self, email):\n        \"\"\" Fetch data for admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from admins where email = '{email}'\"\"\")", "func_src_after": "    def get(self, email):\n        \"\"\" Fetch data for admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"select * from admins where email = %s\"\"\", (email, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/admins.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch an admin's data from a database using their email address."}
{"func_name": "hash_accept", "func_src_before": "static int hash_accept(struct socket *sock, struct socket *newsock, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tstruct hash_ctx *ctx = ask->private;\n\tstruct ahash_request *req = &ctx->req;\n\tchar state[crypto_ahash_statesize(crypto_ahash_reqtfm(req))];\n\tstruct sock *sk2;\n\tstruct alg_sock *ask2;\n\tstruct hash_ctx *ctx2;\n\tint err;\n\n\terr = crypto_ahash_export(req, state);\n\tif (err)\n\t\treturn err;\n\n\terr = af_alg_accept(ask->parent, newsock);\n\tif (err)\n\t\treturn err;\n\n\tsk2 = newsock->sk;\n\task2 = alg_sk(sk2);\n\tctx2 = ask2->private;\n\tctx2->more = 1;\n\n\terr = crypto_ahash_import(&ctx2->req, state);\n\tif (err) {\n\t\tsock_orphan(sk2);\n\t\tsock_put(sk2);\n\t}\n\n\treturn err;\n}", "func_src_after": "static int hash_accept(struct socket *sock, struct socket *newsock, int flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct alg_sock *ask = alg_sk(sk);\n\tstruct hash_ctx *ctx = ask->private;\n\tstruct ahash_request *req = &ctx->req;\n\tchar state[crypto_ahash_statesize(crypto_ahash_reqtfm(req))];\n\tstruct sock *sk2;\n\tstruct alg_sock *ask2;\n\tstruct hash_ctx *ctx2;\n\tbool more;\n\tint err;\n\n\tlock_sock(sk);\n\tmore = ctx->more;\n\terr = more ? crypto_ahash_export(req, state) : 0;\n\trelease_sock(sk);\n\n\tif (err)\n\t\treturn err;\n\n\terr = af_alg_accept(ask->parent, newsock);\n\tif (err)\n\t\treturn err;\n\n\tsk2 = newsock->sk;\n\task2 = alg_sk(sk2);\n\tctx2 = ask2->private;\n\tctx2->more = more;\n\n\tif (!more)\n\t\treturn err;\n\n\terr = crypto_ahash_import(&ctx2->req, state);\n\tif (err) {\n\t\tsock_orphan(sk2);\n\t\tsock_put(sk2);\n\t}\n\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/4afa5f9617927453ac04b24b584f6c718dfb4f45", "file_name": "crypto/algif_hash.c", "vul_type": "cwe-476", "description": "Write a C function named `hash_accept` that handles the acceptance of a new hash algorithm socket connection and the transfer of its state."}
{"func_name": "_formatCredentials", "func_src_before": "    def _formatCredentials(self, data, name):\n        \"\"\"\n        Credentials are of the form\n        RCLONE_CONFIG_CURRENT_TYPE=s3\n            ^          ^        ^   ^\n        [mandatory  ][name  ][key][value]\n        \"\"\"\n\n        prefix = \"RCLONE_CONFIG_{}\".format(name.upper())\n\n        credentials = {}\n        credentials['{}_TYPE'.format(prefix)] = data.type\n\n        def _addCredential(credentials, env_key, data_key):\n            value = getattr(data, data_key, None)\n            if value is not None:\n                credentials[env_key] = value\n            return credentials\n\n\n        if data.type == 's3':\n            credentials = _addCredential(credentials,\n                '{}_REGION'.format(prefix),\n                's3_region'\n            )\n            credentials = _addCredential(credentials,\n                '{}_ACCESS_KEY_ID'.format(prefix),\n                's3_access_key_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SECRET_ACCESS_KEY'.format(prefix),\n                's3_secret_access_key'\n            )\n\n            credentials = _addCredential(credentials,\n                '{}_ENDPOINT'.format(prefix),\n                's3_endpoint'\n            )\n            credentials = _addCredential(credentials,\n                '{}_V2_AUTH'.format(prefix),\n                's3_v2_auth'\n            )\n\n        elif data.type == 'azureblob':\n            credentials = _addCredential(credentials,\n                '{}_ACCOUNT'.format(prefix),\n                'azure_account'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'azure_key'\n            )\n\n        elif data.type == 'swift':\n            credentials = _addCredential(credentials,\n                '{}_USER'.format(prefix),\n                'swift_user'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'swift_key'\n            )\n            credentials = _addCredential(credentials,\n                '{}_AUTH'.format(prefix),\n                'swift_auth'\n            )\n            credentials = _addCredential(credentials,\n                '{}_TENANT'.format(prefix),\n                'swift_tenant'\n            )\n\n        elif data.type == 'google cloud storage':\n            credentials = _addCredential(credentials,\n                '{}_CLIENT_ID'.format(prefix),\n                'gcp_client_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SERVICE_ACCOUNT_CREDENTIALS'.format(prefix),\n                'gcp_service_account_credentials'\n            )\n            credentials = _addCredential(credentials,\n                '{}_PROJECT_NUMBER'.format(prefix),\n                'gcp_project_number'\n            )\n            credentials = _addCredential(credentials,\n                '{}_OBJECT_ACL'.format(prefix),\n                'gcp_object_acl'\n            )\n            credentials = _addCredential(credentials,\n                '{}_BUCKET_ACL'.format(prefix),\n                'gcp_bucket_acl'\n            )\n\n        else:\n            logging.error(\"Connection type unknown: {}\".format(data.type))\n\n        return credentials", "func_src_after": "    def _formatCredentials(self, data, name):\n        \"\"\"\n        Credentials are of the form\n        RCLONE_CONFIG_CURRENT_TYPE=s3\n            ^          ^        ^   ^\n        [mandatory  ][name  ][key][value]\n        \"\"\"\n\n        prefix = \"RCLONE_CONFIG_{}\".format(name.upper())\n\n        credentials = ''\n        credentials += \"{}_TYPE='{}' \".format(prefix, data.type)\n\n        def _addCredential(credentials, env_key, data_key):\n            value = getattr(data, data_key, None)\n            if value is not None:\n                credentials += \"{}='{}' \".format(env_key, value)\n            return credentials\n\n\n        if data.type == 's3':\n            credentials = _addCredential(credentials,\n                '{}_REGION'.format(prefix),\n                's3_region'\n            )\n            credentials = _addCredential(credentials,\n                '{}_ACCESS_KEY_ID'.format(prefix),\n                's3_access_key_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SECRET_ACCESS_KEY'.format(prefix),\n                's3_secret_access_key'\n            )\n\n            credentials = _addCredential(credentials,\n                '{}_ENDPOINT'.format(prefix),\n                's3_endpoint'\n            )\n            credentials = _addCredential(credentials,\n                '{}_V2_AUTH'.format(prefix),\n                's3_v2_auth'\n            )\n\n        elif data.type == 'azureblob':\n            credentials = _addCredential(credentials,\n                '{}_ACCOUNT'.format(prefix),\n                'azure_account'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'azure_key'\n            )\n\n        elif data.type == 'swift':\n            credentials = _addCredential(credentials,\n                '{}_USER'.format(prefix),\n                'swift_user'\n            )\n            credentials = _addCredential(credentials,\n                '{}_KEY'.format(prefix),\n                'swift_key'\n            )\n            credentials = _addCredential(credentials,\n                '{}_AUTH'.format(prefix),\n                'swift_auth'\n            )\n            credentials = _addCredential(credentials,\n                '{}_TENANT'.format(prefix),\n                'swift_tenant'\n            )\n\n        elif data.type == 'google cloud storage':\n            credentials = _addCredential(credentials,\n                '{}_CLIENT_ID'.format(prefix),\n                'gcp_client_id'\n            )\n            credentials = _addCredential(credentials,\n                '{}_SERVICE_ACCOUNT_CREDENTIALS'.format(prefix),\n                'gcp_service_account_credentials'\n            )\n            credentials = _addCredential(credentials,\n                '{}_PROJECT_NUMBER'.format(prefix),\n                'gcp_project_number'\n            )\n            credentials = _addCredential(credentials,\n                '{}_OBJECT_ACL'.format(prefix),\n                'gcp_object_acl'\n            )\n            credentials = _addCredential(credentials,\n                '{}_BUCKET_ACL'.format(prefix),\n                'gcp_bucket_acl'\n            )\n\n        else:\n            logging.error(\"Connection type unknown: {}\".format(data.type))\n\n        return credentials", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function to format cloud storage credentials into a string or dictionary based on the storage type."}
{"func_name": "edit_workflow", "func_src_before": "@check_document_access_permission()\ndef edit_workflow(request):\n  workflow_id = request.GET.get('workflow')\n  \n  if workflow_id:\n    wid = {}\n    if workflow_id.isdigit():\n      wid['id'] = workflow_id\n    else:\n      wid['uuid'] = workflow_id\n    doc = Document2.objects.get(type='oozie-workflow2', **wid)\n    workflow = Workflow(document=doc)\n  else:\n    doc = None\n    workflow = Workflow()\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n  \n  workflow_data = workflow.get_data()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  return render('editor/workflow_editor.mako', request, {\n      'layout_json': json.dumps(workflow_data['layout']),\n      'workflow_json': json.dumps(workflow_data['workflow']),\n      'credentials_json': json.dumps(credentials.credentials.keys()),\n      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'subworkflows_json': json.dumps(_get_workflows(request.user)),\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })", "func_src_after": "@check_document_access_permission()\ndef edit_workflow(request):\n  workflow_id = request.GET.get('workflow')\n  \n  if workflow_id:\n    wid = {}\n    if workflow_id.isdigit():\n      wid['id'] = workflow_id\n    else:\n      wid['uuid'] = workflow_id\n    doc = Document2.objects.get(type='oozie-workflow2', **wid)\n    workflow = Workflow(document=doc)\n  else:\n    doc = None\n    workflow = Workflow()\n    workflow.set_workspace(request.user)\n    workflow.check_workspace(request.fs, request.user)\n  \n  workflow_data = workflow.get_data()\n\n  api = get_oozie(request.user)\n  credentials = Credentials()\n  \n  try:  \n    credentials.fetch(api)\n  except Exception, e:\n    LOG.error(smart_str(e))\n\n  return render('editor/workflow_editor.mako', request, {\n      'layout_json': json.dumps(workflow_data['layout'], cls=JSONEncoderForHTML),\n      'workflow_json': json.dumps(workflow_data['workflow'], cls=JSONEncoderForHTML),\n      'credentials_json': json.dumps(credentials.credentials.keys(), cls=JSONEncoderForHTML),\n      'workflow_properties_json': json.dumps(WORKFLOW_NODE_PROPERTIES, cls=JSONEncoderForHTML),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'subworkflows_json': json.dumps(_get_workflows(request.user), cls=JSONEncoderForHTML),\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))\n  })", "commit_link": "github.com/gethue/hue/commit/6641c62beaa1468082e47d82da5ed758d11c7735", "file_name": "apps/oozie/src/oozie/views/editor2.py", "vul_type": "cwe-079", "description": "Write a Python function with a decorator to check user permissions, which retrieves and edits workflow data based on a request, handling credentials and rendering a response."}
{"func_name": "__ns_get_path", "func_src_before": "static void *__ns_get_path(struct path *path, struct ns_common *ns)\n{\n\tstruct vfsmount *mnt = nsfs_mnt;\n\tstruct qstr qname = { .name = \"\", };\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\tunsigned long d;\n\n\trcu_read_lock();\n\td = atomic_long_read(&ns->stashed);\n\tif (!d)\n\t\tgoto slow;\n\tdentry = (struct dentry *)d;\n\tif (!lockref_get_not_dead(&dentry->d_lockref))\n\t\tgoto slow;\n\trcu_read_unlock();\n\tns->ops->put(ns);\ngot_it:\n\tpath->mnt = mntget(mnt);\n\tpath->dentry = dentry;\n\treturn NULL;\nslow:\n\trcu_read_unlock();\n\tinode = new_inode_pseudo(mnt->mnt_sb);\n\tif (!inode) {\n\t\tns->ops->put(ns);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tinode->i_ino = ns->inum;\n\tinode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\n\tinode->i_flags |= S_IMMUTABLE;\n\tinode->i_mode = S_IFREG | S_IRUGO;\n\tinode->i_fop = &ns_file_operations;\n\tinode->i_private = ns;\n\n\tdentry = d_alloc_pseudo(mnt->mnt_sb, &qname);\n\tif (!dentry) {\n\t\tiput(inode);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\td_instantiate(dentry, inode);\n\tdentry->d_fsdata = (void *)ns->ops;\n\td = atomic_long_cmpxchg(&ns->stashed, 0, (unsigned long)dentry);\n\tif (d) {\n\t\td_delete(dentry);\t/* make sure ->d_prune() does nothing */\n\t\tdput(dentry);\n\t\tcpu_relax();\n\t\treturn ERR_PTR(-EAGAIN);\n\t}\n\tgoto got_it;\n}", "func_src_after": "static void *__ns_get_path(struct path *path, struct ns_common *ns)\n{\n\tstruct vfsmount *mnt = nsfs_mnt;\n\tstruct qstr qname = { .name = \"\", };\n\tstruct dentry *dentry;\n\tstruct inode *inode;\n\tunsigned long d;\n\n\trcu_read_lock();\n\td = atomic_long_read(&ns->stashed);\n\tif (!d)\n\t\tgoto slow;\n\tdentry = (struct dentry *)d;\n\tif (!lockref_get_not_dead(&dentry->d_lockref))\n\t\tgoto slow;\n\trcu_read_unlock();\n\tns->ops->put(ns);\ngot_it:\n\tpath->mnt = mntget(mnt);\n\tpath->dentry = dentry;\n\treturn NULL;\nslow:\n\trcu_read_unlock();\n\tinode = new_inode_pseudo(mnt->mnt_sb);\n\tif (!inode) {\n\t\tns->ops->put(ns);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\tinode->i_ino = ns->inum;\n\tinode->i_mtime = inode->i_atime = inode->i_ctime = current_time(inode);\n\tinode->i_flags |= S_IMMUTABLE;\n\tinode->i_mode = S_IFREG | S_IRUGO;\n\tinode->i_fop = &ns_file_operations;\n\tinode->i_private = ns;\n\n\tdentry = d_alloc_pseudo(mnt->mnt_sb, &qname);\n\tif (!dentry) {\n\t\tiput(inode);\n\t\treturn ERR_PTR(-ENOMEM);\n\t}\n\td_instantiate(dentry, inode);\n\tdentry->d_flags |= DCACHE_RCUACCESS;\n\tdentry->d_fsdata = (void *)ns->ops;\n\td = atomic_long_cmpxchg(&ns->stashed, 0, (unsigned long)dentry);\n\tif (d) {\n\t\td_delete(dentry);\t/* make sure ->d_prune() does nothing */\n\t\tdput(dentry);\n\t\tcpu_relax();\n\t\treturn ERR_PTR(-EAGAIN);\n\t}\n\tgoto got_it;\n}", "commit_link": "github.com/torvalds/linux/commit/073c516ff73557a8f7315066856c04b50383ac34", "file_name": "fs/nsfs.c", "vul_type": "cwe-416", "description": "Write a C function named `__ns_get_path` that retrieves a file path from a namespace object."}
{"func_name": "ExprAppendMultiKeysymList", "func_src_before": "ExprAppendMultiKeysymList(ExprDef *expr, ExprDef *append)\n{\n    unsigned nSyms = darray_size(expr->keysym_list.syms);\n    unsigned numEntries = darray_size(append->keysym_list.syms);\n\n    darray_append(expr->keysym_list.symsMapIndex, nSyms);\n    darray_append(expr->keysym_list.symsNumEntries, numEntries);\n    darray_concat(expr->keysym_list.syms, append->keysym_list.syms);\n\n    FreeStmt((ParseCommon *) &append);\n\n    return expr;\n}", "func_src_after": "ExprAppendMultiKeysymList(ExprDef *expr, ExprDef *append)\n{\n    unsigned nSyms = darray_size(expr->keysym_list.syms);\n    unsigned numEntries = darray_size(append->keysym_list.syms);\n\n    darray_append(expr->keysym_list.symsMapIndex, nSyms);\n    darray_append(expr->keysym_list.symsNumEntries, numEntries);\n    darray_concat(expr->keysym_list.syms, append->keysym_list.syms);\n\n    FreeStmt((ParseCommon *) append);\n\n    return expr;\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/c1e5ac16e77a21f87bdf3bc4dea61b037a17dddb", "file_name": "src/xkbcomp/ast-build.c", "vul_type": "cwe-416", "description": "Write a C function to append one keysym list to another and update indices, then free the appended structure."}
{"func_name": "ReadPSDChannelPixels", "func_src_before": "static MagickBooleanType ReadPSDChannelPixels(Image *image,\n  const size_t channels,const size_t row,const ssize_t type,\n  const unsigned char *pixels,ExceptionInfo *exception)\n{\n  Quantum\n    pixel;\n\n  register const unsigned char\n    *p;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    x;\n\n  size_t\n    packet_size;\n\n  unsigned short\n    nibble;\n\n  p=pixels;\n  q=GetAuthenticPixels(image,0,row,image->columns,1,exception);\n  if (q == (Quantum *) NULL)\n    return MagickFalse;\n  packet_size=GetPSDPacketSize(image);\n  for (x=0; x < (ssize_t) image->columns; x++)\n  {\n    if (packet_size == 1)\n      pixel=ScaleCharToQuantum(*p++);\n    else\n      {\n        p=PushShortPixel(MSBEndian,p,&nibble);\n        pixel=ScaleShortToQuantum(nibble);\n      }\n    switch (type)\n    {\n      case -1:\n      {\n        SetPixelAlpha(image,pixel,q);\n        break;\n      }\n      case -2:\n      case 0:\n      {\n        SetPixelRed(image,pixel,q);\n        if (channels == 1 || type == -2)\n          SetPixelGray(image,pixel,q);\n        if (image->storage_class == PseudoClass)\n          {\n            if (packet_size == 1)\n              SetPixelIndex(image,ScaleQuantumToChar(pixel),q);\n            else\n              SetPixelIndex(image,ScaleQuantumToShort(pixel),q);\n            SetPixelViaPixelInfo(image,image->colormap+(ssize_t)\n              ConstrainColormapIndex(image,GetPixelIndex(image,q),exception),q);\n            if (image->depth == 1)\n              {\n                ssize_t\n                  bit,\n                  number_bits;\n  \n                number_bits=image->columns-x;\n                if (number_bits > 8)\n                  number_bits=8;\n                for (bit=0; bit < number_bits; bit++)\n                {\n                  SetPixelIndex(image,(((unsigned char) pixel) &\n                    (0x01 << (7-bit))) != 0 ? 0 : 255,q);\n                  SetPixelViaPixelInfo(image,image->colormap+(ssize_t)\n                    GetPixelIndex(image,q),q);\n                  q+=GetPixelChannels(image);\n                  x++;\n                }\n                x--;\n                continue;\n              }\n          }\n        break;\n      }\n      case 1:\n      {\n        if (image->storage_class == PseudoClass)\n          SetPixelAlpha(image,pixel,q);\n        else\n          SetPixelGreen(image,pixel,q);\n        break;\n      }\n      case 2:\n      {\n        if (image->storage_class == PseudoClass)\n          SetPixelAlpha(image,pixel,q);\n        else\n          SetPixelBlue(image,pixel,q);\n        break;\n      }\n      case 3:\n      {\n        if (image->colorspace == CMYKColorspace)\n          SetPixelBlack(image,pixel,q);\n        else\n          if (image->alpha_trait != UndefinedPixelTrait)\n            SetPixelAlpha(image,pixel,q);\n        break;\n      }\n      case 4:\n      {\n        if ((IssRGBCompatibleColorspace(image->colorspace) != MagickFalse) &&\n            (channels > 3))\n          break;\n        if (image->alpha_trait != UndefinedPixelTrait)\n          SetPixelAlpha(image,pixel,q);\n        break;\n      }\n      default:\n        break;\n    }\n    q+=GetPixelChannels(image);\n  }\n  return(SyncAuthenticPixels(image,exception));\n}", "func_src_after": "static MagickBooleanType ReadPSDChannelPixels(Image *image,\n  const size_t channels,const size_t row,const ssize_t type,\n  const unsigned char *pixels,ExceptionInfo *exception)\n{\n  Quantum\n    pixel;\n\n  register const unsigned char\n    *p;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    x;\n\n  size_t\n    packet_size;\n\n  unsigned short\n    nibble;\n\n  p=pixels;\n  q=GetAuthenticPixels(image,0,row,image->columns,1,exception);\n  if (q == (Quantum *) NULL)\n    return MagickFalse;\n  packet_size=GetPSDPacketSize(image);\n  for (x=0; x < (ssize_t) image->columns; x++)\n  {\n    if (packet_size == 1)\n      pixel=ScaleCharToQuantum(*p++);\n    else\n      {\n        p=PushShortPixel(MSBEndian,p,&nibble);\n        pixel=ScaleShortToQuantum(nibble);\n      }\n    switch (type)\n    {\n      case -1:\n      {\n        SetPixelAlpha(image,pixel,q);\n        break;\n      }\n      case -2:\n      case 0:\n      {\n        SetPixelRed(image,pixel,q);\n        if (channels == 1 || type == -2)\n          SetPixelGray(image,pixel,q);\n        if (image->storage_class == PseudoClass)\n          {\n            if (packet_size == 1)\n              SetPixelIndex(image,ScaleQuantumToChar(pixel),q);\n            else\n              SetPixelIndex(image,ScaleQuantumToShort(pixel),q);\n            SetPixelViaPixelInfo(image,image->colormap+(ssize_t)\n              ConstrainColormapIndex(image,GetPixelIndex(image,q),exception),q);\n            if (image->depth == 1)\n              {\n                ssize_t\n                  bit,\n                  number_bits;\n  \n                number_bits=image->columns-x;\n                if (number_bits > 8)\n                  number_bits=8;\n                for (bit=0; bit < number_bits; bit++)\n                {\n                  SetPixelIndex(image,(((unsigned char) pixel) &\n                    (0x01 << (7-bit))) != 0 ? 0 : 255,q);\n                  SetPixelViaPixelInfo(image,image->colormap+(ssize_t)\n                    ConstrainColormapIndex(image,GetPixelIndex(image,q),\n                      exception),q);\n                  q+=GetPixelChannels(image);\n                  x++;\n                }\n                x--;\n                continue;\n              }\n          }\n        break;\n      }\n      case 1:\n      {\n        if (image->storage_class == PseudoClass)\n          SetPixelAlpha(image,pixel,q);\n        else\n          SetPixelGreen(image,pixel,q);\n        break;\n      }\n      case 2:\n      {\n        if (image->storage_class == PseudoClass)\n          SetPixelAlpha(image,pixel,q);\n        else\n          SetPixelBlue(image,pixel,q);\n        break;\n      }\n      case 3:\n      {\n        if (image->colorspace == CMYKColorspace)\n          SetPixelBlack(image,pixel,q);\n        else\n          if (image->alpha_trait != UndefinedPixelTrait)\n            SetPixelAlpha(image,pixel,q);\n        break;\n      }\n      case 4:\n      {\n        if ((IssRGBCompatibleColorspace(image->colorspace) != MagickFalse) &&\n            (channels > 3))\n          break;\n        if (image->alpha_trait != UndefinedPixelTrait)\n          SetPixelAlpha(image,pixel,q);\n        break;\n      }\n      default:\n        break;\n    }\n    q+=GetPixelChannels(image);\n  }\n  return(SyncAuthenticPixels(image,exception));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/e14fd0a2801f73bdc123baf4fbab97dec55919eb", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "In C, write a function to process and assign pixel values to an image channel based on the PSD format."}
{"func_name": "HPHP::string_rfind", "func_src_before": "int string_rfind(const char *input, int len, const char *s, int s_len,\n                 int pos, bool case_sensitive) {\n  assertx(input);\n  assertx(s);\n  if (!s_len || pos < -len || pos > len) {\n    return -1;\n  }\n  void *ptr;\n  if (case_sensitive) {\n    if (pos >= 0) {\n      ptr = bstrrstr(input + pos, len - pos, s, s_len);\n    } else {\n      ptr = bstrrstr(input, len + pos + s_len, s, s_len);\n    }\n  } else {\n    if (pos >= 0) {\n      ptr = bstrrcasestr(input + pos, len - pos, s, s_len);\n    } else {\n      ptr = bstrrcasestr(input, len + pos + s_len, s, s_len);\n    }\n  }\n  if (ptr != nullptr) {\n    return (int)((const char *)ptr - input);\n  }\n  return -1;\n}", "func_src_after": "int string_rfind(const char *input, int len, const char *s, int s_len,\n                 int pos, bool case_sensitive) {\n  assertx(input);\n  assertx(s);\n  if (!s_len || pos < -len || pos > len) {\n    return -1;\n  }\n  void *ptr;\n  if (case_sensitive) {\n    if (pos >= 0) {\n      ptr = bstrrstr(input + pos, len - pos, s, s_len);\n    } else {\n      ptr = bstrrstr(input, len + std::min(pos + s_len, 0), s, s_len);\n    }\n  } else {\n    if (pos >= 0) {\n      ptr = bstrrcasestr(input + pos, len - pos, s, s_len);\n    } else {\n      ptr = bstrrcasestr(input, len + std::min(pos + s_len, 0), s, s_len);\n    }\n  }\n  if (ptr != nullptr) {\n    return (int)((const char *)ptr - input);\n  }\n  return -1;\n}", "commit_link": "github.com/facebook/hhvm/commit/46003b4ab564b2abcd8470035fc324fe36aa8c75", "file_name": "hphp/runtime/base/zend-string.cpp", "vul_type": "cwe-125", "description": "Write a C++ function named `string_rfind` that finds the last occurrence of a substring within a string, with options for case sensitivity and starting position."}
{"func_name": "get_mod_taken_together_with", "func_src_before": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = %s AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command, (code,))\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "func_src_after": "def get_mod_taken_together_with(code):\n    '''\n        Retrieves the list of modules taken together with the specified\n        module code in the same semester.\n\n        Returns a table of lists (up to 10 top results). Each list contains\n        (specified code, module code of mod taken together, aySem, number of students)\n\n        e.g. [(CS1010, CS1231, AY 16/17 Sem 1, 5)] means there are 5 students\n        taking CS1010 and CS1231 together in AY 16/17 Sem 1.\n    '''\n    NUM_TOP_RESULTS_TO_RETURN = 10\n\n    sql_command = \"SELECT sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem, COUNT(*) \" + \\\n                \"FROM studentPlans sp1, studentPlans sp2 \" + \\\n                \"WHERE sp1.moduleCode = '\" + code + \"' AND \" + \\\n                \"sp2.moduleCode <> sp1.moduleCode AND \" + \\\n                \"sp1.studentId = sp2.studentId AND \" + \\\n                \"sp1.acadYearAndSem = sp2.acadYearAndSem \" + \\\n                \"GROUP BY sp1.moduleCode, sp2.moduleCode, sp1.acadYearAndSem \" + \\\n                \"ORDER BY COUNT(*) DESC\"\n\n    DB_CURSOR.execute(sql_command)\n\n    return DB_CURSOR.fetchmany(NUM_TOP_RESULTS_TO_RETURN)", "commit_link": "github.com/nus-mtp/cs-modify/commit/79b4b1dd7eba5445751808e4c50b49d2dd08366b", "file_name": "components/model.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the top 10 modules taken alongside a given module code from a database."}
{"func_name": "WavpackVerifySingleBlock", "func_src_before": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff) || *dp++ != ((csum >> 16) & 0xff) || *dp++ != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp++ != (csum & 0xff) || *dp++ != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "func_src_after": "int WavpackVerifySingleBlock (unsigned char *buffer, int verify_checksum)\n{\n    WavpackHeader *wphdr = (WavpackHeader *) buffer;\n    uint32_t checksum_passed = 0, bcount, meta_bc;\n    unsigned char *dp, meta_id, c1, c2;\n\n    if (strncmp (wphdr->ckID, \"wvpk\", 4) || wphdr->ckSize + 8 < sizeof (WavpackHeader))\n        return FALSE;\n\n    bcount = wphdr->ckSize - sizeof (WavpackHeader) + 8;\n    dp = (unsigned char *)(wphdr + 1);\n\n    while (bcount >= 2) {\n        meta_id = *dp++;\n        c1 = *dp++;\n\n        meta_bc = c1 << 1;\n        bcount -= 2;\n\n        if (meta_id & ID_LARGE) {\n            if (bcount < 2)\n                return FALSE;\n\n            c1 = *dp++;\n            c2 = *dp++;\n            meta_bc += ((uint32_t) c1 << 9) + ((uint32_t) c2 << 17);\n            bcount -= 2;\n        }\n\n        if (bcount < meta_bc)\n            return FALSE;\n\n        if (verify_checksum && (meta_id & ID_UNIQUE) == ID_BLOCK_CHECKSUM) {\n#ifdef BITSTREAM_SHORTS\n            uint16_t *csptr = (uint16_t*) buffer;\n#else\n            unsigned char *csptr = buffer;\n#endif\n            int wcount = (int)(dp - 2 - buffer) >> 1;\n            uint32_t csum = (uint32_t) -1;\n\n            if ((meta_id & ID_ODD_SIZE) || meta_bc < 2 || meta_bc > 4)\n                return FALSE;\n\n#ifdef BITSTREAM_SHORTS\n            while (wcount--)\n                csum = (csum * 3) + *csptr++;\n#else\n            WavpackNativeToLittleEndian ((WavpackHeader *) buffer, WavpackHeaderFormat);\n\n            while (wcount--) {\n                csum = (csum * 3) + csptr [0] + (csptr [1] << 8);\n                csptr += 2;\n            }\n\n            WavpackLittleEndianToNative ((WavpackHeader *) buffer, WavpackHeaderFormat);\n#endif\n\n            if (meta_bc == 4) {\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff) || dp[2] != ((csum >> 16) & 0xff) || dp[3] != ((csum >> 24) & 0xff))\n                    return FALSE;\n            }\n            else {\n                csum ^= csum >> 16;\n\n                if (*dp != (csum & 0xff) || dp[1] != ((csum >> 8) & 0xff))\n                    return FALSE;\n            }\n\n            checksum_passed++;\n        }\n\n        bcount -= meta_bc;\n        dp += meta_bc;\n    }\n\n    return (bcount == 0) && (!verify_checksum || !(wphdr->flags & HAS_CHECKSUM) || checksum_passed);\n}", "commit_link": "github.com/dbry/WavPack/commit/bba5389dc598a92bdf2b297c3ea34620b6679b5b", "file_name": "src/open_utils.c", "vul_type": "cwe-125", "description": "In C, write a function to verify the integrity of a single Wavpack audio block, optionally checking its checksum."}
{"func_name": "getToken", "func_src_before": "static x86newTokenType getToken(const char *str, size_t *begin, size_t *end) {\n\t// Skip whitespace\n\twhile (begin && isspace ((ut8)str[*begin])) {\n\t\t++(*begin);\n\t}\n\n\tif (!str[*begin]) {                // null byte\n\t\t*end = *begin;\n\t\treturn TT_EOF;\n\t} else if (isalpha ((ut8)str[*begin])) {   // word token\n\t\t*end = *begin;\n\t\twhile (end && isalnum ((ut8)str[*end])) {\n\t\t\t++(*end);\n\t\t}\n\t\treturn TT_WORD;\n\t} else if (isdigit ((ut8)str[*begin])) {   // number token\n\t\t*end = *begin;\n\t\twhile (end && isalnum ((ut8)str[*end])) {     // accept alphanumeric characters, because hex.\n\t\t\t++(*end);\n\t\t}\n\t\treturn TT_NUMBER;\n\t} else {                             // special character: [, ], +, *, ...\n\t\t*end = *begin + 1;\n\t\treturn TT_SPECIAL;\n\t}\n}", "func_src_after": "static x86newTokenType getToken(const char *str, size_t *begin, size_t *end) {\n\tif (*begin > strlen (str)) {\n\t\treturn TT_EOF;\n\t}\n\t// Skip whitespace\n\twhile (begin && str[*begin] && isspace ((ut8)str[*begin])) {\n\t\t++(*begin);\n\t}\n\n\tif (!str[*begin]) {                // null byte\n\t\t*end = *begin;\n\t\treturn TT_EOF;\n\t}\n\tif (isalpha ((ut8)str[*begin])) {   // word token\n\t\t*end = *begin;\n\t\twhile (end && str[*end] && isalnum ((ut8)str[*end])) {\n\t\t\t++(*end);\n\t\t}\n\t\treturn TT_WORD;\n\t}\n\tif (isdigit ((ut8)str[*begin])) {   // number token\n\t\t*end = *begin;\n\t\twhile (end && isalnum ((ut8)str[*end])) {     // accept alphanumeric characters, because hex.\n\t\t\t++(*end);\n\t\t}\n\t\treturn TT_NUMBER;\n\t} else {                             // special character: [, ], +, *, ...\n\t\t*end = *begin + 1;\n\t\treturn TT_SPECIAL;\n\t}\n}", "commit_link": "github.com/radare/radare2/commit/66191f780863ea8c66ace4040d0d04a8842e8432", "file_name": "libr/asm/p/asm_x86_nz.c", "vul_type": "cwe-125", "description": "Write a C function named `getToken` that identifies the next token in a string by skipping whitespace and classifying the token as EOF, word, number, or special character."}
{"func_name": "jpc_dec_process_siz", "func_src_before": "static int jpc_dec_process_siz(jpc_dec_t *dec, jpc_ms_t *ms)\n{\n\tjpc_siz_t *siz = &ms->parms.siz;\n\tint compno;\n\tint tileno;\n\tjpc_dec_tile_t *tile;\n\tjpc_dec_tcomp_t *tcomp;\n\tint htileno;\n\tint vtileno;\n\tjpc_dec_cmpt_t *cmpt;\n\n\tdec->xstart = siz->xoff;\n\tdec->ystart = siz->yoff;\n\tdec->xend = siz->width;\n\tdec->yend = siz->height;\n\tdec->tilewidth = siz->tilewidth;\n\tdec->tileheight = siz->tileheight;\n\tdec->tilexoff = siz->tilexoff;\n\tdec->tileyoff = siz->tileyoff;\n\tdec->numcomps = siz->numcomps;\n\tif (!(dec->cp = jpc_dec_cp_create(dec->numcomps))) {\n\t\treturn -1;\n\t}\n\n\tif (!(dec->cmpts = jas_alloc2(dec->numcomps, sizeof(jpc_dec_cmpt_t)))) {\n\t\treturn -1;\n\t}\n\n\tfor (compno = 0, cmpt = dec->cmpts; compno < dec->numcomps; ++compno,\n\t  ++cmpt) {\n\t\tcmpt->prec = siz->comps[compno].prec;\n\t\tcmpt->sgnd = siz->comps[compno].sgnd;\n\t\tcmpt->hstep = siz->comps[compno].hsamp;\n\t\tcmpt->vstep = siz->comps[compno].vsamp;\n\t\tcmpt->width = JPC_CEILDIV(dec->xend, cmpt->hstep) -\n\t\t  JPC_CEILDIV(dec->xstart, cmpt->hstep);\n\t\tcmpt->height = JPC_CEILDIV(dec->yend, cmpt->vstep) -\n\t\t  JPC_CEILDIV(dec->ystart, cmpt->vstep);\n\t\tcmpt->hsubstep = 0;\n\t\tcmpt->vsubstep = 0;\n\t}\n\n\tdec->image = 0;\n\n\tdec->numhtiles = JPC_CEILDIV(dec->xend - dec->tilexoff, dec->tilewidth);\n\tdec->numvtiles = JPC_CEILDIV(dec->yend - dec->tileyoff, dec->tileheight);\n\tdec->numtiles = dec->numhtiles * dec->numvtiles;\n\tJAS_DBGLOG(10, (\"numtiles = %d; numhtiles = %d; numvtiles = %d;\\n\",\n\t  dec->numtiles, dec->numhtiles, dec->numvtiles));\n\tif (!(dec->tiles = jas_alloc2(dec->numtiles, sizeof(jpc_dec_tile_t)))) {\n\t\treturn -1;\n\t}\n\n\tfor (tileno = 0, tile = dec->tiles; tileno < dec->numtiles; ++tileno,\n\t  ++tile) {\n\t\thtileno = tileno % dec->numhtiles;\n\t\tvtileno = tileno / dec->numhtiles;\n\t\ttile->realmode = 0;\n\t\ttile->state = JPC_TILE_INIT;\n\t\ttile->xstart = JAS_MAX(dec->tilexoff + htileno * dec->tilewidth,\n\t\t  dec->xstart);\n\t\ttile->ystart = JAS_MAX(dec->tileyoff + vtileno * dec->tileheight,\n\t\t  dec->ystart);\n\t\ttile->xend = JAS_MIN(dec->tilexoff + (htileno + 1) *\n\t\t  dec->tilewidth, dec->xend);\n\t\ttile->yend = JAS_MIN(dec->tileyoff + (vtileno + 1) *\n\t\t  dec->tileheight, dec->yend);\n\t\ttile->numparts = 0;\n\t\ttile->partno = 0;\n\t\ttile->pkthdrstream = 0;\n\t\ttile->pkthdrstreampos = 0;\n\t\ttile->pptstab = 0;\n\t\ttile->cp = 0;\n\t\ttile->pi = 0;\n\t\tif (!(tile->tcomps = jas_alloc2(dec->numcomps,\n\t\t  sizeof(jpc_dec_tcomp_t)))) {\n\t\t\treturn -1;\n\t\t}\n\t\tfor (compno = 0, cmpt = dec->cmpts, tcomp = tile->tcomps;\n\t\t  compno < dec->numcomps; ++compno, ++cmpt, ++tcomp) {\n\t\t\ttcomp->rlvls = 0;\n\t\t\ttcomp->numrlvls = 0;\n\t\t\ttcomp->data = 0;\n\t\t\ttcomp->xstart = JPC_CEILDIV(tile->xstart, cmpt->hstep);\n\t\t\ttcomp->ystart = JPC_CEILDIV(tile->ystart, cmpt->vstep);\n\t\t\ttcomp->xend = JPC_CEILDIV(tile->xend, cmpt->hstep);\n\t\t\ttcomp->yend = JPC_CEILDIV(tile->yend, cmpt->vstep);\n\t\t\ttcomp->tsfb = 0;\n\t\t}\n\t}\n\n\tdec->pkthdrstreams = 0;\n\n\t/* We should expect to encounter other main header marker segments\n\t  or an SOT marker segment next. */\n\tdec->state = JPC_MH;\n\n\treturn 0;\n}", "func_src_after": "static int jpc_dec_process_siz(jpc_dec_t *dec, jpc_ms_t *ms)\n{\n\tjpc_siz_t *siz = &ms->parms.siz;\n\tint compno;\n\tint tileno;\n\tjpc_dec_tile_t *tile;\n\tjpc_dec_tcomp_t *tcomp;\n\tint htileno;\n\tint vtileno;\n\tjpc_dec_cmpt_t *cmpt;\n\tsize_t size;\n\n\tdec->xstart = siz->xoff;\n\tdec->ystart = siz->yoff;\n\tdec->xend = siz->width;\n\tdec->yend = siz->height;\n\tdec->tilewidth = siz->tilewidth;\n\tdec->tileheight = siz->tileheight;\n\tdec->tilexoff = siz->tilexoff;\n\tdec->tileyoff = siz->tileyoff;\n\tdec->numcomps = siz->numcomps;\n\tif (!(dec->cp = jpc_dec_cp_create(dec->numcomps))) {\n\t\treturn -1;\n\t}\n\n\tif (!(dec->cmpts = jas_alloc2(dec->numcomps, sizeof(jpc_dec_cmpt_t)))) {\n\t\treturn -1;\n\t}\n\n\tfor (compno = 0, cmpt = dec->cmpts; compno < dec->numcomps; ++compno,\n\t  ++cmpt) {\n\t\tcmpt->prec = siz->comps[compno].prec;\n\t\tcmpt->sgnd = siz->comps[compno].sgnd;\n\t\tcmpt->hstep = siz->comps[compno].hsamp;\n\t\tcmpt->vstep = siz->comps[compno].vsamp;\n\t\tcmpt->width = JPC_CEILDIV(dec->xend, cmpt->hstep) -\n\t\t  JPC_CEILDIV(dec->xstart, cmpt->hstep);\n\t\tcmpt->height = JPC_CEILDIV(dec->yend, cmpt->vstep) -\n\t\t  JPC_CEILDIV(dec->ystart, cmpt->vstep);\n\t\tcmpt->hsubstep = 0;\n\t\tcmpt->vsubstep = 0;\n\t}\n\n\tdec->image = 0;\n\n\tdec->numhtiles = JPC_CEILDIV(dec->xend - dec->tilexoff, dec->tilewidth);\n\tdec->numvtiles = JPC_CEILDIV(dec->yend - dec->tileyoff, dec->tileheight);\n\tif (!jas_safe_size_mul(dec->numhtiles, dec->numvtiles, &size)) {\n\t\treturn -1;\n\t}\n\tdec->numtiles = size;\n\tJAS_DBGLOG(10, (\"numtiles = %d; numhtiles = %d; numvtiles = %d;\\n\",\n\t  dec->numtiles, dec->numhtiles, dec->numvtiles));\n\tif (!(dec->tiles = jas_alloc2(dec->numtiles, sizeof(jpc_dec_tile_t)))) {\n\t\treturn -1;\n\t}\n\n\tfor (tileno = 0, tile = dec->tiles; tileno < dec->numtiles; ++tileno,\n\t  ++tile) {\n\t\thtileno = tileno % dec->numhtiles;\n\t\tvtileno = tileno / dec->numhtiles;\n\t\ttile->realmode = 0;\n\t\ttile->state = JPC_TILE_INIT;\n\t\ttile->xstart = JAS_MAX(dec->tilexoff + htileno * dec->tilewidth,\n\t\t  dec->xstart);\n\t\ttile->ystart = JAS_MAX(dec->tileyoff + vtileno * dec->tileheight,\n\t\t  dec->ystart);\n\t\ttile->xend = JAS_MIN(dec->tilexoff + (htileno + 1) *\n\t\t  dec->tilewidth, dec->xend);\n\t\ttile->yend = JAS_MIN(dec->tileyoff + (vtileno + 1) *\n\t\t  dec->tileheight, dec->yend);\n\t\ttile->numparts = 0;\n\t\ttile->partno = 0;\n\t\ttile->pkthdrstream = 0;\n\t\ttile->pkthdrstreampos = 0;\n\t\ttile->pptstab = 0;\n\t\ttile->cp = 0;\n\t\ttile->pi = 0;\n\t\tif (!(tile->tcomps = jas_alloc2(dec->numcomps,\n\t\t  sizeof(jpc_dec_tcomp_t)))) {\n\t\t\treturn -1;\n\t\t}\n\t\tfor (compno = 0, cmpt = dec->cmpts, tcomp = tile->tcomps;\n\t\t  compno < dec->numcomps; ++compno, ++cmpt, ++tcomp) {\n\t\t\ttcomp->rlvls = 0;\n\t\t\ttcomp->numrlvls = 0;\n\t\t\ttcomp->data = 0;\n\t\t\ttcomp->xstart = JPC_CEILDIV(tile->xstart, cmpt->hstep);\n\t\t\ttcomp->ystart = JPC_CEILDIV(tile->ystart, cmpt->vstep);\n\t\t\ttcomp->xend = JPC_CEILDIV(tile->xend, cmpt->hstep);\n\t\t\ttcomp->yend = JPC_CEILDIV(tile->yend, cmpt->vstep);\n\t\t\ttcomp->tsfb = 0;\n\t\t}\n\t}\n\n\tdec->pkthdrstreams = 0;\n\n\t/* We should expect to encounter other main header marker segments\n\t  or an SOT marker segment next. */\n\tdec->state = JPC_MH;\n\n\treturn 0;\n}", "commit_link": "github.com/mdadams/jasper/commit/d91198abd00fc435a397fe6bad906a4c1748e9cf", "file_name": "src/libjasper/jpc/jpc_dec.c", "vul_type": "cwe-190", "description": "Write a C function named `jpc_dec_process_siz` that initializes decoder settings based on image size parameters."}
{"func_name": "gps_tracker", "func_src_before": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "func_src_after": "void gps_tracker( void )\n{\n\tssize_t unused;\n    int gpsd_sock;\n    char line[256], *temp;\n    struct sockaddr_in gpsd_addr;\n    int ret, is_json, pos;\n    fd_set read_fd;\n    struct timeval timeout;\n\n    /* attempt to connect to localhost, port 2947 */\n\n    pos = 0;\n    gpsd_sock = socket( AF_INET, SOCK_STREAM, 0 );\n\n    if( gpsd_sock < 0 ) {\n        return;\n    }\n\n    gpsd_addr.sin_family      = AF_INET;\n    gpsd_addr.sin_port        = htons( 2947 );\n    gpsd_addr.sin_addr.s_addr = inet_addr( \"127.0.0.1\" );\n\n    if( connect( gpsd_sock, (struct sockaddr *) &gpsd_addr,\n                 sizeof( gpsd_addr ) ) < 0 ) {\n        return;\n    }\n\n    // Check if it's GPSd < 2.92 or the new one\n    // 2.92+ immediately send stuff\n    // < 2.92 requires to send PVTAD command\n    FD_ZERO(&read_fd);\n    FD_SET(gpsd_sock, &read_fd);\n    timeout.tv_sec = 1;\n    timeout.tv_usec = 0;\n    is_json = select(gpsd_sock + 1, &read_fd, NULL, NULL, &timeout);\n    if (is_json) {\n    \t/*\n\t\t\t{\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n\t\t\t?WATCH={\"json\":true};\n\t\t\t{\"class\":\"DEVICES\",\"devices\":[]}\n    \t */\n\n\n    \t// Get the crap and ignore it: {\"class\":\"VERSION\",\"release\":\"2.95\",\"rev\":\"2010-11-16T21:12:35\",\"proto_major\":3,\"proto_minor\":3}\n    \tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n    \t\treturn;\n\n    \tis_json = (line[0] == '{');\n    \tif (is_json) {\n\t\t\t// Send ?WATCH={\"json\":true};\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tstrcpy(line, \"?WATCH={\\\"json\\\":true};\\n\");\n\t\t\tif( send( gpsd_sock, line, 22, 0 ) != 22 )\n\t\t\t\treturn;\n\n\t\t\t// Check that we have devices\n\t\t\tmemset(line, 0, sizeof(line));\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\t// Stop processing if there is no device\n\t\t\tif (strncmp(line, \"{\\\"class\\\":\\\"DEVICES\\\",\\\"devices\\\":[]}\", 32) == 0) {\n\t\t\t\tclose(gpsd_sock);\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpos = strlen(line);\n\t\t\t}\n    \t}\n    }\n\n    /* loop reading the GPS coordinates */\n\n    while( G.do_exit == 0 )\n    {\n        usleep( 500000 );\n        memset( G.gps_loc, 0, sizeof( float ) * 5 );\n\n        /* read position, speed, heading, altitude */\n        if (is_json) {\n        \t// Format definition: http://catb.org/gpsd/gpsd_json.html\n\n        \tif (pos == sizeof( line )) {\n        \t\tmemset(line, 0, sizeof(line));\n        \t\tpos = 0;\n        \t}\n\n        \t// New version, JSON\n        \tif( recv( gpsd_sock, line + pos, sizeof( line ) - pos - 1, 0 ) <= 0 )\n        \t\treturn;\n\n        \t// search for TPV class: {\"class\":\"TPV\"\n        \ttemp = strstr(line, \"{\\\"class\\\":\\\"TPV\\\"\");\n        \tif (temp == NULL) {\n        \t\tcontinue;\n        \t}\n\n        \t// Make sure the data we have is complete\n        \tif (strchr(temp, '}') == NULL) {\n        \t\t// Move the data at the beginning of the buffer;\n        \t\tpos = strlen(temp);\n        \t\tif (temp != line) {\n        \t\t\tmemmove(line, temp, pos);\n        \t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n        \t\t}\n        \t}\n\n\t\t\t// Example line: {\"class\":\"TPV\",\"tag\":\"MID2\",\"device\":\"/dev/ttyUSB0\",\"time\":1350957517.000,\"ept\":0.005,\"lat\":46.878936576,\"lon\":-115.832602964,\"alt\":1968.382,\"track\":0.0000,\"speed\":0.000,\"climb\":0.000,\"mode\":3}\n\n        \t// Latitude\n        \ttemp = strstr(temp, \"\\\"lat\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[0]);\n\n\t\t\t// Longitude\n\t\t\ttemp = strstr(temp, \"\\\"lon\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[1]);\n\n\t\t\t// Altitude\n\t\t\ttemp = strstr(temp, \"\\\"alt\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[4]);\n\n\t\t\t// Speed\n\t\t\ttemp = strstr(temp, \"\\\"speed\\\":\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = sscanf(temp + 6, \"%f\", &G.gps_loc[2]);\n\n\t\t\t// No more heading\n\n\t\t\t// Get the next TPV class\n\t\t\ttemp = strstr(temp, \"{\\\"class\\\":\\\"TPV\\\"\");\n\t\t\tif (temp == NULL) {\n\t\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\t\tpos = 0;\n\t\t\t} else {\n\t\t\t\tpos = strlen(temp);\n\t\t\t\tmemmove(line, temp, pos);\n\t\t\t\tmemset(line + pos, 0, sizeof(line) - pos);\n\t\t\t}\n\n        } else {\n        \tmemset( line, 0, sizeof( line ) );\n\n\t\t\tsnprintf( line,  sizeof( line ) - 1, \"PVTAD\\r\\n\" );\n\t\t\tif( send( gpsd_sock, line, 7, 0 ) != 7 )\n\t\t\t\treturn;\n\n\t\t\tmemset( line, 0, sizeof( line ) );\n\t\t\tif( recv( gpsd_sock, line, sizeof( line ) - 1, 0 ) <= 0 )\n\t\t\t\treturn;\n\n\t\t\tif( memcmp( line, \"GPSD,P=\", 7 ) != 0 )\n\t\t\t\tcontinue;\n\n\t\t\t/* make sure the coordinates are present */\n\n\t\t\tif( line[7] == '?' )\n\t\t\t\tcontinue;\n\n\t\t\tret = sscanf( line + 7, \"%f %f\", &G.gps_loc[0], &G.gps_loc[1] );\n\n\t\t\tif( ( temp = strstr( line, \"V=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[2] ); /* speed */\n\n\t\t\tif( ( temp = strstr( line, \"T=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[3] ); /* heading */\n\n\t\t\tif( ( temp = strstr( line, \"A=\" ) ) == NULL ) continue;\n\t\t\tret = sscanf( temp + 2, \"%f\", &G.gps_loc[4] ); /* altitude */\n        }\n\n        if (G.record_data)\n\t\t\tfputs( line, G.f_gps );\n\n\t\tG.save_gps = 1;\n\n        if (G.do_exit == 0)\n\t\t{\n\t\t\tunused = write( G.gc_pipe[1], G.gps_loc, sizeof( float ) * 5 );\n\t\t\tkill( getppid(), SIGUSR2 );\n\t\t}\n    }\n}", "commit_link": "github.com/aircrack-ng/aircrack-ng/commit/ff70494dd389ba570dbdbf36f217c28d4381c6b5/", "file_name": "src/airodump-ng.c", "vul_type": "cwe-787", "description": "Write a C function named `gps_tracker` that connects to a GPS daemon on localhost and reads GPS coordinates in a loop."}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\", (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    if \"player1\" not in form or \"player2\" not in form or \"size\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    player1 = form[\"player1\"].value\n    player2 = form[\"player2\"].value\n    for c in player1+player2:\n        if c not in \"_-\" and not c.isdigit() and not c.isalpha():\n            raise FormError(\"Invalid parameters: The player names can only contains upper and lowercase characters, digits, underscores, and hypens\")\n            return\n\n    try:\n        size = int(form[\"size\"].value)\n    except:\n        raise FormError(\"Invalid parameters: 'size' is not an integer.\")\n        return\n\n    if size < 2 or size > 9:\n        raise FormError(\"The 'size' must be in the range 2-9, inclusive.\")\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n    cursor = conn.cursor()\n\n    # insert the new row\n    cursor.execute(\"\"\"INSERT INTO games(player1,player2,size) VALUES(\"%s\",\"%s\",%d);\"\"\" % (player1,player2,size))\n\n    gameID = cursor.lastrowid\n\n\n    # MySQLdb has been building a transaction as we run.  Commit them now, and\n    # also clean up the other resources we've allocated.\n    conn.commit()\n    cursor.close()\n    conn.close()\n\n    return gameID", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/create_game.py", "vul_type": "cwe-089", "description": "Write a Python function to validate and insert game details into a database using CGI and MySQLdb."}
{"func_name": "mark_context_stack", "func_src_before": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n{\n  size_t i;\n  size_t e;\n\n  if (c->stack == NULL) return;\n  e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n    mrb_value v = c->stbase[i];\n\n    if (!mrb_immediate_p(v)) {\n      if (mrb_basic_ptr(v)->tt == MRB_TT_FREE) {\n        c->stbase[i] = mrb_nil_value();\n      }\n      else {\n        mrb_gc_mark(mrb, mrb_basic_ptr(v));\n      }\n    }\n  }\n}", "func_src_after": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n{\n  size_t i;\n  size_t e;\n  mrb_value nil;\n\n  if (c->stack == NULL) return;\n  e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n    mrb_value v = c->stbase[i];\n\n    if (!mrb_immediate_p(v)) {\n      mrb_gc_mark(mrb, mrb_basic_ptr(v));\n    }\n  }\n  e = c->stend - c->stbase;\n  nil = mrb_nil_value();\n  for (; i<e; i++) {\n    c->stbase[i] = nil;\n  }\n}", "commit_link": "github.com/mruby/mruby/commit/5c114c91d4ff31859fcd84cf8bf349b737b90d99", "file_name": "src/gc.c", "vul_type": "cwe-416", "description": "Write a function in C for the MRuby engine that marks the stack context for garbage collection."}
{"func_name": "zmi_page_request", "func_src_before": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "func_src_after": "    def zmi_page_request(self, *args, **kwargs):\r\n      request = self.REQUEST\r\n      RESPONSE = request.RESPONSE\r\n      SESSION = request.SESSION\r\n      self._zmi_page_request()\r\n      RESPONSE.setHeader('Expires',DateTime(request['ZMI_TIME']-10000).toZone('GMT+1').rfc822())\r\n      RESPONSE.setHeader('Cache-Control', 'no-cache')\r\n      RESPONSE.setHeader('Pragma', 'no-cache')\r\n      RESPONSE.setHeader('Content-Type', 'text/html;charset=%s'%request['ZMS_CHARSET'])\r\n      if not request.get( 'preview'):\r\n        request.set( 'preview','preview')\r\n      langs = self.getLanguages(request)\r\n      if request.get('lang') not in langs:\r\n        request.set('lang',langs[0])\r\n      if request.get('manage_lang') not in self.getLocale().get_manage_langs():\r\n        request.set('manage_lang',self.get_manage_lang())\r\n      if not request.get('manage_tabs_message'):\r\n        request.set( 'manage_tabs_message',self.getConfProperty('ZMS.manage_tabs_message',''))\r\n      # manage_system\r\n      if request.form.has_key('zmi-manage-system'):\r\n        request.SESSION.set('zmi-manage-system',int(request.get('zmi-manage-system')))\r\n      # avoid declarative urls\r\n      physical_path = self.getPhysicalPath()\r\n      path_to_handle = request['URL0'][len(request['BASE0']):].split('/')\r\n      path = path_to_handle[:-1]\r\n      if self.getDocumentElement().id in path and len(filter(lambda x:x.find('.')>0 or x.startswith('manage_'),path))==0:\r\n        for i in range(len(path)):\r\n          if path[:-(i+1)] != physical_path[:-(i+1)]:\r\n            path[:-(i+1)] = physical_path[:-(i+1)]\r\n        new_path = path+[path_to_handle[-1]]\r\n        if path_to_handle != new_path:\r\n          request.RESPONSE.redirect('/'.join(new_path))", "commit_link": "github.com/zms-publishing/zms4/commit/3f28620d475220dfdb06f79787158ac50727c61a", "file_name": "ZMSItem.py", "vul_type": "cwe-022", "description": "Write a Python function named `zmi_page_request` that modifies HTTP response headers, manages session variables, and redirects to a normalized URL if necessary."}
{"func_name": "_copy_volume", "func_src_before": "    def _copy_volume(self, src_name, dest_name, cpg=None, snap_cpg=None,\n                     tpvv=True):\n        # Virtual volume sets are not supported with the -online option\n        cmd = 'createvvcopy -p %s -online ' % src_name\n        if snap_cpg:\n            cmd += '-snp_cpg %s ' % snap_cpg\n        if tpvv:\n            cmd += '-tpvv '\n        if cpg:\n            cmd += cpg + ' '\n        cmd += dest_name\n        LOG.debug('Creating clone of a volume with %s' % cmd)\n        self._cli_run(cmd, None)", "func_src_after": "    def _copy_volume(self, src_name, dest_name, cpg=None, snap_cpg=None,\n                     tpvv=True):\n        # Virtual volume sets are not supported with the -online option\n        cmd = ['createvvcopy', '-p', src_name, '-online']\n        if snap_cpg:\n            cmd.extend(['-snp_cpg', snap_cpg])\n        if tpvv:\n            cmd.append('-tpvv')\n        if cpg:\n            cmd.append(cpg)\n        cmd.append(dest_name)\n        LOG.debug('Creating clone of a volume with %s' % cmd)\n        self._cli_run(cmd)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to construct a command for cloning a volume with optional parameters for CPG and snapshot CPG, and a flag for thin provisioning."}
{"func_name": "update_user", "func_src_before": "def update_user(username, chat_id, last_update):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor_settings = settings.cursor()\n    cursor_settings.execute(\"select last_problem from users where chat_id = ?\", (str(chat_id), ))\n    update_eq = cursor_settings.fetchone()\n    cursor_settings.execute(\"select * from last_update_problemset\")\n    update_base = cursor_settings.fetchone()\n    last_problem = update_base[0]\n    if update_eq[0] != update_base[0]:\n        cursor2.execute(\"SELECT * FROM problems\")\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"select * from result where problem = ? and diff = ?\", (str(x[0]), str(x[1])))\n            x2 = cursor.fetchone()\n            if x2 == None:\n                cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n            last_problem = x\n            x = cursor2.fetchone()\n        conn2.close()\n        settings.close()\n    if len(last_problem) == 2:\n        last_problem = last_problem[0] + last_problem[1]\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    v = False\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try_new = soup.find(attrs={\"class\": \"status-small\"})\n    last_try_new = str(last_try_new).split()\n    last_try_new = str(last_try_new[2]) + str(last_try_new[3])\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        j = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        last_try = soup.find_all(attrs={\"class\": \"status-small\"})\n        for link in soup.find_all('a'):\n            last_try_date = str(last_try[j]).split()\n            last_try_date = str(last_try_date[2]) + str(last_try_date[3])\n            if last_try_date == last_update:\n                v = True\n                break\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    j += 1\n                    cursor.execute(\"select * from result where problem = ? and diff = ?\", (s[3], s[4]))\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n                    if x[2] != 'OK':\n                        cursor.execute(\"update result set verdict = ? where problem = ? and diff = ?\", (s2[1], s[3], s[4]))\n        if v:\n            break\n\n    conn.commit()\n    conn.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set username = ? where chat_id = ?\", (str(username), str(chat_id)))\n    conn.execute(\"update users set last_update = ? where chat_id = ?\", (str(last_try_new), str(chat_id)))\n    conn.execute(\"update users set last_problem = ? where chat_id = ?\", (str(last_problem), str(chat_id)))\n\n    settings.commit()\n    settings.close()", "func_src_after": "def update_user(username, chat_id, last_update):\n    conn = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\users\\\\\" + username + '.db')\n    conn2 = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + '\\\\cf.db')\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    cursor = conn.cursor()\n    cursor2 = conn2.cursor()\n    cursor_settings = settings.cursor()\n    cursor_settings.execute(\"select last_problem from users where chat_id = '\" + str(chat_id) + \"'\")\n    update_eq = cursor_settings.fetchone()\n    cursor_settings.execute(\"select * from last_update_problemset\")\n    update_base = cursor_settings.fetchone()\n    last_problem = update_base[0]\n    if update_eq[0] != update_base[0]:\n        cursor2.execute(\"SELECT * FROM problems\")\n        x = cursor2.fetchone()\n        while x != None:\n            cursor.execute(\"select * from result where problem = '\" + str(x[0]) + \"' and diff = '\" + str(x[1]) + \"'\")\n            x2 = cursor.fetchone()\n            if x2 == None:\n                cursor.execute(\"insert into result values (?, ?, ? )\", (x[0], x[1], \"NULL\"))\n            last_problem = x\n            x = cursor2.fetchone()\n        conn2.close()\n        settings.close()\n    if len(last_problem) == 2:\n        last_problem = last_problem[0] + last_problem[1]\n\n    url = 'http://codeforces.com/submissions/' + username\n    r = requests.get(url)\n    max_page = 1\n    soup = BeautifulSoup(r.text, \"lxml\")\n\n    for link in soup.find_all(attrs={\"class\": \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[4]))\n\n    v = False\n    r = requests.get('http://codeforces.com/submissions/' + username + '/page/0')\n    soup = BeautifulSoup(r.text, \"lxml\")\n    last_try_new = soup.find(attrs={\"class\": \"status-small\"})\n    last_try_new = str(last_try_new).split()\n    last_try_new = str(last_try_new[2]) + str(last_try_new[3])\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/submissions/' + username + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        count = 0\n        j = 0\n        ver = soup.find_all(attrs={\"class\": \"submissionVerdictWrapper\"})\n        last_try = soup.find_all(attrs={\"class\": \"status-small\"})\n        for link in soup.find_all('a'):\n            last_try_date = str(last_try[j]).split()\n            last_try_date = str(last_try_date[2]) + str(last_try_date[3])\n            if last_try_date == last_update:\n                v = True\n                break\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5:\n                    s2 = str(ver[count]).split()\n                    s2 = s2[5].split('\\\"')\n                    count += 1\n                    j += 1\n                    cursor.execute(\"select * from result where problem = '\" + s[3] + \"'and diff = '\" + s[4] + \"'\")\n                    x = cursor.fetchone()\n                    if s2[1] == 'OK' and x != None:\n                        cursor.execute(\n                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\")\n                    if x[2] != 'OK':\n                        cursor.execute(\n                            \"update result set verdict = '\" + s2[1] + \"' where problem = '\" + s[3] + \"' and diff = '\" +\n                            s[4] + \"'\")\n        if v:\n            break\n\n    conn.commit()\n    conn.close()\n\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"update users set username = '\" + str(username) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    conn.execute(\"update users set last_update = '\" + str(last_try_new) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n    conn.execute(\"update users set last_problem = '\" + str(last_problem) + \"' where chat_id = '\" + str(chat_id) + \"'\")\n\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's problem-solving status in a database using web scraping and SQLite."}
{"func_name": "_create_3par_iscsi_host", "func_src_before": "    def _create_3par_iscsi_host(self, hostname, iscsi_iqn, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same iqn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        cmd = ['createhost', '-iscsi', '-persona', persona_id, '-domain',\n               domain, hostname, iscsi_iqn]\n        out = self.common._cli_run(cmd)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n        return hostname", "func_src_after": "    def _create_3par_iscsi_host(self, hostname, iscsi_iqn, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same iqn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        cmd = 'createhost -iscsi -persona %s -domain %s %s %s' % \\\n              (persona_id, domain, hostname, iscsi_iqn)\n        out = self.common._cli_run(cmd, None)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_iscsi.py", "vul_type": "cwe-078", "description": "Write a Python function to create an iSCSI host on a 3PAR system, handling potential conflicts with existing IQNs."}
{"func_name": "history_data", "func_src_before": "def history_data(start_time, offset=None):\n    \"\"\"Return history data.\n\n    Arguments:\n        start_time: select history starting from this timestamp.\n        offset: number of items to skip\n    \"\"\"\n    # history atimes are stored as ints, ensure start_time is not a float\n    start_time = int(start_time)\n    hist = objreg.get('web-history')\n    if offset is not None:\n        entries = hist.entries_before(start_time, limit=1000, offset=offset)\n    else:\n        # end is 24hrs earlier than start\n        end_time = start_time - 24*60*60\n        entries = hist.entries_between(end_time, start_time)\n\n    return [{\"url\": e.url, \"title\": e.title or e.url, \"time\": e.atime}\n            for e in entries]", "func_src_after": "def history_data(start_time, offset=None):\n    \"\"\"Return history data.\n\n    Arguments:\n        start_time: select history starting from this timestamp.\n        offset: number of items to skip\n    \"\"\"\n    # history atimes are stored as ints, ensure start_time is not a float\n    start_time = int(start_time)\n    hist = objreg.get('web-history')\n    if offset is not None:\n        entries = hist.entries_before(start_time, limit=1000, offset=offset)\n    else:\n        # end is 24hrs earlier than start\n        end_time = start_time - 24*60*60\n        entries = hist.entries_between(end_time, start_time)\n\n    return [{\"url\": html.escape(e.url),\n             \"title\": html.escape(e.title) or html.escape(e.url),\n             \"time\": e.atime} for e in entries]", "commit_link": "github.com/qutebrowser/qutebrowser/commit/4c9360237f186681b1e3f2a0f30c45161cf405c7", "file_name": "qutebrowser/browser/qutescheme.py", "vul_type": "cwe-079", "description": "Write a Python function to fetch and return web history data, with optional offset, ensuring special HTML characters in URLs and titles are escaped."}
{"func_name": "luaD_shrinkstack", "func_src_before": "void luaD_shrinkstack (lua_State *L) {\n  int inuse = stackinuse(L);\n  int goodsize = inuse + BASIC_STACK_SIZE;\n  if (goodsize > LUAI_MAXSTACK)\n    goodsize = LUAI_MAXSTACK;  /* respect stack limit */\n  /* if thread is currently not handling a stack overflow and its\n     good size is smaller than current size, shrink its stack */\n  if (inuse <= (LUAI_MAXSTACK - EXTRA_STACK) && goodsize < L->stacksize)\n    luaD_reallocstack(L, goodsize, 0);  /* ok if that fails */\n  else  /* don't change stack */\n    condmovestack(L,{},{});  /* (change only for debugging) */\n  luaE_shrinkCI(L);  /* shrink CI list */\n}", "func_src_after": "void luaD_shrinkstack (lua_State *L) {\n  int inuse = stackinuse(L);\n  int goodsize = inuse + (inuse / 8) + 2*EXTRA_STACK;\n  if (goodsize > LUAI_MAXSTACK)\n    goodsize = LUAI_MAXSTACK;  /* respect stack limit */\n  /* if thread is currently not handling a stack overflow and its\n     good size is smaller than current size, shrink its stack */\n  if (inuse <= (LUAI_MAXSTACK - EXTRA_STACK) &&\n      goodsize < L->stacksize)\n    luaD_reallocstack(L, goodsize, 0);  /* ok if that fails */\n  else  /* don't change stack */\n    condmovestack(L,{},{});  /* (change only for debugging) */\n  luaE_shrinkCI(L);  /* shrink CI list */\n}", "commit_link": "github.com/lua/lua/commit/6298903e35217ab69c279056f925fb72900ce0b7", "file_name": "ldo.c", "vul_type": "cwe-416", "description": "Write a C function named `luaD_shrinkstack` for Lua that adjusts the stack size based on current usage and predefined limits."}
{"func_name": "on_message", "func_src_before": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = \"notify-send \"\n            if timeout > 0:\n                cmd = cmd + \" -t %s\" % (1000 * timeout)\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd = cmd + \" \\\"%s\\\" \\\"%s\\\"\" % (title, message)\n            print(cmd)\n            os.system(cmd)\n        return", "func_src_after": "    def on_message( self, profile_id, profile_name, level, message, timeout ):\n        if 1 == level:\n            cmd = ['notify-send']\n            if timeout > 0:\n                cmd.extend(['-t', str(1000 * timeout)])\n\n            title = \"Back In Time (%s) : %s\" % (self.user, profile_name)\n            message = message.replace(\"\\n\", ' ')\n            message = message.replace(\"\\r\", '')\n\n            cmd.append(title)\n            cmd.append(message)\n            subprocess.Popen(cmd).communicate()\n        return", "commit_link": "github.com/bit-team/backintime/commit/cef81d0da93ff601252607df3db1a48f7f6f01b3", "file_name": "qt4/plugins/notifyplugin.py", "vul_type": "cwe-078", "description": "Write a Python function that displays a notification with a title and message when a certain condition is met, with an optional timeout parameter."}
{"func_name": "_add_to_db", "func_src_before": "    @staticmethod\n    def _add_to_db(user):\n        \"\"\"\n        Adds User object to the database\n        :param user: User object with info about user\n        :return: None\n        \"\"\"\n        query = (\"INSERT INTO users (chat_id, first_name, nickname, \"\n                 \"last_name, language) \"\n                 f\"VALUES ({user.chat_id}, '{user.first_name}', \"\n                 f\"'{user.nickname}', '{user.last_name}', '{user.language}')\")\n        try:\n            db.add(query)\n        except DatabaseError:\n            log.error(\"Cannot add user to the database\")\n        else:\n            log.info(f\"User {user} was successfully added to the users db\")", "func_src_after": "    @staticmethod\n    def _add_to_db(user):\n        \"\"\"\n        Adds User object to the database\n        :param user: User object with info about user\n        :return: None\n        \"\"\"\n        query = (\"INSERT INTO users (chat_id, first_name, nickname, \"\n                 \"last_name, language) \"\n                 f\"VALUES (%s, %s, %s, %s, %s)\")\n\n        parameters = (user.chat_id, user.first_name, user.nickname,\n                      user.last_name, user.language)\n\n        try:\n            db.add(query, parameters)\n        except DatabaseError:\n            log.error(\"Cannot add user to the database\")\n        else:\n            log.info(f\"User {user} was successfully added to the users db\")", "commit_link": "github.com/RandyRomero/photoGPSbot/commit/0e9f57f13e61863b3672f5730e27f149da00786a", "file_name": "photogpsbot/users.py", "vul_type": "cwe-089", "description": "Write a Python method to insert a user object into a database with error handling."}
{"func_name": "avr_op_analyze", "func_src_before": "static OPCODE_DESC* avr_op_analyze(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *buf, int len, CPU_MODEL *cpu) {\n\tOPCODE_DESC *opcode_desc;\n\tut16 ins = (buf[1] << 8) | buf[0];\n\tint fail;\n\tchar *t;\n\n\t// initialize op struct\n\tmemset (op, 0, sizeof (RAnalOp));\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->jump = UT64_MAX;\n\tr_strbuf_init (&op->esil);\n\n\t// process opcode\n\tfor (opcode_desc = opcodes; opcode_desc->handler; opcode_desc++) {\n\t\tif ((ins & opcode_desc->mask) == opcode_desc->selector) {\n\t\t\tfail = 0;\n\n\t\t\t// copy default cycles/size values\n\t\t\top->cycles = opcode_desc->cycles;\n\t\t\top->size = opcode_desc->size;\n\t\t\top->type = opcode_desc->type;\n\t\t\top->jump = UT64_MAX;\n\t\t\top->fail = UT64_MAX;\n\t\t\t// op->fail = addr + op->size;\n\t\t\top->addr = addr;\n\n\t\t\t// start void esil expression\n\t\t\tr_strbuf_setf (&op->esil, \"\");\n\n\t\t\t// handle opcode\n\t\t\topcode_desc->handler (anal, op, buf, len, &fail, cpu);\n\t\t\tif (fail) {\n\t\t\t\tgoto INVALID_OP;\n\t\t\t}\n\t\t\tif (op->cycles <= 0) {\n\t\t\t\t// eprintf (\"opcode %s @%\"PFMT64x\" returned 0 cycles.\\n\", opcode_desc->name, op->addr);\n\t\t\t\topcode_desc->cycles = 2;\n\t\t\t}\n\t\t\top->nopcode = (op->type == R_ANAL_OP_TYPE_UNK);\n\n\t\t\t// remove trailing coma (COMETE LA COMA)\n\t\t\tt = r_strbuf_get (&op->esil);\n\t\t\tif (t && strlen (t) > 1) {\n\t\t\t\tt += strlen (t) - 1;\n\t\t\t\tif (*t == ',') {\n\t\t\t\t\t*t = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn opcode_desc;\n\t\t}\n\t}\n\n\t// ignore reserved opcodes (if they have not been caught by the previous loop)\n\tif ((ins & 0xff00) == 0xff00 && (ins & 0xf) > 7) {\n\t\tgoto INVALID_OP;\n\t}\n\nINVALID_OP:\n\t// An unknown or invalid option has appeared.\n\t//  -- Throw pokeball!\n\top->family = R_ANAL_OP_FAMILY_UNKNOWN;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->addr = addr;\n\top->fail = UT64_MAX;\n\top->jump = UT64_MAX;\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->nopcode = 1;\n\top->cycles = 1;\n\top->size = 2;\n\t// launch esil trap (for communicating upper layers about this weird\n\t// and stinky situation\n\tr_strbuf_set (&op->esil, \"1,$\");\n\n\treturn NULL;\n}", "func_src_after": "static OPCODE_DESC* avr_op_analyze(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *buf, int len, CPU_MODEL *cpu) {\n\tOPCODE_DESC *opcode_desc;\n\tif (len < 2) {\n\t\treturn NULL;\n\t}\n\tut16 ins = (buf[1] << 8) | buf[0];\n\tint fail;\n\tchar *t;\n\n\t// initialize op struct\n\tmemset (op, 0, sizeof (RAnalOp));\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->jump = UT64_MAX;\n\tr_strbuf_init (&op->esil);\n\n\t// process opcode\n\tfor (opcode_desc = opcodes; opcode_desc->handler; opcode_desc++) {\n\t\tif ((ins & opcode_desc->mask) == opcode_desc->selector) {\n\t\t\tfail = 0;\n\n\t\t\t// copy default cycles/size values\n\t\t\top->cycles = opcode_desc->cycles;\n\t\t\top->size = opcode_desc->size;\n\t\t\top->type = opcode_desc->type;\n\t\t\top->jump = UT64_MAX;\n\t\t\top->fail = UT64_MAX;\n\t\t\t// op->fail = addr + op->size;\n\t\t\top->addr = addr;\n\n\t\t\t// start void esil expression\n\t\t\tr_strbuf_setf (&op->esil, \"\");\n\n\t\t\t// handle opcode\n\t\t\topcode_desc->handler (anal, op, buf, len, &fail, cpu);\n\t\t\tif (fail) {\n\t\t\t\tgoto INVALID_OP;\n\t\t\t}\n\t\t\tif (op->cycles <= 0) {\n\t\t\t\t// eprintf (\"opcode %s @%\"PFMT64x\" returned 0 cycles.\\n\", opcode_desc->name, op->addr);\n\t\t\t\topcode_desc->cycles = 2;\n\t\t\t}\n\t\t\top->nopcode = (op->type == R_ANAL_OP_TYPE_UNK);\n\n\t\t\t// remove trailing coma (COMETE LA COMA)\n\t\t\tt = r_strbuf_get (&op->esil);\n\t\t\tif (t && strlen (t) > 1) {\n\t\t\t\tt += strlen (t) - 1;\n\t\t\t\tif (*t == ',') {\n\t\t\t\t\t*t = '\\0';\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn opcode_desc;\n\t\t}\n\t}\n\n\t// ignore reserved opcodes (if they have not been caught by the previous loop)\n\tif ((ins & 0xff00) == 0xff00 && (ins & 0xf) > 7) {\n\t\tgoto INVALID_OP;\n\t}\n\nINVALID_OP:\n\t// An unknown or invalid option has appeared.\n\t//  -- Throw pokeball!\n\top->family = R_ANAL_OP_FAMILY_UNKNOWN;\n\top->type = R_ANAL_OP_TYPE_UNK;\n\top->addr = addr;\n\top->fail = UT64_MAX;\n\top->jump = UT64_MAX;\n\top->ptr = UT64_MAX;\n\top->val = UT64_MAX;\n\top->nopcode = 1;\n\top->cycles = 1;\n\top->size = 2;\n\t// launch esil trap (for communicating upper layers about this weird\n\t// and stinky situation\n\tr_strbuf_set (&op->esil, \"1,$\");\n\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/b35530fa0681b27eba084de5527037ebfb397422", "file_name": "libr/anal/p/anal_avr.c", "vul_type": "cwe-125", "description": "Write a C function named `avr_op_analyze` for analyzing AVR opcodes and updating the analysis structure."}
{"func_name": "ecall_restore", "func_src_before": "int ecall_restore(const char *input, uint64_t input_len, char **output,\n                  uint64_t *output_len) {\n  if (!asylo::primitives::TrustedPrimitives::IsOutsideEnclave(input,\n                                                              input_len) ||\n      !asylo::primitives::TrustedPrimitives::IsOutsideEnclave(\n          output_len, sizeof(uint64_t))) {\n    asylo::primitives::TrustedPrimitives::BestEffortAbort(\n        \"ecall_restore: input/output found to not be in untrusted memory.\");\n  }\n  int result = 0;\n  size_t tmp_output_len;\n  try {\n    result = asylo::Restore(input, static_cast<size_t>(input_len), output,\n                            &tmp_output_len);\n  } catch (...) {\n    LOG(FATAL) << \"Uncaught exception in enclave\";\n  }\n\n  if (output_len) {\n    *output_len = static_cast<uint64_t>(tmp_output_len);\n  }\n  return result;\n}", "func_src_after": "int ecall_restore(const char *input, uint64_t input_len, char **output,\n                  uint64_t *output_len) {\n  if (!asylo::primitives::TrustedPrimitives::IsOutsideEnclave(input,\n                                                              input_len) ||\n      !asylo::primitives::TrustedPrimitives::IsOutsideEnclave(\n          output_len, sizeof(uint64_t)) ||\n      !asylo::primitives::TrustedPrimitives::IsOutsideEnclave(output,\n                                                              *output_len)) {\n    asylo::primitives::TrustedPrimitives::BestEffortAbort(\n        \"ecall_restore: input/output found to not be in untrusted memory.\");\n  }\n  int result = 0;\n  size_t tmp_output_len;\n  try {\n    result = asylo::Restore(input, static_cast<size_t>(input_len), output,\n                            &tmp_output_len);\n  } catch (...) {\n    LOG(FATAL) << \"Uncaught exception in enclave\";\n  }\n\n  if (output_len) {\n    *output_len = static_cast<uint64_t>(tmp_output_len);\n  }\n  return result;\n}", "commit_link": "github.com/google/asylo/commit/382da2b8b09cbf928668a2445efb778f76bd9c8a", "file_name": "asylo/platform/primitives/sgx/ecalls.cc", "vul_type": "cwe-787", "description": "Write a C++ function named `ecall_restore` that checks if input and output buffers are outside enclave memory and performs a restore operation using Asylo primitives."}
{"func_name": "WriteBMPImage", "func_src_before": "static MagickBooleanType WriteBMPImage(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  BMPInfo\n    bmp_info;\n\n  const char\n    *option;\n\n  const StringInfo\n    *profile;\n\n  MagickBooleanType\n    have_color_info,\n    status;\n\n  MagickOffsetType\n    scene;\n\n  MemoryInfo\n    *pixel_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *q;\n\n  size_t\n    bytes_per_line,\n    type;\n\n  ssize_t\n    y;\n\n  unsigned char\n    *bmp_data,\n    *pixels;\n\n  /*\n    Open output image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(status);\n  type=4;\n  if (LocaleCompare(image_info->magick,\"BMP2\") == 0)\n    type=2;\n  else\n    if (LocaleCompare(image_info->magick,\"BMP3\") == 0)\n      type=3;\n\n  option=GetImageOption(image_info,\"bmp:format\");\n  if (option != (char *) NULL)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Format=%s\",option);\n\n      if (LocaleCompare(option,\"bmp2\") == 0)\n        type=2;\n      if (LocaleCompare(option,\"bmp3\") == 0)\n        type=3;\n      if (LocaleCompare(option,\"bmp4\") == 0)\n        type=4;\n    }\n\n  scene=0;\n  do\n  {\n    /*\n      Initialize BMP raster file header.\n    */\n    (void) TransformImageColorspace(image,sRGBColorspace,exception);\n    (void) ResetMagickMemory(&bmp_info,0,sizeof(bmp_info));\n    bmp_info.file_size=14+12;\n    if (type > 2)\n      bmp_info.file_size+=28;\n    bmp_info.offset_bits=bmp_info.file_size;\n    bmp_info.compression=BI_RGB;\n    if ((image->storage_class == PseudoClass) && (image->colors > 256))\n      (void) SetImageStorageClass(image,DirectClass,exception);\n    if (image->storage_class != DirectClass)\n      {\n        /*\n          Colormapped BMP raster.\n        */\n        bmp_info.bits_per_pixel=8;\n        if (image->colors <= 2)\n          bmp_info.bits_per_pixel=1;\n        else\n          if (image->colors <= 16)\n            bmp_info.bits_per_pixel=4;\n          else\n            if (image->colors <= 256)\n              bmp_info.bits_per_pixel=8;\n        if (image_info->compression == RLECompression)\n          bmp_info.bits_per_pixel=8;\n        bmp_info.number_colors=1U << bmp_info.bits_per_pixel;\n        if (image->alpha_trait != UndefinedPixelTrait)\n          (void) SetImageStorageClass(image,DirectClass,exception);\n        else\n          if ((size_t) bmp_info.number_colors < image->colors)\n            (void) SetImageStorageClass(image,DirectClass,exception);\n          else\n            {\n              bmp_info.file_size+=3*(1UL << bmp_info.bits_per_pixel);\n              bmp_info.offset_bits+=3*(1UL << bmp_info.bits_per_pixel);\n              if (type > 2)\n                {\n                  bmp_info.file_size+=(1UL << bmp_info.bits_per_pixel);\n                  bmp_info.offset_bits+=(1UL << bmp_info.bits_per_pixel);\n                }\n            }\n      }\n    if (image->storage_class == DirectClass)\n      {\n        /*\n          Full color BMP raster.\n        */\n        bmp_info.number_colors=0;\n        bmp_info.bits_per_pixel=(unsigned short)\n          ((type > 3) && (image->alpha_trait != UndefinedPixelTrait) ? 32 : 24);\n        bmp_info.compression=(unsigned int) ((type > 3) &&\n          (image->alpha_trait != UndefinedPixelTrait) ?  BI_BITFIELDS : BI_RGB);\n        if ((type == 3) && (image->alpha_trait != UndefinedPixelTrait))\n          {\n            option=GetImageOption(image_info,\"bmp3:alpha\");\n            if (IsStringTrue(option))\n              bmp_info.bits_per_pixel=32;\n          }\n      }\n    bytes_per_line=4*((image->columns*bmp_info.bits_per_pixel+31)/32);\n    bmp_info.ba_offset=0;\n    profile=GetImageProfile(image,\"icc\");\n    have_color_info=(image->rendering_intent != UndefinedIntent) ||\n      (profile != (StringInfo *) NULL) || (image->gamma != 0.0) ?  MagickTrue :\n      MagickFalse;\n    if (type == 2)\n      bmp_info.size=12;\n    else\n      if ((type == 3) || ((image->alpha_trait == UndefinedPixelTrait) &&\n          (have_color_info == MagickFalse)))\n        {\n          type=3;\n          bmp_info.size=40;\n        }\n      else\n        {\n          int\n            extra_size;\n\n          bmp_info.size=108;\n          extra_size=68;\n          if ((image->rendering_intent != UndefinedIntent) ||\n              (profile != (StringInfo *) NULL))\n            {\n              bmp_info.size=124;\n              extra_size+=16;\n            }\n          bmp_info.file_size+=extra_size;\n          bmp_info.offset_bits+=extra_size;\n        }\n    bmp_info.width=(ssize_t) image->columns;\n    bmp_info.height=(ssize_t) image->rows;\n    bmp_info.planes=1;\n    bmp_info.image_size=(unsigned int) (bytes_per_line*image->rows);\n    bmp_info.file_size+=bmp_info.image_size;\n    bmp_info.x_pixels=75*39;\n    bmp_info.y_pixels=75*39;\n    switch (image->units)\n    {\n      case UndefinedResolution:\n      case PixelsPerInchResolution:\n      {\n        bmp_info.x_pixels=(unsigned int) (100.0*image->resolution.x/2.54);\n        bmp_info.y_pixels=(unsigned int) (100.0*image->resolution.y/2.54);\n        break;\n      }\n      case PixelsPerCentimeterResolution:\n      {\n        bmp_info.x_pixels=(unsigned int) (100.0*image->resolution.x);\n        bmp_info.y_pixels=(unsigned int) (100.0*image->resolution.y);\n        break;\n      }\n    }\n    bmp_info.colors_important=bmp_info.number_colors;\n    /*\n      Convert MIFF to BMP raster pixels.\n    */\n    pixel_info=AcquireVirtualMemory((size_t) bmp_info.image_size,\n      sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    (void) ResetMagickMemory(pixels,0,(size_t) bmp_info.image_size);\n    switch (bmp_info.bits_per_pixel)\n    {\n      case 1:\n      {\n        size_t\n          bit,\n          byte;\n\n        /*\n          Convert PseudoClass image to a BMP monochrome image.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          ssize_t\n            offset;\n\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          bit=0;\n          byte=0;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            byte<<=1;\n            byte|=GetPixelIndex(image,p) != 0 ? 0x01 : 0x00;\n            bit++;\n            if (bit == 8)\n              {\n                *q++=(unsigned char) byte;\n                bit=0;\n                byte=0;\n              }\n             p+=GetPixelChannels(image);\n           }\n           if (bit != 0)\n             {\n               *q++=(unsigned char) (byte << (8-bit));\n               x++;\n             }\n          offset=(ssize_t) (image->columns+7)/8;\n          for (x=offset; x < (ssize_t) bytes_per_line; x++)\n            *q++=0x00;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case 4:\n      {\n        size_t\n          byte,\n          nibble;\n\n        ssize_t\n          offset;\n\n        /*\n          Convert PseudoClass image to a BMP monochrome image.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          nibble=0;\n          byte=0;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            byte<<=4;\n            byte|=((size_t) GetPixelIndex(image,p) & 0x0f);\n            nibble++;\n            if (nibble == 2)\n              {\n                *q++=(unsigned char) byte;\n                nibble=0;\n                byte=0;\n              }\n            p+=GetPixelChannels(image);\n          }\n          if (nibble != 0)\n            {\n              *q++=(unsigned char) (byte << 4);\n              x++;\n            }\n          offset=(ssize_t) (image->columns+1)/2;\n          for (x=offset; x < (ssize_t) bytes_per_line; x++)\n            *q++=0x00;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case 8:\n      {\n        /*\n          Convert PseudoClass packet to BMP pixel.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            *q++=(unsigned char) GetPixelIndex(image,p);\n            p+=GetPixelChannels(image);\n          }\n          for ( ; x < (ssize_t) bytes_per_line; x++)\n            *q++=0x00;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case 24:\n      {\n        /*\n          Convert DirectClass packet to BMP BGR888.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            *q++=ScaleQuantumToChar(GetPixelBlue(image,p));\n            *q++=ScaleQuantumToChar(GetPixelGreen(image,p));\n            *q++=ScaleQuantumToChar(GetPixelRed(image,p));\n            p+=GetPixelChannels(image);\n          }\n          for (x=3L*(ssize_t) image->columns; x < (ssize_t) bytes_per_line; x++)\n            *q++=0x00;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case 32:\n      {\n        /*\n          Convert DirectClass packet to ARGB8888 pixel.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            *q++=ScaleQuantumToChar(GetPixelBlue(image,p));\n            *q++=ScaleQuantumToChar(GetPixelGreen(image,p));\n            *q++=ScaleQuantumToChar(GetPixelRed(image,p));\n            *q++=ScaleQuantumToChar(GetPixelAlpha(image,p));\n            p+=GetPixelChannels(image);\n          }\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n    }\n    if ((type > 2) && (bmp_info.bits_per_pixel == 8))\n      if (image_info->compression != NoCompression)\n        {\n          MemoryInfo\n            *rle_info;\n\n          /*\n            Convert run-length encoded raster pixels.\n          */\n          rle_info=AcquireVirtualMemory((size_t) (2*(bytes_per_line+2)+2),\n            (image->rows+2)*sizeof(*pixels));\n          if (rle_info == (MemoryInfo *) NULL)\n            {\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n            }\n          bmp_data=(unsigned char *) GetVirtualMemoryBlob(rle_info);\n          bmp_info.file_size-=bmp_info.image_size;\n          bmp_info.image_size=(unsigned int) EncodeImage(image,bytes_per_line,\n            pixels,bmp_data);\n          bmp_info.file_size+=bmp_info.image_size;\n          pixel_info=RelinquishVirtualMemory(pixel_info);\n          pixel_info=rle_info;\n          pixels=bmp_data;\n          bmp_info.compression=BI_RLE8;\n        }\n    /*\n      Write BMP for Windows, all versions, 14-byte header.\n    */\n    if (image->debug != MagickFalse)\n      {\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"   Writing BMP version %.20g datastream\",(double) type);\n        if (image->storage_class == DirectClass)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Storage class=DirectClass\");\n        else\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Storage class=PseudoClass\");\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"   Image depth=%.20g\",(double) image->depth);\n        if (image->alpha_trait != UndefinedPixelTrait)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Matte=True\");\n        else\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Matte=MagickFalse\");\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"   BMP bits_per_pixel=%.20g\",(double) bmp_info.bits_per_pixel);\n        switch ((int) bmp_info.compression)\n        {\n           case BI_RGB:\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"   Compression=BI_RGB\");\n             break;\n           }\n           case BI_RLE8:\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"   Compression=BI_RLE8\");\n             break;\n           }\n           case BI_BITFIELDS:\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"   Compression=BI_BITFIELDS\");\n             break;\n           }\n           default:\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"   Compression=UNKNOWN (%lu)\",bmp_info.compression);\n             break;\n           }\n        }\n        if (bmp_info.number_colors == 0)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Number_colors=unspecified\");\n        else\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Number_colors=%lu\",bmp_info.number_colors);\n      }\n    (void) WriteBlob(image,2,(unsigned char *) \"BM\");\n    (void) WriteBlobLSBLong(image,bmp_info.file_size);\n    (void) WriteBlobLSBLong(image,bmp_info.ba_offset);  /* always 0 */\n    (void) WriteBlobLSBLong(image,bmp_info.offset_bits);\n    if (type == 2)\n      {\n        /*\n          Write 12-byte version 2 bitmap header.\n        */\n        (void) WriteBlobLSBLong(image,bmp_info.size);\n        (void) WriteBlobLSBSignedShort(image,(signed short) bmp_info.width);\n        (void) WriteBlobLSBSignedShort(image,(signed short) bmp_info.height);\n        (void) WriteBlobLSBShort(image,bmp_info.planes);\n        (void) WriteBlobLSBShort(image,bmp_info.bits_per_pixel);\n      }\n    else\n      {\n        /*\n          Write 40-byte version 3+ bitmap header.\n        */\n        (void) WriteBlobLSBLong(image,bmp_info.size);\n        (void) WriteBlobLSBSignedLong(image,(signed int) bmp_info.width);\n        (void) WriteBlobLSBSignedLong(image,(signed int) bmp_info.height);\n        (void) WriteBlobLSBShort(image,bmp_info.planes);\n        (void) WriteBlobLSBShort(image,bmp_info.bits_per_pixel);\n        (void) WriteBlobLSBLong(image,bmp_info.compression);\n        (void) WriteBlobLSBLong(image,bmp_info.image_size);\n        (void) WriteBlobLSBLong(image,bmp_info.x_pixels);\n        (void) WriteBlobLSBLong(image,bmp_info.y_pixels);\n        (void) WriteBlobLSBLong(image,bmp_info.number_colors);\n        (void) WriteBlobLSBLong(image,bmp_info.colors_important);\n      }\n    if ((type > 3) && ((image->alpha_trait != UndefinedPixelTrait) ||\n        (have_color_info != MagickFalse)))\n      {\n        /*\n          Write the rest of the 108-byte BMP Version 4 header.\n        */\n        (void) WriteBlobLSBLong(image,0x00ff0000U);  /* Red mask */\n        (void) WriteBlobLSBLong(image,0x0000ff00U);  /* Green mask */\n        (void) WriteBlobLSBLong(image,0x000000ffU);  /* Blue mask */\n        (void) WriteBlobLSBLong(image,0xff000000U);  /* Alpha mask */\n        (void) WriteBlobLSBLong(image,0x73524742U);  /* sRGB */\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.red_primary.x*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.red_primary.y*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          ((1.000f-(image->chromaticity.red_primary.x+\n          image->chromaticity.red_primary.y))*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.green_primary.x*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.green_primary.y*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          ((1.000f-(image->chromaticity.green_primary.x+\n          image->chromaticity.green_primary.y))*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.blue_primary.x*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.blue_primary.y*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          ((1.000f-(image->chromaticity.blue_primary.x+\n          image->chromaticity.blue_primary.y))*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (bmp_info.gamma_scale.x*0x10000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (bmp_info.gamma_scale.y*0x10000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (bmp_info.gamma_scale.z*0x10000));\n        if ((image->rendering_intent != UndefinedIntent) ||\n            (profile != (StringInfo *) NULL))\n          {\n            ssize_t\n              intent;\n\n            switch ((int) image->rendering_intent)\n            {\n              case SaturationIntent:\n              {\n                intent=LCS_GM_BUSINESS;\n                break;\n              }\n              case RelativeIntent:\n              {\n                intent=LCS_GM_GRAPHICS;\n                break;\n              }\n              case PerceptualIntent:\n              {\n                intent=LCS_GM_IMAGES;\n                break;\n              }\n              case AbsoluteIntent:\n              {\n                intent=LCS_GM_ABS_COLORIMETRIC;\n                break;\n              }\n              default:\n              {\n                intent=0;\n                break;\n              }\n            }\n            (void) WriteBlobLSBLong(image,(unsigned int) intent);\n            (void) WriteBlobLSBLong(image,0x00);  /* dummy profile data */\n            (void) WriteBlobLSBLong(image,0x00);  /* dummy profile length */\n            (void) WriteBlobLSBLong(image,0x00);  /* reserved */\n          }\n      }\n    if (image->storage_class == PseudoClass)\n      {\n        unsigned char\n          *bmp_colormap;\n\n        /*\n          Dump colormap to file.\n        */\n        if (image->debug != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Colormap: %.20g entries\",(double) image->colors);\n        bmp_colormap=(unsigned char *) AcquireQuantumMemory((size_t) (1UL <<\n          bmp_info.bits_per_pixel),4*sizeof(*bmp_colormap));\n        if (bmp_colormap == (unsigned char *) NULL)\n          ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n        q=bmp_colormap;\n        for (i=0; i < (ssize_t) MagickMin((ssize_t) image->colors,(ssize_t) bmp_info.number_colors); i++)\n        {\n          *q++=ScaleQuantumToChar(ClampToQuantum(image->colormap[i].blue));\n          *q++=ScaleQuantumToChar(ClampToQuantum(image->colormap[i].green));\n          *q++=ScaleQuantumToChar(ClampToQuantum(image->colormap[i].red));\n          if (type > 2)\n            *q++=(unsigned char) 0x0;\n        }\n        for ( ; i < (ssize_t) (1UL << bmp_info.bits_per_pixel); i++)\n        {\n          *q++=(unsigned char) 0x00;\n          *q++=(unsigned char) 0x00;\n          *q++=(unsigned char) 0x00;\n          if (type > 2)\n            *q++=(unsigned char) 0x00;\n        }\n        if (type <= 2)\n          (void) WriteBlob(image,(size_t) (3*(1L << bmp_info.bits_per_pixel)),\n            bmp_colormap);\n        else\n          (void) WriteBlob(image,(size_t) (4*(1L << bmp_info.bits_per_pixel)),\n            bmp_colormap);\n        bmp_colormap=(unsigned char *) RelinquishMagickMemory(bmp_colormap);\n      }\n    if (image->debug != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Pixels:  %lu bytes\",bmp_info.image_size);\n    (void) WriteBlob(image,(size_t) bmp_info.image_size,pixels);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (GetNextImageInList(image) == (Image *) NULL)\n      break;\n    image=SyncNextImageInList(image);\n    status=SetImageProgress(image,SaveImagesTag,scene++,\n      GetImageListLength(image));\n    if (status == MagickFalse)\n      break;\n  } while (image_info->adjoin != MagickFalse);\n  (void) CloseBlob(image);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType WriteBMPImage(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  BMPInfo\n    bmp_info;\n\n  const char\n    *option;\n\n  const StringInfo\n    *profile;\n\n  MagickBooleanType\n    have_color_info,\n    status;\n\n  MagickOffsetType\n    scene;\n\n  MemoryInfo\n    *pixel_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i,\n    x;\n\n  register unsigned char\n    *q;\n\n  size_t\n    bytes_per_line,\n    type;\n\n  ssize_t\n    y;\n\n  unsigned char\n    *bmp_data,\n    *pixels;\n\n  /*\n    Open output image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(status);\n  type=4;\n  if (LocaleCompare(image_info->magick,\"BMP2\") == 0)\n    type=2;\n  else\n    if (LocaleCompare(image_info->magick,\"BMP3\") == 0)\n      type=3;\n\n  option=GetImageOption(image_info,\"bmp:format\");\n  if (option != (char *) NULL)\n    {\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"  Format=%s\",option);\n\n      if (LocaleCompare(option,\"bmp2\") == 0)\n        type=2;\n      if (LocaleCompare(option,\"bmp3\") == 0)\n        type=3;\n      if (LocaleCompare(option,\"bmp4\") == 0)\n        type=4;\n    }\n\n  scene=0;\n  do\n  {\n    /*\n      Initialize BMP raster file header.\n    */\n    (void) TransformImageColorspace(image,sRGBColorspace,exception);\n    (void) ResetMagickMemory(&bmp_info,0,sizeof(bmp_info));\n    bmp_info.file_size=14+12;\n    if (type > 2)\n      bmp_info.file_size+=28;\n    bmp_info.offset_bits=bmp_info.file_size;\n    bmp_info.compression=BI_RGB;\n    if ((image->storage_class == PseudoClass) && (image->colors > 256))\n      (void) SetImageStorageClass(image,DirectClass,exception);\n    if (image->storage_class != DirectClass)\n      {\n        /*\n          Colormapped BMP raster.\n        */\n        bmp_info.bits_per_pixel=8;\n        if (image->colors <= 2)\n          bmp_info.bits_per_pixel=1;\n        else\n          if (image->colors <= 16)\n            bmp_info.bits_per_pixel=4;\n          else\n            if (image->colors <= 256)\n              bmp_info.bits_per_pixel=8;\n        if (image_info->compression == RLECompression)\n          bmp_info.bits_per_pixel=8;\n        bmp_info.number_colors=1U << bmp_info.bits_per_pixel;\n        if (image->alpha_trait != UndefinedPixelTrait)\n          (void) SetImageStorageClass(image,DirectClass,exception);\n        else\n          if ((size_t) bmp_info.number_colors < image->colors)\n            (void) SetImageStorageClass(image,DirectClass,exception);\n          else\n            {\n              bmp_info.file_size+=3*(1UL << bmp_info.bits_per_pixel);\n              bmp_info.offset_bits+=3*(1UL << bmp_info.bits_per_pixel);\n              if (type > 2)\n                {\n                  bmp_info.file_size+=(1UL << bmp_info.bits_per_pixel);\n                  bmp_info.offset_bits+=(1UL << bmp_info.bits_per_pixel);\n                }\n            }\n      }\n    if (image->storage_class == DirectClass)\n      {\n        /*\n          Full color BMP raster.\n        */\n        bmp_info.number_colors=0;\n        bmp_info.bits_per_pixel=(unsigned short)\n          ((type > 3) && (image->alpha_trait != UndefinedPixelTrait) ? 32 : 24);\n        bmp_info.compression=(unsigned int) ((type > 3) &&\n          (image->alpha_trait != UndefinedPixelTrait) ?  BI_BITFIELDS : BI_RGB);\n        if ((type == 3) && (image->alpha_trait != UndefinedPixelTrait))\n          {\n            option=GetImageOption(image_info,\"bmp3:alpha\");\n            if (IsStringTrue(option))\n              bmp_info.bits_per_pixel=32;\n          }\n      }\n    bytes_per_line=4*((image->columns*bmp_info.bits_per_pixel+31)/32);\n    bmp_info.ba_offset=0;\n    profile=GetImageProfile(image,\"icc\");\n    have_color_info=(image->rendering_intent != UndefinedIntent) ||\n      (profile != (StringInfo *) NULL) || (image->gamma != 0.0) ?  MagickTrue :\n      MagickFalse;\n    if (type == 2)\n      bmp_info.size=12;\n    else\n      if ((type == 3) || ((image->alpha_trait == UndefinedPixelTrait) &&\n          (have_color_info == MagickFalse)))\n        {\n          type=3;\n          bmp_info.size=40;\n        }\n      else\n        {\n          int\n            extra_size;\n\n          bmp_info.size=108;\n          extra_size=68;\n          if ((image->rendering_intent != UndefinedIntent) ||\n              (profile != (StringInfo *) NULL))\n            {\n              bmp_info.size=124;\n              extra_size+=16;\n            }\n          bmp_info.file_size+=extra_size;\n          bmp_info.offset_bits+=extra_size;\n        }\n    if ((image->columns != (signed int) image->columns) ||\n        (image->rows != (signed int) image->rows))\n      ThrowWriterException(ImageError,\"WidthOrHeightExceedsLimit\");\n    bmp_info.width=(ssize_t) image->columns;\n    bmp_info.height=(ssize_t) image->rows;\n    bmp_info.planes=1;\n    bmp_info.image_size=(unsigned long) (bytes_per_line*image->rows);\n    bmp_info.file_size+=bmp_info.image_size;\n    bmp_info.x_pixels=75*39;\n    bmp_info.y_pixels=75*39;\n    switch (image->units)\n    {\n      case UndefinedResolution:\n      case PixelsPerInchResolution:\n      {\n        bmp_info.x_pixels=(unsigned int) (100.0*image->resolution.x/2.54);\n        bmp_info.y_pixels=(unsigned int) (100.0*image->resolution.y/2.54);\n        break;\n      }\n      case PixelsPerCentimeterResolution:\n      {\n        bmp_info.x_pixels=(unsigned int) (100.0*image->resolution.x);\n        bmp_info.y_pixels=(unsigned int) (100.0*image->resolution.y);\n        break;\n      }\n    }\n    bmp_info.colors_important=bmp_info.number_colors;\n    /*\n      Convert MIFF to BMP raster pixels.\n    */\n    pixel_info=AcquireVirtualMemory((size_t) bmp_info.image_size,\n      sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    (void) ResetMagickMemory(pixels,0,(size_t) bmp_info.image_size);\n    switch (bmp_info.bits_per_pixel)\n    {\n      case 1:\n      {\n        size_t\n          bit,\n          byte;\n\n        /*\n          Convert PseudoClass image to a BMP monochrome image.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          ssize_t\n            offset;\n\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          bit=0;\n          byte=0;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            byte<<=1;\n            byte|=GetPixelIndex(image,p) != 0 ? 0x01 : 0x00;\n            bit++;\n            if (bit == 8)\n              {\n                *q++=(unsigned char) byte;\n                bit=0;\n                byte=0;\n              }\n             p+=GetPixelChannels(image);\n           }\n           if (bit != 0)\n             {\n               *q++=(unsigned char) (byte << (8-bit));\n               x++;\n             }\n          offset=(ssize_t) (image->columns+7)/8;\n          for (x=offset; x < (ssize_t) bytes_per_line; x++)\n            *q++=0x00;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case 4:\n      {\n        size_t\n          byte,\n          nibble;\n\n        ssize_t\n          offset;\n\n        /*\n          Convert PseudoClass image to a BMP monochrome image.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          nibble=0;\n          byte=0;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            byte<<=4;\n            byte|=((size_t) GetPixelIndex(image,p) & 0x0f);\n            nibble++;\n            if (nibble == 2)\n              {\n                *q++=(unsigned char) byte;\n                nibble=0;\n                byte=0;\n              }\n            p+=GetPixelChannels(image);\n          }\n          if (nibble != 0)\n            {\n              *q++=(unsigned char) (byte << 4);\n              x++;\n            }\n          offset=(ssize_t) (image->columns+1)/2;\n          for (x=offset; x < (ssize_t) bytes_per_line; x++)\n            *q++=0x00;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case 8:\n      {\n        /*\n          Convert PseudoClass packet to BMP pixel.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            *q++=(unsigned char) GetPixelIndex(image,p);\n            p+=GetPixelChannels(image);\n          }\n          for ( ; x < (ssize_t) bytes_per_line; x++)\n            *q++=0x00;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case 24:\n      {\n        /*\n          Convert DirectClass packet to BMP BGR888.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            *q++=ScaleQuantumToChar(GetPixelBlue(image,p));\n            *q++=ScaleQuantumToChar(GetPixelGreen(image,p));\n            *q++=ScaleQuantumToChar(GetPixelRed(image,p));\n            p+=GetPixelChannels(image);\n          }\n          for (x=3L*(ssize_t) image->columns; x < (ssize_t) bytes_per_line; x++)\n            *q++=0x00;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n      case 32:\n      {\n        /*\n          Convert DirectClass packet to ARGB8888 pixel.\n        */\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n          if (p == (const Quantum *) NULL)\n            break;\n          q=pixels+(image->rows-y-1)*bytes_per_line;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            *q++=ScaleQuantumToChar(GetPixelBlue(image,p));\n            *q++=ScaleQuantumToChar(GetPixelGreen(image,p));\n            *q++=ScaleQuantumToChar(GetPixelRed(image,p));\n            *q++=ScaleQuantumToChar(GetPixelAlpha(image,p));\n            p+=GetPixelChannels(image);\n          }\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n        break;\n      }\n    }\n    if ((type > 2) && (bmp_info.bits_per_pixel == 8))\n      if (image_info->compression != NoCompression)\n        {\n          MemoryInfo\n            *rle_info;\n\n          /*\n            Convert run-length encoded raster pixels.\n          */\n          rle_info=AcquireVirtualMemory((size_t) (2*(bytes_per_line+2)+2),\n            (image->rows+2)*sizeof(*pixels));\n          if (rle_info == (MemoryInfo *) NULL)\n            {\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n            }\n          bmp_data=(unsigned char *) GetVirtualMemoryBlob(rle_info);\n          bmp_info.file_size-=bmp_info.image_size;\n          bmp_info.image_size=(unsigned int) EncodeImage(image,bytes_per_line,\n            pixels,bmp_data);\n          bmp_info.file_size+=bmp_info.image_size;\n          pixel_info=RelinquishVirtualMemory(pixel_info);\n          pixel_info=rle_info;\n          pixels=bmp_data;\n          bmp_info.compression=BI_RLE8;\n        }\n    /*\n      Write BMP for Windows, all versions, 14-byte header.\n    */\n    if (image->debug != MagickFalse)\n      {\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"   Writing BMP version %.20g datastream\",(double) type);\n        if (image->storage_class == DirectClass)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Storage class=DirectClass\");\n        else\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Storage class=PseudoClass\");\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"   Image depth=%.20g\",(double) image->depth);\n        if (image->alpha_trait != UndefinedPixelTrait)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Matte=True\");\n        else\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Matte=MagickFalse\");\n        (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"   BMP bits_per_pixel=%.20g\",(double) bmp_info.bits_per_pixel);\n        switch ((int) bmp_info.compression)\n        {\n           case BI_RGB:\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"   Compression=BI_RGB\");\n             break;\n           }\n           case BI_RLE8:\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"   Compression=BI_RLE8\");\n             break;\n           }\n           case BI_BITFIELDS:\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"   Compression=BI_BITFIELDS\");\n             break;\n           }\n           default:\n           {\n             (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n               \"   Compression=UNKNOWN (%lu)\",bmp_info.compression);\n             break;\n           }\n        }\n        if (bmp_info.number_colors == 0)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Number_colors=unspecified\");\n        else\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"   Number_colors=%lu\",bmp_info.number_colors);\n      }\n    (void) WriteBlob(image,2,(unsigned char *) \"BM\");\n    (void) WriteBlobLSBLong(image,bmp_info.file_size);\n    (void) WriteBlobLSBLong(image,bmp_info.ba_offset);  /* always 0 */\n    (void) WriteBlobLSBLong(image,bmp_info.offset_bits);\n    if (type == 2)\n      {\n        /*\n          Write 12-byte version 2 bitmap header.\n        */\n        (void) WriteBlobLSBLong(image,bmp_info.size);\n        (void) WriteBlobLSBSignedShort(image,(signed short) bmp_info.width);\n        (void) WriteBlobLSBSignedShort(image,(signed short) bmp_info.height);\n        (void) WriteBlobLSBShort(image,bmp_info.planes);\n        (void) WriteBlobLSBShort(image,bmp_info.bits_per_pixel);\n      }\n    else\n      {\n        /*\n          Write 40-byte version 3+ bitmap header.\n        */\n        (void) WriteBlobLSBLong(image,bmp_info.size);\n        (void) WriteBlobLSBSignedLong(image,(signed int) bmp_info.width);\n        (void) WriteBlobLSBSignedLong(image,(signed int) bmp_info.height);\n        (void) WriteBlobLSBShort(image,bmp_info.planes);\n        (void) WriteBlobLSBShort(image,bmp_info.bits_per_pixel);\n        (void) WriteBlobLSBLong(image,bmp_info.compression);\n        (void) WriteBlobLSBLong(image,bmp_info.image_size);\n        (void) WriteBlobLSBLong(image,bmp_info.x_pixels);\n        (void) WriteBlobLSBLong(image,bmp_info.y_pixels);\n        (void) WriteBlobLSBLong(image,bmp_info.number_colors);\n        (void) WriteBlobLSBLong(image,bmp_info.colors_important);\n      }\n    if ((type > 3) && ((image->alpha_trait != UndefinedPixelTrait) ||\n        (have_color_info != MagickFalse)))\n      {\n        /*\n          Write the rest of the 108-byte BMP Version 4 header.\n        */\n        (void) WriteBlobLSBLong(image,0x00ff0000U);  /* Red mask */\n        (void) WriteBlobLSBLong(image,0x0000ff00U);  /* Green mask */\n        (void) WriteBlobLSBLong(image,0x000000ffU);  /* Blue mask */\n        (void) WriteBlobLSBLong(image,0xff000000U);  /* Alpha mask */\n        (void) WriteBlobLSBLong(image,0x73524742U);  /* sRGB */\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.red_primary.x*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.red_primary.y*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          ((1.000f-(image->chromaticity.red_primary.x+\n          image->chromaticity.red_primary.y))*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.green_primary.x*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.green_primary.y*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          ((1.000f-(image->chromaticity.green_primary.x+\n          image->chromaticity.green_primary.y))*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.blue_primary.x*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (image->chromaticity.blue_primary.y*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          ((1.000f-(image->chromaticity.blue_primary.x+\n          image->chromaticity.blue_primary.y))*0x40000000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (bmp_info.gamma_scale.x*0x10000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (bmp_info.gamma_scale.y*0x10000));\n        (void) WriteBlobLSBLong(image,(unsigned int)\n          (bmp_info.gamma_scale.z*0x10000));\n        if ((image->rendering_intent != UndefinedIntent) ||\n            (profile != (StringInfo *) NULL))\n          {\n            ssize_t\n              intent;\n\n            switch ((int) image->rendering_intent)\n            {\n              case SaturationIntent:\n              {\n                intent=LCS_GM_BUSINESS;\n                break;\n              }\n              case RelativeIntent:\n              {\n                intent=LCS_GM_GRAPHICS;\n                break;\n              }\n              case PerceptualIntent:\n              {\n                intent=LCS_GM_IMAGES;\n                break;\n              }\n              case AbsoluteIntent:\n              {\n                intent=LCS_GM_ABS_COLORIMETRIC;\n                break;\n              }\n              default:\n              {\n                intent=0;\n                break;\n              }\n            }\n            (void) WriteBlobLSBLong(image,(unsigned int) intent);\n            (void) WriteBlobLSBLong(image,0x00);  /* dummy profile data */\n            (void) WriteBlobLSBLong(image,0x00);  /* dummy profile length */\n            (void) WriteBlobLSBLong(image,0x00);  /* reserved */\n          }\n      }\n    if (image->storage_class == PseudoClass)\n      {\n        unsigned char\n          *bmp_colormap;\n\n        /*\n          Dump colormap to file.\n        */\n        if (image->debug != MagickFalse)\n          (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  Colormap: %.20g entries\",(double) image->colors);\n        bmp_colormap=(unsigned char *) AcquireQuantumMemory((size_t) (1UL <<\n          bmp_info.bits_per_pixel),4*sizeof(*bmp_colormap));\n        if (bmp_colormap == (unsigned char *) NULL)\n          ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n        q=bmp_colormap;\n        for (i=0; i < (ssize_t) MagickMin((ssize_t) image->colors,(ssize_t) bmp_info.number_colors); i++)\n        {\n          *q++=ScaleQuantumToChar(ClampToQuantum(image->colormap[i].blue));\n          *q++=ScaleQuantumToChar(ClampToQuantum(image->colormap[i].green));\n          *q++=ScaleQuantumToChar(ClampToQuantum(image->colormap[i].red));\n          if (type > 2)\n            *q++=(unsigned char) 0x0;\n        }\n        for ( ; i < (ssize_t) (1UL << bmp_info.bits_per_pixel); i++)\n        {\n          *q++=(unsigned char) 0x00;\n          *q++=(unsigned char) 0x00;\n          *q++=(unsigned char) 0x00;\n          if (type > 2)\n            *q++=(unsigned char) 0x00;\n        }\n        if (type <= 2)\n          (void) WriteBlob(image,(size_t) (3*(1L << bmp_info.bits_per_pixel)),\n            bmp_colormap);\n        else\n          (void) WriteBlob(image,(size_t) (4*(1L << bmp_info.bits_per_pixel)),\n            bmp_colormap);\n        bmp_colormap=(unsigned char *) RelinquishMagickMemory(bmp_colormap);\n      }\n    if (image->debug != MagickFalse)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"  Pixels:  %lu bytes\",bmp_info.image_size);\n    (void) WriteBlob(image,(size_t) bmp_info.image_size,pixels);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (GetNextImageInList(image) == (Image *) NULL)\n      break;\n    image=SyncNextImageInList(image);\n    status=SetImageProgress(image,SaveImagesTag,scene++,\n      GetImageListLength(image));\n    if (status == MagickFalse)\n      break;\n  } while (image_info->adjoin != MagickFalse);\n  (void) CloseBlob(image);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/4cc6ec8a4197d4c008577127736bf7985d632323", "file_name": "coders/bmp.c", "vul_type": "cwe-190", "description": "Write a function in C to save an image in BMP format."}
{"func_name": "analyze_scene", "func_src_before": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{}';\".format(user)\n            results = self.db.exec(sql)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{}' AND user='{}';\".format(bracket, user)\n                    results = self.db.exec(sql)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(bracket, user, name)\n                        self.db.exec(sql)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{}', '{}', '{}');\".format(url, user, name)\n                    self.db.exec(sql)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '\" + str(base_url) + \"';\"\n            result = self.db.exec(sql)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last=\" + str(new_last) + \" where base_url = '\"+str(base_url)+\"';\"\n                    self.db.exec(sql)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES (\"\n                sql += \"'\"+str(base_url)+\"', \"+str(first)+ \", \"+str(last)+\", '\"+str(name)+\"');\"\n                self.db.exec(sql)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "func_src_after": "    def analyze_scene(self, scene):\n        base_urls = scene.get_base_urls()\n        users = scene.get_users()\n        name = scene.get_name()\n        LOG.info('found the following users for scene {}: {}'.format(name, users))\n\n        # This scene might have one user who always posts the brackets on their challonge account\n        for user in users:\n            # Have we analyzed this user before?\n            sql = \"SELECT * FROM user_analyzed WHERE user='{user}';\"\n            args = {'user': user}\n            results = self.db.exec(sql, args)\n\n            # Did we have any matches in the database?\n            if len(results) > 0:\n                # We have analyzed this user before. Just grab one page of brackets to see if there have been any new tournaments\n                # eg, just look at /users/christmasmike?page=1 instead of all the pages that exist\n                most_recent_page = bracket_utils.get_brackets_from_user(user, pages=1)\n                for bracket in most_recent_page:\n                    LOG.info('here are the brackets from the most recent page of user {}: {}'.format(user, most_recent_page))\n                    # This user has already been analyzed, there's a good chance this bracket has been analyzed also\n                    sql = \"SELECT * FROM user_analyzed WHERE url='{bracket}' AND user='{user}';\"\n                    args = {'bracket': bracket, 'user': user}\n                    results = self.db.exec(sql, args)\n\n                    if len(results) == 0:\n                        # This is a new bracket that must have been published in the last hour or so\n                        LOG.info('found this url from a user: {} {}'.format(bracket, user))\n                        display_name = bracket_utils.get_display_base(bracket)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name)\n\n                        # mark this bracket as analyzed\n                        sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{bracket}', '{user}', '{name}');\"\n                        args = {'bracket': bracket, 'user':user, 'name':name}\n                        self.db.exec(sql, args)\n\n                        # Tweet that we found a new bracket\n                        msg = \"Found new {} bracket: {}\".format(name, bracket)\n                        tweet(msg)\n                    else:\n                        LOG.info('url {} is not new for user {}'.format(bracket, user))\n            else:\n                # This is a new user, analyze all brackets\n                user_urls = bracket_utils.get_brackets_from_user(user)\n                for url in user_urls:\n                    LOG.info('found this url from a user: {} {}'.format(url, user))\n                    display_name = bracket_utils.get_display_base(url)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(url, name, display_name)\n\n                    # mark this bracket as analyzed\n                    sql = \"INSERT INTO user_analyzed (url, user, scene) VALUES ('{url}', '{user}', '{name}');\"\n                    args = {'url': url, 'user':user, 'name':name}\n                    self.db.exec(sql, args)\n\n                LOG.info('done with user {}'.format(user))\n\n\n        # This scene might always call their brackets the same thing, eg weekly1, weekly2, weekly3 etc\n        for base_url in base_urls:\n            # attempt to load this data from the database\n            LOG.info('About to start this analysis thread for scene {}'.format(scene.get_name()))\n            sql = \"SELECT first,last FROM valids WHERE base_url = '{base_url}';\"\n            args = {'base_url': base_url}\n            result = self.db.exec(sql, args)\n            has_results = len(result) > 0 \n\n            # Did we find a match in the database?\n            if has_results:\n                LOG.info(\"validURLs found values in the database\" + str(result))\n                first = result[0][0]\n                last = result[0][1]\n\n                # Check for a new valid URL\n                new_last = bracket_utils._get_last_valid_url(base_url, last-1)\n\n                if not new_last == last:\n                    if new_last - last > 5:\n                        with open(\"DEBUGOUTPUT.txt\", 'a') as f:\n                            f.write(\"[validURLs.py:55]: found a SHIT TON of new tournaments for bracket: {}\".format(base_url))\n\n                    else:\n                        bracket = base_url.replace('###', str(new_last))\n                        LOG.info('Found new bracket: {}'.format(bracket))\n                        msg = \"Found new bracket: {}\".format(bracket)\n                        tweet(msg)\n\n                    # If there's been a new last, update the database\n                    sql = \"UPDATE valids SET last={new_last} where base_url='{base_url}';\"\n                    args = {'new_last': new_last, 'base_url': base_url}\n                    self.db.exec(sql, args)\n\n\n                    # Analyze each of these new brackets\n                    for i in range(last+1, new_last+1):\n                        # Since this URL is new, we have to process the data\n                        bracket = base_url.replace('###', str(i))\n                        # Create the display name for this bracket\n                        # Eg challonge.com/NP9ATX54 -> NP9 54\n                        display_name = bracket_utils.get_display_base(bracket, counter=i)\n                        # We don't care about doubles tournaments\n                        if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                            LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                            continue\n\n                        self.data_processor.process(bracket, name, display_name, new_bracket=True)\n\n            else:\n                # We need to create first and last from scratch\n                first = bracket_utils._get_first_valid_url(base_url)\n                last = bracket_utils._get_last_valid_url(base_url, first)\n\n                # This is new data, we need to put it into the db\n                sql = \"INSERT INTO valids (base_url, first, last, scene) VALUES ('{base_url}', '{first}', '{last}', '{name}');\"\n                args = {'base_url': base_url, 'first': first, 'last': last, 'name': name}\n                self.db.exec(sql, args)\n\n                for i in range(first, last+1):\n                    bracket = base_url.replace('###', str(i))\n                    # Create the display name for this bracket\n                    # Eg challonge.com/NP9ATX54 -> NP9 54\n                    display_name = bracket_utils.get_display_base(bracket, counter=i)\n                    # We don't care about doubles tournaments\n                    if 'doubles' in display_name.lower() or 'dubs' in display_name.lower():\n                        LOG.info('We are skipping the tournament {} because it is a doubles tournament'.format(display_name))\n                        continue\n\n                    self.data_processor.process(bracket, name, display_name)\n\n                    # Calculate ranks after each tournament so we can see how players are progressing\n        if not analyzed_scenes and should_tweet:\n            tweet('About to start ranking for scene {}'.format(name))\n        self.data_processor.check_and_update_ranks(name)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "validURLs.py", "vul_type": "cwe-089", "description": "Write a Python function to analyze tournament brackets for a given scene, checking for new data and updating records accordingly."}
{"func_name": "retrieve_last_video_position", "func_src_before": "def retrieve_last_video_position(playlist_id, db):\n    db.execute(\n        \"SELECT max(position) as position from video WHERE playlist_id=%s;\", (playlist_id,))\n    row = db.fetchone()\n    return row['position']", "func_src_after": "def retrieve_last_video_position(playlist_id, db):\n    db.execute(\"SELECT max(position) as position from video WHERE playlist_id={playlist_id};\".format(\n        playlist_id=playlist_id))\n    row = db.fetchone()\n    return row['position']", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to get the highest position number of a video in a playlist from a database."}
{"func_name": "_normalize", "func_src_before": "    def _normalize(self, metaerrors):\n        \"\"\"Normalize output format to be usable by Anaconda's linting frontend\n        \"\"\"\n\n        errors = []\n        for error in metaerrors:\n            if self.filepath not in error.get('path', ''):\n                continue\n\n            error_type = error.get('severity', 'X').capitalize()[0]\n            if error_type == 'X':\n                continue\n            if error_type not in ['E', 'W']:\n                error_type = 'V'\n            errors.append({\n                'underline_range': True,\n                'lineno': error.get('line', 0),\n                'offset': error.get('col', 0),\n                'raw_message': error.get('message', ''),\n                'code': 0,\n                'level': error_type,\n                'message': '[{0}] {1} ({2}): {3}'.format(\n                    error_type,\n                    error.get('linter', 'none'),\n                    error.get('severity', 'none'),\n                    error.get('message')\n                )\n            })\n\n        return errors", "func_src_after": "    def _normalize(self, metaerrors):\n        \"\"\"Normalize output format to be usable by Anaconda's linting frontend\n        \"\"\"\n\n        errors = []\n        for error in metaerrors:\n            last_path = os.path.join(\n                os.path.basename(os.path.dirname(self.filepath)),\n                os.path.basename(self.filepath)\n            )\n            if last_path not in error.get('path', ''):\n                continue\n\n            error_type = error.get('severity', 'X').capitalize()[0]\n            if error_type == 'X':\n                continue\n            if error_type not in ['E', 'W']:\n                error_type = 'V'\n            errors.append({\n                'underline_range': True,\n                'lineno': error.get('line', 0),\n                'offset': error.get('col', 0),\n                'raw_message': error.get('message', ''),\n                'code': 0,\n                'level': error_type,\n                'message': '[{0}] {1} ({2}): {3}'.format(\n                    error_type,\n                    error.get('linter', 'none'),\n                    error.get('severity', 'none'),\n                    error.get('message')\n                )\n            })\n\n        return errors", "commit_link": "github.com/DamnWidget/anaconda_go/commit/d3db90bb8853d832927818699591b91f56f6413c", "file_name": "plugin/handlers_go/anagonda/context/gometalinter.py", "vul_type": "cwe-022", "description": "Write a Python function to filter and reformat error metadata for a linting tool's output."}
{"func_name": "MultiPartInputFile::Data::chunkOffsetReconstruction", "func_src_before": "MultiPartInputFile::Data::chunkOffsetReconstruction(OPENEXR_IMF_INTERNAL_NAMESPACE::IStream& is, const vector<InputPartData*>& parts)\n{\n    //\n    // Reconstruct broken chunk offset tables. Stop once we received any exception.\n    //\n\n    Int64 position = is.tellg();\n\n    \n    //\n    // check we understand all the parts available: if not, we cannot continue\n    // exceptions thrown here should trickle back up to the constructor\n    //\n    \n    for (size_t i = 0; i < parts.size(); i++)\n    {\n        Header& header=parts[i]->header;\n        \n        //\n        // do we have a valid type entry?\n        // we only need them for true multipart files or single part non-image (deep) files\n        //\n        if(!header.hasType() && (isMultiPart(version) || isNonImage(version)))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with missing type\");\n        }\n        if(!isSupportedType(header.type()))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with unknown type \"+header.type());\n        }\n    }\n    \n    \n    // how many chunks should we read? We should stop when we reach the end\n    size_t total_chunks = 0;\n        \n    // for tiled-based parts, array of (pointers to) tileOffsets objects\n    // to create mapping between tile coordinates and chunk table indices\n    \n    \n    vector<TileOffsets*> tileOffsets(parts.size());\n    \n    // for scanline-based parts, number of scanlines in each chunk\n    vector<int> rowsizes(parts.size());\n        \n    for(size_t i = 0 ; i < parts.size() ; i++)\n    {\n        total_chunks += parts[i]->chunkOffsets.size();\n        if (isTiled(parts[i]->header.type()))\n        {\n            tileOffsets[i] = createTileOffsets(parts[i]->header);\n        }else{\n            tileOffsets[i] = NULL;\n            // (TODO) fix this so that it doesn't need to be revised for future compression types.\n            switch(parts[i]->header.compression())\n            {\n                case DWAB_COMPRESSION :\n                    rowsizes[i] = 256;\n                    break;\n                case PIZ_COMPRESSION :\n                case B44_COMPRESSION :\n                case B44A_COMPRESSION :\n                case DWAA_COMPRESSION :\n                    rowsizes[i]=32;\n                    break;\n                case ZIP_COMPRESSION :\n                case PXR24_COMPRESSION :\n                    rowsizes[i]=16;\n                    break;\n                case ZIPS_COMPRESSION :\n                case RLE_COMPRESSION :\n                case NO_COMPRESSION :\n                    rowsizes[i]=1;\n                    break;\n                default :\n                    throw(IEX_NAMESPACE::ArgExc(\"Unknown compression method in chunk offset reconstruction\"));\n            }\n        }\n     }\n        \n     try\n     {\n            \n        //\n        // \n        //\n        \n        Int64 chunk_start = position;\n        for (size_t i = 0; i < total_chunks ; i++)\n        {\n            //\n            // do we have a part number?\n            //\n            \n            int partNumber = 0;\n            if(isMultiPart(version))\n            {\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, partNumber);\n            }\n            \n            \n            \n            if(partNumber<0 || partNumber>= static_cast<int>(parts.size()))\n            {\n                throw IEX_NAMESPACE::IoExc(\"part number out of range\");\n            }\n            \n            Header& header = parts[partNumber]->header;\n\n            // size of chunk NOT including multipart field\n            \n            Int64 size_of_chunk=0;\n\n            if (isTiled(header.type()))\n            {\n                //\n                // \n                //\n                int tilex,tiley,levelx,levely;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tilex);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tiley);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levelx);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levely);\n                \n                //std::cout << \"chunk_start for \" << tilex <<',' << tiley << ',' << levelx << ' ' << levely << ':' << chunk_start << std::endl;\n                    \n                \n                if(!tileOffsets[partNumber])\n                {\n                    // this shouldn't actually happen - we should have allocated a valid\n                    // tileOffsets for any part which isTiled\n                    throw IEX_NAMESPACE::IoExc(\"part not tiled\");\n                    \n                }\n                \n                if(!tileOffsets[partNumber]->isValidTile(tilex,tiley,levelx,levely))\n                {\n                    throw IEX_NAMESPACE::IoExc(\"invalid tile coordinates\");\n                }\n                \n                (*tileOffsets[partNumber])(tilex,tiley,levelx,levely)=chunk_start;\n                \n                // compute chunk sizes - different procedure for deep tiles and regular\n                // ones\n                if(header.type()==DEEPTILE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    //add 40 byte header to packed sizes (tile coordinates, packed sizes, unpacked size)\n                    size_of_chunk=packed_offset+packed_sample+40;\n                }\n                else\n                {\n                    \n                    // regular image has 20 bytes of header, 4 byte chunksize;\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);\n                    size_of_chunk=chunksize+20;\n                }\n            }\n            else\n            {\n                int y_coordinate;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, y_coordinate);\n                \n                \n                if(y_coordinate < header.dataWindow().min.y || y_coordinate > header.dataWindow().max.y)\n                {\n                   throw IEX_NAMESPACE::IoExc(\"y out of range\");\n                }\n                y_coordinate -= header.dataWindow().min.y;\n                y_coordinate /= rowsizes[partNumber];   \n                \n                if(y_coordinate < 0 || y_coordinate >= int(parts[partNumber]->chunkOffsets.size()))\n                {\n                   throw IEX_NAMESPACE::IoExc(\"chunk index out of range\");\n                }\n                \n                parts[partNumber]->chunkOffsets[y_coordinate]=chunk_start;\n                \n                if(header.type()==DEEPSCANLINE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    \n                    size_of_chunk=packed_offset+packed_sample+28;\n                }\n                else\n                {\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);   \n                    size_of_chunk=chunksize+8;\n                }\n                \n            }\n            \n            if(isMultiPart(version))\n            {\n                chunk_start+=4;\n            }\n            \n            chunk_start+=size_of_chunk;\n            \n            is.seekg(chunk_start);\n            \n        }\n        \n    }\n    catch (...)\n    {\n        //\n        // Suppress all exceptions.  This functions is\n        // called only to reconstruct the line offset\n        // table for incomplete files, and exceptions\n        // are likely.\n        //\n    }\n\n    // copy tiled part data back to chunk offsets\n    \n    for(size_t partNumber=0;partNumber<parts.size();partNumber++)\n    {\n        if(tileOffsets[partNumber])\n        {\n            size_t pos=0;\n            vector<vector<vector <Int64> > > offsets = tileOffsets[partNumber]->getOffsets();\n            for (size_t l = 0; l < offsets.size(); l++)\n                for (size_t y = 0; y < offsets[l].size(); y++)\n                    for (size_t x = 0; x < offsets[l][y].size(); x++)\n                    {\n                        parts[ partNumber ]->chunkOffsets[pos] = offsets[l][y][x];\n                        pos++;\n                    }\n           delete tileOffsets[partNumber];\n        }\n    }\n\n    is.clear();\n    is.seekg (position);\n}", "func_src_after": "MultiPartInputFile::Data::chunkOffsetReconstruction(OPENEXR_IMF_INTERNAL_NAMESPACE::IStream& is, const vector<InputPartData*>& parts)\n{\n    //\n    // Reconstruct broken chunk offset tables. Stop once we received any exception.\n    //\n\n    Int64 position = is.tellg();\n\n    \n    //\n    // check we understand all the parts available: if not, we cannot continue\n    // exceptions thrown here should trickle back up to the constructor\n    //\n    \n    for (size_t i = 0; i < parts.size(); i++)\n    {\n        Header& header=parts[i]->header;\n        \n        //\n        // do we have a valid type entry?\n        // we only need them for true multipart files or single part non-image (deep) files\n        //\n        if(!header.hasType() && (isMultiPart(version) || isNonImage(version)))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with missing type\");\n        }\n        if(!isSupportedType(header.type()))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with unknown type \"+header.type());\n        }\n    }\n    \n    \n    // how many chunks should we read? We should stop when we reach the end\n    size_t total_chunks = 0;\n        \n    // for tiled-based parts, array of (pointers to) tileOffsets objects\n    // to create mapping between tile coordinates and chunk table indices\n    \n    \n    vector<TileOffsets*> tileOffsets(parts.size());\n    \n    // for scanline-based parts, number of scanlines in each chunk\n    vector<int> rowsizes(parts.size());\n        \n    for(size_t i = 0 ; i < parts.size() ; i++)\n    {\n        total_chunks += parts[i]->chunkOffsets.size();\n        if (isTiled(parts[i]->header.type()))\n        {\n            tileOffsets[i] = createTileOffsets(parts[i]->header);\n        }else{\n            tileOffsets[i] = NULL;\n            // (TODO) fix this so that it doesn't need to be revised for future compression types.\n            switch(parts[i]->header.compression())\n            {\n                case DWAB_COMPRESSION :\n                    rowsizes[i] = 256;\n                    break;\n                case PIZ_COMPRESSION :\n                case B44_COMPRESSION :\n                case B44A_COMPRESSION :\n                case DWAA_COMPRESSION :\n                    rowsizes[i]=32;\n                    break;\n                case ZIP_COMPRESSION :\n                case PXR24_COMPRESSION :\n                    rowsizes[i]=16;\n                    break;\n                case ZIPS_COMPRESSION :\n                case RLE_COMPRESSION :\n                case NO_COMPRESSION :\n                    rowsizes[i]=1;\n                    break;\n                default :\n                    throw(IEX_NAMESPACE::ArgExc(\"Unknown compression method in chunk offset reconstruction\"));\n            }\n        }\n     }\n        \n     try\n     {\n            \n        //\n        // \n        //\n        \n        Int64 chunk_start = position;\n        for (size_t i = 0; i < total_chunks ; i++)\n        {\n            //\n            // do we have a part number?\n            //\n            \n            int partNumber = 0;\n            if(isMultiPart(version))\n            {\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, partNumber);\n            }\n            \n            \n            \n            if(partNumber<0 || partNumber> static_cast<int>(parts.size()))\n            {\n                throw IEX_NAMESPACE::IoExc(\"part number out of range\");\n            }\n            \n            Header& header = parts[partNumber]->header;\n\n            // size of chunk NOT including multipart field\n            \n            Int64 size_of_chunk=0;\n\n            if (isTiled(header.type()))\n            {\n                //\n                // \n                //\n                int tilex,tiley,levelx,levely;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tilex);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tiley);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levelx);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levely);\n                \n                //std::cout << \"chunk_start for \" << tilex <<',' << tiley << ',' << levelx << ' ' << levely << ':' << chunk_start << std::endl;\n                    \n                \n                if(!tileOffsets[partNumber])\n                {\n                    // this shouldn't actually happen - we should have allocated a valid\n                    // tileOffsets for any part which isTiled\n                    throw IEX_NAMESPACE::IoExc(\"part not tiled\");\n                    \n                }\n                \n                if(!tileOffsets[partNumber]->isValidTile(tilex,tiley,levelx,levely))\n                {\n                    throw IEX_NAMESPACE::IoExc(\"invalid tile coordinates\");\n                }\n                \n                (*tileOffsets[partNumber])(tilex,tiley,levelx,levely)=chunk_start;\n                \n                // compute chunk sizes - different procedure for deep tiles and regular\n                // ones\n                if(header.type()==DEEPTILE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    //add 40 byte header to packed sizes (tile coordinates, packed sizes, unpacked size)\n                    size_of_chunk=packed_offset+packed_sample+40;\n                }\n                else\n                {\n                    \n                    // regular image has 20 bytes of header, 4 byte chunksize;\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);\n                    size_of_chunk=chunksize+20;\n                }\n            }\n            else\n            {\n                int y_coordinate;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, y_coordinate);\n                \n                \n                if(y_coordinate < header.dataWindow().min.y || y_coordinate > header.dataWindow().max.y)\n                {\n                   throw IEX_NAMESPACE::IoExc(\"y out of range\");\n                }\n                y_coordinate -= header.dataWindow().min.y;\n                y_coordinate /= rowsizes[partNumber];   \n                \n                if(y_coordinate < 0 || y_coordinate >= int(parts[partNumber]->chunkOffsets.size()))\n                {\n                   throw IEX_NAMESPACE::IoExc(\"chunk index out of range\");\n                }\n                \n                parts[partNumber]->chunkOffsets[y_coordinate]=chunk_start;\n                \n                if(header.type()==DEEPSCANLINE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    \n                    size_of_chunk=packed_offset+packed_sample+28;\n                }\n                else\n                {\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);   \n                    size_of_chunk=chunksize+8;\n                }\n                \n            }\n            \n            if(isMultiPart(version))\n            {\n                chunk_start+=4;\n            }\n            \n            chunk_start+=size_of_chunk;\n            \n            is.seekg(chunk_start);\n            \n        }\n        \n    }\n    catch (...)\n    {\n        //\n        // Suppress all exceptions.  This functions is\n        // called only to reconstruct the line offset\n        // table for incomplete files, and exceptions\n        // are likely.\n        //\n    }\n\n    // copy tiled part data back to chunk offsets\n    \n    for(size_t partNumber=0;partNumber<parts.size();partNumber++)\n    {\n        if(tileOffsets[partNumber])\n        {\n            size_t pos=0;\n            vector<vector<vector <Int64> > > offsets = tileOffsets[partNumber]->getOffsets();\n            for (size_t l = 0; l < offsets.size(); l++)\n                for (size_t y = 0; y < offsets[l].size(); y++)\n                    for (size_t x = 0; x < offsets[l][y].size(); x++)\n                    {\n                        parts[ partNumber ]->chunkOffsets[pos] = offsets[l][y][x];\n                        pos++;\n                    }\n           delete tileOffsets[partNumber];\n        }\n    }\n\n    is.clear();\n    is.seekg (position);\n}", "commit_link": "github.com/AcademySoftwareFoundation/openexr/commit/8b5370c688a7362673c3a5256d93695617a4cd9a", "file_name": "OpenEXR/IlmImf/ImfMultiPartInputFile.cpp", "vul_type": "cwe-787", "description": "Write a C++ function to reconstruct chunk offset tables from an OpenEXR file stream, handling exceptions silently."}
{"func_name": "SyncExifProfile", "func_src_before": "MagickBooleanType SyncExifProfile(Image *image,StringInfo *profile)\n{\n#define MaxDirectoryStack  16\n#define EXIF_DELIMITER  \"\\n\"\n#define EXIF_NUM_FORMATS  12\n#define TAG_EXIF_OFFSET  0x8769\n#define TAG_INTEROP_OFFSET  0xa005\n\n  typedef struct _DirectoryInfo\n  {\n    unsigned char\n      *directory;\n\n    size_t\n      entry;\n  } DirectoryInfo;\n\n  DirectoryInfo\n    directory_stack[MaxDirectoryStack];\n\n  EndianType\n    endian;\n\n  size_t\n    entry,\n    length,\n    number_entries;\n\n  ssize_t\n    id,\n    level,\n    offset;\n\n  static int\n    format_bytes[] = {0, 1, 1, 2, 4, 8, 1, 1, 2, 4, 8, 4, 8};\n\n  unsigned char\n    *directory,\n    *exif;\n\n  /*\n    Set EXIF resolution tag.\n  */\n  length=GetStringInfoLength(profile);\n  exif=GetStringInfoDatum(profile);\n  if (length < 16)\n    return(MagickFalse);\n  id=(ssize_t) ReadProfileShort(LSBEndian,exif);\n  if ((id != 0x4949) && (id != 0x4D4D))\n    {\n      while (length != 0)\n      {\n        if (ReadProfileByte(&exif,&length) != 0x45)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x78)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x69)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x66)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x00)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x00)\n          continue;\n        break;\n      }\n      if (length < 16)\n        return(MagickFalse);\n      id=(ssize_t) ReadProfileShort(LSBEndian,exif);\n    }\n  endian=LSBEndian;\n  if (id == 0x4949)\n    endian=LSBEndian;\n  else\n    if (id == 0x4D4D)\n      endian=MSBEndian;\n    else\n      return(MagickFalse);\n  if (ReadProfileShort(endian,exif+2) != 0x002a)\n    return(MagickFalse);\n  /*\n    This the offset to the first IFD.\n  */\n  offset=(ssize_t) ReadProfileLong(endian,exif+4);\n  if ((offset < 0) || (size_t) offset >= length)\n    return(MagickFalse);\n  directory=exif+offset;\n  level=0;\n  entry=0;\n  do\n  {\n    if (level > 0)\n      {\n        level--;\n        directory=directory_stack[level].directory;\n        entry=directory_stack[level].entry;\n      }\n    if ((directory < exif) || (directory > (exif+length-2)))\n      break;\n    /*\n      Determine how many entries there are in the current IFD.\n    */\n    number_entries=ReadProfileShort(endian,directory);\n    for ( ; entry < number_entries; entry++)\n    {\n      int\n        components;\n\n      register unsigned char\n        *p,\n        *q;\n\n      size_t\n        number_bytes;\n\n      ssize_t\n        format,\n        tag_value;\n\n      q=(unsigned char *) (directory+2+(12*entry));\n      if (q > (exif+length-12))\n        break;  /* corrupt EXIF */\n      tag_value=(ssize_t) ReadProfileShort(endian,q);\n      format=(ssize_t) ReadProfileShort(endian,q+2);\n      if ((format-1) >= EXIF_NUM_FORMATS)\n        break;\n      components=(ssize_t) ReadProfileLong(endian,q+4);\n      if (components < 0)\n        break;  /* corrupt EXIF */\n      number_bytes=(size_t) components*format_bytes[format];\n      if ((ssize_t) number_bytes < components)\n        break;  /* prevent overflow */\n      if (number_bytes <= 4)\n        p=q+8;\n      else\n        {\n          /*\n            The directory entry contains an offset.\n          */\n          offset=(ssize_t)  ReadProfileLong(endian,q+8);\n          if ((size_t) (offset+number_bytes) > length)\n            continue;\n          if (~length < number_bytes)\n            continue;  /* prevent overflow */\n          p=(unsigned char *) (exif+offset);\n        }\n      switch (tag_value)\n      {\n        case 0x011a:\n        {\n          (void) WriteProfileLong(endian,(size_t) (image->resolution.x+0.5),p);\n          (void) WriteProfileLong(endian,1UL,p+4);\n          break;\n        }\n        case 0x011b:\n        {\n          (void) WriteProfileLong(endian,(size_t) (image->resolution.y+0.5),p);\n          (void) WriteProfileLong(endian,1UL,p+4);\n          break;\n        }\n        case 0x0112:\n        {\n          if (number_bytes == 4)\n            {\n              (void) WriteProfileLong(endian,(size_t) image->orientation,p);\n              break;\n            }\n          (void) WriteProfileShort(endian,(unsigned short) image->orientation,\n            p);\n          break;\n        }\n        case 0x0128:\n        {\n          if (number_bytes == 4)\n            {\n              (void) WriteProfileLong(endian,(size_t) (image->units+1),p);\n              break;\n            }\n          (void) WriteProfileShort(endian,(unsigned short) (image->units+1),p);\n          break;\n        }\n        default:\n          break;\n      }\n      if ((tag_value == TAG_EXIF_OFFSET) || (tag_value == TAG_INTEROP_OFFSET))\n        {\n          offset=(ssize_t)  ReadProfileLong(endian,p);\n          if (((size_t) offset < length) && (level < (MaxDirectoryStack-2)))\n            {\n              directory_stack[level].directory=directory;\n              entry++;\n              directory_stack[level].entry=entry;\n              level++;\n              directory_stack[level].directory=exif+offset;\n              directory_stack[level].entry=0;\n              level++;\n              if ((directory+2+(12*number_entries)) > (exif+length))\n                break;\n              offset=(ssize_t)  ReadProfileLong(endian,directory+2+(12*\n                number_entries));\n              if ((offset != 0) && ((size_t) offset < length) &&\n                  (level < (MaxDirectoryStack-2)))\n                {\n                  directory_stack[level].directory=exif+offset;\n                  directory_stack[level].entry=0;\n                  level++;\n                }\n            }\n          break;\n        }\n    }\n  } while (level > 0);\n  return(MagickTrue);\n}", "func_src_after": "MagickBooleanType SyncExifProfile(Image *image,StringInfo *profile)\n{\n#define MaxDirectoryStack  16\n#define EXIF_DELIMITER  \"\\n\"\n#define EXIF_NUM_FORMATS  12\n#define TAG_EXIF_OFFSET  0x8769\n#define TAG_INTEROP_OFFSET  0xa005\n\n  typedef struct _DirectoryInfo\n  {\n    unsigned char\n      *directory;\n\n    size_t\n      entry;\n  } DirectoryInfo;\n\n  DirectoryInfo\n    directory_stack[MaxDirectoryStack];\n\n  EndianType\n    endian;\n\n  size_t\n    entry,\n    length,\n    number_entries;\n\n  ssize_t\n    id,\n    level,\n    offset;\n\n  static int\n    format_bytes[] = {0, 1, 1, 2, 4, 8, 1, 1, 2, 4, 8, 4, 8};\n\n  unsigned char\n    *directory,\n    *exif;\n\n  /*\n    Set EXIF resolution tag.\n  */\n  length=GetStringInfoLength(profile);\n  exif=GetStringInfoDatum(profile);\n  if (length < 16)\n    return(MagickFalse);\n  id=(ssize_t) ReadProfileShort(LSBEndian,exif);\n  if ((id != 0x4949) && (id != 0x4D4D))\n    {\n      while (length != 0)\n      {\n        if (ReadProfileByte(&exif,&length) != 0x45)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x78)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x69)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x66)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x00)\n          continue;\n        if (ReadProfileByte(&exif,&length) != 0x00)\n          continue;\n        break;\n      }\n      if (length < 16)\n        return(MagickFalse);\n      id=(ssize_t) ReadProfileShort(LSBEndian,exif);\n    }\n  endian=LSBEndian;\n  if (id == 0x4949)\n    endian=LSBEndian;\n  else\n    if (id == 0x4D4D)\n      endian=MSBEndian;\n    else\n      return(MagickFalse);\n  if (ReadProfileShort(endian,exif+2) != 0x002a)\n    return(MagickFalse);\n  /*\n    This the offset to the first IFD.\n  */\n  offset=(ssize_t) ReadProfileLong(endian,exif+4);\n  if ((offset < 0) || (size_t) offset >= length)\n    return(MagickFalse);\n  directory=exif+offset;\n  level=0;\n  entry=0;\n  do\n  {\n    if (level > 0)\n      {\n        level--;\n        directory=directory_stack[level].directory;\n        entry=directory_stack[level].entry;\n      }\n    if ((directory < exif) || (directory > (exif+length-2)))\n      break;\n    /*\n      Determine how many entries there are in the current IFD.\n    */\n    number_entries=ReadProfileShort(endian,directory);\n    for ( ; entry < number_entries; entry++)\n    {\n      int\n        components;\n\n      register unsigned char\n        *p,\n        *q;\n\n      size_t\n        number_bytes;\n\n      ssize_t\n        format,\n        tag_value;\n\n      q=(unsigned char *) (directory+2+(12*entry));\n      if (q > (exif+length-12))\n        break;  /* corrupt EXIF */\n      tag_value=(ssize_t) ReadProfileShort(endian,q);\n      format=(ssize_t) ReadProfileShort(endian,q+2);\n      if ((format < 0) || ((format-1) >= EXIF_NUM_FORMATS))\n        break;\n      components=(ssize_t) ReadProfileLong(endian,q+4);\n      if (components < 0)\n        break;  /* corrupt EXIF */\n      number_bytes=(size_t) components*format_bytes[format];\n      if ((ssize_t) number_bytes < components)\n        break;  /* prevent overflow */\n      if (number_bytes <= 4)\n        p=q+8;\n      else\n        {\n          /*\n            The directory entry contains an offset.\n          */\n          offset=(ssize_t)  ReadProfileLong(endian,q+8);\n          if ((size_t) (offset+number_bytes) > length)\n            continue;\n          if (~length < number_bytes)\n            continue;  /* prevent overflow */\n          p=(unsigned char *) (exif+offset);\n        }\n      switch (tag_value)\n      {\n        case 0x011a:\n        {\n          (void) WriteProfileLong(endian,(size_t) (image->resolution.x+0.5),p);\n          (void) WriteProfileLong(endian,1UL,p+4);\n          break;\n        }\n        case 0x011b:\n        {\n          (void) WriteProfileLong(endian,(size_t) (image->resolution.y+0.5),p);\n          (void) WriteProfileLong(endian,1UL,p+4);\n          break;\n        }\n        case 0x0112:\n        {\n          if (number_bytes == 4)\n            {\n              (void) WriteProfileLong(endian,(size_t) image->orientation,p);\n              break;\n            }\n          (void) WriteProfileShort(endian,(unsigned short) image->orientation,\n            p);\n          break;\n        }\n        case 0x0128:\n        {\n          if (number_bytes == 4)\n            {\n              (void) WriteProfileLong(endian,(size_t) (image->units+1),p);\n              break;\n            }\n          (void) WriteProfileShort(endian,(unsigned short) (image->units+1),p);\n          break;\n        }\n        default:\n          break;\n      }\n      if ((tag_value == TAG_EXIF_OFFSET) || (tag_value == TAG_INTEROP_OFFSET))\n        {\n          offset=(ssize_t)  ReadProfileLong(endian,p);\n          if (((size_t) offset < length) && (level < (MaxDirectoryStack-2)))\n            {\n              directory_stack[level].directory=directory;\n              entry++;\n              directory_stack[level].entry=entry;\n              level++;\n              directory_stack[level].directory=exif+offset;\n              directory_stack[level].entry=0;\n              level++;\n              if ((directory+2+(12*number_entries)) > (exif+length))\n                break;\n              offset=(ssize_t)  ReadProfileLong(endian,directory+2+(12*\n                number_entries));\n              if ((offset != 0) && ((size_t) offset < length) &&\n                  (level < (MaxDirectoryStack-2)))\n                {\n                  directory_stack[level].directory=exif+offset;\n                  directory_stack[level].entry=0;\n                  level++;\n                }\n            }\n          break;\n        }\n    }\n  } while (level > 0);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/a7bb158b7bedd1449a34432feb3a67c8f1873bfa", "file_name": "MagickCore/profile.c", "vul_type": "cwe-125", "description": "Write a C function to synchronize EXIF profile resolution tags with an image's resolution and orientation."}
{"func_name": "AllocateDataSet", "func_src_before": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    t-> Data = (char**)AllocChunk (it8, ((cmsUInt32Number) t->nSamples + 1) * ((cmsUInt32Number) t->nPatches + 1) *sizeof (char*));\n    if (t->Data == NULL) {\n\n        SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n    }\n\n}", "func_src_after": "void AllocateDataSet(cmsIT8* it8)\n{\n    TABLE* t = GetTable(it8);\n\n    if (t -> Data) return;    // Already allocated\n\n    t-> nSamples   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_FIELDS\"));\n    t-> nPatches   = atoi(cmsIT8GetProperty(it8, \"NUMBER_OF_SETS\"));\n\n    if (t -> nSamples < 0 || t->nSamples > 0x7ffe || t->nPatches < 0 || t->nPatches > 0x7ffe)\n    {\n        SynError(it8, \"AllocateDataSet: too much data\");\n    }\n    else {\n        t->Data = (char**)AllocChunk(it8, ((cmsUInt32Number)t->nSamples + 1) * ((cmsUInt32Number)t->nPatches + 1) * sizeof(char*));\n        if (t->Data == NULL) {\n\n            SynError(it8, \"AllocateDataSet: Unable to allocate data array\");\n        }\n    }\n\n}", "commit_link": "github.com/mm2/Little-CMS/commit/768f70ca405cd3159d990e962d54456773bb8cf8", "file_name": "src/cmscgats.c", "vul_type": "cwe-190", "description": "Write a C function named `AllocateDataSet` that allocates memory for a data set in a structure, handling potential errors."}
{"func_name": "handle_client_startup", "func_src_before": "static bool handle_client_startup(PgSocket *client, PktHdr *pkt)\n{\n\tconst char *passwd;\n\tconst uint8_t *key;\n\tbool ok;\n\n\tSBuf *sbuf = &client->sbuf;\n\n\t/* don't tolerate partial packets */\n\tif (incomplete_pkt(pkt)) {\n\t\tdisconnect_client(client, true, \"client sent partial pkt in startup phase\");\n\t\treturn false;\n\t}\n\n\tif (client->wait_for_welcome) {\n\t\tif  (finish_client_login(client)) {\n\t\t\t/* the packet was already parsed */\n\t\t\tsbuf_prepare_skip(sbuf, pkt->len);\n\t\t\treturn true;\n\t\t} else\n\t\t\treturn false;\n\t}\n\n\tswitch (pkt->type) {\n\tcase PKT_SSLREQ:\n\t\tslog_noise(client, \"C: req SSL\");\n\t\tslog_noise(client, \"P: nak\");\n\n\t\t/* reject SSL attempt */\n\t\tif (!sbuf_answer(&client->sbuf, \"N\", 1)) {\n\t\t\tdisconnect_client(client, false, \"failed to nak SSL\");\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase PKT_STARTUP_V2:\n\t\tdisconnect_client(client, true, \"Old V2 protocol not supported\");\n\t\treturn false;\n\tcase PKT_STARTUP:\n\t\tif (client->pool) {\n\t\t\tdisconnect_client(client, true, \"client re-sent startup pkt\");\n\t\t\treturn false;\n\t\t}\n\n\t\tif (!decide_startup_pool(client, pkt))\n\t\t\treturn false;\n\n\t\tif (client->pool->db->admin) {\n\t\t\tif (!admin_pre_login(client))\n\t\t\t\treturn false;\n\t\t}\n\n\t\tif (cf_auth_type <= AUTH_TRUST || client->own_user) {\n\t\t\tif (!finish_client_login(client))\n\t\t\t\treturn false;\n\t\t} else {\n\t\t\tif (!send_client_authreq(client)) {\n\t\t\t\tdisconnect_client(client, false, \"failed to send auth req\");\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase 'p':\t\t/* PasswordMessage */\n\t\t/* haven't requested it */\n\t\tif (cf_auth_type <= AUTH_TRUST) {\n\t\t\tdisconnect_client(client, true, \"unrequested passwd pkt\");\n\t\t\treturn false;\n\t\t}\n\n\t\tok = mbuf_get_string(&pkt->data, &passwd);\n\t\tif (ok && check_client_passwd(client, passwd)) {\n\t\t\tif (!finish_client_login(client))\n\t\t\t\treturn false;\n\t\t} else {\n\t\t\tdisconnect_client(client, true, \"Auth failed\");\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase PKT_CANCEL:\n\t\tif (mbuf_avail_for_read(&pkt->data) == BACKENDKEY_LEN\n\t\t    && mbuf_get_bytes(&pkt->data, BACKENDKEY_LEN, &key))\n\t\t{\n\t\t\tmemcpy(client->cancel_key, key, BACKENDKEY_LEN);\n\t\t\taccept_cancel_request(client);\n\t\t} else\n\t\t\tdisconnect_client(client, false, \"bad cancel request\");\n\t\treturn false;\n\tdefault:\n\t\tdisconnect_client(client, false, \"bad packet\");\n\t\treturn false;\n\t}\n\tsbuf_prepare_skip(sbuf, pkt->len);\n\tclient->request_time = get_cached_time();\n\treturn true;\n}", "func_src_after": "static bool handle_client_startup(PgSocket *client, PktHdr *pkt)\n{\n\tconst char *passwd;\n\tconst uint8_t *key;\n\tbool ok;\n\n\tSBuf *sbuf = &client->sbuf;\n\n\t/* don't tolerate partial packets */\n\tif (incomplete_pkt(pkt)) {\n\t\tdisconnect_client(client, true, \"client sent partial pkt in startup phase\");\n\t\treturn false;\n\t}\n\n\tif (client->wait_for_welcome) {\n\t\tif  (finish_client_login(client)) {\n\t\t\t/* the packet was already parsed */\n\t\t\tsbuf_prepare_skip(sbuf, pkt->len);\n\t\t\treturn true;\n\t\t} else\n\t\t\treturn false;\n\t}\n\n\tswitch (pkt->type) {\n\tcase PKT_SSLREQ:\n\t\tslog_noise(client, \"C: req SSL\");\n\t\tslog_noise(client, \"P: nak\");\n\n\t\t/* reject SSL attempt */\n\t\tif (!sbuf_answer(&client->sbuf, \"N\", 1)) {\n\t\t\tdisconnect_client(client, false, \"failed to nak SSL\");\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase PKT_STARTUP_V2:\n\t\tdisconnect_client(client, true, \"Old V2 protocol not supported\");\n\t\treturn false;\n\tcase PKT_STARTUP:\n\t\tif (client->pool) {\n\t\t\tdisconnect_client(client, true, \"client re-sent startup pkt\");\n\t\t\treturn false;\n\t\t}\n\n\t\tif (!decide_startup_pool(client, pkt))\n\t\t\treturn false;\n\n\t\tif (client->pool->db->admin) {\n\t\t\tif (!admin_pre_login(client))\n\t\t\t\treturn false;\n\t\t}\n\n\t\tif (cf_auth_type <= AUTH_TRUST || client->own_user) {\n\t\t\tif (!finish_client_login(client))\n\t\t\t\treturn false;\n\t\t} else {\n\t\t\tif (!send_client_authreq(client)) {\n\t\t\t\tdisconnect_client(client, false, \"failed to send auth req\");\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tbreak;\n\tcase 'p':\t\t/* PasswordMessage */\n\t\t/* too early */\n\t\tif (!client->auth_user) {\n\t\t\tdisconnect_client(client, true, \"client password pkt before startup packet\");\n\t\t\treturn false;\n\t\t}\n\n\t\t/* haven't requested it */\n\t\tif (cf_auth_type <= AUTH_TRUST) {\n\t\t\tdisconnect_client(client, true, \"unrequested passwd pkt\");\n\t\t\treturn false;\n\t\t}\n\n\t\tok = mbuf_get_string(&pkt->data, &passwd);\n\t\tif (ok && check_client_passwd(client, passwd)) {\n\t\t\tif (!finish_client_login(client))\n\t\t\t\treturn false;\n\t\t} else {\n\t\t\tdisconnect_client(client, true, \"Auth failed\");\n\t\t\treturn false;\n\t\t}\n\t\tbreak;\n\tcase PKT_CANCEL:\n\t\tif (mbuf_avail_for_read(&pkt->data) == BACKENDKEY_LEN\n\t\t    && mbuf_get_bytes(&pkt->data, BACKENDKEY_LEN, &key))\n\t\t{\n\t\t\tmemcpy(client->cancel_key, key, BACKENDKEY_LEN);\n\t\t\taccept_cancel_request(client);\n\t\t} else\n\t\t\tdisconnect_client(client, false, \"bad cancel request\");\n\t\treturn false;\n\tdefault:\n\t\tdisconnect_client(client, false, \"bad packet\");\n\t\treturn false;\n\t}\n\tsbuf_prepare_skip(sbuf, pkt->len);\n\tclient->request_time = get_cached_time();\n\treturn true;\n}", "commit_link": "github.com/pgbouncer/pgbouncer/commit/74d6e5f7de5ec736f71204b7b422af7380c19ac5", "file_name": "src/client.c", "vul_type": "cwe-476", "description": "Write a C function `handle_client_startup` to process different types of startup packets for a PostgreSQL client connection."}
{"func_name": "test_create_modify_host", "func_src_before": "    def test_create_modify_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack(NO_FC_HOST_RET), ''])\n\n        create_host_cmd = ('createhost -add fakehost '\n                           '123456789012345 123456789054321')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_modify_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack(NO_FC_HOST_RET), ''])\n\n        create_host_cmd = ['createhost', '-add', 'fakehost', '123456789012345',\n                           '123456789054321']\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack(FC_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying a host in an HP 3PAR storage system."}
{"func_name": "cs_winkernel_malloc", "func_src_before": "void * CAPSTONE_API cs_winkernel_malloc(size_t size)\n{\n\t// Disallow zero length allocation because they waste pool header space and,\n\t// in many cases, indicate a potential validation issue in the calling code.\n\tNT_ASSERT(size);\n\n\t// FP; a use of NonPagedPool is required for Windows 7 support\n#pragma prefast(suppress : 30030)\t\t// Allocating executable POOL_TYPE memory\n\tCS_WINKERNEL_MEMBLOCK *block = (CS_WINKERNEL_MEMBLOCK *)ExAllocatePoolWithTag(\n\t\t\tNonPagedPool, size + sizeof(CS_WINKERNEL_MEMBLOCK), CS_WINKERNEL_POOL_TAG);\n\tif (!block) {\n\t\treturn NULL;\n\t}\n\tblock->size = size;\n\n\treturn block->data;\n}", "func_src_after": "void * CAPSTONE_API cs_winkernel_malloc(size_t size)\n{\n\t// Disallow zero length allocation because they waste pool header space and,\n\t// in many cases, indicate a potential validation issue in the calling code.\n\tNT_ASSERT(size);\n\n\t// FP; a use of NonPagedPool is required for Windows 7 support\n#pragma prefast(suppress : 30030)\t\t// Allocating executable POOL_TYPE memory\n\tsize_t number_of_bytes = 0;\n\tCS_WINKERNEL_MEMBLOCK *block = NULL;\n\t// A specially crafted size value can trigger the overflow.\n\t// If the sum in a value that overflows or underflows the capacity of the type,\n\t// the function returns NULL.\n\tif (!NT_SUCCESS(RtlSizeTAdd(size, sizeof(CS_WINKERNEL_MEMBLOCK), &number_of_bytes))) {\n\t\treturn NULL;\n\t}\n\tblock = (CS_WINKERNEL_MEMBLOCK *)ExAllocatePoolWithTag(\n\t\t\tNonPagedPool, number_of_bytes, CS_WINKERNEL_POOL_TAG);\n\tif (!block) {\n\t\treturn NULL;\n\t}\n\tblock->size = size;\n\n\treturn block->data;\n}", "commit_link": "github.com/aquynh/capstone/commit/6fe86eef621b9849f51a5e1e5d73258a93440403", "file_name": "windows/winkernel_mm.c", "vul_type": "cwe-190", "description": "Write a C function named `cs_winkernel_malloc` that allocates memory in the Windows kernel, ensuring it's non-zero and handles potential size overflows."}
{"func_name": "ReadMATImage", "func_src_before": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  clone_info=(ImageInfo *) NULL;\n  if (ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n      MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if ((image != image2) && (image2 != (Image *) NULL))\n        image2=DestroyImage(image2);\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if (MATLAB_HDR.DataType!=miMATRIX)\n      {\n        clone_info=DestroyImageInfo(clone_info);\n        continue;  /* skip another objects. */\n      }\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default:\n        if (clone_info != (ImageInfo *) NULL)\n          clone_info=DestroyImageInfo(clone_info);\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      {\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (clone_info)\n      clone_info=DestroyImageInfo(clone_info);\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          if (tmp == image2)\n            image2=(Image *) NULL;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if (image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\")\n  else\n    if ((image != image2) && (image2 != (Image *) NULL))\n      image2=DestroyImage(image2);\n  return (image);\n}", "func_src_after": "static Image *ReadMATImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n  Image *image, *image2=NULL,\n   *rotated_image;\n  register Quantum *q;\n\n  unsigned int status;\n  MATHeader MATLAB_HDR;\n  size_t size;\n  size_t CellType;\n  QuantumInfo *quantum_info;\n  ImageInfo *clone_info;\n  int i;\n  ssize_t ldblk;\n  unsigned char *BImgBuff = NULL;\n  double MinVal, MaxVal;\n  unsigned z, z2;\n  unsigned Frames;\n  int logging;\n  int sample_size;\n  MagickOffsetType filepos=0x80;\n  BlobInfo *blob;\n  size_t one;\n\n  unsigned int (*ReadBlobXXXLong)(Image *image);\n  unsigned short (*ReadBlobXXXShort)(Image *image);\n  void (*ReadBlobDoublesXXX)(Image * image, size_t len, double *data);\n  void (*ReadBlobFloatsXXX)(Image * image, size_t len, float *data);\n\n\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  logging = LogMagickEvent(CoderEvent,GetMagickModule(),\"enter\");\n\n  /*\n     Open image file.\n   */\n  image = AcquireImage(image_info,exception);\n\n  status = OpenBlob(image_info, image, ReadBinaryBlobMode, exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n     Read MATLAB image.\n   */\n  quantum_info=(QuantumInfo *) NULL;\n  clone_info=(ImageInfo *) NULL;\n  if (ReadBlob(image,124,(unsigned char *) &MATLAB_HDR.identific) != 124)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  if (strncmp(MATLAB_HDR.identific,\"MATLAB\",6) != 0)\n    {\n      image2=ReadMATImageV4(image_info,image,exception);\n      if (image2  == NULL)\n        goto MATLAB_KO;\n      image=image2;\n      goto END_OF_READING;\n    }\n  MATLAB_HDR.Version = ReadBlobLSBShort(image);\n  if(ReadBlob(image,2,(unsigned char *) &MATLAB_HDR.EndianIndicator) != 2)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n\n  if (logging)\n    (void) LogMagickEvent(CoderEvent,GetMagickModule(),\"  Endian %c%c\",\n      MATLAB_HDR.EndianIndicator[0],MATLAB_HDR.EndianIndicator[1]);\n  if (!strncmp(MATLAB_HDR.EndianIndicator, \"IM\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobLSBLong;\n    ReadBlobXXXShort = ReadBlobLSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesLSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsLSB;\n    image->endian = LSBEndian;\n  }\n  else if (!strncmp(MATLAB_HDR.EndianIndicator, \"MI\", 2))\n  {\n    ReadBlobXXXLong = ReadBlobMSBLong;\n    ReadBlobXXXShort = ReadBlobMSBShort;\n    ReadBlobDoublesXXX = ReadBlobDoublesMSB;\n    ReadBlobFloatsXXX = ReadBlobFloatsMSB;\n    image->endian = MSBEndian;\n  }\n  else\n    goto MATLAB_KO;    /* unsupported endian */\n\n  if (strncmp(MATLAB_HDR.identific, \"MATLAB\", 6))\n    {\nMATLAB_KO:\n      if ((image != image2) && (image2 != (Image *) NULL))\n        image2=DestroyImage(image2);\n      if (clone_info != (ImageInfo *) NULL)\n        clone_info=DestroyImageInfo(clone_info);\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    }\n\n  filepos = TellBlob(image);\n  while(!EOFBlob(image)) /* object parser loop */\n  {\n    Frames = 1;\n    (void) SeekBlob(image,filepos,SEEK_SET);\n    /* printf(\"pos=%X\\n\",TellBlob(image)); */\n\n    MATLAB_HDR.DataType = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    MATLAB_HDR.ObjectSize = ReadBlobXXXLong(image);\n    if(EOFBlob(image)) break;\n    if((MagickSizeType) (MATLAB_HDR.ObjectSize+filepos) > GetBlobSize(image))\n      goto MATLAB_KO;\n    filepos += MATLAB_HDR.ObjectSize + 4 + 4;\n\n    clone_info=CloneImageInfo(image_info);\n    image2 = image;\n#if defined(MAGICKCORE_ZLIB_DELEGATE)\n    if(MATLAB_HDR.DataType == miCOMPRESSED)\n    {\n      image2 = decompress_block(image,&MATLAB_HDR.ObjectSize,clone_info,exception);\n      if(image2==NULL) continue;\n      MATLAB_HDR.DataType = ReadBlobXXXLong(image2); /* replace compressed object type. */\n    }\n#endif\n\n    if (MATLAB_HDR.DataType!=miMATRIX)\n      {\n        clone_info=DestroyImageInfo(clone_info);\n        continue;  /* skip another objects. */\n      }\n\n    MATLAB_HDR.unknown1 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.unknown2 = ReadBlobXXXLong(image2);\n\n    MATLAB_HDR.unknown5 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.StructureClass = MATLAB_HDR.unknown5 & 0xFF;\n    MATLAB_HDR.StructureFlag = (MATLAB_HDR.unknown5>>8) & 0xFF;\n\n    MATLAB_HDR.unknown3 = ReadBlobXXXLong(image2);\n    if(image!=image2)\n      MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);  /* ??? don't understand why ?? */\n    MATLAB_HDR.unknown4 = ReadBlobXXXLong(image2);\n    MATLAB_HDR.DimFlag = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeX = ReadBlobXXXLong(image2);\n    MATLAB_HDR.SizeY = ReadBlobXXXLong(image2);\n\n\n    switch(MATLAB_HDR.DimFlag)\n    {\n      case  8: z2=z=1; break;      /* 2D matrix*/\n      case 12: z2=z = ReadBlobXXXLong(image2);  /* 3D matrix RGB*/\n           (void) ReadBlobXXXLong(image2);\n         if(z!=3) ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         break;\n      case 16: z2=z = ReadBlobXXXLong(image2);  /* 4D matrix animation */\n         if(z!=3 && z!=1)\n            ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n         Frames = ReadBlobXXXLong(image2);\n         if (Frames == 0)\n           ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n         break;\n      default:\n        if (clone_info != (ImageInfo *) NULL)\n          clone_info=DestroyImageInfo(clone_info);\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        ThrowReaderException(CoderError, \"MultidimensionalMatricesAreNotSupported\");\n    }\n\n    MATLAB_HDR.Flag1 = ReadBlobXXXShort(image2);\n    MATLAB_HDR.NameFlag = ReadBlobXXXShort(image2);\n\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n          \"MATLAB_HDR.StructureClass %d\",MATLAB_HDR.StructureClass);\n    if (MATLAB_HDR.StructureClass != mxCHAR_CLASS &&\n        MATLAB_HDR.StructureClass != mxSINGLE_CLASS &&    /* float + complex float */\n        MATLAB_HDR.StructureClass != mxDOUBLE_CLASS &&    /* double + complex double */\n        MATLAB_HDR.StructureClass != mxINT8_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT8_CLASS &&    /* uint8 + uint8 3D */\n        MATLAB_HDR.StructureClass != mxINT16_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT16_CLASS &&    /* uint16 + uint16 3D */\n        MATLAB_HDR.StructureClass != mxINT32_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT32_CLASS &&    /* uint32 + uint32 3D */\n        MATLAB_HDR.StructureClass != mxINT64_CLASS &&\n        MATLAB_HDR.StructureClass != mxUINT64_CLASS)    /* uint64 + uint64 3D */\n      ThrowReaderException(CoderError,\"UnsupportedCellTypeInTheMatrix\");\n\n    switch (MATLAB_HDR.NameFlag)\n    {\n      case 0:\n        size = ReadBlobXXXLong(image2);  /* Object name string size */\n        size = 4 * (ssize_t) ((size + 3 + 1) / 4);\n        (void) SeekBlob(image2, size, SEEK_CUR);\n        break;\n      case 1:\n      case 2:\n      case 3:\n      case 4:\n        (void) ReadBlob(image2, 4, (unsigned char *) &size); /* Object name string */\n        break;\n      default:\n        goto MATLAB_KO;\n    }\n\n    CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n    if (logging)\n      (void) LogMagickEvent(CoderEvent,GetMagickModule(),\n        \"MATLAB_HDR.CellType: %.20g\",(double) CellType);\n\n    (void) ReadBlob(image2, 4, (unsigned char *) &size);     /* data size */\n\n    NEXT_FRAME:\n    switch (CellType)\n    {\n      case miINT8:\n      case miUINT8:\n        sample_size = 8;\n        if(MATLAB_HDR.StructureFlag & FLAG_LOGICAL)\n          image->depth = 1;\n        else\n          image->depth = 8;         /* Byte type cell */\n        ldblk = (ssize_t) MATLAB_HDR.SizeX;\n        break;\n      case miINT16:\n      case miUINT16:\n        sample_size = 16;\n        image->depth = 16;        /* Word type cell */\n        ldblk = (ssize_t) (2 * MATLAB_HDR.SizeX);\n        break;\n      case miINT32:\n      case miUINT32:\n        sample_size = 32;\n        image->depth = 32;        /* Dword type cell */\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miINT64:\n      case miUINT64:\n        sample_size = 64;\n        image->depth = 64;        /* Qword type cell */\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      case miSINGLE:\n        sample_size = 32;\n        image->depth = 32;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {              /* complex float type cell */\n  }\n        ldblk = (ssize_t) (4 * MATLAB_HDR.SizeX);\n        break;\n      case miDOUBLE:\n        sample_size = 64;\n        image->depth = 64;        /* double type cell */\n        (void) SetImageOption(clone_info,\"quantum:format\",\"floating-point\");\nDisableMSCWarning(4127)\n        if (sizeof(double) != 8)\nRestoreMSCWarning\n          ThrowReaderException(CoderError, \"IncompatibleSizeOfDouble\");\n        if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n  {                         /* complex double type cell */\n  }\n        ldblk = (ssize_t) (8 * MATLAB_HDR.SizeX);\n        break;\n      default:\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        if (clone_info)\n          clone_info=DestroyImageInfo(clone_info);\n        ThrowReaderException(CoderError, \"UnsupportedCellTypeInTheMatrix\");\n    }\n    (void) sample_size;\n    image->columns = MATLAB_HDR.SizeX;\n    image->rows = MATLAB_HDR.SizeY;\n    one=1;\n    image->colors = one << image->depth;\n    if (image->columns == 0 || image->rows == 0)\n      goto MATLAB_KO;\n    if((unsigned long)ldblk*MATLAB_HDR.SizeY > MATLAB_HDR.ObjectSize)\n      goto MATLAB_KO;\n    /* Image is gray when no complex flag is set and 2D Matrix */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      {\n        image->type=GrayscaleType;\n        SetImageColorspace(image,GRAYColorspace,exception);\n      }\n\n\n    /*\n      If ping is true, then only set image size and colors without\n      reading any image data.\n    */\n    if (image_info->ping)\n    {\n      size_t temp = image->columns;\n      image->columns = image->rows;\n      image->rows = temp;\n      goto done_reading; /* !!!!!! BAD  !!!! */\n    }\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      {\n        if ((image != image2) && (image2 != (Image *) NULL))\n          image2=DestroyImage(image2);\n        return(DestroyImageList(image));\n      }\n    quantum_info=AcquireQuantumInfo(clone_info,image);\n    if (quantum_info == (QuantumInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n\n  /* ----- Load raster data ----- */\n    BImgBuff = (unsigned char *) AcquireQuantumMemory((size_t) (ldblk),sizeof(double));    /* Ldblk was set in the check phase */\n    if (BImgBuff == NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ResetMagickMemory(BImgBuff,0,ldblk*sizeof(double));\n\n    MinVal = 0;\n    MaxVal = 0;\n    if (CellType==miDOUBLE || CellType==miSINGLE)        /* Find Min and Max Values for floats */\n    {\n      CalcMinMax(image2, image_info->endian,  MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &quantum_info->minimum, &quantum_info->maximum);\n    }\n\n    /* Main loop for reading all scanlines */\n    if(z==1) z=0; /* read grey scanlines */\n    /* else read color scanlines */\n    do\n    {\n      for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n      {\n        q=GetAuthenticPixels(image,0,MATLAB_HDR.SizeY-i-1,image->columns,1,exception);\n        if (q == (Quantum *) NULL)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT set image pixels returns unexpected NULL on a row %u.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto done_reading;    /* Skip image rotation, when cannot set image pixels    */\n  }\n        if(ReadBlob(image2,ldblk,(unsigned char *)BImgBuff) != (ssize_t) ldblk)\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n             \"  MAT cannot read scanrow %u from a file.\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n        if((CellType==miINT8 || CellType==miUINT8) && (MATLAB_HDR.StructureFlag & FLAG_LOGICAL))\n        {\n          FixLogical((unsigned char *)BImgBuff,ldblk);\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n    {\nImportQuantumPixelsFailed:\n      if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n              \"  MAT failed to ImportQuantumPixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n      break;\n    }\n        }\n        else\n        {\n          if(ImportQuantumPixels(image,(CacheView *) NULL,quantum_info,z2qtype[z],BImgBuff,exception) <= 0)\n      goto ImportQuantumPixelsFailed;\n\n\n          if (z<=1 &&       /* fix only during a last pass z==0 || z==1 */\n          (CellType==miINT8 || CellType==miINT16 || CellType==miINT32 || CellType==miINT64))\n      FixSignedValues(image,q,MATLAB_HDR.SizeX);\n        }\n\n        if (!SyncAuthenticPixels(image,exception))\n  {\n    if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\n            \"  MAT failed to sync image pixels for a row %u\", (unsigned)(MATLAB_HDR.SizeY-i-1));\n    goto ExitLoop;\n  }\n      }\n    } while(z-- >= 2);\nExitLoop:\n\n\n    /* Read complex part of numbers here */\n    if (MATLAB_HDR.StructureFlag & FLAG_COMPLEX)\n    {        /* Find Min and Max Values for complex parts of floats */\n      CellType = ReadBlobXXXLong(image2);    /* Additional object type */\n      i = ReadBlobXXXLong(image2);           /* size of a complex part - toss away*/\n\n      if (CellType==miDOUBLE || CellType==miSINGLE)\n      {\n        CalcMinMax(image2,  image_info->endian, MATLAB_HDR.SizeX, MATLAB_HDR.SizeY, CellType, ldblk, BImgBuff, &MinVal, &MaxVal);\n      }\n\n      if (CellType==miDOUBLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobDoublesXXX(image2, ldblk, (double *)BImgBuff);\n          InsertComplexDoubleRow(image, (double *)BImgBuff, i, MinVal, MaxVal,\n            exception);\n  }\n\n      if (CellType==miSINGLE)\n        for (i = 0; i < (ssize_t) MATLAB_HDR.SizeY; i++)\n  {\n          ReadBlobFloatsXXX(image2, ldblk, (float *)BImgBuff);\n          InsertComplexFloatRow(image,(float *)BImgBuff,i,MinVal,MaxVal,\n            exception);\n  }\n    }\n\n      /* Image is gray when no complex flag is set and 2D Matrix AGAIN!!! */\n    if ((MATLAB_HDR.DimFlag == 8) &&\n        ((MATLAB_HDR.StructureFlag & FLAG_COMPLEX) == 0))\n      image->type=GrayscaleType;\n    if (image->depth == 1)\n      image->type=BilevelType;\n\n    if(image2==image)\n        image2 = NULL;    /* Remove shadow copy to an image before rotation. */\n\n      /*  Rotate image. */\n    rotated_image = RotateImage(image, 90.0, exception);\n    if (rotated_image != (Image *) NULL)\n    {\n        /* Remove page offsets added by RotateImage */\n      rotated_image->page.x=0;\n      rotated_image->page.y=0;\n\n      blob = rotated_image->blob;\n      rotated_image->blob = image->blob;\n      rotated_image->colors = image->colors;\n      image->blob = blob;\n      AppendImageToList(&image,rotated_image);\n      DeleteImageFromList(&image);\n    }\n\ndone_reading:\n\n    if(image2!=NULL)\n      if(image2!=image)\n      {\n        DeleteImageFromList(&image2);\n  if(clone_info)\n  {\n          if(clone_info->file)\n    {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n    }\n        }\n      }\n\n      /* Allocate next image structure. */\n    AcquireNextImage(image_info,image,exception);\n    if (image->next == (Image *) NULL) break;\n    image=SyncNextImageInList(image);\n    image->columns=image->rows=0;\n    image->colors=0;\n\n      /* row scan buffer is no longer needed */\n    RelinquishMagickMemory(BImgBuff);\n    BImgBuff = NULL;\n\n    if(--Frames>0)\n    {\n      z = z2;\n      if(image2==NULL) image2 = image;\n      goto NEXT_FRAME;\n    }\n    if ((image2!=NULL) && (image2!=image))   /* Does shadow temporary decompressed image exist? */\n      {\n/*  CloseBlob(image2); */\n        DeleteImageFromList(&image2);\n        if(clone_info)\n        {\n          if(clone_info->file)\n          {\n            fclose(clone_info->file);\n            clone_info->file = NULL;\n            (void) remove_utf8(clone_info->filename);\n          }\n        }\n        }\n\n    if (quantum_info != (QuantumInfo *) NULL)\n      quantum_info=DestroyQuantumInfo(quantum_info);\n    if (clone_info)\n      clone_info=DestroyImageInfo(clone_info);\n  }\n\n  RelinquishMagickMemory(BImgBuff);\n  if (quantum_info != (QuantumInfo *) NULL)\n    quantum_info=DestroyQuantumInfo(quantum_info);\nEND_OF_READING:\n  if (clone_info)\n    clone_info=DestroyImageInfo(clone_info);\n  CloseBlob(image);\n\n\n  {\n    Image *p;\n    ssize_t scene=0;\n\n    /*\n      Rewind list, removing any empty images while rewinding.\n    */\n    p=image;\n    image=NULL;\n    while (p != (Image *) NULL)\n      {\n        Image *tmp=p;\n        if ((p->rows == 0) || (p->columns == 0)) {\n          p=p->previous;\n          DeleteImageFromList(&tmp);\n        } else {\n          image=p;\n          p=p->previous;\n        }\n      }\n\n    /*\n      Fix scene numbers\n    */\n    for (p=image; p != (Image *) NULL; p=p->next)\n      p->scene=scene++;\n  }\n\n  if(clone_info != NULL)  /* cleanup garbage file from compression */\n  {\n    if(clone_info->file)\n    {\n      fclose(clone_info->file);\n      clone_info->file = NULL;\n      (void) remove_utf8(clone_info->filename);\n    }\n    DestroyImageInfo(clone_info);\n    clone_info = NULL;\n  }\n  if (logging) (void)LogMagickEvent(CoderEvent,GetMagickModule(),\"return\");\n  if (image==NULL)\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\")\n  else\n    if ((image != image2) && (image2 != (Image *) NULL))\n      image2=DestroyImage(image2);\n  return (image);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/04178de2247e353fc095846784b9a10fefdbf890", "file_name": "coders/mat.c", "vul_type": "cwe-416", "description": "Write a function in C to read and process MATLAB image files."}
{"func_name": "run_interactive_shell_command", "func_src_before": "@contextmanager\ndef run_interactive_shell_command(command, **kwargs):\n    \"\"\"\n    Runs a command in shell and provides stdout, stderr and stdin streams.\n\n    This function creates a context manager that sets up the process, returns\n    to caller, closes streams and waits for process to exit on leaving.\n\n    The process is opened in `universal_newlines` mode.\n\n    :param command: The command to run on shell.\n    :param kwargs:  Additional keyword arguments to pass to `subprocess.Popen`\n                    that is used to spawn the process (except `shell`,\n                    `stdout`, `stderr`, `stdin` and `universal_newlines`, a\n                    `TypeError` is raised then).\n    :return:        A context manager yielding the process started from the\n                    command.\n    \"\"\"\n    process = Popen(command,\n                    shell=True,\n                    stdout=PIPE,\n                    stderr=PIPE,\n                    stdin=PIPE,\n                    universal_newlines=True,\n                    **kwargs)\n    try:\n        yield process\n    finally:\n        process.stdout.close()\n        process.stderr.close()\n        process.stdin.close()\n        process.wait()", "func_src_after": "@contextmanager\ndef run_interactive_shell_command(command, **kwargs):\n    \"\"\"\n    Runs a single command in shell and provides stdout, stderr and stdin\n    streams.\n\n    This function creates a context manager that sets up the process (using\n    `subprocess.Popen()`), returns to caller, closes streams and waits for\n    process to exit on leaving.\n\n    Shell execution is disabled by default (so no shell expansion takes place).\n    If you want to turn shell execution on, you can pass `shell=True` like you\n    would do for `subprocess.Popen()`.\n\n    The process is opened in `universal_newlines` mode by default.\n\n    :param command: The command to run on shell. This parameter can either\n                    be a sequence of arguments that are directly passed to\n                    the process or a string. A string gets splitted beforehand\n                    using `shlex.split()`.\n    :param kwargs:  Additional keyword arguments to pass to `subprocess.Popen`\n                    that is used to spawn the process (except `stdout`,\n                    `stderr`, `stdin` and `universal_newlines`, a `TypeError`\n                    is raised then).\n    :return:        A context manager yielding the process started from the\n                    command.\n    \"\"\"\n    if isinstance(command, str):\n        command = shlex.split(command)\n\n    process = Popen(command,\n                    stdout=PIPE,\n                    stderr=PIPE,\n                    stdin=PIPE,\n                    universal_newlines=True,\n                    **kwargs)\n    try:\n        yield process\n    finally:\n        process.stdout.close()\n        process.stderr.close()\n        process.stdin.close()\n        process.wait()", "commit_link": "github.com/coala/coala/commit/adc94c745e4d9f792fd9c9791c7b4cd8790d0d2f", "file_name": "coalib/misc/Shell.py", "vul_type": "cwe-078", "description": "Write a Python function that acts as a context manager to run shell commands interactively, handling stdin, stdout, and stderr streams."}
{"func_name": "set_geometry", "func_src_before": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif (g->sect <= 0 ||\n\t    g->head <= 0 ||\n\t    /* check for zero in F_SECT_PER_TRACK */\n\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}", "func_src_after": "static int set_geometry(unsigned int cmd, struct floppy_struct *g,\n\t\t\t       int drive, int type, struct block_device *bdev)\n{\n\tint cnt;\n\n\t/* sanity checking for parameters. */\n\tif ((int)g->sect <= 0 ||\n\t    (int)g->head <= 0 ||\n\t    /* check for overflow in max_sector */\n\t    (int)(g->sect * g->head) <= 0 ||\n\t    /* check for zero in F_SECT_PER_TRACK */\n\t    (unsigned char)((g->sect << 2) >> FD_SIZECODE(g)) == 0 ||\n\t    g->track <= 0 || g->track > UDP->tracks >> STRETCH(g) ||\n\t    /* check if reserved bits are set */\n\t    (g->stretch & ~(FD_STRETCH | FD_SWAPSIDES | FD_SECTBASEMASK)) != 0)\n\t\treturn -EINVAL;\n\tif (type) {\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\t\tmutex_lock(&open_lock);\n\t\tif (lock_fdc(drive)) {\n\t\t\tmutex_unlock(&open_lock);\n\t\t\treturn -EINTR;\n\t\t}\n\t\tfloppy_type[type] = *g;\n\t\tfloppy_type[type].name = \"user format\";\n\t\tfor (cnt = type << 2; cnt < (type << 2) + 4; cnt++)\n\t\t\tfloppy_sizes[cnt] = floppy_sizes[cnt + 0x80] =\n\t\t\t    floppy_type[type].size + 1;\n\t\tprocess_fd_request();\n\t\tfor (cnt = 0; cnt < N_DRIVE; cnt++) {\n\t\t\tstruct block_device *bdev = opened_bdev[cnt];\n\t\t\tif (!bdev || ITYPE(drive_state[cnt].fd_device) != type)\n\t\t\t\tcontinue;\n\t\t\t__invalidate_device(bdev, true);\n\t\t}\n\t\tmutex_unlock(&open_lock);\n\t} else {\n\t\tint oldStretch;\n\n\t\tif (lock_fdc(drive))\n\t\t\treturn -EINTR;\n\t\tif (cmd != FDDEFPRM) {\n\t\t\t/* notice a disk change immediately, else\n\t\t\t * we lose our settings immediately*/\n\t\t\tif (poll_drive(true, FD_RAW_NEED_DISK) == -EINTR)\n\t\t\t\treturn -EINTR;\n\t\t}\n\t\toldStretch = g->stretch;\n\t\tuser_params[drive] = *g;\n\t\tif (buffer_drive == drive)\n\t\t\tSUPBOUND(buffer_max, user_params[drive].sect);\n\t\tcurrent_type[drive] = &user_params[drive];\n\t\tfloppy_sizes[drive] = user_params[drive].size;\n\t\tif (cmd == FDDEFPRM)\n\t\t\tDRS->keep_data = -1;\n\t\telse\n\t\t\tDRS->keep_data = 1;\n\t\t/* invalidation. Invalidate only when needed, i.e.\n\t\t * when there are already sectors in the buffer cache\n\t\t * whose number will change. This is useful, because\n\t\t * mtools often changes the geometry of the disk after\n\t\t * looking at the boot block */\n\t\tif (DRS->maxblock > user_params[drive].sect ||\n\t\t    DRS->maxtrack ||\n\t\t    ((user_params[drive].sect ^ oldStretch) &\n\t\t     (FD_SWAPSIDES | FD_SECTBASEMASK)))\n\t\t\tinvalidate_drive(bdev);\n\t\telse\n\t\t\tprocess_fd_request();\n\t}\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/da99466ac243f15fbba65bd261bfc75ffa1532b6", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-190", "description": "Write a C function named `set_geometry` that configures the disk geometry for a floppy drive."}
{"func_name": "get_login2", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_LOGIN.value)\ndef get_login2(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    if bases.createuserbase.check_username(message.text):\n        bot.send_message(message.chat.id, \"Invalid handle.\")\n        set_state(message.chat.id, config.States.S_START.value)\n        return 0\n\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    bases.update.cf_update()\n    bases.createuserbase.clean_base(name[1])\n    bases.createuserbase.clean_base(message.text)\n    bot.send_message(message.chat.id, \"Creating base...\")\n    bases.createuserbase.init_user(message.text, message.chat.id)\n    bot.send_message(message.chat.id, \"Done!\")\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a function that handles a login message for a bot, checks the username, interacts with a SQLite database, and updates the user's state."}
{"func_name": "create_event", "func_src_before": "    def create_event(self, title, start_time, time_zone, server_id, description):\n        sql = \"\"\"\n              INSERT INTO events (title, start_time, time_zone, server_id, description)\n              VALUES (%s, %s, %s, %s, %s)\n              \"\"\"\n        self.cur.execute(sql, (title, start_time, time_zone, server_id, description))\n        self.conn.commit()", "func_src_after": "    def create_event(self, title, start_time, time_zone, server_id, description):\n        sql = \"\"\"INSERT INTO events (title, start_time, time_zone, server_id, description)\n                 VALUES ('{0}', '{1}', '{2}', '{3}', '{4}')\n                 \"\"\".format(title, start_time, time_zone, server_id, description)\n        self.cur.execute(sql)\n        self.conn.commit()", "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089", "description": "Write a Python function to insert an event with details into a database."}
{"func_name": "kvm_vm_ioctl_check_extension", "func_src_before": "int kvm_vm_ioctl_check_extension(struct kvm *kvm, long ext)\n{\n\tint r;\n\t/* Assume we're using HV mode when the HV module is loaded */\n\tint hv_enabled = kvmppc_hv_ops ? 1 : 0;\n\n\tif (kvm) {\n\t\t/*\n\t\t * Hooray - we know which VM type we're running on. Depend on\n\t\t * that rather than the guess above.\n\t\t */\n\t\thv_enabled = is_kvmppc_hv_enabled(kvm);\n\t}\n\n\tswitch (ext) {\n#ifdef CONFIG_BOOKE\n\tcase KVM_CAP_PPC_BOOKE_SREGS:\n\tcase KVM_CAP_PPC_BOOKE_WATCHDOG:\n\tcase KVM_CAP_PPC_EPR:\n#else\n\tcase KVM_CAP_PPC_SEGSTATE:\n\tcase KVM_CAP_PPC_HIOR:\n\tcase KVM_CAP_PPC_PAPR:\n#endif\n\tcase KVM_CAP_PPC_UNSET_IRQ:\n\tcase KVM_CAP_PPC_IRQ_LEVEL:\n\tcase KVM_CAP_ENABLE_CAP:\n\tcase KVM_CAP_ENABLE_CAP_VM:\n\tcase KVM_CAP_ONE_REG:\n\tcase KVM_CAP_IOEVENTFD:\n\tcase KVM_CAP_DEVICE_CTRL:\n\tcase KVM_CAP_IMMEDIATE_EXIT:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_PPC_PAIRED_SINGLES:\n\tcase KVM_CAP_PPC_OSI:\n\tcase KVM_CAP_PPC_GET_PVINFO:\n#if defined(CONFIG_KVM_E500V2) || defined(CONFIG_KVM_E500MC)\n\tcase KVM_CAP_SW_TLB:\n#endif\n\t\t/* We support this only for PR */\n\t\tr = !hv_enabled;\n\t\tbreak;\n#ifdef CONFIG_KVM_MPIC\n\tcase KVM_CAP_IRQ_MPIC:\n\t\tr = 1;\n\t\tbreak;\n#endif\n\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_SPAPR_TCE:\n\tcase KVM_CAP_SPAPR_TCE_64:\n\t\t/* fallthrough */\n\tcase KVM_CAP_SPAPR_TCE_VFIO:\n\tcase KVM_CAP_PPC_RTAS:\n\tcase KVM_CAP_PPC_FIXUP_HCALL:\n\tcase KVM_CAP_PPC_ENABLE_HCALL:\n#ifdef CONFIG_KVM_XICS\n\tcase KVM_CAP_IRQ_XICS:\n#endif\n\t\tr = 1;\n\t\tbreak;\n\n\tcase KVM_CAP_PPC_ALLOC_HTAB:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif /* CONFIG_PPC_BOOK3S_64 */\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_SMT:\n\t\tr = 0;\n\t\tif (kvm) {\n\t\t\tif (kvm->arch.emul_smt_mode > 1)\n\t\t\t\tr = kvm->arch.emul_smt_mode;\n\t\t\telse\n\t\t\t\tr = kvm->arch.smt_mode;\n\t\t} else if (hv_enabled) {\n\t\t\tif (cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = 1;\n\t\t\telse\n\t\t\t\tr = threads_per_subcore;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_SMT_POSSIBLE:\n\t\tr = 1;\n\t\tif (hv_enabled) {\n\t\t\tif (!cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = ((threads_per_subcore << 1) - 1);\n\t\t\telse\n\t\t\t\t/* P9 can emulate dbells, so allow any mode */\n\t\t\t\tr = 8 | 4 | 2 | 1;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_RMA:\n\t\tr = 0;\n\t\tbreak;\n\tcase KVM_CAP_PPC_HWRNG:\n\t\tr = kvmppc_hwrng_present();\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_RADIX:\n\t\tr = !!(hv_enabled && radix_enabled());\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_HASH_V3:\n\t\tr = !!(hv_enabled && !radix_enabled() &&\n\t\t       cpu_has_feature(CPU_FTR_ARCH_300));\n\t\tbreak;\n#endif\n\tcase KVM_CAP_SYNC_MMU:\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\t\tr = hv_enabled;\n#elif defined(KVM_ARCH_WANT_MMU_NOTIFIER)\n\t\tr = 1;\n#else\n\t\tr = 0;\n#endif\n\t\tbreak;\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_HTAB_FD:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_NR_VCPUS:\n\t\t/*\n\t\t * Recommending a number of CPUs is somewhat arbitrary; we\n\t\t * return the number of present CPUs for -HV (since a host\n\t\t * will have secondary threads \"offline\"), and for other KVM\n\t\t * implementations just count online CPUs.\n\t\t */\n\t\tif (hv_enabled)\n\t\t\tr = num_present_cpus();\n\t\telse\n\t\t\tr = num_online_cpus();\n\t\tbreak;\n\tcase KVM_CAP_NR_MEMSLOTS:\n\t\tr = KVM_USER_MEM_SLOTS;\n\t\tbreak;\n\tcase KVM_CAP_MAX_VCPUS:\n\t\tr = KVM_MAX_VCPUS;\n\t\tbreak;\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_PPC_GET_SMMU_INFO:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_MULTITCE:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_RESIZE_HPT:\n\t\t/* Disable this on POWER9 until code handles new HPTE format */\n\t\tr = !!hv_enabled && !cpu_has_feature(CPU_FTR_ARCH_300);\n\t\tbreak;\n#endif\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_FWNMI:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_PPC_HTM:\n\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) && hv_enabled;\n\t\tbreak;\n\tdefault:\n\t\tr = 0;\n\t\tbreak;\n\t}\n\treturn r;\n\n}", "func_src_after": "int kvm_vm_ioctl_check_extension(struct kvm *kvm, long ext)\n{\n\tint r;\n\t/* Assume we're using HV mode when the HV module is loaded */\n\tint hv_enabled = kvmppc_hv_ops ? 1 : 0;\n\n\tif (kvm) {\n\t\t/*\n\t\t * Hooray - we know which VM type we're running on. Depend on\n\t\t * that rather than the guess above.\n\t\t */\n\t\thv_enabled = is_kvmppc_hv_enabled(kvm);\n\t}\n\n\tswitch (ext) {\n#ifdef CONFIG_BOOKE\n\tcase KVM_CAP_PPC_BOOKE_SREGS:\n\tcase KVM_CAP_PPC_BOOKE_WATCHDOG:\n\tcase KVM_CAP_PPC_EPR:\n#else\n\tcase KVM_CAP_PPC_SEGSTATE:\n\tcase KVM_CAP_PPC_HIOR:\n\tcase KVM_CAP_PPC_PAPR:\n#endif\n\tcase KVM_CAP_PPC_UNSET_IRQ:\n\tcase KVM_CAP_PPC_IRQ_LEVEL:\n\tcase KVM_CAP_ENABLE_CAP:\n\tcase KVM_CAP_ENABLE_CAP_VM:\n\tcase KVM_CAP_ONE_REG:\n\tcase KVM_CAP_IOEVENTFD:\n\tcase KVM_CAP_DEVICE_CTRL:\n\tcase KVM_CAP_IMMEDIATE_EXIT:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_PPC_PAIRED_SINGLES:\n\tcase KVM_CAP_PPC_OSI:\n\tcase KVM_CAP_PPC_GET_PVINFO:\n#if defined(CONFIG_KVM_E500V2) || defined(CONFIG_KVM_E500MC)\n\tcase KVM_CAP_SW_TLB:\n#endif\n\t\t/* We support this only for PR */\n\t\tr = !hv_enabled;\n\t\tbreak;\n#ifdef CONFIG_KVM_MPIC\n\tcase KVM_CAP_IRQ_MPIC:\n\t\tr = 1;\n\t\tbreak;\n#endif\n\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_SPAPR_TCE:\n\tcase KVM_CAP_SPAPR_TCE_64:\n\t\t/* fallthrough */\n\tcase KVM_CAP_SPAPR_TCE_VFIO:\n\tcase KVM_CAP_PPC_RTAS:\n\tcase KVM_CAP_PPC_FIXUP_HCALL:\n\tcase KVM_CAP_PPC_ENABLE_HCALL:\n#ifdef CONFIG_KVM_XICS\n\tcase KVM_CAP_IRQ_XICS:\n#endif\n\t\tr = 1;\n\t\tbreak;\n\n\tcase KVM_CAP_PPC_ALLOC_HTAB:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif /* CONFIG_PPC_BOOK3S_64 */\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_SMT:\n\t\tr = 0;\n\t\tif (kvm) {\n\t\t\tif (kvm->arch.emul_smt_mode > 1)\n\t\t\t\tr = kvm->arch.emul_smt_mode;\n\t\t\telse\n\t\t\t\tr = kvm->arch.smt_mode;\n\t\t} else if (hv_enabled) {\n\t\t\tif (cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = 1;\n\t\t\telse\n\t\t\t\tr = threads_per_subcore;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_SMT_POSSIBLE:\n\t\tr = 1;\n\t\tif (hv_enabled) {\n\t\t\tif (!cpu_has_feature(CPU_FTR_ARCH_300))\n\t\t\t\tr = ((threads_per_subcore << 1) - 1);\n\t\t\telse\n\t\t\t\t/* P9 can emulate dbells, so allow any mode */\n\t\t\t\tr = 8 | 4 | 2 | 1;\n\t\t}\n\t\tbreak;\n\tcase KVM_CAP_PPC_RMA:\n\t\tr = 0;\n\t\tbreak;\n\tcase KVM_CAP_PPC_HWRNG:\n\t\tr = kvmppc_hwrng_present();\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_RADIX:\n\t\tr = !!(hv_enabled && radix_enabled());\n\t\tbreak;\n\tcase KVM_CAP_PPC_MMU_HASH_V3:\n\t\tr = !!(hv_enabled && !radix_enabled() &&\n\t\t       cpu_has_feature(CPU_FTR_ARCH_300));\n\t\tbreak;\n#endif\n\tcase KVM_CAP_SYNC_MMU:\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\t\tr = hv_enabled;\n#elif defined(KVM_ARCH_WANT_MMU_NOTIFIER)\n\t\tr = 1;\n#else\n\t\tr = 0;\n#endif\n\t\tbreak;\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_HTAB_FD:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_NR_VCPUS:\n\t\t/*\n\t\t * Recommending a number of CPUs is somewhat arbitrary; we\n\t\t * return the number of present CPUs for -HV (since a host\n\t\t * will have secondary threads \"offline\"), and for other KVM\n\t\t * implementations just count online CPUs.\n\t\t */\n\t\tif (hv_enabled)\n\t\t\tr = num_present_cpus();\n\t\telse\n\t\t\tr = num_online_cpus();\n\t\tbreak;\n\tcase KVM_CAP_NR_MEMSLOTS:\n\t\tr = KVM_USER_MEM_SLOTS;\n\t\tbreak;\n\tcase KVM_CAP_MAX_VCPUS:\n\t\tr = KVM_MAX_VCPUS;\n\t\tbreak;\n#ifdef CONFIG_PPC_BOOK3S_64\n\tcase KVM_CAP_PPC_GET_SMMU_INFO:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_MULTITCE:\n\t\tr = 1;\n\t\tbreak;\n\tcase KVM_CAP_SPAPR_RESIZE_HPT:\n\t\t/* Disable this on POWER9 until code handles new HPTE format */\n\t\tr = !!hv_enabled && !cpu_has_feature(CPU_FTR_ARCH_300);\n\t\tbreak;\n#endif\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\n\tcase KVM_CAP_PPC_FWNMI:\n\t\tr = hv_enabled;\n\t\tbreak;\n#endif\n\tcase KVM_CAP_PPC_HTM:\n\t\tr = cpu_has_feature(CPU_FTR_TM_COMP) &&\n\t\t    is_kvmppc_hv_enabled(kvm);\n\t\tbreak;\n\tdefault:\n\t\tr = 0;\n\t\tbreak;\n\t}\n\treturn r;\n\n}", "commit_link": "github.com/torvalds/linux/commit/ac64115a66c18c01745bbd3c47a36b124e5fd8c0", "file_name": "arch/powerpc/kvm/powerpc.c", "vul_type": "cwe-476", "description": "Write a C function named `kvm_vm_ioctl_check_extension` that checks if a specified KVM extension is supported, considering whether the system is running in HV mode."}
{"func_name": "_modify_3par_iscsi_host", "func_src_before": "    def _modify_3par_iscsi_host(self, hostname, iscsi_iqn):\n        # when using -add, you can not send the persona or domain options\n        self.common._cli_run('createhost -iscsi -add %s %s'\n                             % (hostname, iscsi_iqn), None)", "func_src_after": "    def _modify_3par_iscsi_host(self, hostname, iscsi_iqn):\n        # when using -add, you can not send the persona or domain options\n        command = ['createhost', '-iscsi', '-add', hostname, iscsi_iqn]\n        self.common._cli_run(command)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_iscsi.py", "vul_type": "cwe-078", "description": "Write a Python function to add an iSCSI host to a 3PAR system without persona or domain options."}
{"func_name": "get_first_ranked_month", "func_src_before": "def get_first_ranked_month(db, scene, player):\n    sql = \"select date from ranks where scene='{}' and player='{}' order by date limit 1;\".format(scene, player)\n    res = db.exec(sql)\n    date = res[0][0]\n    return date", "func_src_after": "def get_first_ranked_month(db, scene, player):\n    sql = \"select date from ranks where scene='{scene}' and player='{player}' order by date limit 1;\"\n    args = {'scene': scene, 'player': player}\n    res = db.exec(sql, args)\n    date = res[0][0]\n    return date", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the earliest ranking date for a specific player and scene from a database."}
{"func_name": "showPoll", "func_src_before": "@hook.command(autohelp=False)\ndef showPoll(pollID, db=None):\n    \"\"\"Shows the answers for a given poll.\"\"\"\n    if not db_ready: db_init(db)\n    if pollID == None:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE active = 1\")\n        if len(poll) == 0:\n            reply(\"There's no poll open.\")\n            return\n    else:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE pollID = ?\", (pollID,))\n        if len(poll) == 0:\n            reply(\"No such poll found.\")\n            return\n    pollID = poll[0][0]\n    question = poll[0][1]\n    reply(question)\n    for (index, answer, votes) in db.execute(\"SELECT 'index', answer, count(voteID) FROM answers LEFT JOIN votes ON votes.answerID = answers.answerID WHERE pollID = ? GROUP BY answers.answerID, 'index', answer ORDER BY 'index' ASC\", (pollID, )):\n        reply(\"%s. %s (%s)\" % (index, answer, votes))", "func_src_after": "@hook.command(autohelp=False)\ndef showPoll(pollID, db=None):\n    \"\"\"Shows the answers for a given poll.\"\"\"\n    if not db_ready: db_init(db)\n    if pollID == None:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE active = 1\")\n        if len(poll) == 0:\n            reply(\"There's no poll open.\")\n            return\n    else:\n        poll = db.execute(\"SELECT pollID, question FROM polls WHERE pollID = '{}'\".format(pollID))\n        if len(poll) == 0:\n            reply(\"No such poll found.\")\n            return\n    pollID = poll[0][0]\n    question = poll[0][1]\n    reply(question)\n    for (index, answer, votes) in db.execute(\"SELECT 'index', answer, count(voteID) FROM answers LEFT JOIN votes ON votes.answerID = answers.answerID WHERE pollID = {} GROUP BY answers.answerID, 'index', answer ORDER BY 'index' ASC\".format(pollID, )):\n        reply(\"%s. %s (%s)\" % (index, answer, votes))", "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089", "description": "Write a Python function that displays poll details and answers from a database, handling the case where no poll ID is provided."}
{"func_name": "deleteKey", "func_src_before": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateKeyName(token_data['key'])\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "func_src_after": "def deleteKey(client):\n\t\"\"\"Deletes the specified key.\n\tReturns an error if the key doesn't exist\n\t\"\"\"\n\tglobal BAD_REQUEST\n\tglobal NOT_FOUND\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\n\tif re.search('[^a-zA-Z0-9]', token_data['key']):\n\t\traise FoxlockError(BAD_REQUEST, 'Invalid key requested')\n\n\ttry:\n\t\tos.remove('keys/%s/%s.key' % (client, token_data['key']))\n\texcept FileNotFoundError:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['key'])\n\n\treturn \"Key '%s' successfully deleted\" % token_data['key']", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function named `deleteKey` that removes a client's key file and handles the case where the key does not exist."}
{"func_name": "enc_untrusted_recvfrom", "func_src_before": "ssize_t enc_untrusted_recvfrom(int sockfd, void *buf, size_t len, int flags,\n                               struct sockaddr *src_addr, socklen_t *addrlen) {\n  int klinux_flags = TokLinuxRecvSendFlag(flags);\n  if (klinux_flags == 0 && flags != 0) {\n    errno = EINVAL;\n    return -1;\n  }\n\n  MessageWriter input;\n  input.Push<int>(sockfd);\n  input.Push<uint64_t>(len);\n  input.Push<int>(klinux_flags);\n  MessageReader output;\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvFromHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvfrom\", 4);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  // recvfrom() returns -1 on failure, with errno set to indicate the cause\n  // of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  auto buffer_received = output.next();\n  memcpy(buf, buffer_received.data(), std::min(len, buffer_received.size()));\n\n  // If |src_addr| is not NULL, and the underlying protocol provides the source\n  // address, this source address is filled in. When |src_addr| is NULL, nothing\n  // is filled in; in this case, |addrlen| is not used, and should also be NULL.\n  if (src_addr != nullptr && addrlen != nullptr) {\n    auto klinux_sockaddr_buf = output.next();\n    const struct klinux_sockaddr *klinux_addr =\n        klinux_sockaddr_buf.As<struct klinux_sockaddr>();\n    FromkLinuxSockAddr(klinux_addr, klinux_sockaddr_buf.size(), src_addr,\n                       addrlen, TrustedPrimitives::BestEffortAbort);\n  }\n\n  return result;\n}", "func_src_after": "ssize_t enc_untrusted_recvfrom(int sockfd, void *buf, size_t len, int flags,\n                               struct sockaddr *src_addr, socklen_t *addrlen) {\n  int klinux_flags = TokLinuxRecvSendFlag(flags);\n  if (klinux_flags == 0 && flags != 0) {\n    errno = EINVAL;\n    return -1;\n  }\n\n  MessageWriter input;\n  input.Push<int>(sockfd);\n  input.Push<uint64_t>(len);\n  input.Push<int>(klinux_flags);\n  MessageReader output;\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvFromHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvfrom\", 4);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  // recvfrom() returns -1 on failure, with errno set to indicate the cause\n  // of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  if (result > len) {\n    ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n        \"enc_untrusted_recvfrom: result exceeds requested\");\n  }\n\n  auto buffer_received = output.next();\n  memcpy(buf, buffer_received.data(), std::min(len, buffer_received.size()));\n\n  // If |src_addr| is not NULL, and the underlying protocol provides the source\n  // address, this source address is filled in. When |src_addr| is NULL, nothing\n  // is filled in; in this case, |addrlen| is not used, and should also be NULL.\n  if (src_addr != nullptr && addrlen != nullptr) {\n    auto klinux_sockaddr_buf = output.next();\n    const struct klinux_sockaddr *klinux_addr =\n        klinux_sockaddr_buf.As<struct klinux_sockaddr>();\n    FromkLinuxSockAddr(klinux_addr, klinux_sockaddr_buf.size(), src_addr,\n                       addrlen, TrustedPrimitives::BestEffortAbort);\n  }\n\n  return result;\n}", "commit_link": "github.com/google/asylo/commit/6e158d558abd3c29a0208e30c97c9a8c5bd4230f", "file_name": "asylo/platform/host_call/trusted/host_calls.cc", "vul_type": "cwe-125", "description": "Write a C++ function `enc_untrusted_recvfrom` that wraps a system call to receive data from a socket, handling errors and converting address formats."}
{"func_name": "screenshotcommentcounts", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef screenshotcommentcounts(context, screenshot):\n    \"\"\"\n    Returns a JSON array of current comments for a screenshot.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      text        The text of the comment\n      localdraft  True if this is the current user's draft comment\n      x           The X location of the comment's region\n      y           The Y location of the comment's region\n      w           The width of the comment's region\n      h           The height of the comment's region\n      =========== ==================================================\n    \"\"\"\n    comments = {}\n    user = context.get('user', None)\n\n    for comment in screenshot.comments.all():\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            position = '%dx%d+%d+%d' % (comment.w, comment.h, \\\n                                        comment.x, comment.y)\n\n            comments.setdefault(position, []).append({\n                'id': comment.id,\n                'text': comment.text,\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                'url': comment.get_review_url(),\n                'localdraft' : review.user == user and \\\n                               not review.public,\n                'x' : comment.x,\n                'y' : comment.y,\n                'w' : comment.w,\n                'h' : comment.h,\n            })\n\n    return simplejson.dumps(comments)", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef screenshotcommentcounts(context, screenshot):\n    \"\"\"\n    Returns a JSON array of current comments for a screenshot.\n\n    Each entry in the array has a dictionary containing the following keys:\n\n      =========== ==================================================\n      Key         Description\n      =========== ==================================================\n      text        The text of the comment\n      localdraft  True if this is the current user's draft comment\n      x           The X location of the comment's region\n      y           The Y location of the comment's region\n      w           The width of the comment's region\n      h           The height of the comment's region\n      =========== ==================================================\n    \"\"\"\n    comments = {}\n    user = context.get('user', None)\n\n    for comment in screenshot.comments.all():\n        review = get_object_or_none(comment.review)\n\n        if review and (review.public or review.user == user):\n            position = '%dx%d+%d+%d' % (comment.w, comment.h, \\\n                                        comment.x, comment.y)\n\n            comments.setdefault(position, []).append({\n                'id': comment.id,\n                'text': escape(comment.text),\n                'user': {\n                    'username': review.user.username,\n                    'name': review.user.get_full_name() or review.user.username,\n                },\n                'url': comment.get_review_url(),\n                'localdraft' : review.user == user and \\\n                               not review.public,\n                'x' : comment.x,\n                'y' : comment.y,\n                'w' : comment.w,\n                'h' : comment.h,\n            })\n\n    return simplejson.dumps(comments)", "commit_link": "github.com/reviewboard/reviewboard/commit/7a0a9d94555502278534dedcf2d75e9fccce8c3d", "file_name": "reviewboard/reviews/templatetags/reviewtags.py", "vul_type": "cwe-079", "description": "In Python, write a function that returns a JSON representation of comments associated with a screenshot, including details like text, draft status, and position."}
{"func_name": "add_post", "func_src_before": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  cursor.execute(\"insert into posts values ('%s')\" % content)\n  conn.commit()\n  conn.close()", "func_src_after": "def add_post(content):\n  \"\"\"Add a post to the 'database' with the current timestamp.\"\"\"\n  conn = psycopg2.connect(\"dbname=forum\")\n  cursor = conn.cursor()\n  one_post = content\n  cursor.execute(\"insert into posts values (%s)\", (one_post,))\n  conn.commit()\n  conn.close()", "commit_link": "github.com/paulc1600/DB-API-Forum/commit/069700fb4beec79182fff3c556e9cccce3230d6f", "file_name": "forumdb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new post into a forum database using psycopg2."}
{"func_name": "uas_switch_interface", "func_src_before": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tint alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (alt < 0)\n\t\treturn alt;\n\n\treturn usb_set_interface(udev,\n\t\t\tintf->altsetting[0].desc.bInterfaceNumber, alt);\n}", "func_src_after": "static int uas_switch_interface(struct usb_device *udev,\n\t\t\t\tstruct usb_interface *intf)\n{\n\tstruct usb_host_interface *alt;\n\n\talt = uas_find_uas_alt_setting(intf);\n\tif (!alt)\n\t\treturn -ENODEV;\n\n\treturn usb_set_interface(udev, alt->desc.bInterfaceNumber,\n\t\t\talt->desc.bAlternateSetting);\n}", "commit_link": "github.com/torvalds/linux/commit/786de92b3cb26012d3d0f00ee37adf14527f35c4", "file_name": "drivers/usb/storage/uas.c", "vul_type": "cwe-125", "description": "Write a C function named `uas_switch_interface` that switches the USB interface to an alternate setting for a given USB device and interface."}
{"func_name": "copy", "func_src_before": "    def copy(self, src_data, src_path, dst_data, dst_path, job_id=None):\n        credentials = ''\n\n        if src_data is None: # Local\n            src = src_path\n        else:\n            credentials += self._formatCredentials(src_data, name='src')\n            src = 'src:{}'.format(src_path)\n\n        if dst_data is None: # Local\n            dst = dst_path\n        else:\n            credentials += self._formatCredentials(dst_data, name='dst')\n            dst = 'dst:{}'.format(dst_path)\n\n\n        command = (\n            '{credentials} '\n            'rclone copy {src} {dst} '\n            '--progress '\n            '--stats 2s '\n        ).format(\n            credentials=credentials,\n            src=src,\n            dst=dst,\n        )\n\n        logging.info(sanitize(command))\n\n        if job_id is None:\n            job_id = self._get_next_job_id()\n        else:\n            if self._job_id_exists(job_id):\n                raise ValueError('rclone copy job with ID {} already exists'.fromat(job_id))\n\n        self._stop_events[job_id] = threading.Event()\n\n        try:\n            self._execute_interactive(command, job_id)\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))\n\n        return job_id", "func_src_after": "    def copy(self, src_data, src_path, dst_data, dst_path, job_id=None):\n        credentials = {}\n\n        if src_data is None: # Local\n            src = src_path\n        else:\n            credentials.update(self._formatCredentials(src_data, name='src'))\n            src = 'src:{}'.format(src_path)\n\n        if dst_data is None: # Local\n            dst = dst_path\n        else:\n            credentials.update(self._formatCredentials(dst_data, name='dst'))\n            dst = 'dst:{}'.format(dst_path)\n\n        command = [\n            'rclone',\n            'copy',\n            src,\n            dst,\n            '--progress',\n            '--stats', '2s',\n        ]\n\n        bash_command = \"{} {}\".format(\n            ' '.join(\"{}='{}'\".format(key, value) for key, value in credentials.items()),\n            ' '.join(command),\n        )\n\n        logging.info(sanitize(bash_command))\n\n        if job_id is None:\n            job_id = self._get_next_job_id()\n        else:\n            if self._job_id_exists(job_id):\n                raise ValueError('rclone copy job with ID {} already exists'.fromat(job_id))\n\n        self._stop_events[job_id] = threading.Event()\n\n        try:\n            self._execute_interactive(command, credentials, job_id)\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))\n\n        return job_id", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function named `copy` that handles file copying with rclone, including local and remote sources and destinations, and manages job IDs."}
{"func_name": "save_failure_transaction", "func_src_before": "    def save_failure_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"insert into transactions (project_id,user_id, money, timestamp, state) values (%s, %s, %s, now(), 'failed' )\" % (project_id, user_id, money))\n        self.db.commit()", "func_src_after": "    def save_failure_transaction(self, user_id, project_id, money):\n        self.cursor.execute(\"insert into transactions (project_id,user_id, money, timestamp, state) values (%s, %s, \"\n                            \"%s, now(), 'failed' )\", (project_id, user_id, money))\n        self.db.commit()", "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a failed transaction record into a database."}
{"func_name": "SMB2_write", "func_src_before": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tcifs_small_buf_release(req);\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "func_src_after": "SMB2_write(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t   unsigned int *nbytes, struct kvec *iov, int n_vec)\n{\n\tstruct smb_rqst rqst;\n\tint rc = 0;\n\tstruct smb2_write_req *req = NULL;\n\tstruct smb2_write_rsp *rsp = NULL;\n\tint resp_buftype;\n\tstruct kvec rsp_iov;\n\tint flags = 0;\n\tunsigned int total_len;\n\n\t*nbytes = 0;\n\n\tif (n_vec < 1)\n\t\treturn rc;\n\n\trc = smb2_plain_req_init(SMB2_WRITE, io_parms->tcon, (void **) &req,\n\t\t\t     &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\tif (io_parms->tcon->ses->server == NULL)\n\t\treturn -ECONNABORTED;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\treq->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);\n\n\treq->PersistentFileId = io_parms->persistent_fid;\n\treq->VolatileFileId = io_parms->volatile_fid;\n\treq->WriteChannelInfoOffset = 0;\n\treq->WriteChannelInfoLength = 0;\n\treq->Channel = 0;\n\treq->Length = cpu_to_le32(io_parms->length);\n\treq->Offset = cpu_to_le64(io_parms->offset);\n\treq->DataOffset = cpu_to_le16(\n\t\t\t\toffsetof(struct smb2_write_req, Buffer));\n\treq->RemainingBytes = 0;\n\n\ttrace_smb3_write_enter(xid, io_parms->persistent_fid,\n\t\tio_parms->tcon->tid, io_parms->tcon->ses->Suid,\n\t\tio_parms->offset, io_parms->length);\n\n\tiov[0].iov_base = (char *)req;\n\t/* 1 for Buffer */\n\tiov[0].iov_len = total_len - 1;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = n_vec + 1;\n\n\trc = cifs_send_recv(xid, io_parms->tcon->ses, &rqst,\n\t\t\t    &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_write_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\ttrace_smb3_write_err(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, io_parms->length, rc);\n\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_WRITE_HE);\n\t\tcifs_dbg(VFS, \"Send error in write = %d\\n\", rc);\n\t} else {\n\t\t*nbytes = le32_to_cpu(rsp->DataLength);\n\t\ttrace_smb3_write_done(xid, req->PersistentFileId,\n\t\t\t\t     io_parms->tcon->tid,\n\t\t\t\t     io_parms->tcon->ses->Suid,\n\t\t\t\t     io_parms->offset, *nbytes);\n\t}\n\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/6a3eb3360667170988f8a6477f6686242061488a", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "In C, write a function to perform an SMB2 write operation with error handling and encryption check."}
{"func_name": "search_pages", "func_src_before": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = $1\", search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "func_src_after": "@app.route(\"/search\", methods = [\"POST\"])\ndef search_pages():\n    search = request.form.get(\"search\")\n    page = db.query(\"select title from page where title = '%s'\" % search).namedresult()\n    if len(page) == 0:\n        return redirect(\"/%s\" % search)\n    else:\n        return place_holder(search)", "commit_link": "github.com/jcortes0309/wiki_flask/commit/a6bf5316abe2eb528adf36c8241a013fd02c5ffa", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function that handles a POST request to search for a page title in a database and either redirects to the page if not found or returns a placeholder response."}
{"func_name": "makeJudge", "func_src_before": "def makeJudge(judge):\n\tdb.execute(\"UPDATE players SET Judge = 1 WHERE Name = ? COLLATE NOCASE\", judge) \n\tdatabase.commit()", "func_src_after": "def makeJudge(judge):\n\tdb.execute(\"UPDATE players SET Judge = 1 WHERE Name = '%s' COLLATE NOCASE\" % (judge)) \n\tdatabase.commit()", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function called `makeJudge` that sets a player's 'Judge' status to 1 in a database by their name, case-insensitively."}
{"func_name": "save", "func_src_before": "async def save(request):\n    # TODO csrf\n    data = await request.post()\n    item = Item(data['src'])\n\n    # Update name\n    new_src = data.get('new_src')\n    if new_src and new_src != data['src']:\n        # don't need to worry about html unquote\n        shutil.move(item.abspath, settings.STORAGE_DIR + new_src)\n        old_backup_abspath = item.backup_abspath\n        item = Item(new_src)\n        if os.path.isfile(old_backup_abspath):\n            shutil.move(old_backup_abspath, item.backup_abspath)\n\n    # Update meta\n    for field in item.FORM:\n        # TODO handle .repeatable (keywords)\n        item.meta[field] = [data.get(field, '')]\n\n    if settings.SAVE_ORIGINALS and not os.path.isfile(item.backup_abspath):\n        shutil.copyfile(item.abspath, item.backup_abspath)\n\n    # WISHLIST don't write() if nothing changed\n    item.meta.write()\n\n    return web.Response(\n        status=200,\n        body=json.dumps(item.get_form_fields()).encode('utf8'),\n        content_type='application/json',\n    )", "func_src_after": "async def save(request):\n    # TODO csrf\n    data = await request.post()\n    item = Item(data['src'])\n\n    # Update name\n    new_src = data.get('new_src')\n    if new_src:\n        new_abspath = os.path.abspath(settings.STORAGE_DIR + new_src)\n        if not new_abspath.startswith(settings.STORAGE_DIR):\n            return web.Response(status=400, body=b'Invalid Request')\n\n        if new_abspath != item.abspath:\n            shutil.move(item.abspath, new_abspath)\n            old_backup_abspath = item.backup_abspath\n            item = Item(new_src)\n            if os.path.isfile(old_backup_abspath):\n                shutil.move(old_backup_abspath, item.backup_abspath)\n\n    # Update meta\n    for field in item.FORM:\n        # TODO handle .repeatable (keywords)\n        item.meta[field] = [data.get(field, '')]\n\n    if settings.SAVE_ORIGINALS and not os.path.isfile(item.backup_abspath):\n        shutil.copyfile(item.abspath, item.backup_abspath)\n\n    # WISHLIST don't write() if nothing changed\n    item.meta.write()\n\n    return web.Response(\n        status=200,\n        body=json.dumps(item.get_form_fields()).encode('utf8'),\n        content_type='application/json',\n    )", "commit_link": "github.com/crccheck/gallery-cms/commit/60dec5c580a779ae27824ed54cb113eca25afdc0", "file_name": "gallery/gallery.py", "vul_type": "cwe-022", "description": "Write a Python function to update an item's name and metadata from a POST request."}
{"func_name": "ndpi_search_oracle", "func_src_before": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "func_src_after": "void ndpi_search_oracle(struct ndpi_detection_module_struct *ndpi_struct, struct ndpi_flow_struct *flow)\n{\n  struct ndpi_packet_struct *packet = &flow->packet;\n  u_int16_t dport = 0, sport = 0;\n\n  NDPI_LOG_DBG(ndpi_struct, \"search ORACLE\\n\");\n\n  if(packet->tcp != NULL) {\n    sport = ntohs(packet->tcp->source), dport = ntohs(packet->tcp->dest);\n    NDPI_LOG_DBG2(ndpi_struct, \"calculating ORACLE over tcp\\n\");\n    /* Oracle Database 9g,10g,11g */\n    if ((dport == 1521 || sport == 1521)\n\t&&  (((packet->payload_packet_len >= 3 && packet->payload[0] == 0x07) && (packet->payload[1] == 0xff) && (packet->payload[2] == 0x00))\n\t     || ((packet->payload_packet_len >= 232) && ((packet->payload[0] == 0x00) || (packet->payload[0] == 0x01)) \n\t     && (packet->payload[1] != 0x00)\n\t     && (packet->payload[2] == 0x00)\n\t\t && (packet->payload[3] == 0x00)))) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    } else if (packet->payload_packet_len == 213 && packet->payload[0] == 0x00 &&\n               packet->payload[1] == 0xd5 && packet->payload[2] == 0x00 &&\n               packet->payload[3] == 0x00 ) {\n      NDPI_LOG_INFO(ndpi_struct, \"found oracle\\n\");\n      ndpi_int_oracle_add_connection(ndpi_struct, flow);\n    }\n  } else {\n    NDPI_EXCLUDE_PROTO(ndpi_struct, flow);\n  }\n}", "commit_link": "github.com/ntop/nDPI/commit/b69177be2fbe01c2442239a61832c44e40136c05", "file_name": "src/lib/protocols/oracle.c", "vul_type": "cwe-125", "description": "In C, write a function to detect Oracle database traffic by examining TCP packets and their payload."}
{"func_name": "next_line", "func_src_before": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b, *avail, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "func_src_after": "next_line(struct archive_read *a,\n    const char **b, ssize_t *avail, ssize_t *ravail, ssize_t *nl)\n{\n\tssize_t len;\n\tint quit;\n\t\n\tquit = 0;\n\tif (*avail == 0) {\n\t\t*nl = 0;\n\t\tlen = 0;\n\t} else\n\t\tlen = get_line_size(*b, *avail, nl);\n\t/*\n\t * Read bytes more while it does not reach the end of line.\n\t */\n\twhile (*nl == 0 && len == *avail && !quit) {\n\t\tssize_t diff = *ravail - *avail;\n\t\tsize_t nbytes_req = (*ravail+1023) & ~1023U;\n\t\tssize_t tested;\n\n\t\t/* Increase reading bytes if it is not enough to at least\n\t\t * new two lines. */\n\t\tif (nbytes_req < (size_t)*ravail + 160)\n\t\t\tnbytes_req <<= 1;\n\n\t\t*b = __archive_read_ahead(a, nbytes_req, avail);\n\t\tif (*b == NULL) {\n\t\t\tif (*ravail >= *avail)\n\t\t\t\treturn (0);\n\t\t\t/* Reading bytes reaches the end of file. */\n\t\t\t*b = __archive_read_ahead(a, *avail, avail);\n\t\t\tquit = 1;\n\t\t}\n\t\t*ravail = *avail;\n\t\t*b += diff;\n\t\t*avail -= diff;\n\t\ttested = len;/* Skip some bytes we already determinated. */\n\t\tlen = get_line_size(*b + len, *avail - len, nl);\n\t\tif (len >= 0)\n\t\t\tlen += tested;\n\t}\n\treturn (len);\n}", "commit_link": "github.com/libarchive/libarchive/commit/eec077f52bfa2d3f7103b4b74d52572ba8a15aca", "file_name": "libarchive/archive_read_support_format_mtree.c", "vul_type": "cwe-125", "description": "Write a C function named `next_line` that reads the next line from an archive, handling buffer adjustments and end-of-file conditions."}
{"func_name": "big_key_init", "func_src_before": "static int __init big_key_init(void)\n{\n\treturn register_key_type(&key_type_big_key);\n}", "func_src_after": "static int __init big_key_init(void)\n{\n\tstruct crypto_skcipher *cipher;\n\tstruct crypto_rng *rng;\n\tint ret;\n\n\trng = crypto_alloc_rng(big_key_rng_name, 0, 0);\n\tif (IS_ERR(rng)) {\n\t\tpr_err(\"Can't alloc rng: %ld\\n\", PTR_ERR(rng));\n\t\treturn PTR_ERR(rng);\n\t}\n\n\tbig_key_rng = rng;\n\n\t/* seed RNG */\n\tret = crypto_rng_reset(rng, NULL, crypto_rng_seedsize(rng));\n\tif (ret) {\n\t\tpr_err(\"Can't reset rng: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\t/* init block cipher */\n\tcipher = crypto_alloc_skcipher(big_key_alg_name, 0, CRYPTO_ALG_ASYNC);\n\tif (IS_ERR(cipher)) {\n\t\tret = PTR_ERR(cipher);\n\t\tpr_err(\"Can't alloc crypto: %d\\n\", ret);\n\t\tgoto error_rng;\n\t}\n\n\tbig_key_skcipher = cipher;\n\n\tret = register_key_type(&key_type_big_key);\n\tif (ret < 0) {\n\t\tpr_err(\"Can't register type: %d\\n\", ret);\n\t\tgoto error_cipher;\n\t}\n\n\treturn 0;\n\nerror_cipher:\n\tcrypto_free_skcipher(big_key_skcipher);\nerror_rng:\n\tcrypto_free_rng(big_key_rng);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7df3e59c3d1df4f87fe874c7956ef7a3d2f4d5fb", "file_name": "security/keys/big_key.c", "vul_type": "cwe-476", "description": "Write a C function for Linux kernel module initialization that registers a new key type and optionally sets up cryptographic components."}
{"func_name": "load_tile", "func_src_before": "static MagickBooleanType load_tile(Image *image,Image *tile_image,\n  XCFDocInfo *inDocInfo,XCFLayerInfo *inLayerInfo,size_t data_length,\n  ExceptionInfo *exception)\n{\n  ssize_t\n    y;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *graydata;\n\n  XCFPixelInfo\n    *xcfdata,\n    *xcfodata;\n\n  xcfdata=(XCFPixelInfo *) AcquireQuantumMemory(data_length,sizeof(*xcfdata));\n  if (xcfdata == (XCFPixelInfo *) NULL)\n    ThrowBinaryException(ResourceLimitError,\"MemoryAllocationFailed\",\n      image->filename);\n  xcfodata=xcfdata;\n  graydata=(unsigned char *) xcfdata;  /* used by gray and indexed */\n  count=ReadBlob(image,data_length,(unsigned char *) xcfdata);\n  if (count != (ssize_t) data_length)\n    ThrowBinaryException(CorruptImageError,\"NotEnoughPixelData\",\n      image->filename);\n  for (y=0; y < (ssize_t) tile_image->rows; y++)\n  {\n    q=GetAuthenticPixels(tile_image,0,y,tile_image->columns,1,exception);\n    if (q == (Quantum *) NULL)\n      break;\n    if (inDocInfo->image_type == GIMP_GRAY)\n      {\n        for (x=0; x < (ssize_t) tile_image->columns; x++)\n        {\n          SetPixelGray(tile_image,ScaleCharToQuantum(*graydata),q);\n          SetPixelAlpha(tile_image,ScaleCharToQuantum((unsigned char)\n            inLayerInfo->alpha),q);\n          graydata++;\n          q+=GetPixelChannels(tile_image);\n        }\n      }\n    else\n      if (inDocInfo->image_type == GIMP_RGB)\n        {\n          for (x=0; x < (ssize_t) tile_image->columns; x++)\n          {\n            SetPixelRed(tile_image,ScaleCharToQuantum(xcfdata->red),q);\n            SetPixelGreen(tile_image,ScaleCharToQuantum(xcfdata->green),q);\n            SetPixelBlue(tile_image,ScaleCharToQuantum(xcfdata->blue),q);\n            SetPixelAlpha(tile_image,xcfdata->alpha == 255U ? TransparentAlpha :\n              ScaleCharToQuantum((unsigned char) inLayerInfo->alpha),q);\n            xcfdata++;\n            q+=GetPixelChannels(tile_image);\n          }\n        }\n     if (SyncAuthenticPixels(tile_image,exception) == MagickFalse)\n       break;\n  }\n  xcfodata=(XCFPixelInfo *) RelinquishMagickMemory(xcfodata);\n  return MagickTrue;\n}", "func_src_after": "static MagickBooleanType load_tile(Image *image,Image *tile_image,\n  XCFDocInfo *inDocInfo,XCFLayerInfo *inLayerInfo,size_t data_length,\n  ExceptionInfo *exception)\n{\n  ssize_t\n    y;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  ssize_t\n    count;\n\n  unsigned char\n    *graydata;\n\n  XCFPixelInfo\n    *xcfdata,\n    *xcfodata;\n\n  xcfdata=(XCFPixelInfo *) AcquireQuantumMemory(MagickMax(data_length,\n    tile_image->columns*tile_image->rows),sizeof(*xcfdata));\n  if (xcfdata == (XCFPixelInfo *) NULL)\n    ThrowBinaryException(ResourceLimitError,\"MemoryAllocationFailed\",\n      image->filename);\n  xcfodata=xcfdata;\n  graydata=(unsigned char *) xcfdata;  /* used by gray and indexed */\n  count=ReadBlob(image,data_length,(unsigned char *) xcfdata);\n  if (count != (ssize_t) data_length)\n    ThrowBinaryException(CorruptImageError,\"NotEnoughPixelData\",\n      image->filename);\n  for (y=0; y < (ssize_t) tile_image->rows; y++)\n  {\n    q=GetAuthenticPixels(tile_image,0,y,tile_image->columns,1,exception);\n    if (q == (Quantum *) NULL)\n      break;\n    if (inDocInfo->image_type == GIMP_GRAY)\n      {\n        for (x=0; x < (ssize_t) tile_image->columns; x++)\n        {\n          SetPixelGray(tile_image,ScaleCharToQuantum(*graydata),q);\n          SetPixelAlpha(tile_image,ScaleCharToQuantum((unsigned char)\n            inLayerInfo->alpha),q);\n          graydata++;\n          q+=GetPixelChannels(tile_image);\n        }\n      }\n    else\n      if (inDocInfo->image_type == GIMP_RGB)\n        {\n          for (x=0; x < (ssize_t) tile_image->columns; x++)\n          {\n            SetPixelRed(tile_image,ScaleCharToQuantum(xcfdata->red),q);\n            SetPixelGreen(tile_image,ScaleCharToQuantum(xcfdata->green),q);\n            SetPixelBlue(tile_image,ScaleCharToQuantum(xcfdata->blue),q);\n            SetPixelAlpha(tile_image,xcfdata->alpha == 255U ? TransparentAlpha :\n              ScaleCharToQuantum((unsigned char) inLayerInfo->alpha),q);\n            xcfdata++;\n            q+=GetPixelChannels(tile_image);\n          }\n        }\n     if (SyncAuthenticPixels(tile_image,exception) == MagickFalse)\n       break;\n  }\n  xcfodata=(XCFPixelInfo *) RelinquishMagickMemory(xcfodata);\n  return MagickTrue;\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/a2e1064f288a353bc5fef7f79ccb7683759e775c", "file_name": "coders/xcf.c", "vul_type": "cwe-125", "description": "Write a C function named `load_tile` that processes pixel data for an image tile in ImageMagick."}
{"func_name": "change_pass", "func_src_before": "    def change_pass(self, new_pass, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET password = ?\n            WHERE client_id = ?\n        \"\"\"\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql, (new_pass, logged_user.get_client_id()))\n        self.__conn.commit()", "func_src_after": "    def change_pass(self, new_pass, logged_user):\n        update_sql = \"\"\"\n            UPDATE Clients\n            SET password = '{}'\n            WHERE client_id = '{}'\n        \"\"\".format(new_pass, logged_user.get_client_id())\n\n        cursor = self.__conn.cursor()\n\n        cursor.execute(update_sql)\n        self.__conn.commit()", "commit_link": "github.com/AnetaStoycheva/Programming101_HackBulgaria/commit/c0d6f4b8fe83a375832845a45952b5153e4c34f3", "file_name": "Week_9/sql_manager.py", "vul_type": "cwe-089", "description": "Write a Python function to update a client's password in the database given a new password and the logged-in user object."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES (%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connects()\n        try:\n            # The following introduces a deliberate security flaw. See section on SQL injecton below\n            query = \"INSERT INTO crimes (description) VALUES ('{}');\".format(\n                data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/JeremiahO/crimemap/commit/c17537fcd7aa4e2a26f7ca5cefaeb356ff646858", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function named `add_input` that inserts user-provided data into a database table named `crimes`, but ensure the first snippet is vulnerable to SQL injection while the second is not."}
{"func_name": "manipulate_reservation_action", "func_src_before": "def manipulate_reservation_action(request: HttpRequest, default_foreward_url: str):\n    \"\"\"\n    This function is used to alter the reservation beeing build inside\n    a cookie. This function automatically crafts the required response.\n    \"\"\"\n    js_string: str = \"\"\n    r: GroupReservation = None\n    u: Profile = get_current_user(request)\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if \"srid\" in request.GET:\n        if not request.GET.get(\"rid\"):\n            return HttpResponseRedirect(\"/admin?error=missing%20primary%20reservation%20id\")\n        srid: int = int(request.GET[\"srid\"])\n        sr: SubReservation = None\n        if srid == 0:\n            sr = SubReservation()\n        else:\n            sr = SubReservation.objects.get(id=srid)\n        if request.POST.get(\"notes\"):\n            sr.notes = request.POST[\"notes\"]\n        else:\n            sr.notes = \" \"\n        sr.primary_reservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n        sr.save()\n        print(request.POST)\n        print(sr.notes)\n        return HttpResponseRedirect(\"/admin/reservations/edit?rid=\" + str(int(request.GET[\"rid\"])) + \"&srid=\" + str(sr.id))\n    if \"rid\" in request.GET:\n        # update reservation\n        r = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n    elif u.number_of_allowed_reservations > GroupReservation.objects.all().filter(createdByUser=u).count():\n        r = GroupReservation()\n        r.createdByUser = u\n        r.ready = False\n        r.open = True\n        r.pickupDate = datetime.datetime.now()\n    else:\n        return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\")\n    if request.POST.get(\"notes\"):\n        r.notes = request.POST[\"notes\"]\n    if request.POST.get(\"contact\"):\n        r.responsiblePerson = str(request.POST[\"contact\"])\n    if (r.createdByUser == u or o.rights > 1) and not r.submitted:\n        r.save()\n    else:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    response: HttpResponseRedirect = HttpResponseRedirect(forward_url + \"?rid=\" + str(r.id))\n    return response", "func_src_after": "def manipulate_reservation_action(request: HttpRequest, default_foreward_url: str):\n    \"\"\"\n    This function is used to alter the reservation beeing build inside\n    a cookie. This function automatically crafts the required response.\n    \"\"\"\n    js_string: str = \"\"\n    r: GroupReservation = None\n    u: Profile = get_current_user(request)\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if \"srid\" in request.GET:\n        if not request.GET.get(\"rid\"):\n            return HttpResponseRedirect(\"/admin?error=missing%20primary%20reservation%20id\")\n        srid: int = int(request.GET[\"srid\"])\n        sr: SubReservation = None\n        if srid == 0:\n            sr = SubReservation()\n        else:\n            sr = SubReservation.objects.get(id=srid)\n        if request.POST.get(\"notes\"):\n            sr.notes = escape(request.POST[\"notes\"])\n        else:\n            sr.notes = \" \"\n        sr.primary_reservation = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n        sr.save()\n        print(request.POST)\n        print(sr.notes)\n        return HttpResponseRedirect(\"/admin/reservations/edit?rid=\" + str(int(request.GET[\"rid\"])) + \"&srid=\" + str(sr.id))\n    if \"rid\" in request.GET:\n        # update reservation\n        r = GroupReservation.objects.get(id=int(request.GET[\"rid\"]))\n    elif u.number_of_allowed_reservations > GroupReservation.objects.all().filter(createdByUser=u).count():\n        r = GroupReservation()\n        r.createdByUser = u\n        r.ready = False\n        r.open = True\n        r.pickupDate = datetime.datetime.now()\n    else:\n        return HttpResponseRedirect(\"/admin?error=Too%20Many%20reservations\")\n    if request.POST.get(\"notes\"):\n        r.notes = escape(request.POST[\"notes\"])\n    if request.POST.get(\"contact\"):\n        r.responsiblePerson = escape(str(request.POST[\"contact\"]))\n    if (r.createdByUser == u or o.rights > 1) and not r.submitted:\n        r.save()\n    else:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    response: HttpResponseRedirect = HttpResponseRedirect(forward_url + \"?rid=\" + str(r.id))\n    return response", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/reservation_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle reservation modifications and redirection based on user input from a web request."}
{"func_name": "usage", "func_src_before": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd = cmd + ' -' + args\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "func_src_after": "def usage(args=None):\n    '''\n    Return usage information for volumes mounted on this minion\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' disk.usage\n    '''\n    flags = ''\n    allowed = ('a', 'B', 'h', 'H', 'i', 'k', 'l', 'P', 't', 'T', 'x', 'v')\n    for flag in args:\n        if flag in allowed:\n            flags += flag\n        else:\n            break\n    if __grains__['kernel'] == 'Linux':\n        cmd = 'df -P'\n    elif __grains__['kernel'] == 'OpenBSD':\n        cmd = 'df -kP'\n    else:\n        cmd = 'df'\n    if args:\n        cmd += ' -{0}'.format(flags)\n    ret = {}\n    out = __salt__['cmd.run'](cmd).splitlines()\n    for line in out:\n        if not line:\n            continue\n        if line.startswith('Filesystem'):\n            continue\n        comps = line.split()\n        while not comps[1].isdigit():\n            comps[0] = '{0} {1}'.format(comps[0], comps[1])\n            comps.pop(1)\n        try:\n            if __grains__['kernel'] == 'Darwin':\n                ret[comps[8]] = {\n                        'filesystem': comps[0],\n                        '512-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                        'iused': comps[5],\n                        'ifree': comps[6],\n                        '%iused': comps[7],\n                }\n            else:\n                ret[comps[5]] = {\n                        'filesystem': comps[0],\n                        '1K-blocks': comps[1],\n                        'used': comps[2],\n                        'available': comps[3],\n                        'capacity': comps[4],\n                }\n        except IndexError:\n            log.warn(\"Problem parsing disk usage information\")\n            ret = {}\n    return ret", "commit_link": "github.com/saltstack/salt/commit/ebdef37b7e5d2b95a01d34b211c61c61da67e46a", "file_name": "salt/modules/disk.py", "vul_type": "cwe-078", "description": "Write a Python function named `usage` that returns disk usage information for mounted volumes, with optional arguments for additional flags."}
{"func_name": "parse_string", "func_src_before": "static const char *parse_string(cJSON *item,const char *str,const char **ep)\n{\n\tconst char *ptr=str+1,*end_ptr=str+1;char *ptr2;char *out;int len=0;unsigned uc,uc2;\n\tif (*str!='\\\"') {*ep=str;return 0;}\t/* not a string! */\n\t\n\twhile (*end_ptr!='\\\"' && *end_ptr && ++len) if (*end_ptr++ == '\\\\') end_ptr++;\t/* Skip escaped quotes. */\n\t\n\tout=(char*)cJSON_malloc(len+1);\t/* This is how long we need for the string, roughly. */\n\tif (!out) return 0;\n\titem->valuestring=out; /* assign here so out will be deleted during cJSON_Delete() later */\n\titem->type=cJSON_String;\n\t\n\tptr=str+1;ptr2=out;\n\twhile (ptr < end_ptr)\n\t{\n\t\tif (*ptr!='\\\\') *ptr2++=*ptr++;\n\t\telse\n\t\t{\n\t\t\tptr++;\n\t\t\tswitch (*ptr)\n\t\t\t{\n\t\t\t\tcase 'b': *ptr2++='\\b';\tbreak;\n\t\t\t\tcase 'f': *ptr2++='\\f';\tbreak;\n\t\t\t\tcase 'n': *ptr2++='\\n';\tbreak;\n\t\t\t\tcase 'r': *ptr2++='\\r';\tbreak;\n\t\t\t\tcase 't': *ptr2++='\\t';\tbreak;\n\t\t\t\tcase 'u':\t /* transcode utf16 to utf8. */\n\t\t\t\t\tuc=parse_hex4(ptr+1);ptr+=4;\t/* get the unicode char. */\n\t\t\t\t\tif (ptr >= end_ptr) {*ep=str;return 0;}\t/* invalid */\n\t\t\t\t\t\n\t\t\t\t\tif ((uc>=0xDC00 && uc<=0xDFFF) || uc==0)    {*ep=str;return 0;}\t/* check for invalid.   */\n\t\t\t\t\t\n\t\t\t\t\tif (uc>=0xD800 && uc<=0xDBFF)\t/* UTF16 surrogate pairs.\t*/\n\t\t\t\t\t{\n\t\t\t\t\t\tif (ptr+6 > end_ptr)    {*ep=str;return 0;}\t/* invalid */\n\t\t\t\t\t\tif (ptr[1]!='\\\\' || ptr[2]!='u')    {*ep=str;return 0;}\t/* missing second-half of surrogate.    */\n\t\t\t\t\t\tuc2=parse_hex4(ptr+3);ptr+=6;\n\t\t\t\t\t\tif (uc2<0xDC00 || uc2>0xDFFF)       {*ep=str;return 0;}\t/* invalid second-half of surrogate.    */\n\t\t\t\t\t\tuc=0x10000 + (((uc&0x3FF)<<10) | (uc2&0x3FF));\n\t\t\t\t\t}\n\n\t\t\t\t\tlen=4;if (uc<0x80) len=1;else if (uc<0x800) len=2;else if (uc<0x10000) len=3; ptr2+=len;\n\t\t\t\t\t\n\t\t\t\t\tswitch (len) {\n\t\t\t\t\t\tcase 4: *--ptr2 =((uc | 0x80) & 0xBF); uc >>= 6;\n\t\t\t\t\t\tcase 3: *--ptr2 =((uc | 0x80) & 0xBF); uc >>= 6;\n\t\t\t\t\t\tcase 2: *--ptr2 =((uc | 0x80) & 0xBF); uc >>= 6;\n\t\t\t\t\t\tcase 1: *--ptr2 =(uc | firstByteMark[len]);\n\t\t\t\t\t}\n\t\t\t\t\tptr2+=len;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:  *ptr2++=*ptr; break;\n\t\t\t}\n\t\t\tptr++;\n\t\t}\n\t}\n\t*ptr2=0;\n\tif (*ptr=='\\\"') ptr++;\n\treturn ptr;\n}", "func_src_after": "static const char *parse_string(cJSON *item,const char *str,const char **ep)\n{\n\tconst char *ptr=str+1,*end_ptr=str+1;char *ptr2;char *out;int len=0;unsigned uc,uc2;\n\tif (*str!='\\\"') {*ep=str;return 0;}\t/* not a string! */\n\n\twhile (*end_ptr!='\\\"' && *end_ptr && ++len)\n\t{\n\t    if (*end_ptr++ == '\\\\')\n\t    {\n\t\tif (*end_ptr == '\\0')\n\t\t{\n\t\t    /* prevent buffer overflow when last input character is a backslash */\n\t\t    return 0;\n\t\t}\n\t\tend_ptr++;\t/* Skip escaped quotes. */\n\t    }\n\t}\n\n\tout=(char*)cJSON_malloc(len+1);\t/* This is how long we need for the string, roughly. */\n\tif (!out) return 0;\n\titem->valuestring=out; /* assign here so out will be deleted during cJSON_Delete() later */\n\titem->type=cJSON_String;\n\t\n\tptr=str+1;ptr2=out;\n\twhile (ptr < end_ptr)\n\t{\n\t\tif (*ptr!='\\\\') *ptr2++=*ptr++;\n\t\telse\n\t\t{\n\t\t\tptr++;\n\t\t\tswitch (*ptr)\n\t\t\t{\n\t\t\t\tcase 'b': *ptr2++='\\b';\tbreak;\n\t\t\t\tcase 'f': *ptr2++='\\f';\tbreak;\n\t\t\t\tcase 'n': *ptr2++='\\n';\tbreak;\n\t\t\t\tcase 'r': *ptr2++='\\r';\tbreak;\n\t\t\t\tcase 't': *ptr2++='\\t';\tbreak;\n\t\t\t\tcase 'u':\t /* transcode utf16 to utf8. */\n\t\t\t\t\tuc=parse_hex4(ptr+1);ptr+=4;\t/* get the unicode char. */\n\t\t\t\t\tif (ptr >= end_ptr) {*ep=str;return 0;}\t/* invalid */\n\t\t\t\t\t\n\t\t\t\t\tif ((uc>=0xDC00 && uc<=0xDFFF) || uc==0)    {*ep=str;return 0;}\t/* check for invalid.   */\n\t\t\t\t\t\n\t\t\t\t\tif (uc>=0xD800 && uc<=0xDBFF)\t/* UTF16 surrogate pairs.\t*/\n\t\t\t\t\t{\n\t\t\t\t\t\tif (ptr+6 > end_ptr)    {*ep=str;return 0;}\t/* invalid */\n\t\t\t\t\t\tif (ptr[1]!='\\\\' || ptr[2]!='u')    {*ep=str;return 0;}\t/* missing second-half of surrogate.    */\n\t\t\t\t\t\tuc2=parse_hex4(ptr+3);ptr+=6;\n\t\t\t\t\t\tif (uc2<0xDC00 || uc2>0xDFFF)       {*ep=str;return 0;}\t/* invalid second-half of surrogate.    */\n\t\t\t\t\t\tuc=0x10000 + (((uc&0x3FF)<<10) | (uc2&0x3FF));\n\t\t\t\t\t}\n\n\t\t\t\t\tlen=4;if (uc<0x80) len=1;else if (uc<0x800) len=2;else if (uc<0x10000) len=3; ptr2+=len;\n\t\t\t\t\t\n\t\t\t\t\tswitch (len) {\n\t\t\t\t\t\tcase 4: *--ptr2 =((uc | 0x80) & 0xBF); uc >>= 6;\n\t\t\t\t\t\tcase 3: *--ptr2 =((uc | 0x80) & 0xBF); uc >>= 6;\n\t\t\t\t\t\tcase 2: *--ptr2 =((uc | 0x80) & 0xBF); uc >>= 6;\n\t\t\t\t\t\tcase 1: *--ptr2 =(uc | firstByteMark[len]);\n\t\t\t\t\t}\n\t\t\t\t\tptr2+=len;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:  *ptr2++=*ptr; break;\n\t\t\t}\n\t\t\tptr++;\n\t\t}\n\t}\n\t*ptr2=0;\n\tif (*ptr=='\\\"') ptr++;\n\treturn ptr;\n}", "commit_link": "github.com/DaveGamble/cJSON/commit/94df772485c92866ca417d92137747b2e3b0a917", "file_name": "cJSON.c", "vul_type": "cwe-125", "description": "Write a C function to parse and decode a JSON string, handling escape sequences and UTF-16 surrogate pairs."}
{"func_name": "karma_ask", "func_src_before": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(\n            ''' SELECT karma FROM people WHERE name='{}' '''.format(name))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def karma_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute(''' SELECT karma FROM people WHERE name=%(name)s ''',\n                       (name, ))\n        karma = cursor.fetchone()\n        if karma is None:\n            logger.debug('No karma found for name {}'.format(name))\n            db.close()\n            return karma\n        else:\n            karma = karma[0]\n            logger.debug('karma of {} found for name {}'.format(karma, name))\n            db.close()\n            return karma\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for a person's karma by their name and handle the result or potential errors."}
{"func_name": "talk", "func_src_before": "def talk(myText):\r\n    if( myText.find( \"twitter\" ) >= 0 ):\r\n        myText += \"0\"\r\n        myText = myText[7:-1]\r\n        try:\r\n\t    myText = twitter.getTweet( myText )\r\n\texcept:\r\n\t    print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r\n            return\r\n    \r\n    os.system( \"espeak \\\",...\\\" 2>/dev/null\" ) # Sometimes the beginning of audio can get cut off. Insert silence.\r\n    time.sleep( 0.5 )\r\n    subprocess.call([\"espeak\", \"-w\", \"speech.wav\", myText, \"-s\", \"130\"])\r\n    audio.play(\"speech.wav\")\r\n    return myText", "func_src_after": "def talk(myText):\r\n    if( myText.find( \"twitter\" ) >= 0 ):\r\n        myText += \"0\"\r\n        myText = myText[7:-1]\r\n        try:\r\n\t    myText = twitter.getTweet( myText )\r\n\texcept:\r\n\t    print( \"!!!ERROR: INVALID TWITTER CREDENTIALS. Please read README.md for instructions.\")\r\n            return\r\n    \r\n    os.system( \"espeak \\\",...\\\" 2>/dev/null\" ) # Sometimes the beginning of audio can get cut off. Insert silence.\r\n    time.sleep( 0.5 )\r\n    os.system( \"espeak -w speech.wav \\\"\" + myText + \"\\\" -s 130\" )\r\n    audio.play(\"speech.wav\")\r\n    return myText", "commit_link": "github.com/ntc-chip-revived/ChippyRuxpin/commit/0cd7d78e4d806852fd75fee03c24cce322f76014", "file_name": "chippyRuxpin.py", "vul_type": "cwe-078", "description": "Create a Python function named `talk` that processes a string to fetch a tweet if it contains the word \"twitter\" and then uses the `espeak` tool to convert the text to speech, saving it to a WAV file before playing it."}
{"func_name": "process_ranks", "func_src_before": "    def process_ranks(self, scene, urls, recent_date):\n        PLAYER1 = 0\n        PLAYER2 = 1\n        WINNER = 2\n        DATE = 3\n        SCENE = 4\n\n        # make sure if we already have calculated ranks for these players at this time, we do not do it again\n        sql = \"SELECT * FROM ranks WHERE scene = '{}' AND date='{}';\".format(str(scene), recent_date)\n        res = self.db.exec(sql)\n        if len(res) > 0:\n            LOG.info('We have already calculated ranks for {} on date {}. SKipping'.format(scene, recent_date))\n            return\n\n        matches = bracket_utils.get_matches_from_urls(self.db, urls)\n        LOG.info('About to start processing ranks for scene {} on {}'.format(scene, recent_date))\n\n        # Iterate through each match, and build up our dict\n        win_loss_dict = {}\n        for match in matches:\n            p1 = match[PLAYER1]\n            p2 = match[PLAYER2]\n            winner = match[WINNER]\n            date = match[DATE]\n\n            #Add p1 to the dict\n            if p1 not in win_loss_dict:\n                win_loss_dict[p1] = {}\n\n            if p2 not in win_loss_dict[p1]:\n                win_loss_dict[p1][p2] = []\n\n            # Add an entry to represent this match to p1\n            win_loss_dict[p1][p2].append((date, winner == p1))\n\n            # add p2 to the dict\n            if p2 not in win_loss_dict:\n                win_loss_dict[p2] = {}\n\n            if p1 not in win_loss_dict[p2]:\n                win_loss_dict[p2][p1] = []\n\n            win_loss_dict[p2][p1].append((date, winner == p2))\n\n        ranks = get_ranks(win_loss_dict)\n\n        tag_rank_map = {}\n        for i, x in enumerate(ranks):\n            points, player = x\n            rank = len(ranks) - i\n\n            sql = \"INSERT INTO ranks (scene, player, rank, points, date) VALUES ('{}', '{}', '{}', '{}', '{}');\"\\\n                    .format(str(scene), str(player), int(rank), str(points), str(recent_date))\n            self.db.exec(sql)\n\n            # Only count this player if this is the scene he/she belongs to\n            sql = \"SELECT scene FROM players WHERE tag='{}';\".format(player)\n            res = self.db.exec(sql)\n\n            if len(res) == 0 or res[0][0] == scene:\n                # Also create a list to update the player web\n                map = {'rank':rank, 'total_ranked':len(ranks)}\n                tag_rank_map[player] = map\n\n        player_web.update_ranks(tag_rank_map)", "func_src_after": "    def process_ranks(self, scene, urls, recent_date):\n        PLAYER1 = 0\n        PLAYER2 = 1\n        WINNER = 2\n        DATE = 3\n        SCENE = 4\n\n        # make sure if we already have calculated ranks for these players at this time, we do not do it again\n        sql = \"SELECT * FROM ranks WHERE scene = '{scene}' AND date='{date}';\"\n        args = {'scene': scene, 'date': recent_date}\n        res = self.db.exec(sql, args)\n        if len(res) > 0:\n            LOG.info('We have already calculated ranks for {} on date {}. SKipping'.format(scene, recent_date))\n            return\n\n        matches = bracket_utils.get_matches_from_urls(self.db, urls)\n        LOG.info('About to start processing ranks for scene {} on {}'.format(scene, recent_date))\n\n        # Iterate through each match, and build up our dict\n        win_loss_dict = {}\n        for match in matches:\n            p1 = match[PLAYER1]\n            p2 = match[PLAYER2]\n            winner = match[WINNER]\n            date = match[DATE]\n\n            #Add p1 to the dict\n            if p1 not in win_loss_dict:\n                win_loss_dict[p1] = {}\n\n            if p2 not in win_loss_dict[p1]:\n                win_loss_dict[p1][p2] = []\n\n            # Add an entry to represent this match to p1\n            win_loss_dict[p1][p2].append((date, winner == p1))\n\n            # add p2 to the dict\n            if p2 not in win_loss_dict:\n                win_loss_dict[p2] = {}\n\n            if p1 not in win_loss_dict[p2]:\n                win_loss_dict[p2][p1] = []\n\n            win_loss_dict[p2][p1].append((date, winner == p2))\n\n        ranks = get_ranks(win_loss_dict)\n\n        tag_rank_map = {}\n        for i, x in enumerate(ranks):\n            points, player = x\n            rank = len(ranks) - i\n\n            sql = \"INSERT INTO ranks (scene, player, rank, points, date) VALUES ('{scene}', '{player}', '{rank}', '{points}', '{recent_date}');\"\n            args = {'scene': scene, 'player': player, 'rank': rank, 'points': points, 'recent_date': recent_date}\n            self.db.exec(sql, args)\n\n            # Only count this player if this is the scene he/she belongs to\n            sql = \"SELECT scene FROM players WHERE tag='{player}';\"\n            args = {'player': player}\n            res = self.db.exec(sql, args)\n\n            if len(res) == 0 or res[0][0] == scene:\n                # Also create a list to update the player web\n                map = {'rank':rank, 'total_ranked':len(ranks)}\n                tag_rank_map[player] = map\n\n        player_web.update_ranks(tag_rank_map)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "process_data.py", "vul_type": "cwe-089", "description": "Write a Python function to process player rankings from match URLs, avoiding duplication for the same scene and date."}
{"func_name": "archive_read_format_rar_read_data", "func_src_before": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN)\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "func_src_after": "archive_read_format_rar_read_data(struct archive_read *a, const void **buff,\n                                  size_t *size, int64_t *offset)\n{\n  struct rar *rar = (struct rar *)(a->format->data);\n  int ret;\n\n  if (rar->has_encrypted_entries == ARCHIVE_READ_FORMAT_ENCRYPTION_DONT_KNOW) {\n\t  rar->has_encrypted_entries = 0;\n  }\n\n  if (rar->bytes_unconsumed > 0) {\n      /* Consume as much as the decompressor actually used. */\n      __archive_read_consume(a, rar->bytes_unconsumed);\n      rar->bytes_unconsumed = 0;\n  }\n\n  *buff = NULL;\n  if (rar->entry_eof || rar->offset_seek >= rar->unp_size) {\n    *size = 0;\n    *offset = rar->offset;\n    if (*offset < rar->unp_size)\n      *offset = rar->unp_size;\n    return (ARCHIVE_EOF);\n  }\n\n  switch (rar->compression_method)\n  {\n  case COMPRESS_METHOD_STORE:\n    ret = read_data_stored(a, buff, size, offset);\n    break;\n\n  case COMPRESS_METHOD_FASTEST:\n  case COMPRESS_METHOD_FAST:\n  case COMPRESS_METHOD_NORMAL:\n  case COMPRESS_METHOD_GOOD:\n  case COMPRESS_METHOD_BEST:\n    ret = read_data_compressed(a, buff, size, offset);\n    if (ret != ARCHIVE_OK && ret != ARCHIVE_WARN) {\n      __archive_ppmd7_functions.Ppmd7_Free(&rar->ppmd7_context);\n      rar->start_new_table = 1;\n    }\n    break;\n\n  default:\n    archive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n                      \"Unsupported compression method for RAR file.\");\n    ret = ARCHIVE_FATAL;\n    break;\n  }\n  return (ret);\n}", "commit_link": "github.com/libarchive/libarchive/commit/b8592ecba2f9e451e1f5cb7ab6dcee8b8e7b3f60", "file_name": "libarchive/archive_read_support_format_rar.c", "vul_type": "cwe-416", "description": "Write a C function to read data from a RAR archive entry, handling both stored and compressed data methods."}
{"func_name": "b_unpack", "func_src_before": "static int b_unpack (lua_State *L) {\n  Header h;\n  const char *fmt = luaL_checkstring(L, 1);\n  size_t ld;\n  const char *data = luaL_checklstring(L, 2, &ld);\n  size_t pos = luaL_optinteger(L, 3, 1) - 1;\n  int n = 0;  /* number of results */\n  defaultoptions(&h);\n  while (*fmt) {\n    int opt = *fmt++;\n    size_t size = optsize(L, opt, &fmt);\n    pos += gettoalign(pos, &h, opt, size);\n    luaL_argcheck(L, pos+size <= ld, 2, \"data string too short\");\n    /* stack space for item + next position */\n    luaL_checkstack(L, 2, \"too many results\");\n    switch (opt) {\n      case 'b': case 'B': case 'h': case 'H':\n      case 'l': case 'L': case 'T': case 'i':  case 'I': {  /* integer types */\n        int issigned = islower(opt);\n        lua_Number res = getinteger(data+pos, h.endian, issigned, size);\n        lua_pushnumber(L, res); n++;\n        break;\n      }\n      case 'x': {\n        break;\n      }\n      case 'f': {\n        float f;\n        memcpy(&f, data+pos, size);\n        correctbytes((char *)&f, sizeof(f), h.endian);\n        lua_pushnumber(L, f); n++;\n        break;\n      }\n      case 'd': {\n        double d;\n        memcpy(&d, data+pos, size);\n        correctbytes((char *)&d, sizeof(d), h.endian);\n        lua_pushnumber(L, d); n++;\n        break;\n      }\n      case 'c': {\n        if (size == 0) {\n          if (n == 0 || !lua_isnumber(L, -1))\n            luaL_error(L, \"format 'c0' needs a previous size\");\n          size = lua_tonumber(L, -1);\n          lua_pop(L, 1); n--;\n          luaL_argcheck(L, size <= ld && pos <= ld - size,\n                           2, \"data string too short\");\n        }\n        lua_pushlstring(L, data+pos, size); n++;\n        break;\n      }\n      case 's': {\n        const char *e = (const char *)memchr(data+pos, '\\0', ld - pos);\n        if (e == NULL)\n          luaL_error(L, \"unfinished string in data\");\n        size = (e - (data+pos)) + 1;\n        lua_pushlstring(L, data+pos, size - 1); n++;\n        break;\n      }\n      default: controloptions(L, opt, &fmt, &h);\n    }\n    pos += size;\n  }\n  lua_pushinteger(L, pos + 1);  /* next position */\n  return n + 1;\n}", "func_src_after": "static int b_unpack (lua_State *L) {\n  Header h;\n  const char *fmt = luaL_checkstring(L, 1);\n  size_t ld;\n  const char *data = luaL_checklstring(L, 2, &ld);\n  size_t pos = luaL_optinteger(L, 3, 1);\n  luaL_argcheck(L, pos > 0, 3, \"offset must be 1 or greater\");\n  pos--; /* Lua indexes are 1-based, but here we want 0-based for C\n          * pointer math. */\n  int n = 0;  /* number of results */\n  defaultoptions(&h);\n  while (*fmt) {\n    int opt = *fmt++;\n    size_t size = optsize(L, opt, &fmt);\n    pos += gettoalign(pos, &h, opt, size);\n    luaL_argcheck(L, size <= ld && pos <= ld - size,\n                   2, \"data string too short\");\n    /* stack space for item + next position */\n    luaL_checkstack(L, 2, \"too many results\");\n    switch (opt) {\n      case 'b': case 'B': case 'h': case 'H':\n      case 'l': case 'L': case 'T': case 'i':  case 'I': {  /* integer types */\n        int issigned = islower(opt);\n        lua_Number res = getinteger(data+pos, h.endian, issigned, size);\n        lua_pushnumber(L, res); n++;\n        break;\n      }\n      case 'x': {\n        break;\n      }\n      case 'f': {\n        float f;\n        memcpy(&f, data+pos, size);\n        correctbytes((char *)&f, sizeof(f), h.endian);\n        lua_pushnumber(L, f); n++;\n        break;\n      }\n      case 'd': {\n        double d;\n        memcpy(&d, data+pos, size);\n        correctbytes((char *)&d, sizeof(d), h.endian);\n        lua_pushnumber(L, d); n++;\n        break;\n      }\n      case 'c': {\n        if (size == 0) {\n          if (n == 0 || !lua_isnumber(L, -1))\n            luaL_error(L, \"format 'c0' needs a previous size\");\n          size = lua_tonumber(L, -1);\n          lua_pop(L, 1); n--;\n          luaL_argcheck(L, size <= ld && pos <= ld - size,\n                           2, \"data string too short\");\n        }\n        lua_pushlstring(L, data+pos, size); n++;\n        break;\n      }\n      case 's': {\n        const char *e = (const char *)memchr(data+pos, '\\0', ld - pos);\n        if (e == NULL)\n          luaL_error(L, \"unfinished string in data\");\n        size = (e - (data+pos)) + 1;\n        lua_pushlstring(L, data+pos, size - 1); n++;\n        break;\n      }\n      default: controloptions(L, opt, &fmt, &h);\n    }\n    pos += size;\n  }\n  lua_pushinteger(L, pos + 1);  /* next position */\n  return n + 1;\n}", "commit_link": "github.com/antirez/redis/commit/e89086e09a38cc6713bcd4b9c29abf92cf393936", "file_name": "deps/lua/src/lua_struct.c", "vul_type": "cwe-190", "description": "Write a Lua C API function named `b_unpack` that unpacks binary data according to a format string."}
{"func_name": "karma_sub", "func_src_before": "def karma_sub(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES(%(name)s,-1,0)\n                ''', (name, ))\n            db.commit()\n            logger.debug('Inserted into karmadb -1 karma for {}'.format(name))\n            db.close()\n            return -1\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma - 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = %(karma)s WHERE name = %(name)s\n                ''', (\n                karma,\n                name,\n            ))\n            db.commit()\n            logger.debug('Inserted into karmadb -1 karma for {}'.format(name))\n            db.close()\n            return karma\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "func_src_after": "def karma_sub(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES('{}',-1,0)\n                '''.format(name))\n            db.commit()\n            logger.debug('Inserted into karmadb -1 karma for {}'.format(name))\n            db.close()\n            return -1\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma - 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = {0} WHERE name = '{1}'\n                '''.format(karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb -1 karma for {}'.format(name))\n            db.close()\n            return karma\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function that decreases a user's karma by 1 in a database, inserting the user with negative karma if they don't exist."}
{"func_name": "Logger::addPeer", "func_src_before": "void Logger::addPeer(const QString &ip, bool blocked, const QString &reason)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Peer temp = { peerCounter++, QDateTime::currentMSecsSinceEpoch(), ip, blocked, reason };\n    m_peers.push_back(temp);\n\n    if (m_peers.size() >= MAX_LOG_MESSAGES)\n        m_peers.pop_front();\n\n    emit newLogPeer(temp);\n}", "func_src_after": "void Logger::addPeer(const QString &ip, bool blocked, const QString &reason)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Peer temp = { peerCounter++, QDateTime::currentMSecsSinceEpoch(), Utils::String::toHtmlEscaped(ip), blocked, Utils::String::toHtmlEscaped(reason) };\n    m_peers.push_back(temp);\n\n    if (m_peers.size() >= MAX_LOG_MESSAGES)\n        m_peers.pop_front();\n\n    emit newLogPeer(temp);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/base/logger.cpp", "vul_type": "cwe-079", "description": "Write a C++ function in a Logger class that adds a peer with an IP, block status, and reason to a log, and emits a signal when a new peer is logged."}
{"func_name": "decode_bundle", "func_src_before": "decode_bundle(bool load, const struct nx_action_bundle *nab,\n              const struct vl_mff_map *vl_mff_map, uint64_t *tlv_bitmap,\n              struct ofpbuf *ofpacts)\n{\n    static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT(1, 5);\n    struct ofpact_bundle *bundle;\n    uint32_t slave_type;\n    size_t slaves_size, i;\n    enum ofperr error;\n\n    bundle = ofpact_put_BUNDLE(ofpacts);\n\n    bundle->n_slaves = ntohs(nab->n_slaves);\n    bundle->basis = ntohs(nab->basis);\n    bundle->fields = ntohs(nab->fields);\n    bundle->algorithm = ntohs(nab->algorithm);\n    slave_type = ntohl(nab->slave_type);\n    slaves_size = ntohs(nab->len) - sizeof *nab;\n\n    error = OFPERR_OFPBAC_BAD_ARGUMENT;\n    if (!flow_hash_fields_valid(bundle->fields)) {\n        VLOG_WARN_RL(&rl, \"unsupported fields %d\", (int) bundle->fields);\n    } else if (bundle->n_slaves > BUNDLE_MAX_SLAVES) {\n        VLOG_WARN_RL(&rl, \"too many slaves\");\n    } else if (bundle->algorithm != NX_BD_ALG_HRW\n               && bundle->algorithm != NX_BD_ALG_ACTIVE_BACKUP) {\n        VLOG_WARN_RL(&rl, \"unsupported algorithm %d\", (int) bundle->algorithm);\n    } else if (slave_type != mf_nxm_header(MFF_IN_PORT)) {\n        VLOG_WARN_RL(&rl, \"unsupported slave type %\"PRIu16, slave_type);\n    } else {\n        error = 0;\n    }\n\n    if (!is_all_zeros(nab->zero, sizeof nab->zero)) {\n        VLOG_WARN_RL(&rl, \"reserved field is nonzero\");\n        error = OFPERR_OFPBAC_BAD_ARGUMENT;\n    }\n\n    if (load) {\n        bundle->dst.ofs = nxm_decode_ofs(nab->ofs_nbits);\n        bundle->dst.n_bits = nxm_decode_n_bits(nab->ofs_nbits);\n        error = mf_vl_mff_mf_from_nxm_header(ntohl(nab->dst), vl_mff_map,\n                                             &bundle->dst.field, tlv_bitmap);\n        if (error) {\n            return error;\n        }\n\n        if (bundle->dst.n_bits < 16) {\n            VLOG_WARN_RL(&rl, \"bundle_load action requires at least 16 bit \"\n                         \"destination.\");\n            error = OFPERR_OFPBAC_BAD_ARGUMENT;\n        }\n    } else {\n        if (nab->ofs_nbits || nab->dst) {\n            VLOG_WARN_RL(&rl, \"bundle action has nonzero reserved fields\");\n            error = OFPERR_OFPBAC_BAD_ARGUMENT;\n        }\n    }\n\n    if (slaves_size < bundle->n_slaves * sizeof(ovs_be16)) {\n        VLOG_WARN_RL(&rl, \"Nicira action %s only has %\"PRIuSIZE\" bytes \"\n                     \"allocated for slaves.  %\"PRIuSIZE\" bytes are required \"\n                     \"for %\"PRIu16\" slaves.\",\n                     load ? \"bundle_load\" : \"bundle\", slaves_size,\n                     bundle->n_slaves * sizeof(ovs_be16), bundle->n_slaves);\n        error = OFPERR_OFPBAC_BAD_LEN;\n    }\n\n    for (i = 0; i < bundle->n_slaves; i++) {\n        ofp_port_t ofp_port = u16_to_ofp(ntohs(((ovs_be16 *)(nab + 1))[i]));\n        ofpbuf_put(ofpacts, &ofp_port, sizeof ofp_port);\n        bundle = ofpacts->header;\n    }\n\n    ofpact_finish_BUNDLE(ofpacts, &bundle);\n    if (!error) {\n        error = bundle_check(bundle, OFPP_MAX, NULL);\n    }\n    return error;\n}", "func_src_after": "decode_bundle(bool load, const struct nx_action_bundle *nab,\n              const struct vl_mff_map *vl_mff_map, uint64_t *tlv_bitmap,\n              struct ofpbuf *ofpacts)\n{\n    static struct vlog_rate_limit rl = VLOG_RATE_LIMIT_INIT(1, 5);\n    struct ofpact_bundle *bundle;\n    uint32_t slave_type;\n    size_t slaves_size, i;\n    enum ofperr error;\n\n    bundle = ofpact_put_BUNDLE(ofpacts);\n\n    bundle->n_slaves = ntohs(nab->n_slaves);\n    bundle->basis = ntohs(nab->basis);\n    bundle->fields = ntohs(nab->fields);\n    bundle->algorithm = ntohs(nab->algorithm);\n    slave_type = ntohl(nab->slave_type);\n    slaves_size = ntohs(nab->len) - sizeof *nab;\n\n    error = OFPERR_OFPBAC_BAD_ARGUMENT;\n    if (!flow_hash_fields_valid(bundle->fields)) {\n        VLOG_WARN_RL(&rl, \"unsupported fields %d\", (int) bundle->fields);\n    } else if (bundle->n_slaves > BUNDLE_MAX_SLAVES) {\n        VLOG_WARN_RL(&rl, \"too many slaves\");\n    } else if (bundle->algorithm != NX_BD_ALG_HRW\n               && bundle->algorithm != NX_BD_ALG_ACTIVE_BACKUP) {\n        VLOG_WARN_RL(&rl, \"unsupported algorithm %d\", (int) bundle->algorithm);\n    } else if (slave_type != mf_nxm_header(MFF_IN_PORT)) {\n        VLOG_WARN_RL(&rl, \"unsupported slave type %\"PRIu16, slave_type);\n    } else {\n        error = 0;\n    }\n\n    if (!is_all_zeros(nab->zero, sizeof nab->zero)) {\n        VLOG_WARN_RL(&rl, \"reserved field is nonzero\");\n        error = OFPERR_OFPBAC_BAD_ARGUMENT;\n    }\n\n    if (load) {\n        bundle->dst.ofs = nxm_decode_ofs(nab->ofs_nbits);\n        bundle->dst.n_bits = nxm_decode_n_bits(nab->ofs_nbits);\n        error = mf_vl_mff_mf_from_nxm_header(ntohl(nab->dst), vl_mff_map,\n                                             &bundle->dst.field, tlv_bitmap);\n        if (error) {\n            return error;\n        }\n\n        if (bundle->dst.n_bits < 16) {\n            VLOG_WARN_RL(&rl, \"bundle_load action requires at least 16 bit \"\n                         \"destination.\");\n            error = OFPERR_OFPBAC_BAD_ARGUMENT;\n        }\n    } else {\n        if (nab->ofs_nbits || nab->dst) {\n            VLOG_WARN_RL(&rl, \"bundle action has nonzero reserved fields\");\n            error = OFPERR_OFPBAC_BAD_ARGUMENT;\n        }\n    }\n\n    if (slaves_size < bundle->n_slaves * sizeof(ovs_be16)) {\n        VLOG_WARN_RL(&rl, \"Nicira action %s only has %\"PRIuSIZE\" bytes \"\n                     \"allocated for slaves.  %\"PRIuSIZE\" bytes are required \"\n                     \"for %\"PRIu16\" slaves.\",\n                     load ? \"bundle_load\" : \"bundle\", slaves_size,\n                     bundle->n_slaves * sizeof(ovs_be16), bundle->n_slaves);\n        error = OFPERR_OFPBAC_BAD_LEN;\n    } else {\n        for (i = 0; i < bundle->n_slaves; i++) {\n            ofp_port_t ofp_port\n                = u16_to_ofp(ntohs(((ovs_be16 *)(nab + 1))[i]));\n            ofpbuf_put(ofpacts, &ofp_port, sizeof ofp_port);\n            bundle = ofpacts->header;\n        }\n    }\n\n    ofpact_finish_BUNDLE(ofpacts, &bundle);\n    if (!error) {\n        error = bundle_check(bundle, OFPP_MAX, NULL);\n    }\n    return error;\n}", "commit_link": "github.com/openvswitch/ovs/commit/9237a63c47bd314b807cda0bd2216264e82edbe8", "file_name": "lib/ofp-actions.c", "vul_type": "cwe-125", "description": "In C, write a function `decode_bundle` that processes a bundle action structure for network packet processing."}
{"func_name": "delete_playlists_videos", "func_src_before": "def delete_playlists_videos(playlist_id, db):\n    db.execute(\"DELETE FROM video where playlist_id=%s;\", (playlist_id,))", "func_src_after": "def delete_playlists_videos(playlist_id, db):\n    db.execute(\"DELETE FROM video where playlist_id={playlist_id};\".format(\n        playlist_id=playlist_id))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "video/video_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to remove all videos from a specific playlist in a database using the playlist ID."}
{"func_name": "authDigestNonceLink", "func_src_before": "authDigestNonceLink(digest_nonce_h * nonce)\n{\n    assert(nonce != NULL);\n    ++nonce->references;\n    debugs(29, 9, \"nonce '\" << nonce << \"' now at '\" << nonce->references << \"'.\");\n}", "func_src_after": "authDigestNonceLink(digest_nonce_h * nonce)\n{\n    assert(nonce != NULL);\n    ++nonce->references;\n    assert(nonce->references != 0); // no overflows\n    debugs(29, 9, \"nonce '\" << nonce << \"' now at '\" << nonce->references << \"'.\");\n}", "commit_link": "github.com/squid-cache/squid/commit/eeebf0f37a72a2de08348e85ae34b02c34e9a811", "file_name": "src/auth/digest/Config.cc", "vul_type": "cwe-190", "description": "Write a C++ function named `authDigestNonceLink` that increments a reference counter for a given nonce object and logs the new reference count, ensuring the nonce is not null and, for the second snippet, that the reference count does not overflow."}
{"func_name": "delete_video", "func_src_before": "@app.route('/delete_video/<filename>')\ndef delete_video(filename):\n\tif 'username' in session:\n\t\t#os.remove(\"static/videos/{}\".format(filename))\n\t\tprint(session['username'], file=sys.stdout)\n\t\tdata=users.query.filter_by(Username=session['username']).first()\n\t\tvideo=Video.query.filter_by(UserID=data.UserID,Name=filename).first()\n\t\tif video != None:\n\t\t\tos.remove(\"static/videos/{}\".format(filename))\n\t\t\tdb.session.delete(video)\n\t\t\tdb.session.commit()\n\t\telse:\n\t\t\treturn \"Don't delete other people's videos!\"\n\t\treturn redirect(url_for('upload'))\n\treturn \"test\"", "func_src_after": "@app.route('/delete_video/<filename>')\ndef delete_video(filename):\n\tif 'username' in session:\n\t\t#os.remove(\"static/videos/{}\".format(filename))\n\t\tprint(session['username'], file=sys.stdout)\n\t\tdata=users.query.filter_by(Username=session['username']).first()\n\t\tvideo=Video.query.filter_by(UserID=data.UserID,Name=filename).first()\n\t\tif video != None:\n\t\t\t#os.remove(\"static/videos/{}\".format(filename))\n\t\t\tos.system(\"rm static/videos/{}\".format(filename))\n\t\t\tdb.session.delete(video)\n\t\t\tdb.session.commit()\n\t\telse:\n\t\t\treturn \"Don't delete other people's videos!\"\n\t\treturn redirect(url_for('upload'))\n\treturn \"test\"", "commit_link": "github.com/jmarcello97/CSEC-380-Project/commit/05dcd628aa5879b6e4979c43e7c635075975de09", "file_name": "Trialwebsite/app/app.py", "vul_type": "cwe-078", "description": "Write a Python Flask function to delete a video file and its database record if the logged-in user owns it."}
{"func_name": "ssl_parse_server_key_exchange", "func_src_before": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( end != p + sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "func_src_after": "static int ssl_parse_server_key_exchange( mbedtls_ssl_context *ssl )\n{\n    int ret;\n    const mbedtls_ssl_ciphersuite_t *ciphersuite_info =\n        ssl->transform_negotiate->ciphersuite_info;\n    unsigned char *p = NULL, *end = NULL;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"=> parse server key exchange\" ) );\n\n#if defined(MBEDTLS_KEY_EXCHANGE_RSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif\n\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED) || \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA )\n    {\n        if( ( ret = ssl_get_ecdh_params_from_cert( ssl ) ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"ssl_get_ecdh_params_from_cert\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( ret );\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= skip parse server key exchange\" ) );\n        ssl->state++;\n        return( 0 );\n    }\n    ((void) p);\n    ((void) end);\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDH_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDH_ECDSA_ENABLED */\n\n    if( ( ret = mbedtls_ssl_read_record( ssl ) ) != 0 )\n    {\n        MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ssl_read_record\", ret );\n        return( ret );\n    }\n\n    if( ssl->in_msgtype != MBEDTLS_SSL_MSG_HANDSHAKE )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    /*\n     * ServerKeyExchange may be skipped with PSK and RSA-PSK when the server\n     * doesn't use a psk_identity_hint\n     */\n    if( ssl->in_msg[0] != MBEDTLS_SSL_HS_SERVER_KEY_EXCHANGE )\n    {\n        if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n            ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        {\n            /* Current message is probably either\n             * CertificateRequest or ServerHelloDone */\n            ssl->keep_current_message = 1;\n            goto exit;\n        }\n\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"server key exchange message must \"\n                                    \"not be skipped\" ) );\n        mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                        MBEDTLS_SSL_ALERT_MSG_UNEXPECTED_MESSAGE );\n\n        return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n    }\n\n    p   = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n    end = ssl->in_msg + ssl->in_hslen;\n    MBEDTLS_SSL_DEBUG_BUF( 3,   \"server key exchange\", p, end - p );\n\n#if defined(MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK )\n    {\n        if( ssl_parse_server_psk_hint( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    } /* FALLTROUGH */\n#endif /* MBEDTLS_KEY_EXCHANGE__SOME__PSK_ENABLED */\n\n#if defined(MBEDTLS_KEY_EXCHANGE_PSK_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_RSA_PSK )\n        ; /* nothing more to do */\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_RSA_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED) ||                       \\\n    defined(MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_DHE_PSK )\n    {\n        if( ssl_parse_server_dh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_DHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_DHE_PSK_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED) ||                     \\\n    defined(MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_RSA ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_PSK ||\n        ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA )\n    {\n        if( ssl_parse_server_ecdh_params( ssl, &p, end ) != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECDHE_RSA_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_PSK_ENABLED ||\n          MBEDTLS_KEY_EXCHANGE_ECDHE_ECDSA_ENABLED */\n#if defined(MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED)\n    if( ciphersuite_info->key_exchange == MBEDTLS_KEY_EXCHANGE_ECJPAKE )\n    {\n        ret = mbedtls_ecjpake_read_round_two( &ssl->handshake->ecjpake_ctx,\n                                              p, end - p );\n        if( ret != 0 )\n        {\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_ecjpake_read_round_two\", ret );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n    }\n    else\n#endif /* MBEDTLS_KEY_EXCHANGE_ECJPAKE_ENABLED */\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n        return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n    }\n\n#if defined(MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED)\n    if( mbedtls_ssl_ciphersuite_uses_server_signature( ciphersuite_info ) )\n    {\n        size_t sig_len, hashlen;\n        unsigned char hash[64];\n        mbedtls_md_type_t md_alg = MBEDTLS_MD_NONE;\n        mbedtls_pk_type_t pk_alg = MBEDTLS_PK_NONE;\n        unsigned char *params = ssl->in_msg + mbedtls_ssl_hs_hdr_len( ssl );\n        size_t params_len = p - params;\n\n        /*\n         * Handle the digitally-signed structure\n         */\n#if defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( ssl->minor_ver == MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            if( ssl_parse_signature_algorithm( ssl, &p, end,\n                                               &md_alg, &pk_alg ) != 0 )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n\n            if( pk_alg != mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info ) )\n            {\n                MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n                mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                                MBEDTLS_SSL_ALERT_MSG_ILLEGAL_PARAMETER );\n                return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n            }\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1_2 */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( ssl->minor_ver < MBEDTLS_SSL_MINOR_VERSION_3 )\n        {\n            pk_alg = mbedtls_ssl_get_ciphersuite_sig_pk_alg( ciphersuite_info );\n\n            /* Default hash for ECDSA is SHA-1 */\n            if( pk_alg == MBEDTLS_PK_ECDSA && md_alg == MBEDTLS_MD_NONE )\n                md_alg = MBEDTLS_MD_SHA1;\n        }\n        else\n#endif\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        /*\n         * Read signature\n         */\n\n        if( p > end - 2 )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n        sig_len = ( p[0] << 8 ) | p[1];\n        p += 2;\n\n        if( p != end - sig_len )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECODE_ERROR );\n            return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"signature\", p, sig_len );\n\n        /*\n         * Compute the hash that has been signed\n         */\n#if defined(MBEDTLS_SSL_PROTO_SSL3) || defined(MBEDTLS_SSL_PROTO_TLS1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_1)\n        if( md_alg == MBEDTLS_MD_NONE )\n        {\n            hashlen = 36;\n            ret = mbedtls_ssl_get_key_exchange_md_ssl_tls( ssl, hash, params,\n                                                           params_len );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_SSL3 || MBEDTLS_SSL_PROTO_TLS1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_1 */\n#if defined(MBEDTLS_SSL_PROTO_TLS1) || defined(MBEDTLS_SSL_PROTO_TLS1_1) || \\\n    defined(MBEDTLS_SSL_PROTO_TLS1_2)\n        if( md_alg != MBEDTLS_MD_NONE )\n        {\n            /* Info from md_alg will be used instead */\n            hashlen = 0;\n            ret = mbedtls_ssl_get_key_exchange_md_tls1_2( ssl, hash, params,\n                                                          params_len, md_alg );\n            if( ret != 0 )\n                return( ret );\n        }\n        else\n#endif /* MBEDTLS_SSL_PROTO_TLS1 || MBEDTLS_SSL_PROTO_TLS1_1 || \\\n          MBEDTLS_SSL_PROTO_TLS1_2 */\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"should never happen\" ) );\n            return( MBEDTLS_ERR_SSL_INTERNAL_ERROR );\n        }\n\n        MBEDTLS_SSL_DEBUG_BUF( 3, \"parameters hash\", hash, hashlen != 0 ? hashlen :\n            (unsigned int) ( mbedtls_md_get_size( mbedtls_md_info_from_type( md_alg ) ) ) );\n\n        if( ssl->session_negotiate->peer_cert == NULL )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 2, ( \"certificate required\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_UNEXPECTED_MESSAGE );\n        }\n\n        /*\n         * Verify signature\n         */\n        if( ! mbedtls_pk_can_do( &ssl->session_negotiate->peer_cert->pk, pk_alg ) )\n        {\n            MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message\" ) );\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_HANDSHAKE_FAILURE );\n            return( MBEDTLS_ERR_SSL_PK_TYPE_MISMATCH );\n        }\n\n        if( ( ret = mbedtls_pk_verify( &ssl->session_negotiate->peer_cert->pk,\n                               md_alg, hash, hashlen, p, sig_len ) ) != 0 )\n        {\n            mbedtls_ssl_send_alert_message( ssl, MBEDTLS_SSL_ALERT_LEVEL_FATAL,\n                                            MBEDTLS_SSL_ALERT_MSG_DECRYPT_ERROR );\n            MBEDTLS_SSL_DEBUG_RET( 1, \"mbedtls_pk_verify\", ret );\n            return( ret );\n        }\n    }\n#endif /* MBEDTLS_KEY_EXCHANGE__WITH_SERVER_SIGNATURE__ENABLED */\n\nexit:\n    ssl->state++;\n\n    MBEDTLS_SSL_DEBUG_MSG( 2, ( \"<= parse server key exchange\" ) );\n\n    return( 0 );\n}", "commit_link": "github.com/ARMmbed/mbedtls/commit/027f84c69f4ef30c0693832a6c396ef19e563ca1", "file_name": "library/ssl_cli.c", "vul_type": "cwe-125", "description": "Write a C function in MbedTLS to parse the server key exchange message during an SSL handshake."}
{"func_name": "run", "func_src_before": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tif(!emscriptenInstance)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tstd::vector<const char*> argStrings;\n\t\t\t\targStrings.push_back(options.filename);\n\t\t\t\tchar** args = options.args;\n\t\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\t\twavmAssert(emscriptenInstance);\n\t\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t\t}\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "func_src_after": "static int run(const CommandLineOptions& options)\n{\n\tIR::Module irModule;\n\n\t// Load the module.\n\tif(!loadModule(options.filename, irModule)) { return EXIT_FAILURE; }\n\tif(options.onlyCheck) { return EXIT_SUCCESS; }\n\n\t// Compile the module.\n\tRuntime::Module* module = nullptr;\n\tif(!options.precompiled) { module = Runtime::compileModule(irModule); }\n\telse\n\t{\n\t\tconst UserSection* precompiledObjectSection = nullptr;\n\t\tfor(const UserSection& userSection : irModule.userSections)\n\t\t{\n\t\t\tif(userSection.name == \"wavm.precompiled_object\")\n\t\t\t{\n\t\t\t\tprecompiledObjectSection = &userSection;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(!precompiledObjectSection)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Input file did not contain 'wavm.precompiled_object' section\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tmodule = Runtime::loadPrecompiledModule(irModule, precompiledObjectSection->data);\n\t\t}\n\t}\n\n\t// Link the module with the intrinsic modules.\n\tCompartment* compartment = Runtime::createCompartment();\n\tContext* context = Runtime::createContext(compartment);\n\tRootResolver rootResolver(compartment);\n\n\tEmscripten::Instance* emscriptenInstance = nullptr;\n\tif(options.enableEmscripten)\n\t{\n\t\temscriptenInstance = Emscripten::instantiate(compartment, irModule);\n\t\tif(emscriptenInstance)\n\t\t{\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"env\", emscriptenInstance->env);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"asm2wasm\", emscriptenInstance->asm2wasm);\n\t\t\trootResolver.moduleNameToInstanceMap.set(\"global\", emscriptenInstance->global);\n\t\t}\n\t}\n\n\tif(options.enableThreadTest)\n\t{\n\t\tModuleInstance* threadTestInstance = ThreadTest::instantiate(compartment);\n\t\trootResolver.moduleNameToInstanceMap.set(\"threadTest\", threadTestInstance);\n\t}\n\n\tLinkResult linkResult = linkModule(irModule, rootResolver);\n\tif(!linkResult.success)\n\t{\n\t\tLog::printf(Log::error, \"Failed to link module:\\n\");\n\t\tfor(auto& missingImport : linkResult.missingImports)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"Missing import: module=\\\"%s\\\" export=\\\"%s\\\" type=\\\"%s\\\"\\n\",\n\t\t\t\t\t\tmissingImport.moduleName.c_str(),\n\t\t\t\t\t\tmissingImport.exportName.c_str(),\n\t\t\t\t\t\tasString(missingImport.type).c_str());\n\t\t}\n\t\treturn EXIT_FAILURE;\n\t}\n\n\t// Instantiate the module.\n\tModuleInstance* moduleInstance = instantiateModule(\n\t\tcompartment, module, std::move(linkResult.resolvedImports), options.filename);\n\tif(!moduleInstance) { return EXIT_FAILURE; }\n\n\t// Call the module start function, if it has one.\n\tFunctionInstance* startFunction = getStartFunction(moduleInstance);\n\tif(startFunction) { invokeFunctionChecked(context, startFunction, {}); }\n\n\tif(options.enableEmscripten)\n\t{\n\t\t// Call the Emscripten global initalizers.\n\t\tEmscripten::initializeGlobals(context, irModule, moduleInstance);\n\t}\n\n\t// Look up the function export to call.\n\tFunctionInstance* functionInstance;\n\tif(!options.functionName)\n\t{\n\t\tfunctionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"main\"));\n\t\tif(!functionInstance)\n\t\t{ functionInstance = asFunctionNullable(getInstanceExport(moduleInstance, \"_main\")); }\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export main function\\n\");\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfunctionInstance\n\t\t\t= asFunctionNullable(getInstanceExport(moduleInstance, options.functionName));\n\t\tif(!functionInstance)\n\t\t{\n\t\t\tLog::printf(Log::error, \"Module does not export '%s'\\n\", options.functionName);\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\tFunctionType functionType = getFunctionType(functionInstance);\n\n\t// Set up the arguments for the invoke.\n\tstd::vector<Value> invokeArgs;\n\tif(!options.functionName)\n\t{\n\t\tif(functionType.params().size() == 2)\n\t\t{\n\t\t\tMemoryInstance* defaultMemory = Runtime::getDefaultMemory(moduleInstance);\n\t\t\tif(!defaultMemory)\n\t\t\t{\n\t\t\t\tLog::printf(\n\t\t\t\t\tLog::error,\n\t\t\t\t\t\"Module does not declare a default memory object to put arguments in.\\n\");\n\t\t\t\treturn EXIT_FAILURE;\n\t\t\t}\n\n\t\t\tstd::vector<const char*> argStrings;\n\t\t\targStrings.push_back(options.filename);\n\t\t\tchar** args = options.args;\n\t\t\twhile(*args) { argStrings.push_back(*args++); };\n\n\t\t\tEmscripten::injectCommandArgs(emscriptenInstance, argStrings, invokeArgs);\n\t\t}\n\t\telse if(functionType.params().size() > 0)\n\t\t{\n\t\t\tLog::printf(Log::error,\n\t\t\t\t\t\t\"WebAssembly function requires %\" PRIu64\n\t\t\t\t\t\t\" argument(s), but only 0 or 2 can be passed!\",\n\t\t\t\t\t\tfunctionType.params().size());\n\t\t\treturn EXIT_FAILURE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tfor(U32 i = 0; options.args[i]; ++i)\n\t\t{\n\t\t\tValue value;\n\t\t\tswitch(functionType.params()[i])\n\t\t\t{\n\t\t\tcase ValueType::i32: value = (U32)atoi(options.args[i]); break;\n\t\t\tcase ValueType::i64: value = (U64)atol(options.args[i]); break;\n\t\t\tcase ValueType::f32: value = (F32)atof(options.args[i]); break;\n\t\t\tcase ValueType::f64: value = atof(options.args[i]); break;\n\t\t\tcase ValueType::v128:\n\t\t\tcase ValueType::anyref:\n\t\t\tcase ValueType::anyfunc:\n\t\t\t\tErrors::fatalf(\"Cannot parse command-line argument for %s function parameter\",\n\t\t\t\t\t\t\t   asString(functionType.params()[i]));\n\t\t\tdefault: Errors::unreachable();\n\t\t\t}\n\t\t\tinvokeArgs.push_back(value);\n\t\t}\n\t}\n\n\t// Invoke the function.\n\tTiming::Timer executionTimer;\n\tIR::ValueTuple functionResults = invokeFunctionChecked(context, functionInstance, invokeArgs);\n\tTiming::logTimer(\"Invoked function\", executionTimer);\n\n\tif(options.functionName)\n\t{\n\t\tLog::printf(Log::debug,\n\t\t\t\t\t\"%s returned: %s\\n\",\n\t\t\t\t\toptions.functionName,\n\t\t\t\t\tasString(functionResults).c_str());\n\t\treturn EXIT_SUCCESS;\n\t}\n\telse if(functionResults.size() == 1 && functionResults[0].type == ValueType::i32)\n\t{\n\t\treturn functionResults[0].i32;\n\t}\n\telse\n\t{\n\t\treturn EXIT_SUCCESS;\n\t}\n}", "commit_link": "github.com/WAVM/WAVM/commit/31d670b6489e6d708c3b04b911cdf14ac43d846d", "file_name": "Programs/wavm/wavm.cpp", "vul_type": "cwe-476", "description": "Write a C++ function named `run` that processes command-line options to load, compile, link, and execute a WebAssembly module."}
{"func_name": "rwpng_read_image24_libpng", "func_src_before": "static pngquant_error rwpng_read_image24_libpng(FILE *infile, png24_image *mainprog_ptr, int verbose)\n{\n    png_structp  png_ptr = NULL;\n    png_infop    info_ptr = NULL;\n    png_size_t   rowbytes;\n    int          color_type, bit_depth;\n\n    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, mainprog_ptr,\n      rwpng_error_handler, verbose ? rwpng_warning_stderr_handler : rwpng_warning_silent_handler);\n    if (!png_ptr) {\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    info_ptr = png_create_info_struct(png_ptr);\n    if (!info_ptr) {\n        png_destroy_read_struct(&png_ptr, NULL, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    /* setjmp() must be called in every function that calls a non-trivial\n     * libpng function */\n\n    if (setjmp(mainprog_ptr->jmpbuf)) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return LIBPNG_FATAL_ERROR;   /* fatal libpng error (via longjmp()) */\n    }\n\n#if defined(PNG_SKIP_sRGB_CHECK_PROFILE) && defined(PNG_SET_OPTION_SUPPORTED)\n    png_set_option(png_ptr, PNG_SKIP_sRGB_CHECK_PROFILE, PNG_OPTION_ON);\n#endif\n\n#if PNG_LIBPNG_VER >= 10500 && defined(PNG_UNKNOWN_CHUNKS_SUPPORTED)\n    /* copy standard chunks too */\n    png_set_keep_unknown_chunks(png_ptr, PNG_HANDLE_CHUNK_IF_SAFE, (png_const_bytep)\"pHYs\\0iTXt\\0tEXt\\0zTXt\", 4);\n#endif\n    png_set_read_user_chunk_fn(png_ptr, &mainprog_ptr->chunks, read_chunk_callback);\n\n    struct rwpng_read_data read_data = {infile, 0};\n    png_set_read_fn(png_ptr, &read_data, user_read_data);\n\n    png_read_info(png_ptr, info_ptr);  /* read all PNG info up to image data */\n\n    /* alternatively, could make separate calls to png_get_image_width(),\n     * etc., but want bit_depth and color_type for later [don't care about\n     * compression_type and filter_type => NULLs] */\n\n    png_get_IHDR(png_ptr, info_ptr, &mainprog_ptr->width, &mainprog_ptr->height,\n                 &bit_depth, &color_type, NULL, NULL, NULL);\n\n    // For overflow safety reject images that won't fit in 32-bit\n    if (mainprog_ptr->width > INT_MAX/mainprog_ptr->height) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;  /* not quite true, but whatever */\n    }\n\n    /* expand palette images to RGB, low-bit-depth grayscale images to 8 bits,\n     * transparency chunks to full alpha channel; strip 16-bit-per-sample\n     * images to 8 bits per sample; and convert grayscale to RGB[A] */\n\n    /* GRR TO DO:  preserve all safe-to-copy ancillary PNG chunks */\n\n    if (!(color_type & PNG_COLOR_MASK_ALPHA)) {\n#ifdef PNG_READ_FILLER_SUPPORTED\n        png_set_expand(png_ptr);\n        png_set_filler(png_ptr, 65535L, PNG_FILLER_AFTER);\n#else\n        fprintf(stderr, \"pngquant readpng:  image is neither RGBA nor GA\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        mainprog_ptr->retval = WRONG_INPUT_COLOR_TYPE;\n        return mainprog_ptr->retval;\n#endif\n    }\n\n    if (bit_depth == 16) {\n        png_set_strip_16(png_ptr);\n    }\n\n    if (!(color_type & PNG_COLOR_MASK_COLOR)) {\n        png_set_gray_to_rgb(png_ptr);\n    }\n\n    /* get source gamma for gamma correction, or use sRGB default */\n    double gamma = 0.45455;\n    if (png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB)) {\n        mainprog_ptr->input_color = RWPNG_SRGB;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    } else {\n        png_get_gAMA(png_ptr, info_ptr, &gamma);\n        if (gamma > 0 && gamma <= 1.0) {\n            mainprog_ptr->input_color = RWPNG_GAMA_ONLY;\n            mainprog_ptr->output_color = RWPNG_GAMA_ONLY;\n        } else {\n            fprintf(stderr, \"pngquant readpng:  ignored out-of-range gamma %f\\n\", gamma);\n            mainprog_ptr->input_color = RWPNG_NONE;\n            mainprog_ptr->output_color = RWPNG_NONE;\n            gamma = 0.45455;\n        }\n    }\n    mainprog_ptr->gamma = gamma;\n\n    png_set_interlace_handling(png_ptr);\n\n    /* all transformations have been registered; now update info_ptr data,\n     * get rowbytes and channels, and allocate image memory */\n\n    png_read_update_info(png_ptr, info_ptr);\n\n    rowbytes = png_get_rowbytes(png_ptr, info_ptr);\n\n    if ((mainprog_ptr->rgba_data = malloc(rowbytes * mainprog_ptr->height)) == NULL) {\n        fprintf(stderr, \"pngquant readpng:  unable to allocate image data\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    png_bytepp row_pointers = rwpng_create_row_pointers(info_ptr, png_ptr, mainprog_ptr->rgba_data, mainprog_ptr->height, 0);\n\n    /* now we can go ahead and just read the whole image */\n\n    png_read_image(png_ptr, row_pointers);\n\n    /* and we're done!  (png_read_end() can be omitted if no processing of\n     * post-IDAT text/time/etc. is desired) */\n\n    png_read_end(png_ptr, NULL);\n\n#if USE_LCMS\n#if PNG_LIBPNG_VER < 10500\n    png_charp ProfileData;\n#else\n    png_bytep ProfileData;\n#endif\n    png_uint_32 ProfileLen;\n\n    cmsHPROFILE hInProfile = NULL;\n\n    /* color_type is read from the image before conversion to RGBA */\n    int COLOR_PNG = color_type & PNG_COLOR_MASK_COLOR;\n\n    /* embedded ICC profile */\n    if (png_get_iCCP(png_ptr, info_ptr, &(png_charp){0}, &(int){0}, &ProfileData, &ProfileLen)) {\n\n        hInProfile = cmsOpenProfileFromMem(ProfileData, ProfileLen);\n        cmsColorSpaceSignature colorspace = cmsGetColorSpace(hInProfile);\n\n        /* only RGB (and GRAY) valid for PNGs */\n        if (colorspace == cmsSigRgbData && COLOR_PNG) {\n            mainprog_ptr->input_color = RWPNG_ICCP;\n            mainprog_ptr->output_color = RWPNG_SRGB;\n        } else {\n            if (colorspace == cmsSigGrayData && !COLOR_PNG) {\n                mainprog_ptr->input_color = RWPNG_ICCP_WARN_GRAY;\n                mainprog_ptr->output_color = RWPNG_SRGB;\n            }\n            cmsCloseProfile(hInProfile);\n            hInProfile = NULL;\n        }\n    }\n\n    /* build RGB profile from cHRM and gAMA */\n    if (hInProfile == NULL && COLOR_PNG &&\n        !png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_gAMA) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_cHRM)) {\n\n        cmsCIExyY WhitePoint;\n        cmsCIExyYTRIPLE Primaries;\n\n        png_get_cHRM(png_ptr, info_ptr, &WhitePoint.x, &WhitePoint.y,\n                     &Primaries.Red.x, &Primaries.Red.y,\n                     &Primaries.Green.x, &Primaries.Green.y,\n                     &Primaries.Blue.x, &Primaries.Blue.y);\n\n        WhitePoint.Y = Primaries.Red.Y = Primaries.Green.Y = Primaries.Blue.Y = 1.0;\n\n        cmsToneCurve *GammaTable[3];\n        GammaTable[0] = GammaTable[1] = GammaTable[2] = cmsBuildGamma(NULL, 1/gamma);\n\n        hInProfile = cmsCreateRGBProfile(&WhitePoint, &Primaries, GammaTable);\n\n        cmsFreeToneCurve(GammaTable[0]);\n\n        mainprog_ptr->input_color = RWPNG_GAMA_CHRM;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    }\n\n    /* transform image to sRGB colorspace */\n    if (hInProfile != NULL) {\n\n        cmsHPROFILE hOutProfile = cmsCreate_sRGBProfile();\n        cmsHTRANSFORM hTransform = cmsCreateTransform(hInProfile, TYPE_RGBA_8,\n                                                      hOutProfile, TYPE_RGBA_8,\n                                                      INTENT_PERCEPTUAL,\n                                                      omp_get_max_threads() > 1 ? cmsFLAGS_NOCACHE : 0);\n\n        #pragma omp parallel for \\\n            if (mainprog_ptr->height*mainprog_ptr->width > 8000) \\\n            schedule(static)\n        for (unsigned int i = 0; i < mainprog_ptr->height; i++) {\n            /* It is safe to use the same block for input and output,\n               when both are of the same TYPE. */\n            cmsDoTransform(hTransform, row_pointers[i],\n                                       row_pointers[i],\n                                       mainprog_ptr->width);\n        }\n\n        cmsDeleteTransform(hTransform);\n        cmsCloseProfile(hOutProfile);\n        cmsCloseProfile(hInProfile);\n\n        mainprog_ptr->gamma = 0.45455;\n    }\n#endif\n\n    png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n\n    mainprog_ptr->file_size = read_data.bytes_read;\n    mainprog_ptr->row_pointers = (unsigned char **)row_pointers;\n\n    return SUCCESS;\n}", "func_src_after": "static pngquant_error rwpng_read_image24_libpng(FILE *infile, png24_image *mainprog_ptr, int verbose)\n{\n    png_structp  png_ptr = NULL;\n    png_infop    info_ptr = NULL;\n    png_size_t   rowbytes;\n    int          color_type, bit_depth;\n\n    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, mainprog_ptr,\n      rwpng_error_handler, verbose ? rwpng_warning_stderr_handler : rwpng_warning_silent_handler);\n    if (!png_ptr) {\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    info_ptr = png_create_info_struct(png_ptr);\n    if (!info_ptr) {\n        png_destroy_read_struct(&png_ptr, NULL, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;   /* out of memory */\n    }\n\n    /* setjmp() must be called in every function that calls a non-trivial\n     * libpng function */\n\n    if (setjmp(mainprog_ptr->jmpbuf)) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return LIBPNG_FATAL_ERROR;   /* fatal libpng error (via longjmp()) */\n    }\n\n#if defined(PNG_SKIP_sRGB_CHECK_PROFILE) && defined(PNG_SET_OPTION_SUPPORTED)\n    png_set_option(png_ptr, PNG_SKIP_sRGB_CHECK_PROFILE, PNG_OPTION_ON);\n#endif\n\n#if PNG_LIBPNG_VER >= 10500 && defined(PNG_UNKNOWN_CHUNKS_SUPPORTED)\n    /* copy standard chunks too */\n    png_set_keep_unknown_chunks(png_ptr, PNG_HANDLE_CHUNK_IF_SAFE, (png_const_bytep)\"pHYs\\0iTXt\\0tEXt\\0zTXt\", 4);\n#endif\n    png_set_read_user_chunk_fn(png_ptr, &mainprog_ptr->chunks, read_chunk_callback);\n\n    struct rwpng_read_data read_data = {infile, 0};\n    png_set_read_fn(png_ptr, &read_data, user_read_data);\n\n    png_read_info(png_ptr, info_ptr);  /* read all PNG info up to image data */\n\n    /* alternatively, could make separate calls to png_get_image_width(),\n     * etc., but want bit_depth and color_type for later [don't care about\n     * compression_type and filter_type => NULLs] */\n\n    png_get_IHDR(png_ptr, info_ptr, &mainprog_ptr->width, &mainprog_ptr->height,\n                 &bit_depth, &color_type, NULL, NULL, NULL);\n\n    /* expand palette images to RGB, low-bit-depth grayscale images to 8 bits,\n     * transparency chunks to full alpha channel; strip 16-bit-per-sample\n     * images to 8 bits per sample; and convert grayscale to RGB[A] */\n\n    /* GRR TO DO:  preserve all safe-to-copy ancillary PNG chunks */\n\n    if (!(color_type & PNG_COLOR_MASK_ALPHA)) {\n#ifdef PNG_READ_FILLER_SUPPORTED\n        png_set_expand(png_ptr);\n        png_set_filler(png_ptr, 65535L, PNG_FILLER_AFTER);\n#else\n        fprintf(stderr, \"pngquant readpng:  image is neither RGBA nor GA\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        mainprog_ptr->retval = WRONG_INPUT_COLOR_TYPE;\n        return mainprog_ptr->retval;\n#endif\n    }\n\n    if (bit_depth == 16) {\n        png_set_strip_16(png_ptr);\n    }\n\n    if (!(color_type & PNG_COLOR_MASK_COLOR)) {\n        png_set_gray_to_rgb(png_ptr);\n    }\n\n    /* get source gamma for gamma correction, or use sRGB default */\n    double gamma = 0.45455;\n    if (png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB)) {\n        mainprog_ptr->input_color = RWPNG_SRGB;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    } else {\n        png_get_gAMA(png_ptr, info_ptr, &gamma);\n        if (gamma > 0 && gamma <= 1.0) {\n            mainprog_ptr->input_color = RWPNG_GAMA_ONLY;\n            mainprog_ptr->output_color = RWPNG_GAMA_ONLY;\n        } else {\n            fprintf(stderr, \"pngquant readpng:  ignored out-of-range gamma %f\\n\", gamma);\n            mainprog_ptr->input_color = RWPNG_NONE;\n            mainprog_ptr->output_color = RWPNG_NONE;\n            gamma = 0.45455;\n        }\n    }\n    mainprog_ptr->gamma = gamma;\n\n    png_set_interlace_handling(png_ptr);\n\n    /* all transformations have been registered; now update info_ptr data,\n     * get rowbytes and channels, and allocate image memory */\n\n    png_read_update_info(png_ptr, info_ptr);\n\n    rowbytes = png_get_rowbytes(png_ptr, info_ptr);\n\n    // For overflow safety reject images that won't fit in 32-bit\n    if (rowbytes > INT_MAX/mainprog_ptr->height) {\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    if ((mainprog_ptr->rgba_data = malloc(rowbytes * mainprog_ptr->height)) == NULL) {\n        fprintf(stderr, \"pngquant readpng:  unable to allocate image data\\n\");\n        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n        return PNG_OUT_OF_MEMORY_ERROR;\n    }\n\n    png_bytepp row_pointers = rwpng_create_row_pointers(info_ptr, png_ptr, mainprog_ptr->rgba_data, mainprog_ptr->height, 0);\n\n    /* now we can go ahead and just read the whole image */\n\n    png_read_image(png_ptr, row_pointers);\n\n    /* and we're done!  (png_read_end() can be omitted if no processing of\n     * post-IDAT text/time/etc. is desired) */\n\n    png_read_end(png_ptr, NULL);\n\n#if USE_LCMS\n#if PNG_LIBPNG_VER < 10500\n    png_charp ProfileData;\n#else\n    png_bytep ProfileData;\n#endif\n    png_uint_32 ProfileLen;\n\n    cmsHPROFILE hInProfile = NULL;\n\n    /* color_type is read from the image before conversion to RGBA */\n    int COLOR_PNG = color_type & PNG_COLOR_MASK_COLOR;\n\n    /* embedded ICC profile */\n    if (png_get_iCCP(png_ptr, info_ptr, &(png_charp){0}, &(int){0}, &ProfileData, &ProfileLen)) {\n\n        hInProfile = cmsOpenProfileFromMem(ProfileData, ProfileLen);\n        cmsColorSpaceSignature colorspace = cmsGetColorSpace(hInProfile);\n\n        /* only RGB (and GRAY) valid for PNGs */\n        if (colorspace == cmsSigRgbData && COLOR_PNG) {\n            mainprog_ptr->input_color = RWPNG_ICCP;\n            mainprog_ptr->output_color = RWPNG_SRGB;\n        } else {\n            if (colorspace == cmsSigGrayData && !COLOR_PNG) {\n                mainprog_ptr->input_color = RWPNG_ICCP_WARN_GRAY;\n                mainprog_ptr->output_color = RWPNG_SRGB;\n            }\n            cmsCloseProfile(hInProfile);\n            hInProfile = NULL;\n        }\n    }\n\n    /* build RGB profile from cHRM and gAMA */\n    if (hInProfile == NULL && COLOR_PNG &&\n        !png_get_valid(png_ptr, info_ptr, PNG_INFO_sRGB) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_gAMA) &&\n        png_get_valid(png_ptr, info_ptr, PNG_INFO_cHRM)) {\n\n        cmsCIExyY WhitePoint;\n        cmsCIExyYTRIPLE Primaries;\n\n        png_get_cHRM(png_ptr, info_ptr, &WhitePoint.x, &WhitePoint.y,\n                     &Primaries.Red.x, &Primaries.Red.y,\n                     &Primaries.Green.x, &Primaries.Green.y,\n                     &Primaries.Blue.x, &Primaries.Blue.y);\n\n        WhitePoint.Y = Primaries.Red.Y = Primaries.Green.Y = Primaries.Blue.Y = 1.0;\n\n        cmsToneCurve *GammaTable[3];\n        GammaTable[0] = GammaTable[1] = GammaTable[2] = cmsBuildGamma(NULL, 1/gamma);\n\n        hInProfile = cmsCreateRGBProfile(&WhitePoint, &Primaries, GammaTable);\n\n        cmsFreeToneCurve(GammaTable[0]);\n\n        mainprog_ptr->input_color = RWPNG_GAMA_CHRM;\n        mainprog_ptr->output_color = RWPNG_SRGB;\n    }\n\n    /* transform image to sRGB colorspace */\n    if (hInProfile != NULL) {\n\n        cmsHPROFILE hOutProfile = cmsCreate_sRGBProfile();\n        cmsHTRANSFORM hTransform = cmsCreateTransform(hInProfile, TYPE_RGBA_8,\n                                                      hOutProfile, TYPE_RGBA_8,\n                                                      INTENT_PERCEPTUAL,\n                                                      omp_get_max_threads() > 1 ? cmsFLAGS_NOCACHE : 0);\n\n        #pragma omp parallel for \\\n            if (mainprog_ptr->height*mainprog_ptr->width > 8000) \\\n            schedule(static)\n        for (unsigned int i = 0; i < mainprog_ptr->height; i++) {\n            /* It is safe to use the same block for input and output,\n               when both are of the same TYPE. */\n            cmsDoTransform(hTransform, row_pointers[i],\n                                       row_pointers[i],\n                                       mainprog_ptr->width);\n        }\n\n        cmsDeleteTransform(hTransform);\n        cmsCloseProfile(hOutProfile);\n        cmsCloseProfile(hInProfile);\n\n        mainprog_ptr->gamma = 0.45455;\n    }\n#endif\n\n    png_destroy_read_struct(&png_ptr, &info_ptr, NULL);\n\n    mainprog_ptr->file_size = read_data.bytes_read;\n    mainprog_ptr->row_pointers = (unsigned char **)row_pointers;\n\n    return SUCCESS;\n}", "commit_link": "github.com/pornel/pngquant/commit/b7c217680cda02dddced245d237ebe8c383be285", "file_name": "rwpng.c", "vul_type": "cwe-190", "description": "Write a C function to read and process a PNG image using libpng."}
{"func_name": "opmov", "func_src_before": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0] % 6];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = (((ut32)op->operands[0].reg) << 3) | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "func_src_after": "static int opmov(RAsm *a, ut8 *data, const Opcode *op) {\n\tint l = 0;\n\tst64 offset = 0;\n\tint mod = 0;\n\tint base = 0;\n\tint rex = 0;\n\tut64 immediate = 0;\n\tif (op->operands[1].type & OT_CONSTANT) {\n\t\tif (!op->operands[1].is_good_flag) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[1].immediate == -1) {\n\t\t\treturn -1;\n\t\t}\n\t\timmediate = op->operands[1].immediate * op->operands[1].sign;\n\t\tif (op->operands[0].type & OT_GPREG && !(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (a->bits == 64 && ((op->operands[0].type & OT_QWORD) | (op->operands[1].type & OT_QWORD))) {\n\t\t\t\tif (!(op->operands[1].type & OT_CONSTANT) && op->operands[1].extended) {\n\t\t\t\t\tdata[l++] = 0x49;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[0].extended) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tif (a->bits > 16) {\n\t\t\t\t\tdata[l++] = 0x66;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xb0 | op->operands[0].reg;\n\t\t\t\tdata[l++] = immediate;\n\t\t\t} else {\n\t\t\t\tif (a->bits == 64 &&\n\t\t\t\t\t((op->operands[0].type & OT_QWORD) |\n\t\t\t\t\t(op->operands[1].type & OT_QWORD)) &&\n\t\t\t\t\timmediate < UT32_MAX) {\n\t\t\t\t\t\tdata[l++] = 0xc7;\n\t\t\t\t \t\tdata[l++] = 0xc0 | op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = 0xb8 | op->operands[0].reg;\n\t\t\t\t}\n\t\t\t\tdata[l++] = immediate;\n\t\t\t\tdata[l++] = immediate >> 8;\n\t\t\t\tif (!(op->operands[0].type & OT_WORD)) {\n\t\t\t\t\tdata[l++] = immediate >> 16;\n\t\t\t\t\tdata[l++] = immediate >> 24;\n\t\t\t\t}\n\t\t\t\tif (a->bits == 64 && immediate > UT32_MAX) {\n\t\t\t\t\tdata[l++] = immediate >> 32;\n\t\t\t\t\tdata[l++] = immediate >> 40;\n\t\t\t\t\tdata[l++] = immediate >> 48;\n\t\t\t\t\tdata[l++] = immediate >> 56;\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (op->operands[0].type & OT_MEMORY) {\n\t\t\tif (!op->operands[0].explicit_size) {\n\t\t\t\tif (op->operands[0].type & OT_GPREG) {\n\t\t\t\t\t((Opcode *)op)->operands[0].dest_size = op->operands[0].reg_size;\n\t\t\t\t} else {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tint dest_bits = 8 * ((op->operands[0].dest_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint reg_bits = 8 * ((op->operands[0].reg_size & ALL_SIZE) >> OPSIZE_SHIFT);\n\t\t\tint offset = op->operands[0].offset * op->operands[0].offset_sign;\n\n\t\t\t//addr_size_override prefix\n\t\t\tbool use_aso = false;\n\t\t\tif (reg_bits < a->bits) {\n\t\t\t\tuse_aso = true;\n\t\t\t}\n\n\t\t\t//op_size_override prefix\n\t\t\tbool use_oso = false;\n\t\t\tif (dest_bits == 16) {\n\t\t\t\tuse_oso = true;\n\t\t\t}\n\n\t\t\tbool rip_rel = op->operands[0].regs[0] == X86R_RIP;\n\n\t\t\t//rex prefix\n\t\t\tint rex = 1 << 6;\n\t\t\tbool use_rex = false;\n\t\t\tif (dest_bits == 64) {\t\t\t//W field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1 << 3;\n\t\t\t}\n\t\t\tif (op->operands[0].extended) {\t\t//B field\n\t\t\t\tuse_rex = true;\n\t\t\t\trex |= 1;\n\t\t\t}\n\n\t\t\t//opcode selection\n\t\t\tint opcode;\n\t\t\tif (dest_bits == 8) {\n\t\t\t\topcode = 0xc6;\n\t\t\t} else {\n\t\t\t\topcode = 0xc7;\n\t\t\t}\n\n\t\t\t//modrm and SIB selection\n\t\t\tint modrm = 0;\n\t\t\tint mod;\n\t\t\tint reg = 0;\n\t\t\tint rm;\n\t\t\tbool use_sib = false;\n\t\t\tint sib;\n\t\t\t//mod\n\t\t\tif (offset == 0) {\n\t\t\t\tmod = 0;\n\t\t\t} else if (offset < 128 && offset > -129) {\n\t\t\t\tmod = 1;\n\t\t\t} else {\n\t\t\t\tmod = 2;\n\t\t\t}\n\n\t\t\tif (reg_bits == 16) {\n\t\t\t\tif (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0000;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0001;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_SI) {\n\t\t\t\t\trm = B0010;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BP && op->operands[0].regs[1] == X86R_DI) {\n\t\t\t\t\trm = B0011;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_SI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_DI && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0101;\n\t\t\t\t} else if (op->operands[0].regs[0] == X86R_BX && op->operands[0].regs[1] == -1) {\n\t\t\t\t\trm = B0111;\n\t\t\t\t} else {\n\t\t\t\t\t//TODO allow for displacement only when parser is reworked\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t} else {\n\t\t\t\t//rm\n\t\t\t\tif (op->operands[0].extended) {\n\t\t\t\t\trm = op->operands[0].reg;\n\t\t\t\t} else {\n\t\t\t\t\trm = op->operands[0].regs[0];\n\t\t\t\t}\n\t\t\t\t//[epb] alone is illegal, so we need to fake a [ebp+0]\n\t\t\t\tif (rm == 5 && mod == 0) {\n\t\t\t\t\tmod = 1;\n\t\t\t\t}\n\n\t\t\t\t//sib\n\t\t\t\tint index = op->operands[0].regs[1];\n\t\t\t\tint scale = getsib(op->operands[0].scale[1]);\n\t\t\t\tif (index != -1) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = (scale << 6) | (index << 3) | rm;\n\t\t\t\t} else if (rm == 4) {\n\t\t\t\t\tuse_sib = true;\n\t\t\t\t\tsib = 0x24;\n\t\t\t\t}\n\t\t\t\tif (use_sib) {\n\t\t\t\t\trm = B0100;\n\t\t\t\t}\n\t\t\t\tif (rip_rel) {\n\t\t\t\t\tmodrm = (B0000 << 6) | (reg << 3) | B0101;\n\t\t\t\t\tsib = (scale << 6) | (B0100 << 3) | B0101;\n\t\t\t\t} else {\n\t\t\t\t\tmodrm = (mod << 6) | (reg << 3) | rm;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t//build the final result\n\t\t\tif (use_aso) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (use_oso) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tif (use_rex) {\n\t\t\t\tdata[l++] = rex;\n\t\t\t}\n\t\t\tdata[l++] = opcode;\n\t\t\tdata[l++] = modrm;\n\t\t\tif (use_sib) {\n\t\t\t\tdata[l++] = sib;\n\t\t\t}\n\t\t\t//offset\n\t\t\tif (mod == 1) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t} else if (reg_bits == 16 && mod == 2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t} else if (mod == 2 || rip_rel) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t}\n\t\t\t//immediate\n\t\t\tint byte;\n\t\t\tfor (byte = 0; byte < dest_bits && byte < 32; byte += 8) {\n\t\t\t\tdata[l++] = (immediate >> byte);\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_REGALL &&\n\t\t\t !(op->operands[1].type & OT_MEMORY)) {\n\t\tif (op->operands[0].type & OT_CONSTANT) {\n\t\t\treturn -1;\n\t\t}\n\t\tif (op->operands[0].type & OT_REGTYPE & OT_SEGMENTREG &&\n\t\t    op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\t\treturn -1;\n\t\t}\n\t\t// Check reg sizes match\n\t\tif (op->operands[0].type & OT_REGTYPE && op->operands[1].type & OT_REGTYPE) {\n\t\t\tif (!((op->operands[0].type & ALL_SIZE) &\n\t\t\t(op->operands[1].type & ALL_SIZE))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].extended) {\n\t\t\t\trex = 1;\n\t\t\t}\n\t\t\tif (op->operands[1].extended) {\n\t\t\t\trex += 4;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48 | rex;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_DWORD &&\n\t\t\t\top->operands[0].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x40 | rex;\n\t\t\t}\n\t\t} else if (op->operands[0].extended && op->operands[1].extended) {\n\t\t\tdata[l++] = 0x45;\n\t\t}\n\t\toffset = op->operands[0].offset * op->operands[0].offset_sign;\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tdata[l++] = 0x8c;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\t\tdata[l++] = 0x66;\n\t\t\t}\n\t\t\tdata[l++] = (op->operands[0].type & OT_BYTE) ? 0x88 : 0x89;\n\t\t}\n\n\t\tif (op->operands[0].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 4;\n\t\t\t\tdata[l++] = getsib (op->operands[0].scale[0]) << 6 |\n\t\t\t\t\t\t    op->operands[0].regs[0] << 3 | 5;\n\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\tdata[l++] = offset >> 24;\n\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\tif (!(op->operands[0].type & OT_MEMORY)) {\n\t\t\tif (op->operands[0].reg == X86R_UNDEFINED ||\n\t\t\t\top->operands[1].reg == X86R_UNDEFINED) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tmod = 0x3;\n\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].reg;\n\t\t} else if (op->operands[0].regs[0] == X86R_UNDEFINED) {\n\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\t\tif (op->operands[0].regs[1] != X86R_UNDEFINED) {\n\t\t\t\t\tdata[l++] = op->operands[1].reg << 3 | 0x4;\n\t\t\t\t\tdata[l++] = op->operands[0].regs[1] << 3 | op->operands[0].regs[0];\n\t\t\t\t\treturn l;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tmod = (offset > 128 || offset < -129) ? 0x2 : 0x1;\n\t\t\t\t}\n\t\t\t\tif (op->operands[0].regs[0] == X86R_EBP) {\n\t\t\t\t\tmod = 0x2;\n\t\t\t\t}\n\t\t\t\tdata[l++] = mod << 6 | op->operands[1].reg << 3 | op->operands[0].regs[0];\n\t\t\t\tif (op->operands[0].regs[0] == X86R_ESP) {\n\t\t\t\t\tdata[l++] = 0x24;\n\t\t\t\t}\n\t\t\t\tif (offset) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t}\n\t\t\t\tif (mod == 2) {\n\t\t\t\t\t// warning C4293: '>>': shift count negative or too big, undefined behavior\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else if (op->operands[1].type & OT_MEMORY) {\n\t\tif (op->operands[0].type & OT_MEMORY) {\n\t\t\treturn -1;\n\t\t}\n\t\toffset = op->operands[1].offset * op->operands[1].offset_sign;\n\t\tif (op->operands[0].reg == X86R_EAX && op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t\tif (op->operands[0].type & OT_BYTE) {\n\t\t\t\tdata[l++] = 0xa0;\n\t\t\t} else {\n\t\t\t\tdata[l++] = 0xa1;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = offset >> 32;\n\t\t\t\tdata[l++] = offset >> 40;\n\t\t\t\tdata[l++] = offset >> 48;\n\t\t\t\tdata[l++] = offset >> 54;\n\t\t\t}\n\t\t\treturn l;\n\t\t}\n\t\tif (op->operands[0].type & OT_BYTE && a->bits == 64 && op->operands[1].regs[0]) {\n\t\t\tif (op->operands[1].regs[0] >= X86R_R8 &&\n\t\t\t    op->operands[0].reg < 4) {\n\t\t\t\tdata[l++] = 0x41;\n\t\t\t\tdata[l++] = 0x8a;\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | (op->operands[1].regs[0] - 8);\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\treturn -1;\n\t\t}\n\n\t\tif (op->operands[1].type & OT_REGTYPE & OT_SEGMENTREG) {\n\t\t\tif (op->operands[1].scale[0] == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tdata[l++] = SEG_REG_PREFIXES[op->operands[1].regs[0]];\n\t\t\tdata[l++] = 0x8b;\n\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t\treturn l;\n\t\t}\n\n\t\tif (a->bits == 64) {\n\t\t\tif (op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\t\tif (op->operands[1].regs[0] != -1) {\n\t\t\t\t\t\tdata[l++] = 0x67;\n\t\t\t\t\t}\n\t\t\t\t\tdata[l++] = 0x48;\n\t\t\t\t}\n\t\t\t} else if (op->operands[1].type & OT_DWORD) {\n\t\t\t\tdata[l++] = 0x44;\n\t\t\t} else if (!(op->operands[1].type & OT_QWORD)) {\n\t\t\t\tdata[l++] = 0x67;\n\t\t\t}\n\t\t\tif (op->operands[1].type & OT_QWORD &&\n\t\t\t\top->operands[0].type & OT_QWORD) {\n\t\t\t\tdata[l++] = 0x48;\n\t\t\t}\n\t\t}\n\n\t\tif (op->operands[0].type & OT_WORD) {\n\t\t\tdata[l++] = 0x66;\n\t\t\tdata[l++] = op->operands[1].type & OT_BYTE ? 0x8a : 0x8b;\n\t\t} else {\n\t\t\tdata[l++] = (op->operands[1].type & OT_BYTE ||\n\t\t\t\top->operands[0].type & OT_BYTE) ?\n\t\t\t\t0x8a : 0x8b;\n\t\t}\n\n\t\tif (op->operands[1].regs[0] == X86R_UNDEFINED) {\n\t\t\tif (a->bits == 64) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = 0x25;\n\t\t\t} else {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x5;\n\t\t\t}\n\t\t\tdata[l++] = offset;\n\t\t\tdata[l++] = offset >> 8;\n\t\t\tdata[l++] = offset >> 16;\n\t\t\tdata[l++] = offset >> 24;\n\t\t} else {\n\t\t\tif (op->operands[1].scale[0] > 1) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 4;\n\n\t\t\t\tif (op->operands[1].scale[0] >= 2) {\n\t\t\t\t\tbase = 5;\n\t\t\t\t}\n\t\t\t\tif (base) {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 6 | op->operands[1].regs[0] << 3 | base;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = getsib (op->operands[1].scale[0]) << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t\tif (offset || base) {\n\t\t\t\t\tdata[l++] = offset;\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t\treturn l;\n\t\t\t}\n\t\t\tif (op->operands[1].regs[1] != X86R_UNDEFINED) {\n\t\t\t\tdata[l++] = op->operands[0].reg << 3 | 0x4;\n\t\t\t\tdata[l++] = op->operands[1].regs[1] << 3 | op->operands[1].regs[0];\n\t\t\t\treturn l;\n\t\t\t}\n\n\t\t\tif (offset || op->operands[1].regs[0] == X86R_EBP) {\n\t\t\t\tmod = 0x2;\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x4;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (a->bits == 64 && offset && op->operands[0].type & OT_QWORD) {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = 0x5;\n\t\t\t\t} else {\n\t\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\t\tdata[l++] = 0x80 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t\t} else {\n\t\t\t\t\t\tdata[l++] = 0x40 | op->operands[1].regs[0];\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (op->operands[1].offset > 127) {\n\t\t\t\t\tmod = 0x1;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif (op->operands[1].regs[0] == X86R_EIP && (op->operands[0].type & OT_DWORD)) {\n\t\t\t\t\tdata[l++] = 0x0d;\n\t\t\t\t} else if (op->operands[1].regs[0] == X86R_RIP && (op->operands[0].type & OT_QWORD)) {\n\t\t\t\t\tdata[l++] = 0x05;\n\t\t\t\t} else {\n\t\t\t\t\tdata[l++] = mod << 5 | op->operands[0].reg << 3 | op->operands[1].regs[0];\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op->operands[1].regs[0] == X86R_ESP) {\n\t\t\t\tdata[l++] = 0x24;\n\t\t\t}\n\t\t\tif (mod >= 0x2) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 128 || op->operands[1].regs[0] == X86R_EIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t} else if (a->bits == 64 && (offset || op->operands[1].regs[0] == X86R_RIP)) {\n\t\t\t\tdata[l++] = offset;\n\t\t\t\tif (op->operands[1].offset > 127 || op->operands[1].regs[0] == X86R_RIP) {\n\t\t\t\t\tdata[l++] = offset >> 8;\n\t\t\t\t\tdata[l++] = offset >> 16;\n\t\t\t\t\tdata[l++] = offset >> 24;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn l;\n}", "commit_link": "github.com/radare/radare2/commit/f17bfd9f1da05f30f23a4dd05e9d2363e1406948", "file_name": "libr/asm/p/asm_x86_nz.c", "vul_type": "cwe-125", "description": "Write a C function named `opmov` that assembles an x86 MOV instruction based on the provided operands."}
{"func_name": "HPHP::extractFileTo", "func_src_before": "static bool extractFileTo(zip* zip, const std::string &file, std::string& to,\n                          char* buf, size_t len) {\n  auto sep = file.rfind('/');\n  if (sep != std::string::npos) {\n    auto path = to + file.substr(0, sep);\n    if (!HHVM_FN(is_dir)(path) && !HHVM_FN(mkdir)(path, 0777, true)) {\n      return false;\n    }\n\n    if (sep == file.length() - 1) {\n      return true;\n    }\n  }\n\n  to.append(file);\n  struct zip_stat zipStat;\n  if (zip_stat(zip, file.c_str(), 0, &zipStat) != 0) {\n    return false;\n  }\n\n  auto zipFile = zip_fopen_index(zip, zipStat.index, 0);\n  FAIL_IF_INVALID_PTR(zipFile);\n\n  auto outFile = fopen(to.c_str(), \"wb\");\n  if (outFile == nullptr) {\n    zip_fclose(zipFile);\n    return false;\n  }\n\n  for (auto n = zip_fread(zipFile, buf, len); n != 0;\n       n = zip_fread(zipFile, buf, len)) {\n    if (n < 0 || fwrite(buf, sizeof(char), n, outFile) != n) {\n      zip_fclose(zipFile);\n      fclose(outFile);\n      remove(to.c_str());\n      return false;\n    }\n  }\n\n  zip_fclose(zipFile);\n  if (fclose(outFile) != 0) {\n    return false;\n  }\n\n  return true;\n}", "func_src_after": "static bool extractFileTo(zip* zip, const std::string &file, std::string& to,\n                          char* buf, size_t len) {\n\n  struct zip_stat zipStat;\n  // Verify the file to be extracted is actually in the zip file\n  if (zip_stat(zip, file.c_str(), 0, &zipStat) != 0) {\n    return false;\n  }\n\n  auto clean_file = file;\n  auto sep = std::string::npos;\n  // Normally would just use std::string::rfind here, but if we want to be\n  // consistent between Windows and Linux, even if techincally Linux won't use\n  // backslash for a separator, we are checking for both types.\n  int idx = file.length() - 1;\n  while (idx >= 0) {\n    if (FileUtil::isDirSeparator(file[idx])) {\n      sep = idx;\n      break;\n    }\n    idx--;\n  }\n  if (sep != std::string::npos) {\n    // make_relative_path so we do not try to put files or dirs in bad\n    // places. This securely \"cleans\" the file.\n    clean_file = make_relative_path(file);\n    std::string path = to + clean_file;\n    bool is_dir_only = true;\n    if (sep < file.length() - 1) { // not just a directory\n      auto clean_file_dir = HHVM_FN(dirname)(clean_file);\n      path = to + clean_file_dir.toCppString();\n      is_dir_only = false;\n    }\n\n    // Make sure the directory path to extract to exists or can be created\n    if (!HHVM_FN(is_dir)(path) && !HHVM_FN(mkdir)(path, 0777, true)) {\n      return false;\n    }\n\n    // If we have a good directory to extract to above, we now check whether\n    // the \"file\" parameter passed in is a directory or actually a file.\n    if (is_dir_only) { // directory, like /usr/bin/\n      return true;\n    }\n    // otherwise file is actually a file, so we actually extract.\n  }\n\n  // We have ensured that clean_file will be added to a relative path by the\n  // time we get here.\n  to.append(clean_file);\n\n  auto zipFile = zip_fopen_index(zip, zipStat.index, 0);\n  FAIL_IF_INVALID_PTR(zipFile);\n\n  auto outFile = fopen(to.c_str(), \"wb\");\n  if (outFile == nullptr) {\n    zip_fclose(zipFile);\n    return false;\n  }\n\n  for (auto n = zip_fread(zipFile, buf, len); n != 0;\n       n = zip_fread(zipFile, buf, len)) {\n    if (n < 0 || fwrite(buf, sizeof(char), n, outFile) != n) {\n      zip_fclose(zipFile);\n      fclose(outFile);\n      remove(to.c_str());\n      return false;\n    }\n  }\n\n  zip_fclose(zipFile);\n  if (fclose(outFile) != 0) {\n    return false;\n  }\n\n  return true;\n}", "commit_link": "github.com/facebook/hhvm/commit/65c95a01541dd2fbc9c978ac53bed235b5376686", "file_name": "hphp/runtime/ext/zip/ext_zip.cpp", "vul_type": "cwe-022", "description": "Write a C++ function to extract a file from a zip archive to a specified directory, handling directory creation and path sanitization."}
{"func_name": "decode_frame", "func_src_before": "static int decode_frame(AVCodecContext *avctx,\n                        void *data, int *got_frame,\n                        AVPacket *avpkt)\n{\n    PicContext *s = avctx->priv_data;\n    AVFrame *frame = data;\n    uint32_t *palette;\n    int bits_per_plane, bpp, etype, esize, npal, pos_after_pal;\n    int i, x, y, plane, tmp, ret, val;\n\n    bytestream2_init(&s->g, avpkt->data, avpkt->size);\n\n    if (bytestream2_get_bytes_left(&s->g) < 11)\n        return AVERROR_INVALIDDATA;\n\n    if (bytestream2_get_le16u(&s->g) != 0x1234)\n        return AVERROR_INVALIDDATA;\n\n    s->width       = bytestream2_get_le16u(&s->g);\n    s->height      = bytestream2_get_le16u(&s->g);\n    bytestream2_skip(&s->g, 4);\n    tmp            = bytestream2_get_byteu(&s->g);\n    bits_per_plane = tmp & 0xF;\n    s->nb_planes   = (tmp >> 4) + 1;\n    bpp            = bits_per_plane * s->nb_planes;\n    if (bits_per_plane > 8 || bpp < 1 || bpp > 32) {\n        avpriv_request_sample(avctx, \"Unsupported bit depth\");\n        return AVERROR_PATCHWELCOME;\n    }\n\n    if (bytestream2_peek_byte(&s->g) == 0xFF || bpp == 1 || bpp == 4 || bpp == 8) {\n        bytestream2_skip(&s->g, 2);\n        etype = bytestream2_get_le16(&s->g);\n        esize = bytestream2_get_le16(&s->g);\n        if (bytestream2_get_bytes_left(&s->g) < esize)\n            return AVERROR_INVALIDDATA;\n    } else {\n        etype = -1;\n        esize = 0;\n    }\n\n    avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n    if (av_image_check_size(s->width, s->height, 0, avctx) < 0)\n        return -1;\n    if (s->width != avctx->width && s->height != avctx->height) {\n        ret = ff_set_dimensions(avctx, s->width, s->height);\n        if (ret < 0)\n            return ret;\n    }\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n    memset(frame->data[0], 0, s->height * frame->linesize[0]);\n    frame->pict_type           = AV_PICTURE_TYPE_I;\n    frame->palette_has_changed = 1;\n\n    pos_after_pal = bytestream2_tell(&s->g) + esize;\n    palette = (uint32_t*)frame->data[1];\n    if (etype == 1 && esize > 1 && bytestream2_peek_byte(&s->g) < 6) {\n        int idx = bytestream2_get_byte(&s->g);\n        npal = 4;\n        for (i = 0; i < npal; i++)\n            palette[i] = ff_cga_palette[ cga_mode45_index[idx][i] ];\n    } else if (etype == 2) {\n        npal = FFMIN(esize, 16);\n        for (i = 0; i < npal; i++) {\n            int pal_idx = bytestream2_get_byte(&s->g);\n            palette[i]  = ff_cga_palette[FFMIN(pal_idx, 15)];\n        }\n    } else if (etype == 3) {\n        npal = FFMIN(esize, 16);\n        for (i = 0; i < npal; i++) {\n            int pal_idx = bytestream2_get_byte(&s->g);\n            palette[i]  = ff_ega_palette[FFMIN(pal_idx, 63)];\n        }\n    } else if (etype == 4 || etype == 5) {\n        npal = FFMIN(esize / 3, 256);\n        for (i = 0; i < npal; i++) {\n            palette[i] = bytestream2_get_be24(&s->g) << 2;\n            palette[i] |= 0xFFU << 24 | palette[i] >> 6 & 0x30303;\n        }\n    } else {\n        if (bpp == 1) {\n            npal = 2;\n            palette[0] = 0xFF000000;\n            palette[1] = 0xFFFFFFFF;\n        } else if (bpp == 2) {\n            npal = 4;\n            for (i = 0; i < npal; i++)\n                palette[i] = ff_cga_palette[ cga_mode45_index[0][i] ];\n        } else {\n            npal = 16;\n            memcpy(palette, ff_cga_palette, npal * 4);\n        }\n    }\n    // fill remaining palette entries\n    memset(palette + npal, 0, AVPALETTE_SIZE - npal * 4);\n    // skip remaining palette bytes\n    bytestream2_seek(&s->g, pos_after_pal, SEEK_SET);\n\n    val = 0;\n    y = s->height - 1;\n    if (bytestream2_get_le16(&s->g)) {\n        x = 0;\n        plane = 0;\n        while (bytestream2_get_bytes_left(&s->g) >= 6) {\n            int stop_size, marker, t1, t2;\n\n            t1        = bytestream2_get_bytes_left(&s->g);\n            t2        = bytestream2_get_le16(&s->g);\n            stop_size = t1 - FFMIN(t1, t2);\n            // ignore uncompressed block size\n            bytestream2_skip(&s->g, 2);\n            marker    = bytestream2_get_byte(&s->g);\n\n            while (plane < s->nb_planes &&\n                   bytestream2_get_bytes_left(&s->g) > stop_size) {\n                int run = 1;\n                val = bytestream2_get_byte(&s->g);\n                if (val == marker) {\n                    run = bytestream2_get_byte(&s->g);\n                    if (run == 0)\n                        run = bytestream2_get_le16(&s->g);\n                    val = bytestream2_get_byte(&s->g);\n                }\n                if (!bytestream2_get_bytes_left(&s->g))\n                    break;\n\n                if (bits_per_plane == 8) {\n                    picmemset_8bpp(s, frame, val, run, &x, &y);\n                    if (y < 0)\n                        goto finish;\n                } else {\n                    picmemset(s, frame, val, run, &x, &y, &plane, bits_per_plane);\n                }\n            }\n        }\n\n        if (x < avctx->width) {\n            int run = (y + 1) * avctx->width - x;\n            if (bits_per_plane == 8)\n                picmemset_8bpp(s, frame, val, run, &x, &y);\n            else\n                picmemset(s, frame, val, run / (8 / bits_per_plane), &x, &y, &plane, bits_per_plane);\n        }\n    } else {\n        while (y >= 0 && bytestream2_get_bytes_left(&s->g) > 0) {\n            memcpy(frame->data[0] + y * frame->linesize[0], s->g.buffer, FFMIN(avctx->width, bytestream2_get_bytes_left(&s->g)));\n            bytestream2_skip(&s->g, avctx->width);\n            y--;\n        }\n    }\nfinish:\n\n    *got_frame      = 1;\n    return avpkt->size;\n}", "func_src_after": "static int decode_frame(AVCodecContext *avctx,\n                        void *data, int *got_frame,\n                        AVPacket *avpkt)\n{\n    PicContext *s = avctx->priv_data;\n    AVFrame *frame = data;\n    uint32_t *palette;\n    int bits_per_plane, bpp, etype, esize, npal, pos_after_pal;\n    int i, x, y, plane, tmp, ret, val;\n\n    bytestream2_init(&s->g, avpkt->data, avpkt->size);\n\n    if (bytestream2_get_bytes_left(&s->g) < 11)\n        return AVERROR_INVALIDDATA;\n\n    if (bytestream2_get_le16u(&s->g) != 0x1234)\n        return AVERROR_INVALIDDATA;\n\n    s->width       = bytestream2_get_le16u(&s->g);\n    s->height      = bytestream2_get_le16u(&s->g);\n    bytestream2_skip(&s->g, 4);\n    tmp            = bytestream2_get_byteu(&s->g);\n    bits_per_plane = tmp & 0xF;\n    s->nb_planes   = (tmp >> 4) + 1;\n    bpp            = bits_per_plane * s->nb_planes;\n    if (bits_per_plane > 8 || bpp < 1 || bpp > 32) {\n        avpriv_request_sample(avctx, \"Unsupported bit depth\");\n        return AVERROR_PATCHWELCOME;\n    }\n\n    if (bytestream2_peek_byte(&s->g) == 0xFF || bpp == 1 || bpp == 4 || bpp == 8) {\n        bytestream2_skip(&s->g, 2);\n        etype = bytestream2_get_le16(&s->g);\n        esize = bytestream2_get_le16(&s->g);\n        if (bytestream2_get_bytes_left(&s->g) < esize)\n            return AVERROR_INVALIDDATA;\n    } else {\n        etype = -1;\n        esize = 0;\n    }\n\n    avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n    if (av_image_check_size(s->width, s->height, 0, avctx) < 0)\n        return -1;\n    if (s->width != avctx->width || s->height != avctx->height) {\n        ret = ff_set_dimensions(avctx, s->width, s->height);\n        if (ret < 0)\n            return ret;\n    }\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n    memset(frame->data[0], 0, s->height * frame->linesize[0]);\n    frame->pict_type           = AV_PICTURE_TYPE_I;\n    frame->palette_has_changed = 1;\n\n    pos_after_pal = bytestream2_tell(&s->g) + esize;\n    palette = (uint32_t*)frame->data[1];\n    if (etype == 1 && esize > 1 && bytestream2_peek_byte(&s->g) < 6) {\n        int idx = bytestream2_get_byte(&s->g);\n        npal = 4;\n        for (i = 0; i < npal; i++)\n            palette[i] = ff_cga_palette[ cga_mode45_index[idx][i] ];\n    } else if (etype == 2) {\n        npal = FFMIN(esize, 16);\n        for (i = 0; i < npal; i++) {\n            int pal_idx = bytestream2_get_byte(&s->g);\n            palette[i]  = ff_cga_palette[FFMIN(pal_idx, 15)];\n        }\n    } else if (etype == 3) {\n        npal = FFMIN(esize, 16);\n        for (i = 0; i < npal; i++) {\n            int pal_idx = bytestream2_get_byte(&s->g);\n            palette[i]  = ff_ega_palette[FFMIN(pal_idx, 63)];\n        }\n    } else if (etype == 4 || etype == 5) {\n        npal = FFMIN(esize / 3, 256);\n        for (i = 0; i < npal; i++) {\n            palette[i] = bytestream2_get_be24(&s->g) << 2;\n            palette[i] |= 0xFFU << 24 | palette[i] >> 6 & 0x30303;\n        }\n    } else {\n        if (bpp == 1) {\n            npal = 2;\n            palette[0] = 0xFF000000;\n            palette[1] = 0xFFFFFFFF;\n        } else if (bpp == 2) {\n            npal = 4;\n            for (i = 0; i < npal; i++)\n                palette[i] = ff_cga_palette[ cga_mode45_index[0][i] ];\n        } else {\n            npal = 16;\n            memcpy(palette, ff_cga_palette, npal * 4);\n        }\n    }\n    // fill remaining palette entries\n    memset(palette + npal, 0, AVPALETTE_SIZE - npal * 4);\n    // skip remaining palette bytes\n    bytestream2_seek(&s->g, pos_after_pal, SEEK_SET);\n\n    val = 0;\n    y = s->height - 1;\n    if (bytestream2_get_le16(&s->g)) {\n        x = 0;\n        plane = 0;\n        while (bytestream2_get_bytes_left(&s->g) >= 6) {\n            int stop_size, marker, t1, t2;\n\n            t1        = bytestream2_get_bytes_left(&s->g);\n            t2        = bytestream2_get_le16(&s->g);\n            stop_size = t1 - FFMIN(t1, t2);\n            // ignore uncompressed block size\n            bytestream2_skip(&s->g, 2);\n            marker    = bytestream2_get_byte(&s->g);\n\n            while (plane < s->nb_planes &&\n                   bytestream2_get_bytes_left(&s->g) > stop_size) {\n                int run = 1;\n                val = bytestream2_get_byte(&s->g);\n                if (val == marker) {\n                    run = bytestream2_get_byte(&s->g);\n                    if (run == 0)\n                        run = bytestream2_get_le16(&s->g);\n                    val = bytestream2_get_byte(&s->g);\n                }\n                if (!bytestream2_get_bytes_left(&s->g))\n                    break;\n\n                if (bits_per_plane == 8) {\n                    picmemset_8bpp(s, frame, val, run, &x, &y);\n                    if (y < 0)\n                        goto finish;\n                } else {\n                    picmemset(s, frame, val, run, &x, &y, &plane, bits_per_plane);\n                }\n            }\n        }\n\n        if (x < avctx->width) {\n            int run = (y + 1) * avctx->width - x;\n            if (bits_per_plane == 8)\n                picmemset_8bpp(s, frame, val, run, &x, &y);\n            else\n                picmemset(s, frame, val, run / (8 / bits_per_plane), &x, &y, &plane, bits_per_plane);\n        }\n    } else {\n        while (y >= 0 && bytestream2_get_bytes_left(&s->g) > 0) {\n            memcpy(frame->data[0] + y * frame->linesize[0], s->g.buffer, FFMIN(avctx->width, bytestream2_get_bytes_left(&s->g)));\n            bytestream2_skip(&s->g, avctx->width);\n            y--;\n        }\n    }\nfinish:\n\n    *got_frame      = 1;\n    return avpkt->size;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/8c2ea3030af7b40a3c4275696fb5c76cdb80950a", "file_name": "libavcodec/pictordec.c", "vul_type": "cwe-787", "description": "Write a C function for decoding a video frame using the FFmpeg library."}
{"func_name": "AP4_AtomFactory::CreateAtomFromStream", "func_src_before": "AP4_AtomFactory::CreateAtomFromStream(AP4_ByteStream& stream, \n                                      AP4_UI32        type,\n                                      AP4_UI32        size_32,\n                                      AP4_UI64        size_64,\n                                      AP4_Atom*&      atom)\n{\n    bool atom_is_large = (size_32 == 1);\n    bool force_64 = (size_32==1 && ((size_64>>32) == 0));\n    \n    // create the atom\n    if (GetContext() == AP4_ATOM_TYPE_STSD) {\n        // sample entry\n        if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n        switch (type) {\n          case AP4_ATOM_TYPE_MP4A:\n            atom = new AP4_Mp4aSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_MP4V:\n            atom = new AP4_Mp4vSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_MP4S:\n            atom = new AP4_Mp4sSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_ENCA:\n            atom = new AP4_EncaSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_ENCV:\n            atom = new AP4_EncvSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_DRMS:\n            atom = new AP4_DrmsSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_DRMI:\n            atom = new AP4_DrmiSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_AVC1:\n          case AP4_ATOM_TYPE_AVC2:\n          case AP4_ATOM_TYPE_AVC3:\n          case AP4_ATOM_TYPE_AVC4:\n          case AP4_ATOM_TYPE_DVAV:\n          case AP4_ATOM_TYPE_DVA1:\n            atom = new AP4_AvcSampleEntry(type, size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_HEV1:\n          case AP4_ATOM_TYPE_HVC1:\n          case AP4_ATOM_TYPE_DVHE:\n          case AP4_ATOM_TYPE_DVH1:\n            atom = new AP4_HevcSampleEntry(type, size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_ALAC:\n          case AP4_ATOM_TYPE_AC_3:\n          case AP4_ATOM_TYPE_EC_3:\n          case AP4_ATOM_TYPE_DTSC:\n          case AP4_ATOM_TYPE_DTSH:\n          case AP4_ATOM_TYPE_DTSL:\n          case AP4_ATOM_TYPE_DTSE:\n            atom = new AP4_AudioSampleEntry(type, size_32, stream, *this);\n            break;\n            \n          case AP4_ATOM_TYPE_RTP_:\n            atom = new AP4_RtpHintSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_STPP:\n            atom = new AP4_SubtitleSampleEntry(type, size_32, stream, *this);\n            break;\n\n          default: {\n            // try all the external type handlers\n            AP4_List<TypeHandler>::Item* handler_item = m_TypeHandlers.FirstItem();\n            while (handler_item) {\n                TypeHandler* handler = handler_item->GetData();\n                if (AP4_SUCCEEDED(handler->CreateAtom(type, size_32, stream, GetContext(), atom))) {\n                    break;\n                }\n                handler_item = handler_item->GetNext();\n            }\n\n            // no custom handler, create a generic entry\n            if (atom == NULL) {\n                atom = new AP4_UnknownSampleEntry(type, (AP4_UI32)size_64, stream);\n            }\n\n            break;\n          }\n        }\n    } else {\n        // regular atom\n        switch (type) {\n          case AP4_ATOM_TYPE_MOOV:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MoovAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_MVHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MvhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MEHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MehdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MFHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MfhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TRAK:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TrakAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_TREX:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TrexAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_HDLR:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_HdlrAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TKHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TkhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TFHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TfhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TRUN:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TrunAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TFRA:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TfraAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MFRO:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MfroAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MDHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MdhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STSD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StsdAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_STSC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StscAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STCO:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StcoAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_CO64:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_Co64Atom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STSZ:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StszAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STZ2:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_Stz2Atom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STTS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SttsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_CTTS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_CttsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STSS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StssAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_IODS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IodsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ESDS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_EsdsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_AVCC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_AvccAtom::Create(size_32, stream);\n            break;\n            \n          case AP4_ATOM_TYPE_HVCC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_HvccAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_DVCC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_DvccAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_HVCE:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_HvccAtom::Create(size_32, stream);\n            atom->SetType(AP4_ATOM_TYPE_HVCE);\n            break;\n\n          case AP4_ATOM_TYPE_AVCE:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_AvccAtom::Create(size_32, stream);\n            atom->SetType(AP4_ATOM_TYPE_AVCE);\n            break;\n\n    #if !defined(AP4_CONFIG_MINI_BUILD)\n          case AP4_ATOM_TYPE_UUID: {\n              AP4_UI08 uuid[16];\n              AP4_Result result = stream.Read(uuid, 16);\n              if (AP4_FAILED(result)) return result;\n              \n              if (AP4_CompareMemory(uuid, AP4_UUID_PIFF_TRACK_ENCRYPTION_ATOM, 16) == 0) {\n                  atom = AP4_PiffTrackEncryptionAtom::Create((AP4_UI32)size_64, stream);\n              } else if (AP4_CompareMemory(uuid, AP4_UUID_PIFF_SAMPLE_ENCRYPTION_ATOM, 16) == 0) {\n                  atom = AP4_PiffSampleEncryptionAtom::Create((AP4_UI32)size_64, stream);\n              } else {\n                  atom = new AP4_UnknownUuidAtom(size_64, uuid, stream);\n              }\n              break;\n          }\n            \n          case AP4_ATOM_TYPE_8ID_:\n            atom = new AP4_NullTerminatedStringAtom(type, size_64, stream);\n            break;\n\n          case AP4_ATOM_TYPE_8BDL:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_8bdlAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_DREF:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_DrefAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_URL:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_UrlAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ELST:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_ElstAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_VMHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_VmhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SMHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SmhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_NMHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_NmhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SthdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_HMHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_HmhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_FRMA:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_FrmaAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SCHM:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SchmAtom::Create(size_32, &m_ContextStack, stream);\n            break;\n\n          case AP4_ATOM_TYPE_FTYP:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_FtypAtom::Create(size_32, stream);\n            break;\n                        \n          case AP4_ATOM_TYPE_TIMS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TimsAtom::Create(size_32, stream);\n            break;\n     \n          case AP4_ATOM_TYPE_SDP_:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SdpAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_IKMS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IkmsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ISFM:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IsfmAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ISLT:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IsltAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ODHE:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_OdheAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_OHDR:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_OhdrAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_ODDA:\n            atom = AP4_OddaAtom::Create(size_64, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ODAF:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_OdafAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_GRPI:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_GrpiAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_IPRO:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IproAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_RTP_:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_RtpAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TFDT:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TfdtAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TENC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TencAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SENC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SencAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SAIZ:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SaizAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SAIO:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SaioAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_PDIN:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_PdinAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_BLOC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_BlocAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_AINF:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_AinfAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_PSSH:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_PsshAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SIDX:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SidxAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SBGP:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SbgpAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SGPD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SgpdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MKID:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            if (GetContext() == AP4_ATOM_TYPE_MARL) {\n                atom = AP4_MkidAtom::Create(size_32, stream);\n            }\n            break;\n\n          case AP4_ATOM_TYPE_DEC3:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            if (GetContext() == AP4_ATOM_TYPE_EC_3 || GetContext() == AP4_ATOM_TYPE_ENCA) {\n                atom = AP4_Dec3Atom::Create(size_32, stream);\n            }\n            break;\n\n          // track ref types\n          case AP4_ATOM_TYPE_HINT:\n          case AP4_ATOM_TYPE_CDSC:\n          case AP4_ATOM_TYPE_SYNC:\n          case AP4_ATOM_TYPE_MPOD:\n          case AP4_ATOM_TYPE_DPND:\n          case AP4_ATOM_TYPE_IPIR:\n          case AP4_ATOM_TYPE_ALIS:\n          case AP4_ATOM_TYPE_CHAP:\n            if (GetContext() == AP4_ATOM_TYPE_TREF) {\n                if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n                atom = AP4_TrefTypeAtom::Create(type, size_32, stream);\n            }\n            break;\n\n    #endif // AP4_CONFIG_MINI_BUILD\n\n          // container atoms\n          case AP4_ATOM_TYPE_MOOF:\n          case AP4_ATOM_TYPE_MVEX:\n          case AP4_ATOM_TYPE_TRAF:\n          case AP4_ATOM_TYPE_TREF:\n          case AP4_ATOM_TYPE_MFRA:\n          case AP4_ATOM_TYPE_HNTI:\n          case AP4_ATOM_TYPE_STBL:\n          case AP4_ATOM_TYPE_MDIA:\n          case AP4_ATOM_TYPE_DINF:\n          case AP4_ATOM_TYPE_MINF:\n          case AP4_ATOM_TYPE_SCHI:\n          case AP4_ATOM_TYPE_SINF:\n          case AP4_ATOM_TYPE_UDTA:\n          case AP4_ATOM_TYPE_ILST:\n          case AP4_ATOM_TYPE_EDTS: \n          case AP4_ATOM_TYPE_MDRI:\n          case AP4_ATOM_TYPE_WAVE:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_ContainerAtom::Create(type, size_64, false, force_64, stream, *this);\n            break;\n\n          // containers, only at the top\n          case AP4_ATOM_TYPE_MARL:\n            if (GetContext() == 0) {\n                atom = AP4_ContainerAtom::Create(type, size_64, false, force_64, stream, *this);\n            }\n            break;\n            \n          // full container atoms\n          case AP4_ATOM_TYPE_META:\n          case AP4_ATOM_TYPE_ODRM:\n          case AP4_ATOM_TYPE_ODKM:\n            atom = AP4_ContainerAtom::Create(type, size_64, true, force_64, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_FREE:\n          case AP4_ATOM_TYPE_WIDE:\n          case AP4_ATOM_TYPE_MDAT:\n            // generic atoms\n            break;\n            \n          default: {\n            // try all the external type handlers\n            AP4_List<TypeHandler>::Item* handler_item = m_TypeHandlers.FirstItem();\n            while (handler_item) {\n                TypeHandler* handler = handler_item->GetData();\n                if (AP4_SUCCEEDED(handler->CreateAtom(type, size_32, stream, GetContext(), atom))) {\n                    break;\n                }\n                handler_item = handler_item->GetNext();\n            }\n\n            break;\n          }\n        }\n    }\n    \n    return AP4_SUCCESS;\n}", "func_src_after": "AP4_AtomFactory::CreateAtomFromStream(AP4_ByteStream& stream, \n                                      AP4_UI32        type,\n                                      AP4_UI32        size_32,\n                                      AP4_UI64        size_64,\n                                      AP4_Atom*&      atom)\n{\n    bool atom_is_large = (size_32 == 1);\n    bool force_64 = (size_32==1 && ((size_64>>32) == 0));\n    \n    // create the atom\n    if (GetContext() == AP4_ATOM_TYPE_STSD) {\n        // sample entry\n        if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n        switch (type) {\n          case AP4_ATOM_TYPE_MP4A:\n            atom = new AP4_Mp4aSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_MP4V:\n            atom = new AP4_Mp4vSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_MP4S:\n            atom = new AP4_Mp4sSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_ENCA:\n            atom = new AP4_EncaSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_ENCV:\n            atom = new AP4_EncvSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_DRMS:\n            atom = new AP4_DrmsSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_DRMI:\n            atom = new AP4_DrmiSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_AVC1:\n          case AP4_ATOM_TYPE_AVC2:\n          case AP4_ATOM_TYPE_AVC3:\n          case AP4_ATOM_TYPE_AVC4:\n          case AP4_ATOM_TYPE_DVAV:\n          case AP4_ATOM_TYPE_DVA1:\n            atom = new AP4_AvcSampleEntry(type, size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_HEV1:\n          case AP4_ATOM_TYPE_HVC1:\n          case AP4_ATOM_TYPE_DVHE:\n          case AP4_ATOM_TYPE_DVH1:\n            atom = new AP4_HevcSampleEntry(type, size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_ALAC:\n          case AP4_ATOM_TYPE_AC_3:\n          case AP4_ATOM_TYPE_EC_3:\n          case AP4_ATOM_TYPE_DTSC:\n          case AP4_ATOM_TYPE_DTSH:\n          case AP4_ATOM_TYPE_DTSL:\n          case AP4_ATOM_TYPE_DTSE:\n            atom = new AP4_AudioSampleEntry(type, size_32, stream, *this);\n            break;\n            \n          case AP4_ATOM_TYPE_RTP_:\n            atom = new AP4_RtpHintSampleEntry(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_STPP:\n            atom = new AP4_SubtitleSampleEntry(type, size_32, stream, *this);\n            break;\n\n          default: {\n            // try all the external type handlers\n            AP4_List<TypeHandler>::Item* handler_item = m_TypeHandlers.FirstItem();\n            while (handler_item) {\n                TypeHandler* handler = handler_item->GetData();\n                if (AP4_SUCCEEDED(handler->CreateAtom(type, size_32, stream, GetContext(), atom))) {\n                    break;\n                }\n                handler_item = handler_item->GetNext();\n            }\n\n            // no custom handler, create a generic entry\n            if (atom == NULL) {\n                atom = new AP4_UnknownSampleEntry(type, (AP4_UI32)size_64, stream);\n            }\n\n            break;\n          }\n        }\n    } else {\n        // regular atom\n        switch (type) {\n          case AP4_ATOM_TYPE_MOOV:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MoovAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_MVHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MvhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MEHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MehdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MFHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MfhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TRAK:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TrakAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_TREX:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TrexAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_HDLR:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_HdlrAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TKHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TkhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TFHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TfhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TRUN:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TrunAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TFRA:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TfraAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MFRO:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MfroAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MDHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_MdhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STSD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StsdAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_STSC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StscAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STCO:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StcoAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_CO64:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_Co64Atom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STSZ:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StszAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STZ2:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_Stz2Atom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STTS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SttsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_CTTS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_CttsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STSS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_StssAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_IODS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IodsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ESDS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_EsdsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_AVCC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_AvccAtom::Create(size_32, stream);\n            break;\n            \n          case AP4_ATOM_TYPE_HVCC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_HvccAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_DVCC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_DvccAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_HVCE:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_HvccAtom::Create(size_32, stream);\n            if (atom) {\n                atom->SetType(AP4_ATOM_TYPE_HVCE);\n            }\n            break;\n\n          case AP4_ATOM_TYPE_AVCE:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_AvccAtom::Create(size_32, stream);\n            if (atom) {\n                atom->SetType(AP4_ATOM_TYPE_AVCE);\n            }\n            break;\n\n    #if !defined(AP4_CONFIG_MINI_BUILD)\n          case AP4_ATOM_TYPE_UUID: {\n              AP4_UI08 uuid[16];\n              AP4_Result result = stream.Read(uuid, 16);\n              if (AP4_FAILED(result)) return result;\n              \n              if (AP4_CompareMemory(uuid, AP4_UUID_PIFF_TRACK_ENCRYPTION_ATOM, 16) == 0) {\n                  atom = AP4_PiffTrackEncryptionAtom::Create((AP4_UI32)size_64, stream);\n              } else if (AP4_CompareMemory(uuid, AP4_UUID_PIFF_SAMPLE_ENCRYPTION_ATOM, 16) == 0) {\n                  atom = AP4_PiffSampleEncryptionAtom::Create((AP4_UI32)size_64, stream);\n              } else {\n                  atom = new AP4_UnknownUuidAtom(size_64, uuid, stream);\n              }\n              break;\n          }\n            \n          case AP4_ATOM_TYPE_8ID_:\n            atom = new AP4_NullTerminatedStringAtom(type, size_64, stream);\n            break;\n\n          case AP4_ATOM_TYPE_8BDL:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_8bdlAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_DREF:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_DrefAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_URL:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_UrlAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ELST:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_ElstAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_VMHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_VmhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SMHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SmhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_NMHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_NmhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_STHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SthdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_HMHD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_HmhdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_FRMA:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_FrmaAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SCHM:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SchmAtom::Create(size_32, &m_ContextStack, stream);\n            break;\n\n          case AP4_ATOM_TYPE_FTYP:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_FtypAtom::Create(size_32, stream);\n            break;\n                        \n          case AP4_ATOM_TYPE_TIMS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TimsAtom::Create(size_32, stream);\n            break;\n     \n          case AP4_ATOM_TYPE_SDP_:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SdpAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_IKMS:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IkmsAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ISFM:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IsfmAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ISLT:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IsltAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ODHE:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_OdheAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_OHDR:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_OhdrAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_ODDA:\n            atom = AP4_OddaAtom::Create(size_64, stream);\n            break;\n\n          case AP4_ATOM_TYPE_ODAF:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_OdafAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_GRPI:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_GrpiAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_IPRO:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_IproAtom::Create(size_32, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_RTP_:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_RtpAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TFDT:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TfdtAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_TENC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_TencAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SENC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SencAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SAIZ:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SaizAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SAIO:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SaioAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_PDIN:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_PdinAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_BLOC:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_BlocAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_AINF:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_AinfAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_PSSH:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_PsshAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SIDX:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SidxAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SBGP:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SbgpAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_SGPD:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_SgpdAtom::Create(size_32, stream);\n            break;\n\n          case AP4_ATOM_TYPE_MKID:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            if (GetContext() == AP4_ATOM_TYPE_MARL) {\n                atom = AP4_MkidAtom::Create(size_32, stream);\n            }\n            break;\n\n          case AP4_ATOM_TYPE_DEC3:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            if (GetContext() == AP4_ATOM_TYPE_EC_3 || GetContext() == AP4_ATOM_TYPE_ENCA) {\n                atom = AP4_Dec3Atom::Create(size_32, stream);\n            }\n            break;\n\n          // track ref types\n          case AP4_ATOM_TYPE_HINT:\n          case AP4_ATOM_TYPE_CDSC:\n          case AP4_ATOM_TYPE_SYNC:\n          case AP4_ATOM_TYPE_MPOD:\n          case AP4_ATOM_TYPE_DPND:\n          case AP4_ATOM_TYPE_IPIR:\n          case AP4_ATOM_TYPE_ALIS:\n          case AP4_ATOM_TYPE_CHAP:\n            if (GetContext() == AP4_ATOM_TYPE_TREF) {\n                if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n                atom = AP4_TrefTypeAtom::Create(type, size_32, stream);\n            }\n            break;\n\n    #endif // AP4_CONFIG_MINI_BUILD\n\n          // container atoms\n          case AP4_ATOM_TYPE_MOOF:\n          case AP4_ATOM_TYPE_MVEX:\n          case AP4_ATOM_TYPE_TRAF:\n          case AP4_ATOM_TYPE_TREF:\n          case AP4_ATOM_TYPE_MFRA:\n          case AP4_ATOM_TYPE_HNTI:\n          case AP4_ATOM_TYPE_STBL:\n          case AP4_ATOM_TYPE_MDIA:\n          case AP4_ATOM_TYPE_DINF:\n          case AP4_ATOM_TYPE_MINF:\n          case AP4_ATOM_TYPE_SCHI:\n          case AP4_ATOM_TYPE_SINF:\n          case AP4_ATOM_TYPE_UDTA:\n          case AP4_ATOM_TYPE_ILST:\n          case AP4_ATOM_TYPE_EDTS: \n          case AP4_ATOM_TYPE_MDRI:\n          case AP4_ATOM_TYPE_WAVE:\n            if (atom_is_large) return AP4_ERROR_INVALID_FORMAT;\n            atom = AP4_ContainerAtom::Create(type, size_64, false, force_64, stream, *this);\n            break;\n\n          // containers, only at the top\n          case AP4_ATOM_TYPE_MARL:\n            if (GetContext() == 0) {\n                atom = AP4_ContainerAtom::Create(type, size_64, false, force_64, stream, *this);\n            }\n            break;\n            \n          // full container atoms\n          case AP4_ATOM_TYPE_META:\n          case AP4_ATOM_TYPE_ODRM:\n          case AP4_ATOM_TYPE_ODKM:\n            atom = AP4_ContainerAtom::Create(type, size_64, true, force_64, stream, *this);\n            break;\n\n          case AP4_ATOM_TYPE_FREE:\n          case AP4_ATOM_TYPE_WIDE:\n          case AP4_ATOM_TYPE_MDAT:\n            // generic atoms\n            break;\n            \n          default: {\n            // try all the external type handlers\n            AP4_List<TypeHandler>::Item* handler_item = m_TypeHandlers.FirstItem();\n            while (handler_item) {\n                TypeHandler* handler = handler_item->GetData();\n                if (AP4_SUCCEEDED(handler->CreateAtom(type, size_32, stream, GetContext(), atom))) {\n                    break;\n                }\n                handler_item = handler_item->GetNext();\n            }\n\n            break;\n          }\n        }\n    }\n    \n    return AP4_SUCCESS;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/be7185faf7f52674028977dcf501c6039ff03aa5", "file_name": "Source/C++/Core/Ap4AtomFactory.cpp", "vul_type": "cwe-476", "description": "Write a C++ function in AP4_AtomFactory that creates an atom from a stream based on type and size."}
{"func_name": "get_top_popular", "func_src_before": "def get_top_popular(top_num):\r\n    \"\"\" query the top(top_num) popular articles\r\n        top_num => list of [title, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT title, views FROM articles\r\n             INNER JOIN (\r\n             SELECT path, count(path) AS views\r\n             FROM log GROUP BY log.path\r\n             ) AS log\r\n             ON log.path = '/article/' || articles.slug\r\n             ORDER BY views DESC\r\n             LIMIT {}\"\"\".format(top_num)\r\n    return execute_query(cmd)", "func_src_after": "def get_top_popular(top_num):\r\n    \"\"\" query the top(top_num) popular articles\r\n        top_num => list of [title, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT title, views FROM articles\r\n             INNER JOIN (\r\n             SELECT path, count(path) AS views\r\n             FROM log GROUP BY log.path\r\n             ) AS log\r\n             ON log.path = '/article/' || articles.slug\r\n             ORDER BY views DESC\r\n             LIMIT %s\"\"\"\r\n    data = [top_num, ]\r\n    return execute_query(cmd, data)", "commit_link": "github.com/thugasin/udacity-homework-logAnalyzer/commit/506f25f9a1caee7f17034adf7c75e0efbc88082b", "file_name": "logAnalyzerDb.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the top N most viewed articles from a database, using SQL queries with parameter substitution."}
{"func_name": "deletePost", "func_src_before": "    def deletePost(self,postid):\n        sqlText=\"delete from post where post.postid=%d\"%(postid)\n        result=sql.deleteDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def deletePost(self,postid):\n        sqlText=\"delete from post where post.postid=%s\"\n        params=[postid]\n        result=sql.deleteDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089", "description": "Write a Python function named `deletePost` that deletes a post with a given `postid` from a database using SQL."}
{"func_name": "decode_studio_vop_header", "func_src_before": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "func_src_after": "static int decode_studio_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n{\n    MpegEncContext *s = &ctx->m;\n\n    if (get_bits_left(gb) <= 32)\n        return 0;\n\n    s->partitioned_frame = 0;\n    s->interlaced_dct = 0;\n    s->decode_mb = mpeg4_decode_studio_mb;\n\n    decode_smpte_tc(ctx, gb);\n\n    skip_bits(gb, 10); /* temporal_reference */\n    skip_bits(gb, 2); /* vop_structure */\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I; /* vop_coding_type */\n    if (get_bits1(gb)) { /* vop_coded */\n        skip_bits1(gb); /* top_field_first */\n        skip_bits1(gb); /* repeat_first_field */\n        s->progressive_frame = get_bits1(gb) ^ 1; /* progressive_frame */\n    }\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n        if (get_bits1(gb))\n            reset_studio_dc_predictors(s);\n    }\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n        s->alternate_scan = get_bits1(gb);\n        s->frame_pred_frame_dct = get_bits1(gb);\n        s->dct_precision = get_bits(gb, 2);\n        s->intra_dc_precision = get_bits(gb, 2);\n        s->q_scale_type = get_bits1(gb);\n    }\n\n    if (s->alternate_scan) {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    } else {\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n    }\n\n    mpeg4_load_default_matrices(s);\n\n    next_start_code_studio(gb);\n    extension_and_user_data(s, gb, 4);\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/1f686d023b95219db933394a7704ad9aa5f01cbb", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to decode the header of a studio video object plane (VOP) for an MPEG4 decoder context."}
{"func_name": "amqp_handle_input", "func_src_before": "int amqp_handle_input(amqp_connection_state_t state, amqp_bytes_t received_data,\n                      amqp_frame_t *decoded_frame) {\n  size_t bytes_consumed;\n  void *raw_frame;\n\n  /* Returning frame_type of zero indicates either insufficient input,\n     or a complete, ignored frame was read. */\n  decoded_frame->frame_type = 0;\n\n  if (received_data.len == 0) {\n    return AMQP_STATUS_OK;\n  }\n\n  if (state->state == CONNECTION_STATE_IDLE) {\n    state->state = CONNECTION_STATE_HEADER;\n  }\n\n  bytes_consumed = consume_data(state, &received_data);\n\n  /* do we have target_size data yet? if not, return with the\n     expectation that more will arrive */\n  if (state->inbound_offset < state->target_size) {\n    return (int)bytes_consumed;\n  }\n\n  raw_frame = state->inbound_buffer.bytes;\n\n  switch (state->state) {\n    case CONNECTION_STATE_INITIAL:\n      /* check for a protocol header from the server */\n      if (memcmp(raw_frame, \"AMQP\", 4) == 0) {\n        decoded_frame->frame_type = AMQP_PSEUDOFRAME_PROTOCOL_HEADER;\n        decoded_frame->channel = 0;\n\n        decoded_frame->payload.protocol_header.transport_high =\n            amqp_d8(amqp_offset(raw_frame, 4));\n        decoded_frame->payload.protocol_header.transport_low =\n            amqp_d8(amqp_offset(raw_frame, 5));\n        decoded_frame->payload.protocol_header.protocol_version_major =\n            amqp_d8(amqp_offset(raw_frame, 6));\n        decoded_frame->payload.protocol_header.protocol_version_minor =\n            amqp_d8(amqp_offset(raw_frame, 7));\n\n        return_to_idle(state);\n        return (int)bytes_consumed;\n      }\n\n    /* it's not a protocol header; fall through to process it as a\n       regular frame header */\n\n    case CONNECTION_STATE_HEADER: {\n      amqp_channel_t channel;\n      amqp_pool_t *channel_pool;\n      /* frame length is 3 bytes in */\n      channel = amqp_d16(amqp_offset(raw_frame, 1));\n\n      state->target_size =\n          amqp_d32(amqp_offset(raw_frame, 3)) + HEADER_SIZE + FOOTER_SIZE;\n\n      if ((size_t)state->frame_max < state->target_size) {\n        return AMQP_STATUS_BAD_AMQP_DATA;\n      }\n\n      channel_pool = amqp_get_or_create_channel_pool(state, channel);\n      if (NULL == channel_pool) {\n        return AMQP_STATUS_NO_MEMORY;\n      }\n\n      amqp_pool_alloc_bytes(channel_pool, state->target_size,\n                            &state->inbound_buffer);\n      if (NULL == state->inbound_buffer.bytes) {\n        return AMQP_STATUS_NO_MEMORY;\n      }\n      memcpy(state->inbound_buffer.bytes, state->header_buffer, HEADER_SIZE);\n      raw_frame = state->inbound_buffer.bytes;\n\n      state->state = CONNECTION_STATE_BODY;\n\n      bytes_consumed += consume_data(state, &received_data);\n\n      /* do we have target_size data yet? if not, return with the\n         expectation that more will arrive */\n      if (state->inbound_offset < state->target_size) {\n        return (int)bytes_consumed;\n      }\n    }\n    /* fall through to process body */\n\n    case CONNECTION_STATE_BODY: {\n      amqp_bytes_t encoded;\n      int res;\n      amqp_pool_t *channel_pool;\n\n      /* Check frame end marker (footer) */\n      if (amqp_d8(amqp_offset(raw_frame, state->target_size - 1)) !=\n          AMQP_FRAME_END) {\n        return AMQP_STATUS_BAD_AMQP_DATA;\n      }\n\n      decoded_frame->frame_type = amqp_d8(amqp_offset(raw_frame, 0));\n      decoded_frame->channel = amqp_d16(amqp_offset(raw_frame, 1));\n\n      channel_pool =\n          amqp_get_or_create_channel_pool(state, decoded_frame->channel);\n      if (NULL == channel_pool) {\n        return AMQP_STATUS_NO_MEMORY;\n      }\n\n      switch (decoded_frame->frame_type) {\n        case AMQP_FRAME_METHOD:\n          decoded_frame->payload.method.id =\n              amqp_d32(amqp_offset(raw_frame, HEADER_SIZE));\n          encoded.bytes = amqp_offset(raw_frame, HEADER_SIZE + 4);\n          encoded.len = state->target_size - HEADER_SIZE - 4 - FOOTER_SIZE;\n\n          res = amqp_decode_method(decoded_frame->payload.method.id,\n                                   channel_pool, encoded,\n                                   &decoded_frame->payload.method.decoded);\n          if (res < 0) {\n            return res;\n          }\n\n          break;\n\n        case AMQP_FRAME_HEADER:\n          decoded_frame->payload.properties.class_id =\n              amqp_d16(amqp_offset(raw_frame, HEADER_SIZE));\n          /* unused 2-byte weight field goes here */\n          decoded_frame->payload.properties.body_size =\n              amqp_d64(amqp_offset(raw_frame, HEADER_SIZE + 4));\n          encoded.bytes = amqp_offset(raw_frame, HEADER_SIZE + 12);\n          encoded.len = state->target_size - HEADER_SIZE - 12 - FOOTER_SIZE;\n          decoded_frame->payload.properties.raw = encoded;\n\n          res = amqp_decode_properties(\n              decoded_frame->payload.properties.class_id, channel_pool, encoded,\n              &decoded_frame->payload.properties.decoded);\n          if (res < 0) {\n            return res;\n          }\n\n          break;\n\n        case AMQP_FRAME_BODY:\n          decoded_frame->payload.body_fragment.len =\n              state->target_size - HEADER_SIZE - FOOTER_SIZE;\n          decoded_frame->payload.body_fragment.bytes =\n              amqp_offset(raw_frame, HEADER_SIZE);\n          break;\n\n        case AMQP_FRAME_HEARTBEAT:\n          break;\n\n        default:\n          /* Ignore the frame */\n          decoded_frame->frame_type = 0;\n          break;\n      }\n\n      return_to_idle(state);\n      return (int)bytes_consumed;\n    }\n\n    default:\n      amqp_abort(\"Internal error: invalid amqp_connection_state_t->state %d\",\n                 state->state);\n  }\n}", "func_src_after": "int amqp_handle_input(amqp_connection_state_t state, amqp_bytes_t received_data,\n                      amqp_frame_t *decoded_frame) {\n  size_t bytes_consumed;\n  void *raw_frame;\n\n  /* Returning frame_type of zero indicates either insufficient input,\n     or a complete, ignored frame was read. */\n  decoded_frame->frame_type = 0;\n\n  if (received_data.len == 0) {\n    return AMQP_STATUS_OK;\n  }\n\n  if (state->state == CONNECTION_STATE_IDLE) {\n    state->state = CONNECTION_STATE_HEADER;\n  }\n\n  bytes_consumed = consume_data(state, &received_data);\n\n  /* do we have target_size data yet? if not, return with the\n     expectation that more will arrive */\n  if (state->inbound_offset < state->target_size) {\n    return (int)bytes_consumed;\n  }\n\n  raw_frame = state->inbound_buffer.bytes;\n\n  switch (state->state) {\n    case CONNECTION_STATE_INITIAL:\n      /* check for a protocol header from the server */\n      if (memcmp(raw_frame, \"AMQP\", 4) == 0) {\n        decoded_frame->frame_type = AMQP_PSEUDOFRAME_PROTOCOL_HEADER;\n        decoded_frame->channel = 0;\n\n        decoded_frame->payload.protocol_header.transport_high =\n            amqp_d8(amqp_offset(raw_frame, 4));\n        decoded_frame->payload.protocol_header.transport_low =\n            amqp_d8(amqp_offset(raw_frame, 5));\n        decoded_frame->payload.protocol_header.protocol_version_major =\n            amqp_d8(amqp_offset(raw_frame, 6));\n        decoded_frame->payload.protocol_header.protocol_version_minor =\n            amqp_d8(amqp_offset(raw_frame, 7));\n\n        return_to_idle(state);\n        return (int)bytes_consumed;\n      }\n\n    /* it's not a protocol header; fall through to process it as a\n       regular frame header */\n\n    case CONNECTION_STATE_HEADER: {\n      amqp_channel_t channel;\n      amqp_pool_t *channel_pool;\n      uint32_t frame_size;\n\n      channel = amqp_d16(amqp_offset(raw_frame, 1));\n\n      /* frame length is 3 bytes in */\n      frame_size = amqp_d32(amqp_offset(raw_frame, 3));\n      /* To prevent the target_size calculation below from overflowing, check\n       * that the stated frame_size is smaller than a signed 32-bit. Given\n       * the library only allows configuring frame_max as an int32_t, and\n       * frame_size is uint32_t, the math below is safe from overflow. */\n      if (frame_size >= INT32_MAX) {\n        return AMQP_STATUS_BAD_AMQP_DATA;\n      }\n\n      state->target_size = frame_size + HEADER_SIZE + FOOTER_SIZE;\n      if ((size_t)state->frame_max < state->target_size) {\n        return AMQP_STATUS_BAD_AMQP_DATA;\n      }\n\n      channel_pool = amqp_get_or_create_channel_pool(state, channel);\n      if (NULL == channel_pool) {\n        return AMQP_STATUS_NO_MEMORY;\n      }\n\n      amqp_pool_alloc_bytes(channel_pool, state->target_size,\n                            &state->inbound_buffer);\n      if (NULL == state->inbound_buffer.bytes) {\n        return AMQP_STATUS_NO_MEMORY;\n      }\n      memcpy(state->inbound_buffer.bytes, state->header_buffer, HEADER_SIZE);\n      raw_frame = state->inbound_buffer.bytes;\n\n      state->state = CONNECTION_STATE_BODY;\n\n      bytes_consumed += consume_data(state, &received_data);\n\n      /* do we have target_size data yet? if not, return with the\n         expectation that more will arrive */\n      if (state->inbound_offset < state->target_size) {\n        return (int)bytes_consumed;\n      }\n    }\n    /* fall through to process body */\n\n    case CONNECTION_STATE_BODY: {\n      amqp_bytes_t encoded;\n      int res;\n      amqp_pool_t *channel_pool;\n\n      /* Check frame end marker (footer) */\n      if (amqp_d8(amqp_offset(raw_frame, state->target_size - 1)) !=\n          AMQP_FRAME_END) {\n        return AMQP_STATUS_BAD_AMQP_DATA;\n      }\n\n      decoded_frame->frame_type = amqp_d8(amqp_offset(raw_frame, 0));\n      decoded_frame->channel = amqp_d16(amqp_offset(raw_frame, 1));\n\n      channel_pool =\n          amqp_get_or_create_channel_pool(state, decoded_frame->channel);\n      if (NULL == channel_pool) {\n        return AMQP_STATUS_NO_MEMORY;\n      }\n\n      switch (decoded_frame->frame_type) {\n        case AMQP_FRAME_METHOD:\n          decoded_frame->payload.method.id =\n              amqp_d32(amqp_offset(raw_frame, HEADER_SIZE));\n          encoded.bytes = amqp_offset(raw_frame, HEADER_SIZE + 4);\n          encoded.len = state->target_size - HEADER_SIZE - 4 - FOOTER_SIZE;\n\n          res = amqp_decode_method(decoded_frame->payload.method.id,\n                                   channel_pool, encoded,\n                                   &decoded_frame->payload.method.decoded);\n          if (res < 0) {\n            return res;\n          }\n\n          break;\n\n        case AMQP_FRAME_HEADER:\n          decoded_frame->payload.properties.class_id =\n              amqp_d16(amqp_offset(raw_frame, HEADER_SIZE));\n          /* unused 2-byte weight field goes here */\n          decoded_frame->payload.properties.body_size =\n              amqp_d64(amqp_offset(raw_frame, HEADER_SIZE + 4));\n          encoded.bytes = amqp_offset(raw_frame, HEADER_SIZE + 12);\n          encoded.len = state->target_size - HEADER_SIZE - 12 - FOOTER_SIZE;\n          decoded_frame->payload.properties.raw = encoded;\n\n          res = amqp_decode_properties(\n              decoded_frame->payload.properties.class_id, channel_pool, encoded,\n              &decoded_frame->payload.properties.decoded);\n          if (res < 0) {\n            return res;\n          }\n\n          break;\n\n        case AMQP_FRAME_BODY:\n          decoded_frame->payload.body_fragment.len =\n              state->target_size - HEADER_SIZE - FOOTER_SIZE;\n          decoded_frame->payload.body_fragment.bytes =\n              amqp_offset(raw_frame, HEADER_SIZE);\n          break;\n\n        case AMQP_FRAME_HEARTBEAT:\n          break;\n\n        default:\n          /* Ignore the frame */\n          decoded_frame->frame_type = 0;\n          break;\n      }\n\n      return_to_idle(state);\n      return (int)bytes_consumed;\n    }\n\n    default:\n      amqp_abort(\"Internal error: invalid amqp_connection_state_t->state %d\",\n                 state->state);\n  }\n}", "commit_link": "github.com/alanxz/rabbitmq-c/commit/fc85be7123050b91b054e45b91c78d3241a5047a", "file_name": "librabbitmq/amqp_connection.c", "vul_type": "cwe-190", "description": "Write a C function named `amqp_handle_input` that processes incoming AMQP data and decodes it into a frame structure."}
{"func_name": "usb_audio_probe", "func_src_before": "static int usb_audio_probe(struct usb_interface *intf,\n\t\t\t   const struct usb_device_id *usb_id)\n{\n\tstruct usb_device *dev = interface_to_usbdev(intf);\n\tconst struct snd_usb_audio_quirk *quirk =\n\t\t(const struct snd_usb_audio_quirk *)usb_id->driver_info;\n\tstruct snd_usb_audio *chip;\n\tint i, err;\n\tstruct usb_host_interface *alts;\n\tint ifnum;\n\tu32 id;\n\n\talts = &intf->altsetting[0];\n\tifnum = get_iface_desc(alts)->bInterfaceNumber;\n\tid = USB_ID(le16_to_cpu(dev->descriptor.idVendor),\n\t\t    le16_to_cpu(dev->descriptor.idProduct));\n\tif (get_alias_id(dev, &id))\n\t\tquirk = get_alias_quirk(dev, id);\n\tif (quirk && quirk->ifnum >= 0 && ifnum != quirk->ifnum)\n\t\treturn -ENXIO;\n\n\terr = snd_usb_apply_boot_quirk(dev, intf, quirk, id);\n\tif (err < 0)\n\t\treturn err;\n\n\t/*\n\t * found a config.  now register to ALSA\n\t */\n\n\t/* check whether it's already registered */\n\tchip = NULL;\n\tmutex_lock(&register_mutex);\n\tfor (i = 0; i < SNDRV_CARDS; i++) {\n\t\tif (usb_chip[i] && usb_chip[i]->dev == dev) {\n\t\t\tif (atomic_read(&usb_chip[i]->shutdown)) {\n\t\t\t\tdev_err(&dev->dev, \"USB device is in the shutdown state, cannot create a card instance\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto __error;\n\t\t\t}\n\t\t\tchip = usb_chip[i];\n\t\t\tatomic_inc(&chip->active); /* avoid autopm */\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (! chip) {\n\t\t/* it's a fresh one.\n\t\t * now look for an empty slot and create a new card instance\n\t\t */\n\t\tfor (i = 0; i < SNDRV_CARDS; i++)\n\t\t\tif (!usb_chip[i] &&\n\t\t\t    (vid[i] == -1 || vid[i] == USB_ID_VENDOR(id)) &&\n\t\t\t    (pid[i] == -1 || pid[i] == USB_ID_PRODUCT(id))) {\n\t\t\t\tif (enable[i]) {\n\t\t\t\t\terr = snd_usb_audio_create(intf, dev, i, quirk,\n\t\t\t\t\t\t\t\t   id, &chip);\n\t\t\t\t\tif (err < 0)\n\t\t\t\t\t\tgoto __error;\n\t\t\t\t\tchip->pm_intf = intf;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (vid[i] != -1 || pid[i] != -1) {\n\t\t\t\t\tdev_info(&dev->dev,\n\t\t\t\t\t\t \"device (%04x:%04x) is disabled\\n\",\n\t\t\t\t\t\t USB_ID_VENDOR(id),\n\t\t\t\t\t\t USB_ID_PRODUCT(id));\n\t\t\t\t\terr = -ENOENT;\n\t\t\t\t\tgoto __error;\n\t\t\t\t}\n\t\t\t}\n\t\tif (!chip) {\n\t\t\tdev_err(&dev->dev, \"no available usb audio device\\n\");\n\t\t\terr = -ENODEV;\n\t\t\tgoto __error;\n\t\t}\n\t}\n\tdev_set_drvdata(&dev->dev, chip);\n\n\t/*\n\t * For devices with more than one control interface, we assume the\n\t * first contains the audio controls. We might need a more specific\n\t * check here in the future.\n\t */\n\tif (!chip->ctrl_intf)\n\t\tchip->ctrl_intf = alts;\n\n\tchip->txfr_quirk = 0;\n\terr = 1; /* continue */\n\tif (quirk && quirk->ifnum != QUIRK_NO_INTERFACE) {\n\t\t/* need some special handlings */\n\t\terr = snd_usb_create_quirk(chip, intf, &usb_audio_driver, quirk);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\tif (err > 0) {\n\t\t/* create normal USB audio interfaces */\n\t\terr = snd_usb_create_streams(chip, ifnum);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t\terr = snd_usb_create_mixer(chip, ifnum, ignore_ctl_error);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\t/* we are allowed to call snd_card_register() many times */\n\terr = snd_card_register(chip->card);\n\tif (err < 0)\n\t\tgoto __error;\n\n\tusb_chip[chip->index] = chip;\n\tchip->num_interfaces++;\n\tusb_set_intfdata(intf, chip);\n\tatomic_dec(&chip->active);\n\tmutex_unlock(&register_mutex);\n\treturn 0;\n\n __error:\n\tif (chip) {\n\t\tif (!chip->num_interfaces)\n\t\t\tsnd_card_free(chip->card);\n\t\tatomic_dec(&chip->active);\n\t}\n\tmutex_unlock(&register_mutex);\n\treturn err;\n}", "func_src_after": "static int usb_audio_probe(struct usb_interface *intf,\n\t\t\t   const struct usb_device_id *usb_id)\n{\n\tstruct usb_device *dev = interface_to_usbdev(intf);\n\tconst struct snd_usb_audio_quirk *quirk =\n\t\t(const struct snd_usb_audio_quirk *)usb_id->driver_info;\n\tstruct snd_usb_audio *chip;\n\tint i, err;\n\tstruct usb_host_interface *alts;\n\tint ifnum;\n\tu32 id;\n\n\talts = &intf->altsetting[0];\n\tifnum = get_iface_desc(alts)->bInterfaceNumber;\n\tid = USB_ID(le16_to_cpu(dev->descriptor.idVendor),\n\t\t    le16_to_cpu(dev->descriptor.idProduct));\n\tif (get_alias_id(dev, &id))\n\t\tquirk = get_alias_quirk(dev, id);\n\tif (quirk && quirk->ifnum >= 0 && ifnum != quirk->ifnum)\n\t\treturn -ENXIO;\n\n\terr = snd_usb_apply_boot_quirk(dev, intf, quirk, id);\n\tif (err < 0)\n\t\treturn err;\n\n\t/*\n\t * found a config.  now register to ALSA\n\t */\n\n\t/* check whether it's already registered */\n\tchip = NULL;\n\tmutex_lock(&register_mutex);\n\tfor (i = 0; i < SNDRV_CARDS; i++) {\n\t\tif (usb_chip[i] && usb_chip[i]->dev == dev) {\n\t\t\tif (atomic_read(&usb_chip[i]->shutdown)) {\n\t\t\t\tdev_err(&dev->dev, \"USB device is in the shutdown state, cannot create a card instance\\n\");\n\t\t\t\terr = -EIO;\n\t\t\t\tgoto __error;\n\t\t\t}\n\t\t\tchip = usb_chip[i];\n\t\t\tatomic_inc(&chip->active); /* avoid autopm */\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (! chip) {\n\t\t/* it's a fresh one.\n\t\t * now look for an empty slot and create a new card instance\n\t\t */\n\t\tfor (i = 0; i < SNDRV_CARDS; i++)\n\t\t\tif (!usb_chip[i] &&\n\t\t\t    (vid[i] == -1 || vid[i] == USB_ID_VENDOR(id)) &&\n\t\t\t    (pid[i] == -1 || pid[i] == USB_ID_PRODUCT(id))) {\n\t\t\t\tif (enable[i]) {\n\t\t\t\t\terr = snd_usb_audio_create(intf, dev, i, quirk,\n\t\t\t\t\t\t\t\t   id, &chip);\n\t\t\t\t\tif (err < 0)\n\t\t\t\t\t\tgoto __error;\n\t\t\t\t\tchip->pm_intf = intf;\n\t\t\t\t\tbreak;\n\t\t\t\t} else if (vid[i] != -1 || pid[i] != -1) {\n\t\t\t\t\tdev_info(&dev->dev,\n\t\t\t\t\t\t \"device (%04x:%04x) is disabled\\n\",\n\t\t\t\t\t\t USB_ID_VENDOR(id),\n\t\t\t\t\t\t USB_ID_PRODUCT(id));\n\t\t\t\t\terr = -ENOENT;\n\t\t\t\t\tgoto __error;\n\t\t\t\t}\n\t\t\t}\n\t\tif (!chip) {\n\t\t\tdev_err(&dev->dev, \"no available usb audio device\\n\");\n\t\t\terr = -ENODEV;\n\t\t\tgoto __error;\n\t\t}\n\t}\n\tdev_set_drvdata(&dev->dev, chip);\n\n\t/*\n\t * For devices with more than one control interface, we assume the\n\t * first contains the audio controls. We might need a more specific\n\t * check here in the future.\n\t */\n\tif (!chip->ctrl_intf)\n\t\tchip->ctrl_intf = alts;\n\n\tchip->txfr_quirk = 0;\n\terr = 1; /* continue */\n\tif (quirk && quirk->ifnum != QUIRK_NO_INTERFACE) {\n\t\t/* need some special handlings */\n\t\terr = snd_usb_create_quirk(chip, intf, &usb_audio_driver, quirk);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\tif (err > 0) {\n\t\t/* create normal USB audio interfaces */\n\t\terr = snd_usb_create_streams(chip, ifnum);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t\terr = snd_usb_create_mixer(chip, ifnum, ignore_ctl_error);\n\t\tif (err < 0)\n\t\t\tgoto __error;\n\t}\n\n\t/* we are allowed to call snd_card_register() many times */\n\terr = snd_card_register(chip->card);\n\tif (err < 0)\n\t\tgoto __error;\n\n\tusb_chip[chip->index] = chip;\n\tchip->num_interfaces++;\n\tusb_set_intfdata(intf, chip);\n\tatomic_dec(&chip->active);\n\tmutex_unlock(&register_mutex);\n\treturn 0;\n\n __error:\n\tif (chip) {\n\t\t/* chip->active is inside the chip->card object,\n\t\t * decrement before memory is possibly returned.\n\t\t */\n\t\tatomic_dec(&chip->active);\n\t\tif (!chip->num_interfaces)\n\t\t\tsnd_card_free(chip->card);\n\t}\n\tmutex_unlock(&register_mutex);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/5f8cf712582617d523120df67d392059eaf2fc4b", "file_name": "sound/usb/card.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_audio_probe` for probing USB audio devices and registering them with the ALSA sound system."}
{"func_name": "snd_pcm_period_elapsed", "func_src_before": "void snd_pcm_period_elapsed(struct snd_pcm_substream *substream)\n{\n\tstruct snd_pcm_runtime *runtime;\n\tunsigned long flags;\n\n\tif (PCM_RUNTIME_CHECK(substream))\n\t\treturn;\n\truntime = substream->runtime;\n\n\tsnd_pcm_stream_lock_irqsave(substream, flags);\n\tif (!snd_pcm_running(substream) ||\n\t    snd_pcm_update_hw_ptr0(substream, 1) < 0)\n\t\tgoto _end;\n\n#ifdef CONFIG_SND_PCM_TIMER\n\tif (substream->timer_running)\n\t\tsnd_timer_interrupt(substream->timer, 1);\n#endif\n _end:\n\tkill_fasync(&runtime->fasync, SIGIO, POLL_IN);\n\tsnd_pcm_stream_unlock_irqrestore(substream, flags);\n}", "func_src_after": "void snd_pcm_period_elapsed(struct snd_pcm_substream *substream)\n{\n\tstruct snd_pcm_runtime *runtime;\n\tunsigned long flags;\n\n\tif (PCM_RUNTIME_CHECK(substream))\n\t\treturn;\n\truntime = substream->runtime;\n\n\tsnd_pcm_stream_lock_irqsave(substream, flags);\n\tif (!snd_pcm_running(substream) ||\n\t    snd_pcm_update_hw_ptr0(substream, 1) < 0)\n\t\tgoto _end;\n\n#ifdef CONFIG_SND_PCM_TIMER\n\tif (substream->timer_running)\n\t\tsnd_timer_interrupt(substream->timer, 1);\n#endif\n _end:\n\tsnd_pcm_stream_unlock_irqrestore(substream, flags);\n\tkill_fasync(&runtime->fasync, SIGIO, POLL_IN);\n}", "commit_link": "github.com/torvalds/linux/commit/3aa02cb664c5fb1042958c8d1aa8c35055a2ebc4", "file_name": "sound/core/pcm_lib.c", "vul_type": "cwe-416", "description": "Write a C function named `snd_pcm_period_elapsed` that handles the end-of-period interrupt for a PCM audio substream."}
{"func_name": "ap_limit_section", "func_src_before": "AP_CORE_DECLARE_NONSTD(const char *) ap_limit_section(cmd_parms *cmd,\n                                                      void *dummy,\n                                                      const char *arg)\n{\n    const char *endp = ap_strrchr_c(arg, '>');\n    const char *limited_methods;\n    void *tog = cmd->cmd->cmd_data;\n    apr_int64_t limited = 0;\n    apr_int64_t old_limited = cmd->limited;\n    const char *errmsg;\n\n    if (endp == NULL) {\n        return unclosed_directive(cmd);\n    }\n\n    limited_methods = apr_pstrmemdup(cmd->temp_pool, arg, endp - arg);\n\n    if (!limited_methods[0]) {\n        return missing_container_arg(cmd);\n    }\n\n    while (limited_methods[0]) {\n        char *method = ap_getword_conf(cmd->temp_pool, &limited_methods);\n        int methnum;\n\n        /* check for builtin or module registered method number */\n        methnum = ap_method_number_of(method);\n\n        if (methnum == M_TRACE && !tog) {\n            return \"TRACE cannot be controlled by <Limit>, see TraceEnable\";\n        }\n        else if (methnum == M_INVALID) {\n            /* method has not been registered yet, but resource restriction\n             * is always checked before method handling, so register it.\n             */\n            methnum = ap_method_register(cmd->pool,\n                                         apr_pstrdup(cmd->pool, method));\n        }\n\n        limited |= (AP_METHOD_BIT << methnum);\n    }\n\n    /* Killing two features with one function,\n     * if (tog == NULL) <Limit>, else <LimitExcept>\n     */\n    limited = tog ? ~limited : limited;\n\n    if (!(old_limited & limited)) {\n        return apr_pstrcat(cmd->pool, cmd->cmd->name,\n                           \"> directive excludes all methods\", NULL);\n    }\n    else if ((old_limited & limited) == old_limited) {\n        return apr_pstrcat(cmd->pool, cmd->cmd->name,\n                           \"> directive specifies methods already excluded\",\n                           NULL);\n    }\n\n    cmd->limited &= limited;\n\n    errmsg = ap_walk_config(cmd->directive->first_child, cmd, cmd->context);\n\n    cmd->limited = old_limited;\n\n    return errmsg;\n}", "func_src_after": "AP_CORE_DECLARE_NONSTD(const char *) ap_limit_section(cmd_parms *cmd,\n                                                      void *dummy,\n                                                      const char *arg)\n{\n    const char *endp = ap_strrchr_c(arg, '>');\n    const char *limited_methods;\n    void *tog = cmd->cmd->cmd_data;\n    apr_int64_t limited = 0;\n    apr_int64_t old_limited = cmd->limited;\n    const char *errmsg;\n\n    if (endp == NULL) {\n        return unclosed_directive(cmd);\n    }\n\n    limited_methods = apr_pstrmemdup(cmd->temp_pool, arg, endp - arg);\n\n    if (!limited_methods[0]) {\n        return missing_container_arg(cmd);\n    }\n\n    while (limited_methods[0]) {\n        char *method = ap_getword_conf(cmd->temp_pool, &limited_methods);\n        int methnum;\n\n        /* check for builtin or module registered method number */\n        methnum = ap_method_number_of(method);\n\n        if (methnum == M_TRACE && !tog) {\n            return \"TRACE cannot be controlled by <Limit>, see TraceEnable\";\n        }\n        else if (methnum == M_INVALID) {\n            /* method has not been registered yet, but resource restriction\n             * is always checked before method handling, so register it.\n             */\n            if (cmd->pool == cmd->temp_pool) {\n                /* In .htaccess, we can't globally register new methods. */\n                return apr_psprintf(cmd->pool, \"Could not register method '%s' \"\n                                   \"for %s from .htaccess configuration\",\n                                    method, cmd->cmd->name);\n            }\n            methnum = ap_method_register(cmd->pool,\n                                         apr_pstrdup(cmd->pool, method));\n        }\n\n        limited |= (AP_METHOD_BIT << methnum);\n    }\n\n    /* Killing two features with one function,\n     * if (tog == NULL) <Limit>, else <LimitExcept>\n     */\n    limited = tog ? ~limited : limited;\n\n    if (!(old_limited & limited)) {\n        return apr_pstrcat(cmd->pool, cmd->cmd->name,\n                           \"> directive excludes all methods\", NULL);\n    }\n    else if ((old_limited & limited) == old_limited) {\n        return apr_pstrcat(cmd->pool, cmd->cmd->name,\n                           \"> directive specifies methods already excluded\",\n                           NULL);\n    }\n\n    cmd->limited &= limited;\n\n    errmsg = ap_walk_config(cmd->directive->first_child, cmd, cmd->context);\n\n    cmd->limited = old_limited;\n\n    return errmsg;\n}", "commit_link": "github.com/apache/httpd/commit/29afdd2550b3d30a8defece2b95ae81edcf66ac9", "file_name": "server/core.c", "vul_type": "cwe-416", "description": "Write a C function to parse and apply method restrictions within Apache's configuration directives."}
{"func_name": "rds_rdma_extra_size", "func_src_before": "int rds_rdma_extra_size(struct rds_rdma_args *args)\n{\n\tstruct rds_iovec vec;\n\tstruct rds_iovec __user *local_vec;\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n\n\t/* figure out the number of pages in the vector */\n\tfor (i = 0; i < args->nr_local; i++) {\n\t\tif (copy_from_user(&vec, &local_vec[i],\n\t\t\t\t   sizeof(struct rds_iovec)))\n\t\t\treturn -EFAULT;\n\n\t\tnr_pages = rds_pages_in_vec(&vec);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t/*\n\t\t * nr_pages for one entry is limited to (UINT_MAX>>PAGE_SHIFT)+1,\n\t\t * so tot_pages cannot overflow without first going negative.\n\t\t */\n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages * sizeof(struct scatterlist);\n}", "func_src_after": "int rds_rdma_extra_size(struct rds_rdma_args *args)\n{\n\tstruct rds_iovec vec;\n\tstruct rds_iovec __user *local_vec;\n\tint tot_pages = 0;\n\tunsigned int nr_pages;\n\tunsigned int i;\n\n\tlocal_vec = (struct rds_iovec __user *)(unsigned long) args->local_vec_addr;\n\n\tif (args->nr_local == 0)\n\t\treturn -EINVAL;\n\n\t/* figure out the number of pages in the vector */\n\tfor (i = 0; i < args->nr_local; i++) {\n\t\tif (copy_from_user(&vec, &local_vec[i],\n\t\t\t\t   sizeof(struct rds_iovec)))\n\t\t\treturn -EFAULT;\n\n\t\tnr_pages = rds_pages_in_vec(&vec);\n\t\tif (nr_pages == 0)\n\t\t\treturn -EINVAL;\n\n\t\ttot_pages += nr_pages;\n\n\t\t/*\n\t\t * nr_pages for one entry is limited to (UINT_MAX>>PAGE_SHIFT)+1,\n\t\t * so tot_pages cannot overflow without first going negative.\n\t\t */\n\t\tif (tot_pages < 0)\n\t\t\treturn -EINVAL;\n\t}\n\n\treturn tot_pages * sizeof(struct scatterlist);\n}", "commit_link": "github.com/torvalds/linux/commit/c095508770aebf1b9218e77026e48345d719b17c", "file_name": "net/rds/rdma.c", "vul_type": "cwe-787", "description": "Write a C function named `rds_rdma_extra_size` that calculates the total size of memory pages described by an array of `rds_iovec` structures, handling user-space memory copying and validation."}
{"func_name": "avcodec_align_dimensions2", "func_src_before": "void avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height,\n                               int linesize_align[AV_NUM_DATA_POINTERS])\n{\n    int i;\n    int w_align = 1;\n    int h_align = 1;\n    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(s->pix_fmt);\n\n    if (desc) {\n        w_align = 1 << desc->log2_chroma_w;\n        h_align = 1 << desc->log2_chroma_h;\n    }\n\n    switch (s->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUYV422:\n    case AV_PIX_FMT_YVYU422:\n    case AV_PIX_FMT_UYVY422:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV440P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_GBRP:\n    case AV_PIX_FMT_GBRAP:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_GRAY16BE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_YUVJ420P:\n    case AV_PIX_FMT_YUVJ422P:\n    case AV_PIX_FMT_YUVJ440P:\n    case AV_PIX_FMT_YUVJ444P:\n    case AV_PIX_FMT_YUVA420P:\n    case AV_PIX_FMT_YUVA422P:\n    case AV_PIX_FMT_YUVA444P:\n    case AV_PIX_FMT_YUV420P9LE:\n    case AV_PIX_FMT_YUV420P9BE:\n    case AV_PIX_FMT_YUV420P10LE:\n    case AV_PIX_FMT_YUV420P10BE:\n    case AV_PIX_FMT_YUV420P12LE:\n    case AV_PIX_FMT_YUV420P12BE:\n    case AV_PIX_FMT_YUV420P14LE:\n    case AV_PIX_FMT_YUV420P14BE:\n    case AV_PIX_FMT_YUV420P16LE:\n    case AV_PIX_FMT_YUV420P16BE:\n    case AV_PIX_FMT_YUVA420P9LE:\n    case AV_PIX_FMT_YUVA420P9BE:\n    case AV_PIX_FMT_YUVA420P10LE:\n    case AV_PIX_FMT_YUVA420P10BE:\n    case AV_PIX_FMT_YUVA420P16LE:\n    case AV_PIX_FMT_YUVA420P16BE:\n    case AV_PIX_FMT_YUV422P9LE:\n    case AV_PIX_FMT_YUV422P9BE:\n    case AV_PIX_FMT_YUV422P10LE:\n    case AV_PIX_FMT_YUV422P10BE:\n    case AV_PIX_FMT_YUV422P12LE:\n    case AV_PIX_FMT_YUV422P12BE:\n    case AV_PIX_FMT_YUV422P14LE:\n    case AV_PIX_FMT_YUV422P14BE:\n    case AV_PIX_FMT_YUV422P16LE:\n    case AV_PIX_FMT_YUV422P16BE:\n    case AV_PIX_FMT_YUVA422P9LE:\n    case AV_PIX_FMT_YUVA422P9BE:\n    case AV_PIX_FMT_YUVA422P10LE:\n    case AV_PIX_FMT_YUVA422P10BE:\n    case AV_PIX_FMT_YUVA422P16LE:\n    case AV_PIX_FMT_YUVA422P16BE:\n    case AV_PIX_FMT_YUV440P10LE:\n    case AV_PIX_FMT_YUV440P10BE:\n    case AV_PIX_FMT_YUV440P12LE:\n    case AV_PIX_FMT_YUV440P12BE:\n    case AV_PIX_FMT_YUV444P9LE:\n    case AV_PIX_FMT_YUV444P9BE:\n    case AV_PIX_FMT_YUV444P10LE:\n    case AV_PIX_FMT_YUV444P10BE:\n    case AV_PIX_FMT_YUV444P12LE:\n    case AV_PIX_FMT_YUV444P12BE:\n    case AV_PIX_FMT_YUV444P14LE:\n    case AV_PIX_FMT_YUV444P14BE:\n    case AV_PIX_FMT_YUV444P16LE:\n    case AV_PIX_FMT_YUV444P16BE:\n    case AV_PIX_FMT_YUVA444P9LE:\n    case AV_PIX_FMT_YUVA444P9BE:\n    case AV_PIX_FMT_YUVA444P10LE:\n    case AV_PIX_FMT_YUVA444P10BE:\n    case AV_PIX_FMT_YUVA444P16LE:\n    case AV_PIX_FMT_YUVA444P16BE:\n    case AV_PIX_FMT_GBRP9LE:\n    case AV_PIX_FMT_GBRP9BE:\n    case AV_PIX_FMT_GBRP10LE:\n    case AV_PIX_FMT_GBRP10BE:\n    case AV_PIX_FMT_GBRP12LE:\n    case AV_PIX_FMT_GBRP12BE:\n    case AV_PIX_FMT_GBRP14LE:\n    case AV_PIX_FMT_GBRP14BE:\n    case AV_PIX_FMT_GBRP16LE:\n    case AV_PIX_FMT_GBRP16BE:\n    case AV_PIX_FMT_GBRAP12LE:\n    case AV_PIX_FMT_GBRAP12BE:\n    case AV_PIX_FMT_GBRAP16LE:\n    case AV_PIX_FMT_GBRAP16BE:\n        w_align = 16; //FIXME assume 16 pixel per macroblock\n        h_align = 16 * 2; // interlaced needs 2 macroblocks height\n        break;\n    case AV_PIX_FMT_YUV411P:\n    case AV_PIX_FMT_YUVJ411P:\n    case AV_PIX_FMT_UYYVYY411:\n        w_align = 32;\n        h_align = 16 * 2;\n        break;\n    case AV_PIX_FMT_YUV410P:\n        if (s->codec_id == AV_CODEC_ID_SVQ1) {\n            w_align = 64;\n            h_align = 64;\n        }\n        break;\n    case AV_PIX_FMT_RGB555:\n        if (s->codec_id == AV_CODEC_ID_RPZA) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_PAL8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB8:\n        if (s->codec_id == AV_CODEC_ID_SMC ||\n            s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_JV) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_BGR24:\n        if ((s->codec_id == AV_CODEC_ID_MSZH) ||\n            (s->codec_id == AV_CODEC_ID_ZLIB)) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_RGB24:\n        if (s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    default:\n        break;\n    }\n\n    if (s->codec_id == AV_CODEC_ID_IFF_ILBM) {\n        w_align = FFMAX(w_align, 8);\n    }\n\n    *width  = FFALIGN(*width, w_align);\n    *height = FFALIGN(*height, h_align);\n    if (s->codec_id == AV_CODEC_ID_H264 || s->lowres) {\n        // some of the optimized chroma MC reads one line too much\n        // which is also done in mpeg decoders with lowres > 0\n        *height += 2;\n\n        // H.264 uses edge emulation for out of frame motion vectors, for this\n        // it requires a temporary area large enough to hold a 21x21 block,\n        // increasing witdth ensure that the temporary area is large enough,\n        // the next rounded up width is 32\n        *width = FFMAX(*width, 32);\n    }\n\n    for (i = 0; i < 4; i++)\n        linesize_align[i] = STRIDE_ALIGN;\n}", "func_src_after": "void avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height,\n                               int linesize_align[AV_NUM_DATA_POINTERS])\n{\n    int i;\n    int w_align = 1;\n    int h_align = 1;\n    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(s->pix_fmt);\n\n    if (desc) {\n        w_align = 1 << desc->log2_chroma_w;\n        h_align = 1 << desc->log2_chroma_h;\n    }\n\n    switch (s->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUYV422:\n    case AV_PIX_FMT_YVYU422:\n    case AV_PIX_FMT_UYVY422:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV440P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_GBRP:\n    case AV_PIX_FMT_GBRAP:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_GRAY16BE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_YUVJ420P:\n    case AV_PIX_FMT_YUVJ422P:\n    case AV_PIX_FMT_YUVJ440P:\n    case AV_PIX_FMT_YUVJ444P:\n    case AV_PIX_FMT_YUVA420P:\n    case AV_PIX_FMT_YUVA422P:\n    case AV_PIX_FMT_YUVA444P:\n    case AV_PIX_FMT_YUV420P9LE:\n    case AV_PIX_FMT_YUV420P9BE:\n    case AV_PIX_FMT_YUV420P10LE:\n    case AV_PIX_FMT_YUV420P10BE:\n    case AV_PIX_FMT_YUV420P12LE:\n    case AV_PIX_FMT_YUV420P12BE:\n    case AV_PIX_FMT_YUV420P14LE:\n    case AV_PIX_FMT_YUV420P14BE:\n    case AV_PIX_FMT_YUV420P16LE:\n    case AV_PIX_FMT_YUV420P16BE:\n    case AV_PIX_FMT_YUVA420P9LE:\n    case AV_PIX_FMT_YUVA420P9BE:\n    case AV_PIX_FMT_YUVA420P10LE:\n    case AV_PIX_FMT_YUVA420P10BE:\n    case AV_PIX_FMT_YUVA420P16LE:\n    case AV_PIX_FMT_YUVA420P16BE:\n    case AV_PIX_FMT_YUV422P9LE:\n    case AV_PIX_FMT_YUV422P9BE:\n    case AV_PIX_FMT_YUV422P10LE:\n    case AV_PIX_FMT_YUV422P10BE:\n    case AV_PIX_FMT_YUV422P12LE:\n    case AV_PIX_FMT_YUV422P12BE:\n    case AV_PIX_FMT_YUV422P14LE:\n    case AV_PIX_FMT_YUV422P14BE:\n    case AV_PIX_FMT_YUV422P16LE:\n    case AV_PIX_FMT_YUV422P16BE:\n    case AV_PIX_FMT_YUVA422P9LE:\n    case AV_PIX_FMT_YUVA422P9BE:\n    case AV_PIX_FMT_YUVA422P10LE:\n    case AV_PIX_FMT_YUVA422P10BE:\n    case AV_PIX_FMT_YUVA422P16LE:\n    case AV_PIX_FMT_YUVA422P16BE:\n    case AV_PIX_FMT_YUV440P10LE:\n    case AV_PIX_FMT_YUV440P10BE:\n    case AV_PIX_FMT_YUV440P12LE:\n    case AV_PIX_FMT_YUV440P12BE:\n    case AV_PIX_FMT_YUV444P9LE:\n    case AV_PIX_FMT_YUV444P9BE:\n    case AV_PIX_FMT_YUV444P10LE:\n    case AV_PIX_FMT_YUV444P10BE:\n    case AV_PIX_FMT_YUV444P12LE:\n    case AV_PIX_FMT_YUV444P12BE:\n    case AV_PIX_FMT_YUV444P14LE:\n    case AV_PIX_FMT_YUV444P14BE:\n    case AV_PIX_FMT_YUV444P16LE:\n    case AV_PIX_FMT_YUV444P16BE:\n    case AV_PIX_FMT_YUVA444P9LE:\n    case AV_PIX_FMT_YUVA444P9BE:\n    case AV_PIX_FMT_YUVA444P10LE:\n    case AV_PIX_FMT_YUVA444P10BE:\n    case AV_PIX_FMT_YUVA444P16LE:\n    case AV_PIX_FMT_YUVA444P16BE:\n    case AV_PIX_FMT_GBRP9LE:\n    case AV_PIX_FMT_GBRP9BE:\n    case AV_PIX_FMT_GBRP10LE:\n    case AV_PIX_FMT_GBRP10BE:\n    case AV_PIX_FMT_GBRP12LE:\n    case AV_PIX_FMT_GBRP12BE:\n    case AV_PIX_FMT_GBRP14LE:\n    case AV_PIX_FMT_GBRP14BE:\n    case AV_PIX_FMT_GBRP16LE:\n    case AV_PIX_FMT_GBRP16BE:\n    case AV_PIX_FMT_GBRAP12LE:\n    case AV_PIX_FMT_GBRAP12BE:\n    case AV_PIX_FMT_GBRAP16LE:\n    case AV_PIX_FMT_GBRAP16BE:\n        w_align = 16; //FIXME assume 16 pixel per macroblock\n        h_align = 16 * 2; // interlaced needs 2 macroblocks height\n        break;\n    case AV_PIX_FMT_YUV411P:\n    case AV_PIX_FMT_YUVJ411P:\n    case AV_PIX_FMT_UYYVYY411:\n        w_align = 32;\n        h_align = 16 * 2;\n        break;\n    case AV_PIX_FMT_YUV410P:\n        if (s->codec_id == AV_CODEC_ID_SVQ1) {\n            w_align = 64;\n            h_align = 64;\n        }\n        break;\n    case AV_PIX_FMT_RGB555:\n        if (s->codec_id == AV_CODEC_ID_RPZA) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_PAL8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB8:\n        if (s->codec_id == AV_CODEC_ID_SMC ||\n            s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_JV ||\n            s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_BGR24:\n        if ((s->codec_id == AV_CODEC_ID_MSZH) ||\n            (s->codec_id == AV_CODEC_ID_ZLIB)) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_RGB24:\n        if (s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    default:\n        break;\n    }\n\n    if (s->codec_id == AV_CODEC_ID_IFF_ILBM) {\n        w_align = FFMAX(w_align, 8);\n    }\n\n    *width  = FFALIGN(*width, w_align);\n    *height = FFALIGN(*height, h_align);\n    if (s->codec_id == AV_CODEC_ID_H264 || s->lowres) {\n        // some of the optimized chroma MC reads one line too much\n        // which is also done in mpeg decoders with lowres > 0\n        *height += 2;\n\n        // H.264 uses edge emulation for out of frame motion vectors, for this\n        // it requires a temporary area large enough to hold a 21x21 block,\n        // increasing witdth ensure that the temporary area is large enough,\n        // the next rounded up width is 32\n        *width = FFMAX(*width, 32);\n    }\n\n    for (i = 0; i < 4; i++)\n        linesize_align[i] = STRIDE_ALIGN;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/2080bc33717955a0e4268e738acf8c1eeddbf8cb", "file_name": "libavcodec/utils.c", "vul_type": "cwe-787", "description": "Write a C function named `avcodec_align_dimensions2` that adjusts the width and height of a video frame based on the codec context and pixel format."}
{"func_name": "getFileCacheID", "func_src_before": "\tdef getFileCacheID(self, pth):\n\t\t\"\"\"\n\t\tReturns ID of a cached file on Telegram from DB. None if file doesn't exist or has no cached ID.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"SELECT file_id FROM {0} WHERE path=?;\".format(TABLE_NAME)\n\t\tparams = (pth,)\n\t\tdata = self._run_command(command, params)\n\n\t\ttry:\n\t\t\tdata = data[0][0]\n\t\texcept IndexError:\n\t\t\tdata = None\n\n\t\treturn data", "func_src_after": "\tdef getFileCacheID(self, pth):\n\t\t\"\"\"\n\t\tReturns ID of a cached file on Telegram from DB. None if file doesn't exist or has no cached ID.\n\t\t:param pth:\n\t\t:return:\n\t\t\"\"\"\n\t\tcommand = \"SELECT file_id FROM {0} WHERE path='{1}'\".format(TABLE_NAME, pth)\n\t\tdata = self._run_command(command)\n\n\t\ttry:\n\t\t\tdata = data[0][0]\n\t\texcept IndexError:\n\t\t\tdata = None\n\n\t\treturn data", "commit_link": "github.com/Highstaker/Picture-sender-telegram-bot/commit/db4bc6adb41e086418761426ff4958a81c30adca", "file_name": "file_db.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve a file's cache ID from a database using a file path, returning None if not found."}
{"func_name": "HPHP::StringUtil::Implode", "func_src_before": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  int len = 0;\n  int lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "func_src_after": "String StringUtil::Implode(const Variant& items, const String& delim,\n                           const bool checkIsContainer /* = true */) {\n  if (checkIsContainer && !isContainer(items)) {\n    throw_param_is_not_container();\n  }\n  int size = getContainerSize(items);\n  if (size == 0) return empty_string();\n\n  req::vector<String> sitems;\n  sitems.reserve(size);\n  size_t len = 0;\n  size_t lenDelim = delim.size();\n  for (ArrayIter iter(items); iter; ++iter) {\n    sitems.emplace_back(iter.second().toString());\n    len += sitems.back().size() + lenDelim;\n  }\n  len -= lenDelim; // always one delimiter less than count of items\n  assert(sitems.size() == size);\n\n  String s = String(len, ReserveString);\n  char *buffer = s.mutableData();\n  const char *sdelim = delim.data();\n  char *p = buffer;\n  String &init_str = sitems[0];\n  int init_len = init_str.size();\n  memcpy(p, init_str.data(), init_len);\n  p += init_len;\n  for (int i = 1; i < size; i++) {\n    String &item = sitems[i];\n    memcpy(p, sdelim, lenDelim);\n    p += lenDelim;\n    int lenItem = item.size();\n    memcpy(p, item.data(), lenItem);\n    p += lenItem;\n  }\n  assert(p - buffer == len);\n  s.setSize(len);\n  return s;\n}", "commit_link": "github.com/facebook/hhvm/commit/2c9a8fcc73a151608634d3e712973d192027c271", "file_name": "hphp/runtime/base/string-util.cpp", "vul_type": "cwe-190", "description": "Write a C++ function that concatenates elements of a container into a string with a specified delimiter, throwing an exception if the input is not a container."}
{"func_name": "add", "func_src_before": "@mod.route('/add', methods=['GET', 'POST'])\ndef add():\n    if request.method == 'POST':\n        msg_id = int(request.form['msg_id'])\n        user_id = session['logged_id']\n        content = request.form['content']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        cursor.execute(\"INSERT INTO comment(msg_id,user_id,content,c_time) VALUES(%s,%s,%s,%s);\", (msg_id, user_id, content, c_time))\n        conn.commit()\n    return redirect(url_for('comment.show', msg_id=msg_id))", "func_src_after": "@mod.route('/add', methods=['GET', 'POST'])\ndef add():\n    if request.method == 'POST':\n        msg_id = int(request.form['msg_id'])\n        user_id = session['logged_id']\n        content = request.form['content']\n        c_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n        sql = \"INSERT INTO comment(msg_id,user_id,content,c_time) \" + \\\n                \"VALUES(%d,%d,'%s','%s');\" % (msg_id, user_id, content, c_time)\n        cursor.execute(sql)\n        conn.commit()\n    return redirect(url_for('comment.show', msg_id=msg_id))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to handle adding comments to a database, using both GET and POST methods."}
{"func_name": "formUpdateBuffer", "func_src_before": "formUpdateBuffer(Anchor *a, Buffer *buf, FormItemList *form)\n{\n    Buffer save;\n    char *p;\n    int spos, epos, rows, c_rows, pos, col = 0;\n    Line *l;\n\n    copyBuffer(&save, buf);\n    gotoLine(buf, a->start.line);\n    switch (form->type) {\n    case FORM_TEXTAREA:\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n#endif\t\t\t\t/* MENU_SELECT */\n\tspos = a->start.pos;\n\tepos = a->end.pos;\n\tbreak;\n    default:\n\tspos = a->start.pos + 1;\n\tepos = a->end.pos - 1;\n    }\n    switch (form->type) {\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n\tif (buf->currentLine == NULL ||\n\t    spos >= buf->currentLine->len || spos < 0)\n\t    break;\n\tif (form->checked)\n\t    buf->currentLine->lineBuf[spos] = '*';\n\telse\n\t    buf->currentLine->lineBuf[spos] = ' ';\n\tbreak;\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_TEXTAREA:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n\tif (form->type == FORM_SELECT) {\n\t    p = form->label->ptr;\n\t    updateSelectOption(form, form->select_option);\n\t}\n\telse\n#endif\t\t\t\t/* MENU_SELECT */\n\t{\n\t    if (!form->value)\n\t\tbreak;\n\t    p = form->value->ptr;\n\t}\n\tl = buf->currentLine;\n\tif (!l)\n\t    break;\n\tif (form->type == FORM_TEXTAREA) {\n\t    int n = a->y - buf->currentLine->linenumber;\n\t    if (n > 0)\n\t\tfor (; l && n; l = l->prev, n--) ;\n\t    else if (n < 0)\n\t\tfor (; l && n; l = l->prev, n++) ;\n\t    if (!l)\n\t\tbreak;\n\t}\n\trows = form->rows ? form->rows : 1;\n\tcol = COLPOS(l, a->start.pos);\n\tfor (c_rows = 0; c_rows < rows; c_rows++, l = l->next) {\n\t    if (rows > 1) {\n\t\tpos = columnPos(l, col);\n\t\ta = retrieveAnchor(buf->formitem, l->linenumber, pos);\n\t\tif (a == NULL)\n\t\t    break;\n\t\tspos = a->start.pos;\n\t\tepos = a->end.pos;\n\t    }\n\t    if (a->start.line != a->end.line || spos > epos || epos >= l->len ||\n\t\tspos < 0 || epos < 0 || COLPOS(l, epos) < col)\n\t\tbreak;\n\t    pos = form_update_line(l, &p, spos, epos, COLPOS(l, epos) - col,\n\t\t\t\t   rows > 1,\n\t\t\t\t   form->type == FORM_INPUT_PASSWORD);\n\t    if (pos != epos) {\n\t\tshiftAnchorPosition(buf->href, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->name, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->img, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->formitem, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t    }\n\t}\n\tbreak;\n    }\n    copyBuffer(buf, &save);\n    arrangeLine(buf);\n}", "func_src_after": "formUpdateBuffer(Anchor *a, Buffer *buf, FormItemList *form)\n{\n    Buffer save;\n    char *p;\n    int spos, epos, rows, c_rows, pos, col = 0;\n    Line *l;\n\n    copyBuffer(&save, buf);\n    gotoLine(buf, a->start.line);\n    switch (form->type) {\n    case FORM_TEXTAREA:\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n#endif\t\t\t\t/* MENU_SELECT */\n\tspos = a->start.pos;\n\tepos = a->end.pos;\n\tbreak;\n    default:\n\tspos = a->start.pos + 1;\n\tepos = a->end.pos - 1;\n    }\n    switch (form->type) {\n    case FORM_INPUT_CHECKBOX:\n    case FORM_INPUT_RADIO:\n\tif (buf->currentLine == NULL ||\n\t    spos >= buf->currentLine->len || spos < 0)\n\t    break;\n\tif (form->checked)\n\t    buf->currentLine->lineBuf[spos] = '*';\n\telse\n\t    buf->currentLine->lineBuf[spos] = ' ';\n\tbreak;\n    case FORM_INPUT_TEXT:\n    case FORM_INPUT_FILE:\n    case FORM_INPUT_PASSWORD:\n    case FORM_TEXTAREA:\n#ifdef MENU_SELECT\n    case FORM_SELECT:\n\tif (form->type == FORM_SELECT) {\n\t    p = form->label->ptr;\n\t    updateSelectOption(form, form->select_option);\n\t}\n\telse\n#endif\t\t\t\t/* MENU_SELECT */\n\t{\n\t    if (!form->value)\n\t\tbreak;\n\t    p = form->value->ptr;\n\t}\n\tl = buf->currentLine;\n\tif (!l)\n\t    break;\n\tif (form->type == FORM_TEXTAREA) {\n\t    int n = a->y - buf->currentLine->linenumber;\n\t    if (n > 0)\n\t\tfor (; l && n; l = l->prev, n--) ;\n\t    else if (n < 0)\n\t\tfor (; l && n; l = l->prev, n++) ;\n\t    if (!l)\n\t\tbreak;\n\t}\n\trows = form->rows ? form->rows : 1;\n\tcol = COLPOS(l, a->start.pos);\n\tfor (c_rows = 0; c_rows < rows; c_rows++, l = l->next) {\n\t    if (l == NULL)\n\t\tbreak;\n\t    if (rows > 1) {\n\t\tpos = columnPos(l, col);\n\t\ta = retrieveAnchor(buf->formitem, l->linenumber, pos);\n\t\tif (a == NULL)\n\t\t    break;\n\t\tspos = a->start.pos;\n\t\tepos = a->end.pos;\n\t    }\n\t    if (a->start.line != a->end.line || spos > epos || epos >= l->len ||\n\t\tspos < 0 || epos < 0 || COLPOS(l, epos) < col)\n\t\tbreak;\n\t    pos = form_update_line(l, &p, spos, epos, COLPOS(l, epos) - col,\n\t\t\t\t   rows > 1,\n\t\t\t\t   form->type == FORM_INPUT_PASSWORD);\n\t    if (pos != epos) {\n\t\tshiftAnchorPosition(buf->href, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->name, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->img, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t\tshiftAnchorPosition(buf->formitem, buf->hmarklist,\n\t\t\t\t    a->start.line, spos, pos - epos);\n\t    }\n\t}\n\tbreak;\n    }\n    copyBuffer(buf, &save);\n    arrangeLine(buf);\n}", "commit_link": "github.com/tats/w3m/commit/7fdc83b0364005a0b5ed869230dd81752ba022e8", "file_name": "form.c", "vul_type": "cwe-476", "description": "In C, write a function `formUpdateBuffer` to update the contents of a buffer with form input data based on the position of an anchor."}
{"func_name": "set_interface_var", "func_src_before": "set_interface_var(const char *iface,\n\t\t  const char *var, const char *name,\n\t\t  uint32_t val)\n{\n\tFILE *fp;\n\tchar spath[64+IFNAMSIZ];\t/* XXX: magic constant */\n\tif (snprintf(spath, sizeof(spath), var, iface) >= sizeof(spath))\n\t\treturn -1;\n\n\tif (access(spath, F_OK) != 0)\n\t\treturn -1;\n\n\tfp = fopen(spath, \"w\");\n\tif (!fp) {\n\t\tif (name)\n\t\t\tflog(LOG_ERR, \"failed to set %s (%u) for %s: %s\",\n\t\t\t     name, val, iface, strerror(errno));\n\t\treturn -1;\n\t}\n\tfprintf(fp, \"%u\", val);\n\tfclose(fp);\n\n\treturn 0;\n}", "func_src_after": "set_interface_var(const char *iface,\n\t\t  const char *var, const char *name,\n\t\t  uint32_t val)\n{\n\tFILE *fp;\n\tchar spath[64+IFNAMSIZ];\t/* XXX: magic constant */\n\tif (snprintf(spath, sizeof(spath), var, iface) >= sizeof(spath))\n\t\treturn -1;\n\n\t/* No path traversal */\n\tif (strstr(name, \"..\") || strchr(name, '/'))\n\t\treturn -1;\n\n\tif (access(spath, F_OK) != 0)\n\t\treturn -1;\n\n\tfp = fopen(spath, \"w\");\n\tif (!fp) {\n\t\tif (name)\n\t\t\tflog(LOG_ERR, \"failed to set %s (%u) for %s: %s\",\n\t\t\t     name, val, iface, strerror(errno));\n\t\treturn -1;\n\t}\n\tfprintf(fp, \"%u\", val);\n\tfclose(fp);\n\n\treturn 0;\n}", "commit_link": "github.com/reubenhwk/radvd/commit/92e22ca23e52066da2258df8c76a2dca8a428bcc", "file_name": "device-linux.c", "vul_type": "cwe-022", "description": "Write a C function to update a network interface variable in a file, handling file paths and potential errors."}
{"func_name": "getQueue", "func_src_before": "    def getQueue(self, numberOfLinks=10):\n        self.cursor.execute(\"SELECT url FROM queue WHERE visited = '0' LIMIT ?;\", numberOfLinks)\n        result = self.cursor.fetchall()\n        self.remove(result)\n        return result", "func_src_after": "    def getQueue(self, numberOfLinks=10):\n        self.cursor.execute(\"SELECT url FROM queue WHERE visited = '0' LIMIT {};\".format(numberOfLinks))\n        result = self.cursor.fetchall()\n        self.remove(result)\n        return result", "commit_link": "github.com/jappe999/WebScraper/commit/46a4e0843aa44d903293637afad53dfcbc37b480", "file_name": "beta/database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getQueue` that retrieves a specified number of unvisited URLs from a queue in a database and removes them from the queue after retrieval."}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = '{email}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, email):\n        \"\"\" Deletes admin with the corresponding email \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from admins where email = %s\"\"\", (email, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/admins.py", "vul_type": "cwe-089", "description": "Write a Python function with JWT authentication that deletes an admin by email from a database using SQL query execution."}
{"func_name": "delete_event", "func_src_before": "    def delete_event(self, event_id):\n        sql = \"\"\"\n              DELETE FROM events\n              WHERE event_id = %s\n              \"\"\"\n        affected_count = self.cur.execute(sql, (event_id,))\n        self.conn.commit()\n        return affected_count", "func_src_after": "    def delete_event(self, event_id):\n        sql = \"\"\"DELETE FROM events\n                 WHERE event_id = {0}\n                 \"\"\".format(event_id)\n        affected_count = self.cur.execute(sql)\n        self.conn.commit()\n        return affected_count", "commit_link": "github.com/jgayfer/spirit/commit/01c846c534c8d3cf6763f8b7444a0efe2caa3799", "file_name": "db/dbase.py", "vul_type": "cwe-089", "description": "Write a Python function to delete an event by its ID from a database and return the number of affected rows."}
{"func_name": "perf_cpu_time_max_percent_handler", "func_src_before": "int perf_cpu_time_max_percent_handler(struct ctl_table *table, int write,\n\t\t\t\tvoid __user *buffer, size_t *lenp,\n\t\t\t\tloff_t *ppos)\n{\n\tint ret = proc_dointvec(table, write, buffer, lenp, ppos);\n\n\tif (ret || !write)\n\t\treturn ret;\n\n\tif (sysctl_perf_cpu_time_max_percent == 100 ||\n\t    sysctl_perf_cpu_time_max_percent == 0) {\n\t\tprintk(KERN_WARNING\n\t\t       \"perf: Dynamic interrupt throttling disabled, can hang your system!\\n\");\n\t\tWRITE_ONCE(perf_sample_allowed_ns, 0);\n\t} else {\n\t\tupdate_perf_cpu_limits();\n\t}\n\n\treturn 0;\n}", "func_src_after": "int perf_cpu_time_max_percent_handler(struct ctl_table *table, int write,\n\t\t\t\tvoid __user *buffer, size_t *lenp,\n\t\t\t\tloff_t *ppos)\n{\n\tint ret = proc_dointvec_minmax(table, write, buffer, lenp, ppos);\n\n\tif (ret || !write)\n\t\treturn ret;\n\n\tif (sysctl_perf_cpu_time_max_percent == 100 ||\n\t    sysctl_perf_cpu_time_max_percent == 0) {\n\t\tprintk(KERN_WARNING\n\t\t       \"perf: Dynamic interrupt throttling disabled, can hang your system!\\n\");\n\t\tWRITE_ONCE(perf_sample_allowed_ns, 0);\n\t} else {\n\t\tupdate_perf_cpu_limits();\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/1572e45a924f254d9570093abde46430c3172e3d", "file_name": "kernel/events/core.c", "vul_type": "cwe-190", "description": "Write a C function to handle changes to a sysctl setting that controls CPU time percentage for performance monitoring, warning if set to 0 or 100%."}
{"func_name": "mode_keepalive", "func_src_before": "    def mode_keepalive(self, request):\n        \"\"\"\n        This is called by render_POST when the\n        client is replying to the keepalive.\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        self.last_alive[csessid] = (time.time(), False)\n        return '\"\"'", "func_src_after": "    def mode_keepalive(self, request):\n        \"\"\"\n        This is called by render_POST when the\n        client is replying to the keepalive.\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        self.last_alive[csessid] = (time.time(), False)\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_keepalive` that updates a timestamp for a client session ID from a POST request and returns an empty string."}
{"func_name": "get_item", "func_src_before": "@api.route('/items/<int:item_id>', methods=['GET'])\ndef get_item(item_id):\n    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = {} AND auctionable = true;'''.format(item_id)\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql)\n    data = cursor.fetchone()\n\n    if data:\n        item = {}\n        for tup in zip([column[0] for column in cursor.description], data):\n            item[tup[0]] = tup[1]\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify(item)", "func_src_after": "@api.route('/items/<int:item_id>', methods=['GET'])\ndef get_item(item_id):\n    sql = '''SELECT id, name_enus FROM tblDBCItem WHERE id = %s AND auctionable = true;'''\n    cursor = mysql.connection.cursor()\n    cursor.execute(sql, [item_id])\n    data = cursor.fetchone()\n\n    if data:\n        item = {}\n        for tup in zip([column[0] for column in cursor.description], data):\n            item[tup[0]] = tup[1]\n    else:\n        return jsonify({\"error\": \"item not found\"}), 404\n\n    return jsonify(item)", "commit_link": "github.com/cosileone/TimeIsMoneyFriend-API/commit/3d3b5defd26ef7d205915bf643b6b1df90a15e44", "file_name": "timf/api/views.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint to fetch an auctionable item by its ID from a MySQL database and return it as JSON, handling item not found errors."}
{"func_name": "Magick::Image::read", "func_src_before": "void Magick::Image::read(MagickCore::Image *image,\n  MagickCore::ExceptionInfo *exceptionInfo)\n{\n  // Ensure that multiple image frames were not read.\n  if (image != (MagickCore::Image *) NULL &&\n      image->next != (MagickCore::Image *) NULL)\n    {\n      MagickCore::Image\n        *next;\n\n      // Destroy any extra image frames\n      next=image->next;\n      image->next=(MagickCore::Image *) NULL;\n      next->previous=(MagickCore::Image *) NULL;\n      DestroyImageList(next);\n    }\n  replaceImage(image);\n  if (exceptionInfo->severity == MagickCore::UndefinedException &&\n      image == (MagickCore::Image *) NULL)\n    {\n      (void) MagickCore::DestroyExceptionInfo(exceptionInfo);\n      if (!quiet())\n        throwExceptionExplicit(MagickCore::ImageWarning,\n          \"No image was loaded.\");\n    }\n  ThrowImageException;\n}", "func_src_after": "void Magick::Image::read(MagickCore::Image *image,\n  MagickCore::ExceptionInfo *exceptionInfo)\n{\n  // Ensure that multiple image frames were not read.\n  if (image != (MagickCore::Image *) NULL &&\n      image->next != (MagickCore::Image *) NULL)\n    {\n      MagickCore::Image\n        *next;\n\n      // Destroy any extra image frames\n      next=image->next;\n      image->next=(MagickCore::Image *) NULL;\n      next->previous=(MagickCore::Image *) NULL;\n      DestroyImageList(next);\n    }\n  replaceImage(image);\n  if (exceptionInfo->severity == MagickCore::UndefinedException &&\n      image == (MagickCore::Image *) NULL)\n    {\n      (void) MagickCore::DestroyExceptionInfo(exceptionInfo);\n      if (!quiet())\n        throwExceptionExplicit(MagickCore::ImageWarning,\n          \"No image was loaded.\");\n      return;\n    }\n  ThrowImageException;\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/8c35502217c1879cb8257c617007282eee3fe1cc", "file_name": "Magick++/lib/Image.cpp", "vul_type": "cwe-416", "description": "In C++, write a function within the Magick::Image class to read an image, ensuring only a single frame is retained and handling exceptions if no image is loaded."}
{"func_name": "lys_restr_dup", "func_src_before": "lys_restr_dup(struct lys_module *mod, struct lys_restr *old, int size, int shallow, struct unres_schema *unres)\n{\n    struct lys_restr *result;\n    int i;\n\n    if (!size) {\n        return NULL;\n    }\n\n    result = calloc(size, sizeof *result);\n    LY_CHECK_ERR_RETURN(!result, LOGMEM(mod->ctx), NULL);\n\n    for (i = 0; i < size; i++) {\n        result[i].ext_size = old[i].ext_size;\n        lys_ext_dup(mod->ctx, mod, old[i].ext, old[i].ext_size, &result[i], LYEXT_PAR_RESTR, &result[i].ext, shallow, unres);\n        result[i].expr = lydict_insert(mod->ctx, old[i].expr, 0);\n        result[i].dsc = lydict_insert(mod->ctx, old[i].dsc, 0);\n        result[i].ref = lydict_insert(mod->ctx, old[i].ref, 0);\n        result[i].eapptag = lydict_insert(mod->ctx, old[i].eapptag, 0);\n        result[i].emsg = lydict_insert(mod->ctx, old[i].emsg, 0);\n    }\n\n    return result;\n}", "func_src_after": "lys_restr_dup(struct lys_module *mod, struct lys_restr *old, int size, int shallow, struct unres_schema *unres)\n{\n    struct lys_restr *result;\n    int i;\n\n    if (!size) {\n        return NULL;\n    }\n\n    result = calloc(size, sizeof *result);\n    LY_CHECK_ERR_RETURN(!result, LOGMEM(mod->ctx), NULL);\n\n    for (i = 0; i < size; i++) {\n        /* copying unresolved extensions is not supported */\n        if (unres_schema_find(unres, -1, (void *)&old[i].ext, UNRES_EXT) == -1) {\n            result[i].ext_size = old[i].ext_size;\n            lys_ext_dup(mod->ctx, mod, old[i].ext, old[i].ext_size, &result[i], LYEXT_PAR_RESTR, &result[i].ext, shallow, unres);\n        }\n        result[i].expr = lydict_insert(mod->ctx, old[i].expr, 0);\n        result[i].dsc = lydict_insert(mod->ctx, old[i].dsc, 0);\n        result[i].ref = lydict_insert(mod->ctx, old[i].ref, 0);\n        result[i].eapptag = lydict_insert(mod->ctx, old[i].eapptag, 0);\n        result[i].emsg = lydict_insert(mod->ctx, old[i].emsg, 0);\n    }\n\n    return result;\n}", "commit_link": "github.com/CESNET/libyang/commit/7852b272ef77f8098c35deea6c6f09cb78176f08", "file_name": "src/tree_schema.c", "vul_type": "cwe-476", "description": "Write a C function `lys_restr_dup` to duplicate an array of `lys_restr` structures, handling memory allocation and deep copying of contained strings and extensions."}
{"func_name": "_delete_vdisk", "func_src_before": "    def _delete_vdisk(self, name, force):\n        \"\"\"Deletes existing vdisks.\n\n        It is very important to properly take care of mappings before deleting\n        the disk:\n        1. If no mappings, then it was a vdisk, and can be deleted\n        2. If it is the source of a flashcopy mapping and copy_rate is 0, then\n           it is a vdisk that has a snapshot.  If the force flag is set,\n           delete the mapping and the vdisk, otherwise set the mapping to\n           copy and wait (this will allow users to delete vdisks that have\n           snapshots if/when the upper layers allow it).\n        3. If it is the target of a mapping and copy_rate is 0, it is a\n           snapshot, and we should properly stop the mapping and delete.\n        4. If it is the source/target of a mapping and copy_rate is not 0, it\n           is a clone or vdisk created from a snapshot.  We wait for the copy\n           to complete (the mapping will be autodeleted) and then delete the\n           vdisk.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _delete_vdisk: vdisk %s') % name)\n\n        # Try to delete volume only if found on the storage\n        vdisk_defined = self._is_vdisk_defined(name)\n        if not vdisk_defined:\n            LOG.info(_('warning: Tried to delete vdisk %s but it does not '\n                       'exist.') % name)\n            return\n\n        self._ensure_vdisk_no_fc_mappings(name)\n\n        ssh_cmd = ['svctask', 'rmvdisk', '-force', name]\n        if not force:\n            ssh_cmd.remove('-force')\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmvdisk\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                ('_delete_vdisk %(name)s')\n                                % {'name': name},\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: _delete_vdisk: vdisk %s') % name)", "func_src_after": "    def _delete_vdisk(self, name, force):\n        \"\"\"Deletes existing vdisks.\n\n        It is very important to properly take care of mappings before deleting\n        the disk:\n        1. If no mappings, then it was a vdisk, and can be deleted\n        2. If it is the source of a flashcopy mapping and copy_rate is 0, then\n           it is a vdisk that has a snapshot.  If the force flag is set,\n           delete the mapping and the vdisk, otherwise set the mapping to\n           copy and wait (this will allow users to delete vdisks that have\n           snapshots if/when the upper layers allow it).\n        3. If it is the target of a mapping and copy_rate is 0, it is a\n           snapshot, and we should properly stop the mapping and delete.\n        4. If it is the source/target of a mapping and copy_rate is not 0, it\n           is a clone or vdisk created from a snapshot.  We wait for the copy\n           to complete (the mapping will be autodeleted) and then delete the\n           vdisk.\n\n        \"\"\"\n\n        LOG.debug(_('enter: _delete_vdisk: vdisk %s') % name)\n\n        # Try to delete volume only if found on the storage\n        vdisk_defined = self._is_vdisk_defined(name)\n        if not vdisk_defined:\n            LOG.info(_('warning: Tried to delete vdisk %s but it does not '\n                       'exist.') % name)\n            return\n\n        self._ensure_vdisk_no_fc_mappings(name)\n\n        forceflag = '-force' if force else ''\n        cmd_params = {'frc': forceflag, 'name': name}\n        ssh_cmd = 'svctask rmvdisk %(frc)s %(name)s' % cmd_params\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmvdisk\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                ('_delete_vdisk %(name)s')\n                                % {'name': name},\n                                ssh_cmd, out, err)\n        LOG.debug(_('leave: _delete_vdisk: vdisk %s') % name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to delete a virtual disk with an option to force deletion, handling necessary pre-deletion checks and mappings."}
{"func_name": "__init__", "func_src_before": "    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Takes two additional keyword arguments:\n\n        :param cartpos: The cart position the form should be for\n        :param event: The event this belongs to\n        \"\"\"\n        cartpos = self.cartpos = kwargs.pop('cartpos', None)\n        orderpos = self.orderpos = kwargs.pop('orderpos', None)\n        pos = cartpos or orderpos\n        item = pos.item\n        questions = pos.item.questions_to_ask\n        event = kwargs.pop('event')\n\n        super().__init__(*args, **kwargs)\n\n        if item.admission and event.settings.attendee_names_asked:\n            self.fields['attendee_name_parts'] = NamePartsFormField(\n                max_length=255,\n                required=event.settings.attendee_names_required,\n                scheme=event.settings.name_scheme,\n                label=_('Attendee name'),\n                initial=(cartpos.attendee_name_parts if cartpos else orderpos.attendee_name_parts),\n            )\n        if item.admission and event.settings.attendee_emails_asked:\n            self.fields['attendee_email'] = forms.EmailField(\n                required=event.settings.attendee_emails_required,\n                label=_('Attendee email'),\n                initial=(cartpos.attendee_email if cartpos else orderpos.attendee_email)\n            )\n\n        for q in questions:\n            # Do we already have an answer? Provide it as the initial value\n            answers = [a for a in pos.answerlist if a.question_id == q.id]\n            if answers:\n                initial = answers[0]\n            else:\n                initial = None\n            tz = pytz.timezone(event.settings.timezone)\n            help_text = rich_text(q.help_text)\n            label = escape(q.question)  # django-bootstrap3 calls mark_safe\n            if q.type == Question.TYPE_BOOLEAN:\n                if q.required:\n                    # For some reason, django-bootstrap3 does not set the required attribute\n                    # itself.\n                    widget = forms.CheckboxInput(attrs={'required': 'required'})\n                else:\n                    widget = forms.CheckboxInput()\n\n                if initial:\n                    initialbool = (initial.answer == \"True\")\n                else:\n                    initialbool = False\n\n                field = forms.BooleanField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=initialbool, widget=widget,\n                )\n            elif q.type == Question.TYPE_NUMBER:\n                field = forms.DecimalField(\n                    label=label, required=q.required,\n                    help_text=q.help_text,\n                    initial=initial.answer if initial else None,\n                    min_value=Decimal('0.00'),\n                )\n            elif q.type == Question.TYPE_STRING:\n                field = forms.CharField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_TEXT:\n                field = forms.CharField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Textarea,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE:\n                field = forms.ModelChoiceField(\n                    queryset=q.options,\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Select,\n                    empty_label='',\n                    initial=initial.options.first() if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE_MULTIPLE:\n                field = forms.ModelMultipleChoiceField(\n                    queryset=q.options,\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    widget=forms.CheckboxSelectMultiple,\n                    initial=initial.options.all() if initial else None,\n                )\n            elif q.type == Question.TYPE_FILE:\n                field = forms.FileField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=initial.file if initial else None,\n                    widget=UploadedFileWidget(position=pos, event=event, answer=initial),\n                )\n            elif q.type == Question.TYPE_DATE:\n                field = forms.DateField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).date() if initial and initial.answer else None,\n                    widget=DatePickerWidget(),\n                )\n            elif q.type == Question.TYPE_TIME:\n                field = forms.TimeField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).time() if initial and initial.answer else None,\n                    widget=TimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            elif q.type == Question.TYPE_DATETIME:\n                field = SplitDateTimeField(\n                    label=label, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).astimezone(tz) if initial and initial.answer else None,\n                    widget=SplitDateTimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            field.question = q\n            if answers:\n                # Cache the answer object for later use\n                field.answer = answers[0]\n            self.fields['question_%s' % q.id] = field\n\n        responses = question_form_fields.send(sender=event, position=pos)\n        data = pos.meta_info_data\n        for r, response in sorted(responses, key=lambda r: str(r[0])):\n            for key, value in response.items():\n                # We need to be this explicit, since OrderedDict.update does not retain ordering\n                self.fields[key] = value\n                value.initial = data.get('question_form_data', {}).get(key)", "func_src_after": "    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Takes two additional keyword arguments:\n\n        :param cartpos: The cart position the form should be for\n        :param event: The event this belongs to\n        \"\"\"\n        cartpos = self.cartpos = kwargs.pop('cartpos', None)\n        orderpos = self.orderpos = kwargs.pop('orderpos', None)\n        pos = cartpos or orderpos\n        item = pos.item\n        questions = pos.item.questions_to_ask\n        event = kwargs.pop('event')\n\n        super().__init__(*args, **kwargs)\n\n        if item.admission and event.settings.attendee_names_asked:\n            self.fields['attendee_name_parts'] = NamePartsFormField(\n                max_length=255,\n                required=event.settings.attendee_names_required,\n                scheme=event.settings.name_scheme,\n                label=_('Attendee name'),\n                initial=(cartpos.attendee_name_parts if cartpos else orderpos.attendee_name_parts),\n            )\n        if item.admission and event.settings.attendee_emails_asked:\n            self.fields['attendee_email'] = forms.EmailField(\n                required=event.settings.attendee_emails_required,\n                label=_('Attendee email'),\n                initial=(cartpos.attendee_email if cartpos else orderpos.attendee_email)\n            )\n\n        for q in questions:\n            # Do we already have an answer? Provide it as the initial value\n            answers = [a for a in pos.answerlist if a.question_id == q.id]\n            if answers:\n                initial = answers[0]\n            else:\n                initial = None\n            tz = pytz.timezone(event.settings.timezone)\n            help_text = rich_text(q.help_text)\n            if q.type == Question.TYPE_BOOLEAN:\n                if q.required:\n                    # For some reason, django-bootstrap3 does not set the required attribute\n                    # itself.\n                    widget = forms.CheckboxInput(attrs={'required': 'required'})\n                else:\n                    widget = forms.CheckboxInput()\n\n                if initial:\n                    initialbool = (initial.answer == \"True\")\n                else:\n                    initialbool = False\n\n                field = forms.BooleanField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=initialbool, widget=widget,\n                )\n            elif q.type == Question.TYPE_NUMBER:\n                field = forms.DecimalField(\n                    label=q.question, required=q.required,\n                    help_text=q.help_text,\n                    initial=initial.answer if initial else None,\n                    min_value=Decimal('0.00'),\n                )\n            elif q.type == Question.TYPE_STRING:\n                field = forms.CharField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_TEXT:\n                field = forms.CharField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Textarea,\n                    initial=initial.answer if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE:\n                field = forms.ModelChoiceField(\n                    queryset=q.options,\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    widget=forms.Select,\n                    empty_label='',\n                    initial=initial.options.first() if initial else None,\n                )\n            elif q.type == Question.TYPE_CHOICE_MULTIPLE:\n                field = forms.ModelMultipleChoiceField(\n                    queryset=q.options,\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    widget=forms.CheckboxSelectMultiple,\n                    initial=initial.options.all() if initial else None,\n                )\n            elif q.type == Question.TYPE_FILE:\n                field = forms.FileField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=initial.file if initial else None,\n                    widget=UploadedFileWidget(position=pos, event=event, answer=initial),\n                )\n            elif q.type == Question.TYPE_DATE:\n                field = forms.DateField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).date() if initial and initial.answer else None,\n                    widget=DatePickerWidget(),\n                )\n            elif q.type == Question.TYPE_TIME:\n                field = forms.TimeField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).time() if initial and initial.answer else None,\n                    widget=TimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            elif q.type == Question.TYPE_DATETIME:\n                field = SplitDateTimeField(\n                    label=q.question, required=q.required,\n                    help_text=help_text,\n                    initial=dateutil.parser.parse(initial.answer).astimezone(tz) if initial and initial.answer else None,\n                    widget=SplitDateTimePickerWidget(time_format=get_format_without_seconds('TIME_INPUT_FORMATS')),\n                )\n            field.question = q\n            if answers:\n                # Cache the answer object for later use\n                field.answer = answers[0]\n            self.fields['question_%s' % q.id] = field\n\n        responses = question_form_fields.send(sender=event, position=pos)\n        data = pos.meta_info_data\n        for r, response in sorted(responses, key=lambda r: str(r[0])):\n            for key, value in response.items():\n                # We need to be this explicit, since OrderedDict.update does not retain ordering\n                self.fields[key] = value\n                value.initial = data.get('question_form_data', {}).get(key)", "commit_link": "github.com/pretix/pretix/commit/affc6254a8316643d4afe9e8b7f8cd288c86ca1f", "file_name": "src/pretix/base/forms/questions.py", "vul_type": "cwe-079", "description": "Write a Python class initializer that processes event-related form fields with dynamic question types and initial values."}
{"func_name": "ip_cmsg_recv_checksum", "func_src_before": "static void ip_cmsg_recv_checksum(struct msghdr *msg, struct sk_buff *skb,\n\t\t\t\t  int tlen, int offset)\n{\n\t__wsum csum = skb->csum;\n\n\tif (skb->ip_summed != CHECKSUM_COMPLETE)\n\t\treturn;\n\n\tif (offset != 0)\n\t\tcsum = csum_sub(csum,\n\t\t\t\tcsum_partial(skb_transport_header(skb) + tlen,\n\t\t\t\t\t     offset, 0));\n\n\tput_cmsg(msg, SOL_IP, IP_CHECKSUM, sizeof(__wsum), &csum);\n}", "func_src_after": "static void ip_cmsg_recv_checksum(struct msghdr *msg, struct sk_buff *skb,\n\t\t\t\t  int tlen, int offset)\n{\n\t__wsum csum = skb->csum;\n\n\tif (skb->ip_summed != CHECKSUM_COMPLETE)\n\t\treturn;\n\n\tif (offset != 0) {\n\t\tint tend_off = skb_transport_offset(skb) + tlen;\n\t\tcsum = csum_sub(csum, skb_checksum(skb, tend_off, offset, 0));\n\t}\n\n\tput_cmsg(msg, SOL_IP, IP_CHECKSUM, sizeof(__wsum), &csum);\n}", "commit_link": "github.com/torvalds/linux/commit/ca4ef4574f1ee5252e2cd365f8f5d5bafd048f32", "file_name": "net/ipv4/ip_sockglue.c", "vul_type": "cwe-125", "description": "Write a C function named `ip_cmsg_recv_checksum` that calculates and sets the checksum for a received packet in a socket buffer."}
{"func_name": "get_monthly_ranks_for_scene", "func_src_before": "def get_monthly_ranks_for_scene(db, scene, tag):\n\n    sql = \"SELECT date, rank FROM ranks WHERE scene='{}' AND player='{}'\".format(scene, tag)\n    res = db.exec(sql)\n\n    res = [r for r in res if played_during_month(db, scene, tag, get_previous_month(r[0]))]\n\n    # Build up a dict of {date: rank}\n    ranks = {}\n    for r in res:\n        ranks[r[0]] = r[1]\n\n    return ranks", "func_src_after": "def get_monthly_ranks_for_scene(db, scene, tag):\n\n    sql = \"SELECT date, rank FROM ranks WHERE scene='{scene}' AND player='{tag}'\"\n    args = {'scene': scene, 'tag': tag}\n    res = db.exec(sql, args)\n\n    res = [r for r in res if played_during_month(db, scene, tag, get_previous_month(r[0]))]\n\n    # Build up a dict of {date: rank}\n    ranks = {}\n    for r in res:\n        ranks[r[0]] = r[1]\n\n    return ranks", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve a dictionary of dates and ranks for a specific scene and player from a database, ensuring the player was active in the previous month."}
{"func_name": "_gdContributionsCalc", "func_src_before": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "func_src_after": "static inline LineContribType *_gdContributionsCalc(unsigned int line_size, unsigned int src_size, double scale_d,  const interpolation_method pFilter)\n{\n\tdouble width_d;\n\tdouble scale_f_d = 1.0;\n\tconst double filter_width_d = DEFAULT_BOX_RADIUS;\n\tint windows_size;\n\tunsigned int u;\n\tLineContribType *res;\n\n\tif (scale_d < 1.0) {\n\t\twidth_d = filter_width_d / scale_d;\n\t\tscale_f_d = scale_d;\n\t}  else {\n\t\twidth_d= filter_width_d;\n\t}\n\n\twindows_size = 2 * (int)ceil(width_d) + 1;\n\tres = _gdContributionsAlloc(line_size, windows_size);\n\n\tfor (u = 0; u < line_size; u++) {\n\t\tconst double dCenter = (double)u / scale_d;\n\t\t/* get the significant edge points affecting the pixel */\n\t\tregister int iLeft = MAX(0, (int)floor (dCenter - width_d));\n\t\tint iRight = MIN((int)ceil(dCenter + width_d), (int)src_size - 1);\n\t\tdouble dTotalWeight = 0.0;\n\t\tint iSrc;\n\n\t\t/* Cut edge points to fit in filter window in case of spill-off */\n\t\tif (iRight - iLeft + 1 > windows_size)  {\n\t\t\tif (iLeft < ((int)src_size - 1 / 2))  {\n\t\t\t\tiLeft++;\n\t\t\t} else {\n\t\t\t\tiRight--;\n\t\t\t}\n\t\t}\n\n\t\tres->ContribRow[u].Left = iLeft;\n\t\tres->ContribRow[u].Right = iRight;\n\n\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\tdTotalWeight += (res->ContribRow[u].Weights[iSrc-iLeft] =  scale_f_d * (*pFilter)(scale_f_d * (dCenter - (double)iSrc)));\n\t\t}\n\n\t\tif (dTotalWeight < 0.0) {\n\t\t\t_gdContributionsFree(res);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (dTotalWeight > 0.0) {\n\t\t\tfor (iSrc = iLeft; iSrc <= iRight; iSrc++) {\n\t\t\t\tres->ContribRow[u].Weights[iSrc-iLeft] /= dTotalWeight;\n\t\t\t}\n\t\t}\n\t}\n\treturn res;\n}", "commit_link": "github.com/libgd/libgd/commit/4f65a3e4eedaffa1efcf9ee1eb08f0b504fbc31a", "file_name": "src/gd_interpolation.c", "vul_type": "cwe-125", "description": "In C, write a function to calculate the contribution of source pixels to a line with scaling, using a specified interpolation method."}
{"func_name": "nfc_genl_deactivate_target", "func_src_before": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}", "func_src_after": "static int nfc_genl_deactivate_target(struct sk_buff *skb,\n\t\t\t\t      struct genl_info *info)\n{\n\tstruct nfc_dev *dev;\n\tu32 device_idx, target_idx;\n\tint rc;\n\n\tif (!info->attrs[NFC_ATTR_DEVICE_INDEX] ||\n\t    !info->attrs[NFC_ATTR_TARGET_INDEX])\n\t\treturn -EINVAL;\n\n\tdevice_idx = nla_get_u32(info->attrs[NFC_ATTR_DEVICE_INDEX]);\n\n\tdev = nfc_get_device(device_idx);\n\tif (!dev)\n\t\treturn -ENODEV;\n\n\ttarget_idx = nla_get_u32(info->attrs[NFC_ATTR_TARGET_INDEX]);\n\n\trc = nfc_deactivate_target(dev, target_idx, NFC_TARGET_MODE_SLEEP);\n\n\tnfc_put_device(dev);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/385097a3675749cbc9e97c085c0e5dfe4269ca51", "file_name": "net/nfc/netlink.c", "vul_type": "cwe-476", "description": "Write a C function to deactivate an NFC target by putting it into sleep mode, handling errors for invalid device or target indices."}
{"func_name": "repodata_schema2id", "func_src_before": "repodata_schema2id(Repodata *data, Id *schema, int create)\n{\n  int h, len, i;\n  Id *sp, cid;\n  Id *schematahash;\n\n  if (!*schema)\n    return 0;\t/* XXX: allow empty schema? */\n  if ((schematahash = data->schematahash) == 0)\n    {\n      data->schematahash = schematahash = solv_calloc(256, sizeof(Id));\n      for (i = 1; i < data->nschemata; i++)\n\t{\n\t  for (sp = data->schemadata + data->schemata[i], h = 0; *sp;)\n\t    h = h * 7 + *sp++;\n\t  h &= 255;\n\t  schematahash[h] = i;\n\t}\n      data->schemadata = solv_extend_resize(data->schemadata, data->schemadatalen, sizeof(Id), SCHEMATADATA_BLOCK);\n      data->schemata = solv_extend_resize(data->schemata, data->nschemata, sizeof(Id), SCHEMATA_BLOCK);\n    }\n\n  for (sp = schema, len = 0, h = 0; *sp; len++)\n    h = h * 7 + *sp++;\n  h &= 255;\n  len++;\n\n  cid = schematahash[h];\n  if (cid)\n    {\n      if (!memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n        return cid;\n      /* cache conflict, do a slow search */\n      for (cid = 1; cid < data->nschemata; cid++)\n        if (!memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n          return cid;\n    }\n  /* a new one */\n  if (!create)\n    return 0;\n  data->schemadata = solv_extend(data->schemadata, data->schemadatalen, len, sizeof(Id), SCHEMATADATA_BLOCK);\n  data->schemata = solv_extend(data->schemata, data->nschemata, 1, sizeof(Id), SCHEMATA_BLOCK);\n  /* add schema */\n  memcpy(data->schemadata + data->schemadatalen, schema, len * sizeof(Id));\n  data->schemata[data->nschemata] = data->schemadatalen;\n  data->schemadatalen += len;\n  schematahash[h] = data->nschemata;\n#if 0\nfprintf(stderr, \"schema2id: new schema\\n\");\n#endif\n  return data->nschemata++;\n}", "func_src_after": "repodata_schema2id(Repodata *data, Id *schema, int create)\n{\n  int h, len, i;\n  Id *sp, cid;\n  Id *schematahash;\n\n  if (!*schema)\n    return 0;\t/* XXX: allow empty schema? */\n  if ((schematahash = data->schematahash) == 0)\n    {\n      data->schematahash = schematahash = solv_calloc(256, sizeof(Id));\n      for (i = 1; i < data->nschemata; i++)\n\t{\n\t  for (sp = data->schemadata + data->schemata[i], h = 0; *sp;)\n\t    h = h * 7 + *sp++;\n\t  h &= 255;\n\t  schematahash[h] = i;\n\t}\n      data->schemadata = solv_extend_resize(data->schemadata, data->schemadatalen, sizeof(Id), SCHEMATADATA_BLOCK);\n      data->schemata = solv_extend_resize(data->schemata, data->nschemata, sizeof(Id), SCHEMATA_BLOCK);\n    }\n\n  for (sp = schema, len = 0, h = 0; *sp; len++)\n    h = h * 7 + *sp++;\n  h &= 255;\n  len++;\n\n  cid = schematahash[h];\n  if (cid)\n    {\n      if ((data->schemata[cid] + len <= data->schemadatalen) &&\n\t\t\t  !memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n        return cid;\n      /* cache conflict, do a slow search */\n      for (cid = 1; cid < data->nschemata; cid++)\n        if ((data->schemata[cid] + len <= data->schemadatalen) &&\n\t\t\t\t!memcmp(data->schemadata + data->schemata[cid], schema, len * sizeof(Id)))\n          return cid;\n    }\n  /* a new one */\n  if (!create)\n    return 0;\n  data->schemadata = solv_extend(data->schemadata, data->schemadatalen, len, sizeof(Id), SCHEMATADATA_BLOCK);\n  data->schemata = solv_extend(data->schemata, data->nschemata, 1, sizeof(Id), SCHEMATA_BLOCK);\n  /* add schema */\n  memcpy(data->schemadata + data->schemadatalen, schema, len * sizeof(Id));\n  data->schemata[data->nschemata] = data->schemadatalen;\n  data->schemadatalen += len;\n  schematahash[h] = data->nschemata;\n#if 0\nfprintf(stderr, \"schema2id: new schema\\n\");\n#endif\n  return data->nschemata++;\n}", "commit_link": "github.com/openSUSE/libsolv/commit/fdb9c9c03508990e4583046b590c30d958f272da", "file_name": "src/repodata.c", "vul_type": "cwe-125", "description": "Write a C function named `repodata_schema2id` that maps a schema to an identifier, optionally creating a new entry if it doesn't exist."}
{"func_name": "test_process_as_form", "func_src_before": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES (?, 'alex.roy616@gmail.com', ?)\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert, [job_number, was_prev_closed])\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert, [job_number, 1])\n                else:\n                    conn.cursor().execute(fake_match_insert, [job_number, 0])\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_pre = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(\"SELECT * FROM df_dilfo WHERE job_number=?\", conn, params=[job_number])\n            df_matched_post = pd.read_sql(\"SELECT * FROM df_matched WHERE job_number=?\", conn, params=[job_number])\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "func_src_after": "    @unpack\n    def test_process_as_form(self, job_number, dcn_key, was_prev_matched,\n            was_prev_closed, was_prev_tracked):\n        email_obj = {\n            'sender' : \"Alex Roy <Alex.Roy@dilfo.com>\",\n            'subject' : \"DO NOT MODIFY MESSAGE BELOW - JUST HIT `SEND`\",\n            'date' : \"Tue, 7 May 2019 17:34:17 +0000\",\n            'content' : (\n                f\"job_number={job_number}&title=TEST_ENTRY&city=Ottawa&\"\n                f\"address=2562+Del+Zotto+Ave.%2C+Ottawa%2C+Ontario&\"\n                f\"contractor=GCN&engineer=Goodkey&owner=Douglas+Stalker&\"\n                f\"quality=2&cc_email=&link_to_cert={dcn_key}\\r\\n\"\n            )\n        }\n        # set-up new entries in db, if necessary\n        fake_dilfo_insert = \"\"\"\n            INSERT INTO df_dilfo (job_number, receiver_email, closed)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        fake_match_insert = \"\"\"\n            INSERT INTO df_matched (job_number, verifier, ground_truth)\n            VALUES ({}, 'alex.roy616@gmail.com', {})\n        \"\"\"\n        with create_connection() as conn:\n            if was_prev_closed or was_prev_tracked:\n                conn.cursor().execute(fake_dilfo_insert.format(job_number, was_prev_closed))\n            if was_prev_matched:\n                if was_prev_closed:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 1))\n                else:\n                    conn.cursor().execute(fake_match_insert.format(job_number, 0))\n        with create_connection() as conn:\n            df_dilfo_pre = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_pre = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        process_as_form(email_obj)\n        # make assertions about db now that reply has been processed\n        with create_connection() as conn:\n            df_dilfo_post = pd.read_sql(f\"SELECT * FROM df_dilfo WHERE job_number={job_number}\", conn)\n            df_matched_post = pd.read_sql(f\"SELECT * FROM df_matched WHERE job_number={job_number}\", conn)\n        self.assertEqual(len(df_dilfo_post), 1)\n        self.assertEqual(bool(df_dilfo_post.iloc[0].closed), bool(was_prev_closed or dcn_key))\n        self.assertEqual(any(df_matched_post.ground_truth), bool(was_prev_closed or dcn_key))\n        self.assertEqual(len(df_matched_pre) + bool(dcn_key and not(was_prev_closed)), len(df_matched_post))\n        self.assertEqual(list(df_matched_pre.columns), list(df_matched_post.columns))\n        self.assertEqual(list(df_dilfo_pre.columns), list(df_dilfo_post.columns))", "commit_link": "github.com/confirmationbias616/certificate_checker/commit/9e890b9613b627e3a5995d0e4a594c8e0831e2ce", "file_name": "tests.py", "vul_type": "cwe-089", "description": "Write a Python function to process an email and update database entries based on the job number and certain conditions."}
{"func_name": "save", "func_src_before": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        self.description = self.description_plain_text\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "func_src_after": "    def save(self):\n        # copy the user's input from plain text to description to be processed\n        # uses bleach to remove potentially harmful HTML code\n        self.description = bleach.clean(str(self.description_plain_text),\n                                        tags=CE.settings.bleach_allowed,\n                                        strip=True)\n        if CE.settings.auto_cross_reference:\n            self.auto_cross_ref()\n        else:\n            self.find_tag()\n        self.slug = slugify(self.title)\n        super().save()", "commit_link": "github.com/stevetasticsteve/CLA_Hub/commit/a06d85cd0b0964f8469e5c4bc9a6c132aa0b4c37", "file_name": "CE/models.py", "vul_type": "cwe-079", "description": "Write a Python method named `save` that sanitizes user input, handles cross-referencing or tagging, generates a slug from the title, and then calls the superclass's save method."}
{"func_name": "core_anal_bytes", "func_src_before": "static void core_anal_bytes(RCore *core, const ut8 *buf, int len, int nops, int fmt) {\n\tint stacksize = r_config_get_i (core->config, \"esil.stack.depth\");\n\tbool iotrap = r_config_get_i (core->config, \"esil.iotrap\");\n\tbool romem = r_config_get_i (core->config, \"esil.romem\");\n\tbool stats = r_config_get_i (core->config, \"esil.stats\");\n\tbool be = core->print->big_endian;\n\tbool use_color = core->print->flags & R_PRINT_FLAGS_COLOR;\n\tcore->parser->relsub = r_config_get_i (core->config, \"asm.relsub\");\n\tint ret, i, j, idx, size;\n\tconst char *color = \"\";\n\tconst char *esilstr;\n\tconst char *opexstr;\n\tRAnalHint *hint;\n\tRAnalEsil *esil = NULL;\n\tRAsmOp asmop;\n\tRAnalOp op = {0};\n\tut64 addr;\n\tbool isFirst = true;\n\tunsigned int addrsize = r_config_get_i (core->config, \"esil.addr.size\");\n\tint totalsize = 0;\n\n\t// Variables required for setting up ESIL to REIL conversion\n\tif (use_color) {\n\t\tcolor = core->cons->pal.label;\n\t}\n\tswitch (fmt) {\n\tcase 'j':\n\t\tr_cons_printf (\"[\");\n\t\tbreak;\n\tcase 'r':\n\t\t// Setup for ESIL to REIL conversion\n\t\tesil = r_anal_esil_new (stacksize, iotrap, addrsize);\n\t\tif (!esil) {\n\t\t\treturn;\n\t\t}\n\t\tr_anal_esil_to_reil_setup (esil, core->anal, romem, stats);\n\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\tbreak;\n\t}\n\tfor (i = idx = ret = 0; idx < len && (!nops || (nops && i < nops)); i++, idx += ret) {\n\t\taddr = core->offset + idx;\n\t\t// TODO: use more anal hints\n\t\thint = r_anal_hint_get (core->anal, addr);\n\t\tr_asm_set_pc (core->assembler, addr);\n\t\t(void)r_asm_disassemble (core->assembler, &asmop, buf + idx, len - idx);\n\t\tret = r_anal_op (core->anal, &op, core->offset + idx, buf + idx, len - idx, R_ANAL_OP_MASK_ESIL);\n\t\tesilstr = R_STRBUF_SAFEGET (&op.esil);\n\t\topexstr = R_STRBUF_SAFEGET (&op.opex);\n\t\tchar *mnem = strdup (r_asm_op_get_asm (&asmop));\n\t\tchar *sp = strchr (mnem, ' ');\n\t\tif (sp) {\n\t\t\t*sp = 0;\n\t\t\tif (op.prefix) {\n\t\t\t\tchar *arg = strdup (sp + 1);\n\t\t\t\tchar *sp = strchr (arg, ' ');\n\t\t\t\tif (sp) {\n\t\t\t\t\t*sp = 0;\n\t\t\t\t}\n\t\t\t\tfree (mnem);\n\t\t\t\tmnem = arg;\n\t\t\t}\n\t\t}\n\t\tif (ret < 1 && fmt != 'd') {\n\t\t\teprintf (\"Oops at 0x%08\" PFMT64x \" (\", core->offset + idx);\n\t\t\tfor (i = idx, j = 0; i < core->blocksize && j < 3; ++i, ++j) {\n\t\t\t\teprintf (\"%02x \", buf[i]);\n\t\t\t}\n\t\t\teprintf (\"...)\\n\");\n\t\t\tfree (mnem);\n\t\t\tbreak;\n\t\t}\n\t\tsize = (hint && hint->size)? hint->size: op.size;\n\t\tif (fmt == 'd') {\n\t\t\tchar *opname = strdup (r_asm_op_get_asm (&asmop));\n\t\t\tif (opname) {\n\t\t\t\tr_str_split (opname, ' ');\n\t\t\t\tchar *d = r_asm_describe (core->assembler, opname);\n\t\t\t\tif (d && *d) {\n\t\t\t\t\tr_cons_printf (\"%s: %s\\n\", opname, d);\n\t\t\t\t\tfree (d);\n\t\t\t\t} else {\n\t\t\t\t\teprintf (\"Unknown opcode\\n\");\n\t\t\t\t}\n\t\t\t\tfree (opname);\n\t\t\t}\n\t\t} else if (fmt == 'e') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \" %s\\n\", color, core->offset + idx, esilstr);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \" %s\\n\", core->offset + idx, esilstr);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (fmt == 's') {\n\t\t\ttotalsize += op.size;\n\t\t} else if (fmt == 'r') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \"\\n\", color, core->offset + idx);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\t\t}\n\t\t\t\tr_anal_esil_parse (esil, esilstr);\n\t\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\t\tr_anal_esil_stack_free (esil);\n\t\t\t}\n\t\t} else if (fmt == 'j') {\n\t\t\tif (isFirst) {\n\t\t\t\tisFirst = false;\n\t\t\t} else {\n\t\t\t\tr_cons_print (\",\");\n\t\t\t}\n\t\t\tr_cons_printf (\"{\\\"opcode\\\":\\\"%s\\\",\", r_asm_op_get_asm (&asmop));\n\t\t\t{\n\t\t\t\tchar strsub[128] = { 0 };\n\t\t\t\t// pc+33\n\t\t\t\tr_parse_varsub (core->parser, NULL,\n\t\t\t\t\tcore->offset + idx,\n\t\t\t\t\tasmop.size, r_asm_op_get_asm (&asmop),\n\t\t\t\t\tstrsub, sizeof (strsub));\n\t\t\t\t{\n\t\t\t\t\tut64 killme = UT64_MAX;\n\t\t\t\t\tif (r_io_read_i (core->io, op.ptr, &killme, op.refptr, be)) {\n\t\t\t\t\t\tcore->parser->relsub_addr = killme;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// 0x33->sym.xx\n\t\t\t\tchar *p = strdup (strsub);\n\t\t\t\tif (p) {\n\t\t\t\t\tr_parse_filter (core->parser, addr, core->flags, p,\n\t\t\t\t\t\t\tstrsub, sizeof (strsub), be);\n\t\t\t\t\tfree (p);\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"disasm\\\":\\\"%s\\\",\", strsub);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"mnemonic\\\":\\\"%s\\\",\", mnem);\n\t\t\tif (hint && hint->opcode) {\n\t\t\t\tr_cons_printf (\"\\\"ophint\\\":\\\"%s\\\",\", hint->opcode);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"sign\\\":%s,\", r_str_bool (op.sign));\n\t\t\tr_cons_printf (\"\\\"prefix\\\":%\" PFMT64u \",\", op.prefix);\n\t\t\tr_cons_printf (\"\\\"id\\\":%d,\", op.id);\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tr_cons_printf (\"\\\"opex\\\":%s,\", opexstr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"addr\\\":%\" PFMT64u \",\", core->offset + idx);\n\t\t\tr_cons_printf (\"\\\"bytes\\\":\\\"\");\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tr_cons_printf (\"%02x\", buf[j + idx]);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\",\");\n\t\t\tif (op.val != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"val\\\": %\" PFMT64u \",\", op.val);\n\t\t\t}\n\t\t\tif (op.ptr != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"ptr\\\": %\" PFMT64u \",\", op.ptr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"size\\\": %d,\", size);\n\t\t\tr_cons_printf (\"\\\"type\\\": \\\"%s\\\",\",\n\t\t\t\tr_anal_optype_to_string (op.type));\n\t\t\tif (op.reg) {\n\t\t\t\tr_cons_printf (\"\\\"reg\\\": \\\"%s\\\",\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tr_cons_printf (\"\\\"ireg\\\": \\\"%s\\\",\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tr_cons_printf (\"\\\"scale\\\":%d,\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"jump\\\":%\" PFMT64u \",\", op.jump);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.refptr != -1) {\n\t\t\t\tr_cons_printf (\"\\\"refptr\\\":%d,\", op.refptr);\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"fail\\\":%\" PFMT64u \",\", op.fail);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"cycles\\\":%d,\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tr_cons_printf (\"\\\"failcycles\\\":%d,\", op.failcycles);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"delay\\\":%d,\", op.delay);\n\t\t\t{\n\t\t\t\tconst char *p = r_anal_stackop_tostring (op.stackop);\n\t\t\t\tif (p && *p && strcmp (p, \"null\"))\n\t\t\t\t\tr_cons_printf (\"\\\"stack\\\":\\\"%s\\\",\", p);\n\t\t\t}\n\t\t\tif (op.stackptr) {\n\t\t\t\tr_cons_printf (\"\\\"stackptr\\\":%d,\", op.stackptr);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)\n\t\t\t\t\t? r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tr_cons_printf (\"\\\"cond\\\":\\\"%s\\\",\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"family\\\":\\\"%s\\\"}\", r_anal_op_family_to_string (op.family));\n\t\t} else {\n#define printline(k, fmt, arg)\\\n\t{ \\\n\t\tif (use_color)\\\n\t\t\tr_cons_printf (\"%s%s: \" Color_RESET, color, k);\\\n\t\telse\\\n\t\t\tr_cons_printf (\"%s: \", k);\\\n\t\tif (fmt) r_cons_printf (fmt, arg);\\\n\t}\n\t\t\tprintline (\"address\", \"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\tprintline (\"opcode\", \"%s\\n\", r_asm_op_get_asm (&asmop));\n\t\t\tprintline (\"mnemonic\", \"%s\\n\", mnem);\n\t\t\tif (hint) {\n\t\t\t\tif (hint->opcode) {\n\t\t\t\t\tprintline (\"ophint\", \"%s\\n\", hint->opcode);\n\t\t\t\t}\n#if 0\n\t\t\t\t// addr should not override core->offset + idx.. its silly\n\t\t\t\tif (hint->addr != UT64_MAX) {\n\t\t\t\t\tprintline (\"addr\", \"0x%08\" PFMT64x \"\\n\", (hint->addr + idx));\n\t\t\t\t}\n#endif\n\t\t\t}\n\t\t\tprintline (\"prefix\", \"%\" PFMT64u \"\\n\", op.prefix);\n\t\t\tprintline (\"id\", \"%d\\n\", op.id);\n#if 0\n// no opex here to avoid lot of tests broken..and having json in here is not much useful imho\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tprintline (\"opex\", \"%s\\n\", opexstr);\n\t\t\t}\n#endif\n\t\t\tprintline (\"bytes\", NULL, 0);\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tr_cons_printf (\"%02x\", buf[j + idx]);\n\t\t\t}\n\t\t\tr_cons_newline ();\n\t\t\tif (op.val != UT64_MAX)\n\t\t\t\tprintline (\"val\", \"0x%08\" PFMT64x \"\\n\", op.val);\n\t\t\tif (op.ptr != UT64_MAX)\n\t\t\t\tprintline (\"ptr\", \"0x%08\" PFMT64x \"\\n\", op.ptr);\n\t\t\tif (op.refptr != -1)\n\t\t\t\tprintline (\"refptr\", \"%d\\n\", op.refptr);\n\t\t\tprintline (\"size\", \"%d\\n\", size);\n\t\t\tprintline (\"sign\", \"%s\\n\", r_str_bool (op.sign));\n\t\t\tprintline (\"type\", \"%s\\n\", r_anal_optype_to_string (op.type));\n\t\t\tprintline (\"cycles\", \"%d\\n\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tprintline (\"failcycles\", \"%d\\n\", op.failcycles);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *t2 = r_anal_optype_to_string (op.type2);\n\t\t\t\tif (t2 && strcmp (t2, \"null\")) {\n\t\t\t\t\tprintline (\"type2\", \"%s\\n\", t2);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op.reg) {\n\t\t\t\tprintline (\"reg\", \"%s\\n\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tprintline (\"ireg\", \"%s\\n\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tprintline (\"scale\", \"%d\\n\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tprintline (\"jump\", \"0x%08\" PFMT64x \"\\n\", op.jump);\n\t\t\t}\n\t\t\tif (op.direction != 0) {\n\t\t\t\tconst char * dir = op.direction == 1 ? \"read\"\n\t\t\t\t\t: op.direction == 2 ? \"write\"\n\t\t\t\t\t: op.direction == 4 ? \"exec\"\n\t\t\t\t\t: op.direction == 8 ? \"ref\": \"none\";\n\t\t\t\tprintline (\"direction\", \"%s\\n\", dir);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tprintline (\"fail\", \"0x%08\" PFMT64x \"\\n\", op.fail);\n\t\t\t}\n\t\t\tif (op.delay) {\n\t\t\t\tprintline (\"delay\", \"%d\\n\", op.delay);\n\t\t\t}\n\t\t\tprintline (\"stack\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)?  r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tprintline (\"cond\", \"%s\\n\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tprintline (\"family\", \"%s\\n\", r_anal_op_family_to_string (op.family));\n\t\t\tprintline (\"stackop\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\tif (op.stackptr) {\n\t\t\t\tprintline (\"stackptr\", \"%\"PFMT64u\"\\n\", op.stackptr);\n\t\t\t}\n\t\t}\n\t\t//r_cons_printf (\"false: 0x%08\"PFMT64x\"\\n\", core->offset+idx);\n\t\t//free (hint);\n\t\tfree (mnem);\n\t\tr_anal_hint_free (hint);\n\t\tr_anal_op_fini (&op);\n\t}\n\tr_anal_op_fini (&op);\n\tif (fmt == 'j') {\n\t\tr_cons_printf (\"]\");\n\t\tr_cons_newline ();\n\t} else if (fmt == 's') {\n\t\tr_cons_printf (\"%d\\n\", totalsize);\n\t}\n\tr_anal_esil_free (esil);\n}", "func_src_after": "static void core_anal_bytes(RCore *core, const ut8 *buf, int len, int nops, int fmt) {\n\tint stacksize = r_config_get_i (core->config, \"esil.stack.depth\");\n\tbool iotrap = r_config_get_i (core->config, \"esil.iotrap\");\n\tbool romem = r_config_get_i (core->config, \"esil.romem\");\n\tbool stats = r_config_get_i (core->config, \"esil.stats\");\n\tbool be = core->print->big_endian;\n\tbool use_color = core->print->flags & R_PRINT_FLAGS_COLOR;\n\tcore->parser->relsub = r_config_get_i (core->config, \"asm.relsub\");\n\tint ret, i, j, idx, size;\n\tconst char *color = \"\";\n\tconst char *esilstr;\n\tconst char *opexstr;\n\tRAnalHint *hint;\n\tRAnalEsil *esil = NULL;\n\tRAsmOp asmop;\n\tRAnalOp op = {0};\n\tut64 addr;\n\tbool isFirst = true;\n\tunsigned int addrsize = r_config_get_i (core->config, \"esil.addr.size\");\n\tint totalsize = 0;\n\n\t// Variables required for setting up ESIL to REIL conversion\n\tif (use_color) {\n\t\tcolor = core->cons->pal.label;\n\t}\n\tswitch (fmt) {\n\tcase 'j':\n\t\tr_cons_printf (\"[\");\n\t\tbreak;\n\tcase 'r':\n\t\t// Setup for ESIL to REIL conversion\n\t\tesil = r_anal_esil_new (stacksize, iotrap, addrsize);\n\t\tif (!esil) {\n\t\t\treturn;\n\t\t}\n\t\tr_anal_esil_to_reil_setup (esil, core->anal, romem, stats);\n\t\tr_anal_esil_set_pc (esil, core->offset);\n\t\tbreak;\n\t}\n\tfor (i = idx = ret = 0; idx < len && (!nops || (nops && i < nops)); i++, idx += ret) {\n\t\taddr = core->offset + idx;\n\t\t// TODO: use more anal hints\n\t\thint = r_anal_hint_get (core->anal, addr);\n\t\tr_asm_set_pc (core->assembler, addr);\n\t\t(void)r_asm_disassemble (core->assembler, &asmop, buf + idx, len - idx);\n\t\tret = r_anal_op (core->anal, &op, core->offset + idx, buf + idx, len - idx, R_ANAL_OP_MASK_ESIL);\n\t\tesilstr = R_STRBUF_SAFEGET (&op.esil);\n\t\topexstr = R_STRBUF_SAFEGET (&op.opex);\n\t\tchar *mnem = strdup (r_asm_op_get_asm (&asmop));\n\t\tchar *sp = strchr (mnem, ' ');\n\t\tif (sp) {\n\t\t\t*sp = 0;\n\t\t\tif (op.prefix) {\n\t\t\t\tchar *arg = strdup (sp + 1);\n\t\t\t\tchar *sp = strchr (arg, ' ');\n\t\t\t\tif (sp) {\n\t\t\t\t\t*sp = 0;\n\t\t\t\t}\n\t\t\t\tfree (mnem);\n\t\t\t\tmnem = arg;\n\t\t\t}\n\t\t}\n\t\tif (ret < 1 && fmt != 'd') {\n\t\t\teprintf (\"Oops at 0x%08\" PFMT64x \" (\", core->offset + idx);\n\t\t\tfor (i = idx, j = 0; i < core->blocksize && j < 3; ++i, ++j) {\n\t\t\t\teprintf (\"%02x \", buf[i]);\n\t\t\t}\n\t\t\teprintf (\"...)\\n\");\n\t\t\tfree (mnem);\n\t\t\tbreak;\n\t\t}\n\t\tsize = (hint && hint->size)? hint->size: op.size;\n\t\tif (fmt == 'd') {\n\t\t\tchar *opname = strdup (r_asm_op_get_asm (&asmop));\n\t\t\tif (opname) {\n\t\t\t\tr_str_split (opname, ' ');\n\t\t\t\tchar *d = r_asm_describe (core->assembler, opname);\n\t\t\t\tif (d && *d) {\n\t\t\t\t\tr_cons_printf (\"%s: %s\\n\", opname, d);\n\t\t\t\t\tfree (d);\n\t\t\t\t} else {\n\t\t\t\t\teprintf (\"Unknown opcode\\n\");\n\t\t\t\t}\n\t\t\t\tfree (opname);\n\t\t\t}\n\t\t} else if (fmt == 'e') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \" %s\\n\", color, core->offset + idx, esilstr);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \" %s\\n\", core->offset + idx, esilstr);\n\t\t\t\t}\n\t\t\t}\n\t\t} else if (fmt == 's') {\n\t\t\ttotalsize += op.size;\n\t\t} else if (fmt == 'r') {\n\t\t\tif (*esilstr) {\n\t\t\t\tif (use_color) {\n\t\t\t\t\tr_cons_printf (\"%s0x%\" PFMT64x Color_RESET \"\\n\", color, core->offset + idx);\n\t\t\t\t} else {\n\t\t\t\t\tr_cons_printf (\"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\t\t}\n\t\t\t\tr_anal_esil_parse (esil, esilstr);\n\t\t\t\tr_anal_esil_dumpstack (esil);\n\t\t\t\tr_anal_esil_stack_free (esil);\n\t\t\t}\n\t\t} else if (fmt == 'j') {\n\t\t\tif (isFirst) {\n\t\t\t\tisFirst = false;\n\t\t\t} else {\n\t\t\t\tr_cons_print (\",\");\n\t\t\t}\n\t\t\tr_cons_printf (\"{\\\"opcode\\\":\\\"%s\\\",\", r_asm_op_get_asm (&asmop));\n\t\t\t{\n\t\t\t\tchar strsub[128] = { 0 };\n\t\t\t\t// pc+33\n\t\t\t\tr_parse_varsub (core->parser, NULL,\n\t\t\t\t\tcore->offset + idx,\n\t\t\t\t\tasmop.size, r_asm_op_get_asm (&asmop),\n\t\t\t\t\tstrsub, sizeof (strsub));\n\t\t\t\t{\n\t\t\t\t\tut64 killme = UT64_MAX;\n\t\t\t\t\tif (r_io_read_i (core->io, op.ptr, &killme, op.refptr, be)) {\n\t\t\t\t\t\tcore->parser->relsub_addr = killme;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// 0x33->sym.xx\n\t\t\t\tchar *p = strdup (strsub);\n\t\t\t\tif (p) {\n\t\t\t\t\tr_parse_filter (core->parser, addr, core->flags, p,\n\t\t\t\t\t\t\tstrsub, sizeof (strsub), be);\n\t\t\t\t\tfree (p);\n\t\t\t\t}\n\t\t\t\tr_cons_printf (\"\\\"disasm\\\":\\\"%s\\\",\", strsub);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"mnemonic\\\":\\\"%s\\\",\", mnem);\n\t\t\tif (hint && hint->opcode) {\n\t\t\t\tr_cons_printf (\"\\\"ophint\\\":\\\"%s\\\",\", hint->opcode);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"sign\\\":%s,\", r_str_bool (op.sign));\n\t\t\tr_cons_printf (\"\\\"prefix\\\":%\" PFMT64u \",\", op.prefix);\n\t\t\tr_cons_printf (\"\\\"id\\\":%d,\", op.id);\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tr_cons_printf (\"\\\"opex\\\":%s,\", opexstr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"addr\\\":%\" PFMT64u \",\", core->offset + idx);\n\t\t\tr_cons_printf (\"\\\"bytes\\\":\\\"\");\n\t\t\tfor (j = 0; j < size; j++) {\n\t\t\t\tr_cons_printf (\"%02x\", buf[j + idx]);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\",\");\n\t\t\tif (op.val != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"val\\\": %\" PFMT64u \",\", op.val);\n\t\t\t}\n\t\t\tif (op.ptr != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"ptr\\\": %\" PFMT64u \",\", op.ptr);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"size\\\": %d,\", size);\n\t\t\tr_cons_printf (\"\\\"type\\\": \\\"%s\\\",\",\n\t\t\t\tr_anal_optype_to_string (op.type));\n\t\t\tif (op.reg) {\n\t\t\t\tr_cons_printf (\"\\\"reg\\\": \\\"%s\\\",\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tr_cons_printf (\"\\\"ireg\\\": \\\"%s\\\",\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tr_cons_printf (\"\\\"scale\\\":%d,\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tr_cons_printf (\"\\\"esil\\\": \\\"%s\\\",\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"jump\\\":%\" PFMT64u \",\", op.jump);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.refptr != -1) {\n\t\t\t\tr_cons_printf (\"\\\"refptr\\\":%d,\", op.refptr);\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tr_cons_printf (\"\\\"fail\\\":%\" PFMT64u \",\", op.fail);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"cycles\\\":%d,\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tr_cons_printf (\"\\\"failcycles\\\":%d,\", op.failcycles);\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"delay\\\":%d,\", op.delay);\n\t\t\t{\n\t\t\t\tconst char *p = r_anal_stackop_tostring (op.stackop);\n\t\t\t\tif (p && *p && strcmp (p, \"null\"))\n\t\t\t\t\tr_cons_printf (\"\\\"stack\\\":\\\"%s\\\",\", p);\n\t\t\t}\n\t\t\tif (op.stackptr) {\n\t\t\t\tr_cons_printf (\"\\\"stackptr\\\":%d,\", op.stackptr);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)\n\t\t\t\t\t? r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tr_cons_printf (\"\\\"cond\\\":\\\"%s\\\",\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tr_cons_printf (\"\\\"family\\\":\\\"%s\\\"}\", r_anal_op_family_to_string (op.family));\n\t\t} else {\n#define printline(k, fmt, arg)\\\n\t{ \\\n\t\tif (use_color)\\\n\t\t\tr_cons_printf (\"%s%s: \" Color_RESET, color, k);\\\n\t\telse\\\n\t\t\tr_cons_printf (\"%s: \", k);\\\n\t\tif (fmt) r_cons_printf (fmt, arg);\\\n\t}\n\t\t\tprintline (\"address\", \"0x%\" PFMT64x \"\\n\", core->offset + idx);\n\t\t\tprintline (\"opcode\", \"%s\\n\", r_asm_op_get_asm (&asmop));\n\t\t\tprintline (\"mnemonic\", \"%s\\n\", mnem);\n\t\t\tif (hint) {\n\t\t\t\tif (hint->opcode) {\n\t\t\t\t\tprintline (\"ophint\", \"%s\\n\", hint->opcode);\n\t\t\t\t}\n#if 0\n\t\t\t\t// addr should not override core->offset + idx.. its silly\n\t\t\t\tif (hint->addr != UT64_MAX) {\n\t\t\t\t\tprintline (\"addr\", \"0x%08\" PFMT64x \"\\n\", (hint->addr + idx));\n\t\t\t\t}\n#endif\n\t\t\t}\n\t\t\tprintline (\"prefix\", \"%\" PFMT64u \"\\n\", op.prefix);\n\t\t\tprintline (\"id\", \"%d\\n\", op.id);\n#if 0\n// no opex here to avoid lot of tests broken..and having json in here is not much useful imho\n\t\t\tif (opexstr && *opexstr) {\n\t\t\t\tprintline (\"opex\", \"%s\\n\", opexstr);\n\t\t\t}\n#endif\n\t\t\tprintline (\"bytes\", NULL, 0);\n\t\t\tint minsz = R_MIN (len, size);\n\t\t\tminsz = R_MAX (minsz, 0);\n\t\t\tfor (j = 0; j < minsz; j++) {\n\t\t\t\tut8 ch = ((j + idx - 1) > minsz)? 0xff: buf[j + idx];\n\t\t\t\tr_cons_printf (\"%02x\", ch);\n\t\t\t}\n\t\t\tr_cons_newline ();\n\t\t\tif (op.val != UT64_MAX) {\n\t\t\t\tprintline (\"val\", \"0x%08\" PFMT64x \"\\n\", op.val);\n\t\t\t}\n\t\t\tif (op.ptr != UT64_MAX) {\n\t\t\t\tprintline (\"ptr\", \"0x%08\" PFMT64x \"\\n\", op.ptr);\n\t\t\t}\n\t\t\tif (op.refptr != -1) {\n\t\t\t\tprintline (\"refptr\", \"%d\\n\", op.refptr);\n\t\t\t}\n\t\t\tprintline (\"size\", \"%d\\n\", size);\n\t\t\tprintline (\"sign\", \"%s\\n\", r_str_bool (op.sign));\n\t\t\tprintline (\"type\", \"%s\\n\", r_anal_optype_to_string (op.type));\n\t\t\tprintline (\"cycles\", \"%d\\n\", op.cycles);\n\t\t\tif (op.failcycles) {\n\t\t\t\tprintline (\"failcycles\", \"%d\\n\", op.failcycles);\n\t\t\t}\n\t\t\t{\n\t\t\t\tconst char *t2 = r_anal_optype_to_string (op.type2);\n\t\t\t\tif (t2 && strcmp (t2, \"null\")) {\n\t\t\t\t\tprintline (\"type2\", \"%s\\n\", t2);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (op.reg) {\n\t\t\t\tprintline (\"reg\", \"%s\\n\", op.reg);\n\t\t\t}\n\t\t\tif (op.ireg) {\n\t\t\t\tprintline (\"ireg\", \"%s\\n\", op.ireg);\n\t\t\t}\n\t\t\tif (op.scale) {\n\t\t\t\tprintline (\"scale\", \"%d\\n\", op.scale);\n\t\t\t}\n\t\t\tif (hint && hint->esil) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", hint->esil);\n\t\t\t} else if (*esilstr) {\n\t\t\t\tprintline (\"esil\", \"%s\\n\", esilstr);\n\t\t\t}\n\t\t\tif (hint && hint->jump != UT64_MAX) {\n\t\t\t\top.jump = hint->jump;\n\t\t\t}\n\t\t\tif (op.jump != UT64_MAX) {\n\t\t\t\tprintline (\"jump\", \"0x%08\" PFMT64x \"\\n\", op.jump);\n\t\t\t}\n\t\t\tif (op.direction != 0) {\n\t\t\t\tconst char * dir = op.direction == 1 ? \"read\"\n\t\t\t\t\t: op.direction == 2 ? \"write\"\n\t\t\t\t\t: op.direction == 4 ? \"exec\"\n\t\t\t\t\t: op.direction == 8 ? \"ref\": \"none\";\n\t\t\t\tprintline (\"direction\", \"%s\\n\", dir);\n\t\t\t}\n\t\t\tif (hint && hint->fail != UT64_MAX) {\n\t\t\t\top.fail = hint->fail;\n\t\t\t}\n\t\t\tif (op.fail != UT64_MAX) {\n\t\t\t\tprintline (\"fail\", \"0x%08\" PFMT64x \"\\n\", op.fail);\n\t\t\t}\n\t\t\tif (op.delay) {\n\t\t\t\tprintline (\"delay\", \"%d\\n\", op.delay);\n\t\t\t}\n\t\t\tprintline (\"stack\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\t{\n\t\t\t\tconst char *arg = (op.type & R_ANAL_OP_TYPE_COND)?  r_anal_cond_tostring (op.cond): NULL;\n\t\t\t\tif (arg) {\n\t\t\t\t\tprintline (\"cond\", \"%s\\n\", arg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tprintline (\"family\", \"%s\\n\", r_anal_op_family_to_string (op.family));\n\t\t\tprintline (\"stackop\", \"%s\\n\", r_anal_stackop_tostring (op.stackop));\n\t\t\tif (op.stackptr) {\n\t\t\t\tprintline (\"stackptr\", \"%\"PFMT64u\"\\n\", op.stackptr);\n\t\t\t}\n\t\t}\n\t\t//r_cons_printf (\"false: 0x%08\"PFMT64x\"\\n\", core->offset+idx);\n\t\t//free (hint);\n\t\tfree (mnem);\n\t\tr_anal_hint_free (hint);\n\t\tr_anal_op_fini (&op);\n\t}\n\tr_anal_op_fini (&op);\n\tif (fmt == 'j') {\n\t\tr_cons_printf (\"]\");\n\t\tr_cons_newline ();\n\t} else if (fmt == 's') {\n\t\tr_cons_printf (\"%d\\n\", totalsize);\n\t}\n\tr_anal_esil_free (esil);\n}", "commit_link": "github.com/radare/radare2/commit/a1bc65c3db593530775823d6d7506a457ed95267", "file_name": "libr/core/cmd_anal.c", "vul_type": "cwe-125", "description": "Write a C function named `core_anal_bytes` that analyzes a buffer of bytes for disassembly and ESIL (Evaluable Strings Intermediate Language) conversion in Radare2."}
{"func_name": "fetch_issue", "func_src_before": "def fetch_issue(cursor, id):\n    \"\"\"\n    Fetch an issue by id along with its tags. Returns None if no issue\n    with the specified id exists in the database.\n    \"\"\"\n    cursor.execute(f\"\"\"\n        SELECT\n            issue.id,\n            issue.title,\n            issue.description,\n            tag.namespace,\n            tag.predicate,\n            tag.value\n        FROM\n            issue LEFT JOIN tag\n            ON issue.id = tag.issue_id\n        WHERE\n            issue.id = {id}\n    \"\"\")\n\n    issue = None\n    for row in cursor:\n        if issue is None:\n            issue = {\n                \"id\": row[\"id\"],\n                \"title\": row[\"title\"],\n                \"description\": row[\"description\"],\n                \"tags\": [],\n            }\n        # If tag exists in row, add to issue.\n        if row[\"value\"]:\n            issue[\"tags\"].append({\n                \"namespace\": row[\"namespace\"],\n                \"predicate\": row[\"predicate\"],\n                \"value\": row[\"value\"],\n            })\n\n    return issue", "func_src_after": "def fetch_issue(cursor, id):\n    \"\"\"\n    Fetch an issue by id along with its tags. Returns None if no issue\n    with the specified id exists in the database.\n    \"\"\"\n    cursor.execute(\"\"\"\n        SELECT\n            issue.id,\n            issue.title,\n            issue.description,\n            tag.namespace,\n            tag.predicate,\n            tag.value\n        FROM\n            issue LEFT JOIN tag\n            ON issue.id = tag.issue_id\n        WHERE\n            issue.id = ?\n    \"\"\", (id,))\n\n    issue = None\n    for row in cursor:\n        if issue is None:\n            issue = {\n                \"id\": row[\"id\"],\n                \"title\": row[\"title\"],\n                \"description\": row[\"description\"],\n                \"tags\": [],\n            }\n        # If tag exists in row, add to issue.\n        if row[\"value\"]:\n            issue[\"tags\"].append({\n                \"namespace\": row[\"namespace\"],\n                \"predicate\": row[\"predicate\"],\n                \"value\": row[\"value\"],\n            })\n\n    return issue", "commit_link": "github.com/nutty7t/tissue/commit/306dd094749bb39cbd5c74a6ded3d3b191033061", "file_name": "server/server.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve an issue and its associated tags from a database using a given id, returning None if not found."}
{"func_name": "_create_vdisk", "func_src_before": "    def _create_vdisk(self, name, size, units, opts):\n        \"\"\"Create a new vdisk.\"\"\"\n\n        LOG.debug(_('enter: _create_vdisk: vdisk %s ') % name)\n\n        model_update = None\n        easytier = 'on' if opts['easytier'] else 'off'\n\n        # Set space-efficient options\n        if opts['rsize'] == -1:\n            ssh_cmd_se_opt = []\n        else:\n            ssh_cmd_se_opt = ['-rsize', '%s%%' % str(opts['rsize']),\n                              '-autoexpand', '-warning',\n                              '%s%%' % str(opts['warning'])]\n            if not opts['autoexpand']:\n                ssh_cmd_se_opt.remove('-autoexpand')\n\n            if opts['compression']:\n                ssh_cmd_se_opt.append('-compressed')\n            else:\n                ssh_cmd_se_opt.extend(['-grainsize', str(opts['grainsize'])])\n\n        ssh_cmd = ['svctask', 'mkvdisk', '-name', name, '-mdiskgrp',\n                   self.configuration.storwize_svc_volpool_name,\n                   '-iogrp', '0', '-size', size, '-unit',\n                   units, '-easytier', easytier] + ssh_cmd_se_opt\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), '_create_vdisk',\n                                ssh_cmd, out, err)\n\n        # Ensure that the output is as expected\n        match_obj = re.search('Virtual Disk, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('_create_vdisk %(name)s - did not find '\n              'success message in CLI output.\\n '\n              'stdout: %(out)s\\n stderr: %(err)s')\n            % {'name': name, 'out': str(out), 'err': str(err)})\n\n        LOG.debug(_('leave: _create_vdisk: volume %s ') % name)", "func_src_after": "    def _create_vdisk(self, name, size, units, opts):\n        \"\"\"Create a new vdisk.\"\"\"\n\n        LOG.debug(_('enter: _create_vdisk: vdisk %s ') % name)\n\n        model_update = None\n        autoex = '-autoexpand' if opts['autoexpand'] else ''\n        easytier = '-easytier on' if opts['easytier'] else '-easytier off'\n\n        # Set space-efficient options\n        if opts['rsize'] == -1:\n            ssh_cmd_se_opt = ''\n        else:\n            ssh_cmd_se_opt = (\n                '-rsize %(rsize)d%% %(autoex)s -warning %(warn)d%%' %\n                {'rsize': opts['rsize'],\n                 'autoex': autoex,\n                 'warn': opts['warning']})\n            if opts['compression']:\n                ssh_cmd_se_opt = ssh_cmd_se_opt + ' -compressed'\n            else:\n                ssh_cmd_se_opt = ssh_cmd_se_opt + (\n                    ' -grainsize %d' % opts['grainsize'])\n\n        ssh_cmd = ('svctask mkvdisk -name %(name)s -mdiskgrp %(mdiskgrp)s '\n                   '-iogrp 0 -size %(size)s -unit '\n                   '%(unit)s %(easytier)s %(ssh_cmd_se_opt)s'\n                   % {'name': name,\n                   'mdiskgrp': self.configuration.storwize_svc_volpool_name,\n                   'size': size, 'unit': units, 'easytier': easytier,\n                   'ssh_cmd_se_opt': ssh_cmd_se_opt})\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), '_create_vdisk',\n                                ssh_cmd, out, err)\n\n        # Ensure that the output is as expected\n        match_obj = re.search('Virtual Disk, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('_create_vdisk %(name)s - did not find '\n              'success message in CLI output.\\n '\n              'stdout: %(out)s\\n stderr: %(err)s')\n            % {'name': name, 'out': str(out), 'err': str(err)})\n\n        LOG.debug(_('leave: _create_vdisk: volume %s ') % name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a virtual disk with options for size, auto-expansion, easy tier, and compression."}
{"func_name": "ims_pcu_get_cdc_union_desc", "func_src_before": "static const struct usb_cdc_union_desc *\nims_pcu_get_cdc_union_desc(struct usb_interface *intf)\n{\n\tconst void *buf = intf->altsetting->extra;\n\tsize_t buflen = intf->altsetting->extralen;\n\tstruct usb_cdc_union_desc *union_desc;\n\n\tif (!buf) {\n\t\tdev_err(&intf->dev, \"Missing descriptor data\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!buflen) {\n\t\tdev_err(&intf->dev, \"Zero length descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\twhile (buflen > 0) {\n\t\tunion_desc = (struct usb_cdc_union_desc *)buf;\n\n\t\tif (union_desc->bDescriptorType == USB_DT_CS_INTERFACE &&\n\t\t    union_desc->bDescriptorSubType == USB_CDC_UNION_TYPE) {\n\t\t\tdev_dbg(&intf->dev, \"Found union header\\n\");\n\t\t\treturn union_desc;\n\t\t}\n\n\t\tbuflen -= union_desc->bLength;\n\t\tbuf += union_desc->bLength;\n\t}\n\n\tdev_err(&intf->dev, \"Missing CDC union descriptor\\n\");\n\treturn NULL;", "func_src_after": "static const struct usb_cdc_union_desc *\nims_pcu_get_cdc_union_desc(struct usb_interface *intf)\n{\n\tconst void *buf = intf->altsetting->extra;\n\tsize_t buflen = intf->altsetting->extralen;\n\tstruct usb_cdc_union_desc *union_desc;\n\n\tif (!buf) {\n\t\tdev_err(&intf->dev, \"Missing descriptor data\\n\");\n\t\treturn NULL;\n\t}\n\n\tif (!buflen) {\n\t\tdev_err(&intf->dev, \"Zero length descriptor\\n\");\n\t\treturn NULL;\n\t}\n\n\twhile (buflen >= sizeof(*union_desc)) {\n\t\tunion_desc = (struct usb_cdc_union_desc *)buf;\n\n\t\tif (union_desc->bLength > buflen) {\n\t\t\tdev_err(&intf->dev, \"Too large descriptor\\n\");\n\t\t\treturn NULL;\n\t\t}\n\n\t\tif (union_desc->bDescriptorType == USB_DT_CS_INTERFACE &&\n\t\t    union_desc->bDescriptorSubType == USB_CDC_UNION_TYPE) {\n\t\t\tdev_dbg(&intf->dev, \"Found union header\\n\");\n\n\t\t\tif (union_desc->bLength >= sizeof(*union_desc))\n\t\t\t\treturn union_desc;\n\n\t\t\tdev_err(&intf->dev,\n\t\t\t\t\"Union descriptor to short (%d vs %zd\\n)\",\n\t\t\t\tunion_desc->bLength, sizeof(*union_desc));\n\t\t\treturn NULL;\n\t\t}\n\n\t\tbuflen -= union_desc->bLength;\n\t\tbuf += union_desc->bLength;\n\t}\n\n\tdev_err(&intf->dev, \"Missing CDC union descriptor\\n\");\n\treturn NULL;", "commit_link": "github.com/torvalds/linux/commit/ea04efee7635c9120d015dcdeeeb6988130cb67a", "file_name": "drivers/input/misc/ims-pcu.c", "vul_type": "cwe-125", "description": "Write a C function to find and return the CDC union descriptor from a USB interface's alternate setting descriptor data."}
{"func_name": "add_language", "func_src_before": "def add_language(lang):\n    try:\n        cur.execute(\"INSERT INTO language (name) VALUES (%s)\", (lang, ))\n    except Exception as e:\n        pass\n    cur.execute(\"SELECT language_id FROM language where name=%s\", (lang, ))\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "func_src_after": "def add_language(lang):\n    try:\n        cur.execute(f\"INSERT INTO language (name) VALUES ('{lang}')\")\n    except Exception as e:\n        pass\n    cur.execute(f\"SELECT language_id FROM language where name='{lang}'\")\n    lang_id = cur.fetchone()[0]\n    if conn.commit():\n        return lang_id\n    return lang_id", "commit_link": "github.com/Elbertbiggs360/dvdrental/commit/ad144ae2a08a332498d0831bc255170d57ba754b", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new language into a database and return its ID, handling exceptions silently."}
{"func_name": "patch", "func_src_before": "    @jwt_required\n    def patch(self, user_id):\n        \"\"\" Replaces information of corresponding user_id with request body \"\"\"\n        query = f\"\"\"update users set user_id = %s \"\"\"\n        query += f\"\"\"where user_id = '{user_id}'\"\"\"\n        json_data = request.get_json()\n        parameters = (json_data['user_id'], )\n        database_utilities.execute_query(query, parameters)", "func_src_after": "    @jwt_required\n    def patch(self, user_id):\n        \"\"\" Replaces information of corresponding user_id with request body \"\"\"\n        query = f\"\"\"update users set user_id = %s \"\"\"\n        query += f\"\"\"where user_id = %s\"\"\"\n        json_data = request.get_json()\n        parameters = (json_data['user_id'], user_id)\n        database_utilities.execute_query(query, parameters)", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Write a Python function to update a user's ID in the database using JWT authentication and the user's ID from the request body."}
{"func_name": "WriteHDRImage", "func_src_before": "static MagickBooleanType WriteHDRImage(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  char\n    header[MagickPathExtent];\n\n  const char\n    *property;\n\n  MagickBooleanType\n    status;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i,\n    x;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    pixel[4],\n    *pixels;\n\n  /*\n    Open output image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(status);\n  if (IsRGBColorspace(image->colorspace) == MagickFalse)\n    (void) TransformImageColorspace(image,RGBColorspace,exception);\n  /*\n    Write header.\n  */\n  (void) ResetMagickMemory(header,' ',MagickPathExtent);\n  length=CopyMagickString(header,\"#?RGBE\\n\",MagickPathExtent);\n  (void) WriteBlob(image,length,(unsigned char *) header);\n  property=GetImageProperty(image,\"comment\",exception);\n  if ((property != (const char *) NULL) &&\n      (strchr(property,'\\n') == (char *) NULL))\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"#%s\\n\",property);\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  property=GetImageProperty(image,\"hdr:exposure\",exception);\n  if (property != (const char *) NULL)\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"EXPOSURE=%g\\n\",\n        strtod(property,(char **) NULL));\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  if (image->gamma != 0.0)\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"GAMMA=%g\\n\",image->gamma);\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  count=FormatLocaleString(header,MagickPathExtent,\n    \"PRIMARIES=%g %g %g %g %g %g %g %g\\n\",\n    image->chromaticity.red_primary.x,image->chromaticity.red_primary.y,\n    image->chromaticity.green_primary.x,image->chromaticity.green_primary.y,\n    image->chromaticity.blue_primary.x,image->chromaticity.blue_primary.y,\n    image->chromaticity.white_point.x,image->chromaticity.white_point.y);\n  (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n  length=CopyMagickString(header,\"FORMAT=32-bit_rle_rgbe\\n\\n\",MagickPathExtent);\n  (void) WriteBlob(image,length,(unsigned char *) header);\n  count=FormatLocaleString(header,MagickPathExtent,\"-Y %.20g +X %.20g\\n\",\n    (double) image->rows,(double) image->columns);\n  (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n  /*\n    Write HDR pixels.\n  */\n  pixels=(unsigned char *) AcquireQuantumMemory(image->columns,4*\n    sizeof(*pixels));\n  if (pixels == (unsigned char *) NULL)\n    ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n      {\n        pixel[0]=2;\n        pixel[1]=2;\n        pixel[2]=(unsigned char) (image->columns >> 8);\n        pixel[3]=(unsigned char) (image->columns & 0xff);\n        count=WriteBlob(image,4*sizeof(*pixel),pixel);\n        if (count != (ssize_t) (4*sizeof(*pixel)))\n          break;\n      }\n    i=0;\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      double\n        gamma;\n\n      pixel[0]=0;\n      pixel[1]=0;\n      pixel[2]=0;\n      pixel[3]=0;\n      gamma=QuantumScale*GetPixelRed(image,p);\n      if ((QuantumScale*GetPixelGreen(image,p)) > gamma)\n        gamma=QuantumScale*GetPixelGreen(image,p);\n      if ((QuantumScale*GetPixelBlue(image,p)) > gamma)\n        gamma=QuantumScale*GetPixelBlue(image,p);\n      if (gamma > MagickEpsilon)\n        {\n          int\n            exponent;\n\n          gamma=frexp(gamma,&exponent)*256.0/gamma;\n          pixel[0]=(unsigned char) (gamma*QuantumScale*GetPixelRed(image,p));\n          pixel[1]=(unsigned char) (gamma*QuantumScale*GetPixelGreen(image,p));\n          pixel[2]=(unsigned char) (gamma*QuantumScale*GetPixelBlue(image,p));\n          pixel[3]=(unsigned char) (exponent+128);\n        }\n      if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n        {\n          pixels[x]=pixel[0];\n          pixels[x+image->columns]=pixel[1];\n          pixels[x+2*image->columns]=pixel[2];\n          pixels[x+3*image->columns]=pixel[3];\n        }\n      else\n        {\n          pixels[i++]=pixel[0];\n          pixels[i++]=pixel[1];\n          pixels[i++]=pixel[2];\n          pixels[i++]=pixel[3];\n        }\n      p+=GetPixelChannels(image);\n    }\n    if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n      {\n        for (i=0; i < 4; i++)\n          length=HDRWriteRunlengthPixels(image,&pixels[i*image->columns]);\n      }\n    else\n      {\n        count=WriteBlob(image,4*image->columns*sizeof(*pixels),pixels);\n        if (count != (ssize_t) (4*image->columns*sizeof(*pixels)))\n          break;\n      }\n    status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n      image->rows);\n    if (status == MagickFalse)\n      break;\n  }\n  pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n  (void) CloseBlob(image);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType WriteHDRImage(const ImageInfo *image_info,Image *image,\n  ExceptionInfo *exception)\n{\n  char\n    header[MagickPathExtent];\n\n  const char\n    *property;\n\n  MagickBooleanType\n    status;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i,\n    x;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    pixel[4],\n    *pixels;\n\n  /*\n    Open output image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  assert(image != (Image *) NULL);\n  assert(image->signature == MagickCoreSignature);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  status=OpenBlob(image_info,image,WriteBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(status);\n  if (IsRGBColorspace(image->colorspace) == MagickFalse)\n    (void) TransformImageColorspace(image,RGBColorspace,exception);\n  /*\n    Write header.\n  */\n  (void) ResetMagickMemory(header,' ',MagickPathExtent);\n  length=CopyMagickString(header,\"#?RGBE\\n\",MagickPathExtent);\n  (void) WriteBlob(image,length,(unsigned char *) header);\n  property=GetImageProperty(image,\"comment\",exception);\n  if ((property != (const char *) NULL) &&\n      (strchr(property,'\\n') == (char *) NULL))\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"#%s\\n\",property);\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  property=GetImageProperty(image,\"hdr:exposure\",exception);\n  if (property != (const char *) NULL)\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"EXPOSURE=%g\\n\",\n        strtod(property,(char **) NULL));\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  if (image->gamma != 0.0)\n    {\n      count=FormatLocaleString(header,MagickPathExtent,\"GAMMA=%g\\n\",\n        image->gamma);\n      (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n    }\n  count=FormatLocaleString(header,MagickPathExtent,\n    \"PRIMARIES=%g %g %g %g %g %g %g %g\\n\",\n    image->chromaticity.red_primary.x,image->chromaticity.red_primary.y,\n    image->chromaticity.green_primary.x,image->chromaticity.green_primary.y,\n    image->chromaticity.blue_primary.x,image->chromaticity.blue_primary.y,\n    image->chromaticity.white_point.x,image->chromaticity.white_point.y);\n  (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n  length=CopyMagickString(header,\"FORMAT=32-bit_rle_rgbe\\n\\n\",MagickPathExtent);\n  (void) WriteBlob(image,length,(unsigned char *) header);\n  count=FormatLocaleString(header,MagickPathExtent,\"-Y %.20g +X %.20g\\n\",\n    (double) image->rows,(double) image->columns);\n  (void) WriteBlob(image,(size_t) count,(unsigned char *) header);\n  /*\n    Write HDR pixels.\n  */\n  pixels=(unsigned char *) AcquireQuantumMemory(image->columns+128,4*\n    sizeof(*pixels));\n  if (pixels == (unsigned char *) NULL)\n    ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n  (void) ResetMagickMemory(pixels,0,4*(image->columns+128)*sizeof(*pixels));\n  for (y=0; y < (ssize_t) image->rows; y++)\n  {\n    p=GetVirtualPixels(image,0,y,image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n      {\n        pixel[0]=2;\n        pixel[1]=2;\n        pixel[2]=(unsigned char) (image->columns >> 8);\n        pixel[3]=(unsigned char) (image->columns & 0xff);\n        count=WriteBlob(image,4*sizeof(*pixel),pixel);\n        if (count != (ssize_t) (4*sizeof(*pixel)))\n          break;\n      }\n    i=0;\n    for (x=0; x < (ssize_t) image->columns; x++)\n    {\n      double\n        gamma;\n\n      pixel[0]=0;\n      pixel[1]=0;\n      pixel[2]=0;\n      pixel[3]=0;\n      gamma=QuantumScale*GetPixelRed(image,p);\n      if ((QuantumScale*GetPixelGreen(image,p)) > gamma)\n        gamma=QuantumScale*GetPixelGreen(image,p);\n      if ((QuantumScale*GetPixelBlue(image,p)) > gamma)\n        gamma=QuantumScale*GetPixelBlue(image,p);\n      if (gamma > MagickEpsilon)\n        {\n          int\n            exponent;\n\n          gamma=frexp(gamma,&exponent)*256.0/gamma;\n          pixel[0]=(unsigned char) (gamma*QuantumScale*GetPixelRed(image,p));\n          pixel[1]=(unsigned char) (gamma*QuantumScale*GetPixelGreen(image,p));\n          pixel[2]=(unsigned char) (gamma*QuantumScale*GetPixelBlue(image,p));\n          pixel[3]=(unsigned char) (exponent+128);\n        }\n      if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n        {\n          pixels[x]=pixel[0];\n          pixels[x+image->columns]=pixel[1];\n          pixels[x+2*image->columns]=pixel[2];\n          pixels[x+3*image->columns]=pixel[3];\n        }\n      else\n        {\n          pixels[i++]=pixel[0];\n          pixels[i++]=pixel[1];\n          pixels[i++]=pixel[2];\n          pixels[i++]=pixel[3];\n        }\n      p+=GetPixelChannels(image);\n    }\n    if ((image->columns >= 8) && (image->columns <= 0x7ffff))\n      {\n        for (i=0; i < 4; i++)\n          length=HDRWriteRunlengthPixels(image,&pixels[i*image->columns]);\n      }\n    else\n      {\n        count=WriteBlob(image,4*image->columns*sizeof(*pixels),pixels);\n        if (count != (ssize_t) (4*image->columns*sizeof(*pixels)))\n          break;\n      }\n    status=SetImageProgress(image,SaveImageTag,(MagickOffsetType) y,\n      image->rows);\n    if (status == MagickFalse)\n      break;\n  }\n  pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n  (void) CloseBlob(image);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/14e606db148d6ebcaae20f1e1d6d71903ca4a556", "file_name": "coders/hdr.c", "vul_type": "cwe-125", "description": "Write a C function to output an HDR image file using ImageMagick's API."}
{"func_name": "UnicodeString::doAppend", "func_src_before": "UnicodeString::doAppend(const UChar *srcChars, int32_t srcStart, int32_t srcLength) {\n  if(!isWritable() || srcLength == 0 || srcChars == NULL) {\n    return *this;\n  }\n\n  // Perform all remaining operations relative to srcChars + srcStart.\n  // From this point forward, do not use srcStart.\n  srcChars += srcStart;\n\n  if(srcLength < 0) {\n    // get the srcLength if necessary\n    if((srcLength = u_strlen(srcChars)) == 0) {\n      return *this;\n    }\n  }\n\n  int32_t oldLength = length();\n  int32_t newLength = oldLength + srcLength;\n\n  // Check for append onto ourself\n  const UChar* oldArray = getArrayStart();\n  if (isBufferWritable() &&\n      oldArray < srcChars + srcLength &&\n      srcChars < oldArray + oldLength) {\n    // Copy into a new UnicodeString and start over\n    UnicodeString copy(srcChars, srcLength);\n    if (copy.isBogus()) {\n      setToBogus();\n      return *this;\n    }\n    return doAppend(copy.getArrayStart(), 0, srcLength);\n  }\n\n  // optimize append() onto a large-enough, owned string\n  if((newLength <= getCapacity() && isBufferWritable()) ||\n      cloneArrayIfNeeded(newLength, getGrowCapacity(newLength))) {\n    UChar *newArray = getArrayStart();\n    // Do not copy characters when\n    //   UChar *buffer=str.getAppendBuffer(...);\n    // is followed by\n    //   str.append(buffer, length);\n    // or\n    //   str.appendString(buffer, length)\n    // or similar.\n    if(srcChars != newArray + oldLength) {\n      us_arrayCopy(srcChars, 0, newArray, oldLength, srcLength);\n    }\n    setLength(newLength);\n  }\n  return *this;\n}", "func_src_after": "UnicodeString::doAppend(const UChar *srcChars, int32_t srcStart, int32_t srcLength) {\n  if(!isWritable() || srcLength == 0 || srcChars == NULL) {\n    return *this;\n  }\n\n  // Perform all remaining operations relative to srcChars + srcStart.\n  // From this point forward, do not use srcStart.\n  srcChars += srcStart;\n\n  if(srcLength < 0) {\n    // get the srcLength if necessary\n    if((srcLength = u_strlen(srcChars)) == 0) {\n      return *this;\n    }\n  }\n\n  int32_t oldLength = length();\n  int32_t newLength;\n  if (uprv_add32_overflow(oldLength, srcLength, &newLength)) {\n    setToBogus();\n    return *this;\n  }\n\n  // Check for append onto ourself\n  const UChar* oldArray = getArrayStart();\n  if (isBufferWritable() &&\n      oldArray < srcChars + srcLength &&\n      srcChars < oldArray + oldLength) {\n    // Copy into a new UnicodeString and start over\n    UnicodeString copy(srcChars, srcLength);\n    if (copy.isBogus()) {\n      setToBogus();\n      return *this;\n    }\n    return doAppend(copy.getArrayStart(), 0, srcLength);\n  }\n\n  // optimize append() onto a large-enough, owned string\n  if((newLength <= getCapacity() && isBufferWritable()) ||\n      cloneArrayIfNeeded(newLength, getGrowCapacity(newLength))) {\n    UChar *newArray = getArrayStart();\n    // Do not copy characters when\n    //   UChar *buffer=str.getAppendBuffer(...);\n    // is followed by\n    //   str.append(buffer, length);\n    // or\n    //   str.appendString(buffer, length)\n    // or similar.\n    if(srcChars != newArray + oldLength) {\n      us_arrayCopy(srcChars, 0, newArray, oldLength, srcLength);\n    }\n    setLength(newLength);\n  }\n  return *this;\n}", "commit_link": "github.com/unicode-org/icu/commit/b7d08bc04a4296982fcef8b6b8a354a9e4e7afca", "file_name": "icu4c/source/common/unistr.cpp", "vul_type": "cwe-190", "description": "In C++, write a method `doAppend` for the `UnicodeString` class that appends a substring to the current string, handling memory allocation and avoiding self-appending issues."}
{"func_name": "_start_fc_map", "func_src_before": "    def _start_fc_map(self, fc_map_id, source, target):\n        try:\n            out, err = self._run_ssh('svctask startfcmap %s' % fc_map_id)\n        except exception.ProcessExecutionError as e:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_('_start_fc_map: Failed to start FlashCopy '\n                            'from %(source)s to %(target)s.\\n'\n                            'stdout: %(out)s\\n stderr: %(err)s')\n                          % {'source': source,\n                             'target': target,\n                             'out': e.stdout,\n                             'err': e.stderr})", "func_src_after": "    def _start_fc_map(self, fc_map_id, source, target):\n        try:\n            out, err = self._run_ssh(['svctask', 'startfcmap', fc_map_id])\n        except exception.ProcessExecutionError as e:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_('_start_fc_map: Failed to start FlashCopy '\n                            'from %(source)s to %(target)s.\\n'\n                            'stdout: %(out)s\\n stderr: %(err)s')\n                          % {'source': source,\n                             'target': target,\n                             'out': e.stdout,\n                             'err': e.stderr})", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to initiate a FlashCopy operation over SSH and handle any execution errors with logging."}
{"func_name": "_update_volume_stats", "func_src_before": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = ['svcinfo', 'lssystem', '-delim', '!']\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-bytes', '-delim', '!', pool]\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "func_src_after": "    def _update_volume_stats(self):\n        \"\"\"Retrieve stats info from volume group.\"\"\"\n\n        LOG.debug(_(\"Updating volume stats\"))\n        data = {}\n\n        data['vendor_name'] = 'IBM'\n        data['driver_version'] = '1.1'\n        data['storage_protocol'] = list(self._enabled_protocols)\n\n        data['total_capacity_gb'] = 0  # To be overwritten\n        data['free_capacity_gb'] = 0   # To be overwritten\n        data['reserved_percentage'] = 0\n        data['QoS_support'] = False\n\n        pool = self.configuration.storwize_svc_volpool_name\n        #Get storage system name\n        ssh_cmd = 'svcinfo lssystem -delim !'\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes or not attributes['name']:\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get system name'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        backend_name = self.configuration.safe_get('volume_backend_name')\n        if not backend_name:\n            backend_name = '%s_%s' % (attributes['name'], pool)\n        data['volume_backend_name'] = backend_name\n\n        ssh_cmd = 'svcinfo lsmdiskgrp -bytes -delim ! %s' % pool\n        attributes = self._execute_command_and_parse_attributes(ssh_cmd)\n        if not attributes:\n            LOG.error(_('Could not get pool data from the storage'))\n            exception_message = (_('_update_volume_stats: '\n                                   'Could not get storage pool data'))\n            raise exception.VolumeBackendAPIException(data=exception_message)\n\n        data['total_capacity_gb'] = (float(attributes['capacity']) /\n                                    (1024 ** 3))\n        data['free_capacity_gb'] = (float(attributes['free_capacity']) /\n                                    (1024 ** 3))\n        data['easytier_support'] = attributes['easy_tier'] in ['on', 'auto']\n        data['compression_support'] = self._compression_enabled\n\n        self._stats = data", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to update storage volume statistics with IBM vendor details and capacity information."}
{"func_name": "test", "func_src_before": "@mod.route('/test', methods=['GET', 'POST'])\ndef test():\n    user_id = session['logged_id']\n    cursor.execute('SELECT * FROM message where user_id = %s ORDER BY c_time DESC', (user_id,))\n    m = cursor.fetchall()\n    print(m)", "func_src_after": "@mod.route('/test', methods=['GET', 'POST'])\ndef test():\n    user_id = session['logged_id']\n    sql = 'SELECT * FROM message where user_id = %d ORDER BY c_time DESC' \\\n        % (user_id)\n    cursor.execute(sql)\n    m = cursor.fetchall()\n    print(m)", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/message.py", "vul_type": "cwe-089", "description": "Create a Python Flask route function that retrieves and prints all messages for the logged-in user, ordered by creation time in descending order."}
{"func_name": "patch", "func_src_before": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "func_src_after": "static PyObject* patch(PyObject* self, PyObject* args)\n{\n    char *origData, *newData, *diffBlock, *extraBlock, *diffPtr, *extraPtr;\n    Py_ssize_t origDataLength, newDataLength, diffBlockLength, extraBlockLength;\n    PyObject *controlTuples, *tuple, *results;\n    off_t oldpos, newpos, x, y, z;\n    int i, j, numTuples;\n\n    if (!PyArg_ParseTuple(args, \"s#nO!s#s#\",\n                          &origData, &origDataLength, &newDataLength,\n                          &PyList_Type, &controlTuples,\n                          &diffBlock, &diffBlockLength,\n                          &extraBlock, &extraBlockLength))\n        return NULL;\n\n    /* allocate the memory for the new data */\n    newData = PyMem_Malloc(newDataLength + 1);\n    if (!newData)\n        return PyErr_NoMemory();\n\n    oldpos = 0;\n    newpos = 0;\n    diffPtr = diffBlock;\n    extraPtr = extraBlock;\n    numTuples = PyList_GET_SIZE(controlTuples);\n    for (i = 0; i < numTuples; i++) {\n        tuple = PyList_GET_ITEM(controlTuples, i);\n        if (!PyTuple_Check(tuple)) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple\");\n            return NULL;\n        }\n        if (PyTuple_GET_SIZE(tuple) != 3) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_TypeError, \"expecting tuple of size 3\");\n            return NULL;\n        }\n        x = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 0));\n        y = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 1));\n        z = PyLong_AsLong(PyTuple_GET_ITEM(tuple, 2));\n        if (newpos + x > newDataLength ||\n                diffPtr + x > diffBlock + diffBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, diffPtr, x);\n        diffPtr += x;\n        for (j = 0; j < x; j++)\n            if ((oldpos + j >= 0) && (oldpos + j < origDataLength))\n                newData[newpos + j] += origData[oldpos + j];\n        newpos += x;\n        oldpos += x;\n        if (newpos + y > newDataLength ||\n                extraPtr + y > extraBlock + extraBlockLength) {\n            PyMem_Free(newData);\n            PyErr_SetString(PyExc_ValueError, \"corrupt patch (overflow)\");\n            return NULL;\n        }\n        memcpy(newData + newpos, extraPtr, y);\n        extraPtr += y;\n        newpos += y;\n        oldpos += z;\n    }\n\n    /* confirm that a valid patch was applied */\n    if (newpos != newDataLength ||\n            diffPtr != diffBlock + diffBlockLength ||\n            extraPtr != extraBlock + extraBlockLength) {\n        PyMem_Free(newData);\n        PyErr_SetString(PyExc_ValueError, \"corrupt patch (underflow)\");\n        return NULL;\n    }\n\n    results = PyBytes_FromStringAndSize(newData, newDataLength);\n    PyMem_Free(newData);\n    return results;\n}", "commit_link": "github.com/ilanschnell/bsdiff4/commit/49a4cee2feef7deaf9d89e5e793a8824930284d7", "file_name": "bsdiff4/core.c", "vul_type": "cwe-787", "description": "Write a Python C extension function named `patch` that applies a binary patch to given data using control tuples and diff/extra blocks."}
{"func_name": "get_top_author", "func_src_before": "def get_top_author(top_num):\r\n    \"\"\" query the top(top_num) popular author\r\n        top_num => list of [author, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT authors.name,author_result.num\r\n                    FROM authors JOIN\r\n                    (SELECT SUM(article_result.num) as num,\r\n                    article_result.author\r\n                    from (SELECT articles.title, articles.author,\r\n                    SUM(log.views) AS num\r\n                    FROM articles\r\n                    INNER JOIN (\r\n                    SELECT path, count(path) AS views\r\n                    FROM log GROUP BY log.path\r\n                    ) AS log ON log.path = '/article/'\r\n                    || articles.slug\r\n                    GROUP BY articles.title, articles.author)\r\n                    AS article_result\r\n                    GROUP BY article_result.author) as author_result\r\n                    ON authors.id = author_result.author\r\n                    ORDER BY num DESC LIMIT {}\"\"\".format(top_num)\r\n    return execute_query(cmd)", "func_src_after": "def get_top_author(top_num):\r\n    \"\"\" query the top(top_num) popular author\r\n        top_num => list of [author, count]\r\n    \"\"\"\r\n    cmd = \"\"\"SELECT authors.name,author_result.num\r\n                    FROM authors JOIN\r\n                    (SELECT SUM(article_result.num) as num,\r\n                    article_result.author\r\n                    from (SELECT articles.title, articles.author,\r\n                    SUM(log.views) AS num\r\n                    FROM articles\r\n                    INNER JOIN (\r\n                    SELECT path, count(path) AS views\r\n                    FROM log GROUP BY log.path\r\n                    ) AS log ON log.path = '/article/'\r\n                    || articles.slug\r\n                    GROUP BY articles.title, articles.author)\r\n                    AS article_result\r\n                    GROUP BY article_result.author) as author_result\r\n                    ON authors.id = author_result.author\r\n                    ORDER BY num DESC LIMIT %s\"\"\"\r\n    data = [top_num, ]\r\n    return execute_query(cmd, data)", "commit_link": "github.com/thugasin/udacity-homework-logAnalyzer/commit/506f25f9a1caee7f17034adf7c75e0efbc88082b", "file_name": "logAnalyzerDb.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the top N authors by popularity from a database, using SQL queries."}
{"func_name": "ffs_user_copy_worker", "func_src_before": "static void ffs_user_copy_worker(struct work_struct *work)\n{\n\tstruct ffs_io_data *io_data = container_of(work, struct ffs_io_data,\n\t\t\t\t\t\t   work);\n\tint ret = io_data->req->status ? io_data->req->status :\n\t\t\t\t\t io_data->req->actual;\n\n\tif (io_data->read && ret > 0) {\n\t\tuse_mm(io_data->mm);\n\t\tret = copy_to_iter(io_data->buf, ret, &io_data->data);\n\t\tif (iov_iter_count(&io_data->data))\n\t\t\tret = -EFAULT;\n\t\tunuse_mm(io_data->mm);\n\t}\n\n\tio_data->kiocb->ki_complete(io_data->kiocb, ret, ret);\n\n\tif (io_data->ffs->ffs_eventfd &&\n\t    !(io_data->kiocb->ki_flags & IOCB_EVENTFD))\n\t\teventfd_signal(io_data->ffs->ffs_eventfd, 1);\n\n\tusb_ep_free_request(io_data->ep, io_data->req);\n\n\tio_data->kiocb->private = NULL;\n\tif (io_data->read)\n\t\tkfree(io_data->to_free);\n\tkfree(io_data->buf);\n\tkfree(io_data);\n}", "func_src_after": "static void ffs_user_copy_worker(struct work_struct *work)\n{\n\tstruct ffs_io_data *io_data = container_of(work, struct ffs_io_data,\n\t\t\t\t\t\t   work);\n\tint ret = io_data->req->status ? io_data->req->status :\n\t\t\t\t\t io_data->req->actual;\n\tbool kiocb_has_eventfd = io_data->kiocb->ki_flags & IOCB_EVENTFD;\n\n\tif (io_data->read && ret > 0) {\n\t\tuse_mm(io_data->mm);\n\t\tret = copy_to_iter(io_data->buf, ret, &io_data->data);\n\t\tif (iov_iter_count(&io_data->data))\n\t\t\tret = -EFAULT;\n\t\tunuse_mm(io_data->mm);\n\t}\n\n\tio_data->kiocb->ki_complete(io_data->kiocb, ret, ret);\n\n\tif (io_data->ffs->ffs_eventfd && !kiocb_has_eventfd)\n\t\teventfd_signal(io_data->ffs->ffs_eventfd, 1);\n\n\tusb_ep_free_request(io_data->ep, io_data->req);\n\n\tif (io_data->read)\n\t\tkfree(io_data->to_free);\n\tkfree(io_data->buf);\n\tkfree(io_data);\n}", "commit_link": "github.com/torvalds/linux/commit/38740a5b87d53ceb89eb2c970150f6e94e00373a", "file_name": "drivers/usb/gadget/function/f_fs.c", "vul_type": "cwe-416", "description": "Write a C function named `ffs_user_copy_worker` that processes I/O data for a USB function filesystem."}
{"func_name": "Mat_VarReadNextInfo4", "func_src_before": "Mat_VarReadNextInfo4(mat_t *mat)\n{\n    int       M,O,data_type,class_type;\n    mat_int32_t tmp;\n    long      nBytes;\n    size_t    readresult;\n    matvar_t *matvar = NULL;\n    union {\n        mat_uint32_t u;\n        mat_uint8_t  c[4];\n    } endian;\n\n    if ( mat == NULL || mat->fp == NULL )\n        return NULL;\n    else if ( NULL == (matvar = Mat_VarCalloc()) )\n        return NULL;\n\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    endian.u = 0x01020304;\n\n    /* See if MOPT may need byteswapping */\n    if ( tmp < 0 || tmp > 4052 ) {\n        if ( Mat_int32Swap(&tmp) > 4052 ) {\n            Mat_VarFree(matvar);\n            return NULL;\n        }\n    }\n\n    M = (int)floor(tmp / 1000.0);\n    switch ( M ) {\n        case 0:\n            /* IEEE little endian */\n            mat->byteswap = endian.c[0] != 4;\n            break;\n        case 1:\n            /* IEEE big endian */\n            mat->byteswap = endian.c[0] != 1;\n            break;\n        default:\n            /* VAX, Cray, or bogus */\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= M*1000;\n    O = (int)floor(tmp / 100.0);\n    /* O must be zero */\n    if ( 0 != O ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    tmp -= O*100;\n    data_type = (int)floor(tmp / 10.0);\n    /* Convert the V4 data type */\n    switch ( data_type ) {\n        case 0:\n            matvar->data_type = MAT_T_DOUBLE;\n            break;\n        case 1:\n            matvar->data_type = MAT_T_SINGLE;\n            break;\n        case 2:\n            matvar->data_type = MAT_T_INT32;\n            break;\n        case 3:\n            matvar->data_type = MAT_T_INT16;\n            break;\n        case 4:\n            matvar->data_type = MAT_T_UINT16;\n            break;\n        case 5:\n            matvar->data_type = MAT_T_UINT8;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= data_type*10;\n    class_type = (int)floor(tmp / 1.0);\n    switch ( class_type ) {\n        case 0:\n            matvar->class_type = MAT_C_DOUBLE;\n            break;\n        case 1:\n            matvar->class_type = MAT_C_CHAR;\n            break;\n        case 2:\n            matvar->class_type = MAT_C_SPARSE;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    matvar->rank = 2;\n    matvar->dims = (size_t*)calloc(2, sizeof(*matvar->dims));\n    if ( NULL == matvar->dims ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[0] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[1] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    readresult = fread(&(matvar->isComplex),sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( matvar->isComplex && MAT_C_CHAR == matvar->class_type ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    /* Check that the length of the variable name is at least 1 */\n    if ( tmp < 1 ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    matvar->name = (char*)malloc(tmp);\n    if ( NULL == matvar->name ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(matvar->name,1,tmp,(FILE*)mat->fp);\n    if ( tmp != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    matvar->internal->datapos = ftell((FILE*)mat->fp);\n    if ( matvar->internal->datapos == -1L ) {\n        Mat_VarFree(matvar);\n        Mat_Critical(\"Couldn't determine file position\");\n        return NULL;\n    }\n    {\n        int err;\n        size_t tmp2 = Mat_SizeOf(matvar->data_type);\n        if ( matvar->isComplex )\n            tmp2 *= 2;\n        err = SafeMulDims(matvar, &tmp2);\n        if ( err ) {\n            Mat_VarFree(matvar);\n            Mat_Critical(\"Integer multiplication overflow\");\n            return NULL;\n        }\n\n        nBytes = (long)tmp2;\n    }\n    (void)fseek((FILE*)mat->fp,nBytes,SEEK_CUR);\n\n    return matvar;\n}", "func_src_after": "Mat_VarReadNextInfo4(mat_t *mat)\n{\n    int       M,O,data_type,class_type;\n    mat_int32_t tmp;\n    long      nBytes;\n    size_t    readresult;\n    matvar_t *matvar = NULL;\n    union {\n        mat_uint32_t u;\n        mat_uint8_t  c[4];\n    } endian;\n\n    if ( mat == NULL || mat->fp == NULL )\n        return NULL;\n    else if ( NULL == (matvar = Mat_VarCalloc()) )\n        return NULL;\n\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    endian.u = 0x01020304;\n\n    /* See if MOPT may need byteswapping */\n    if ( tmp < 0 || tmp > 4052 ) {\n        if ( Mat_int32Swap(&tmp) > 4052 ) {\n            Mat_VarFree(matvar);\n            return NULL;\n        }\n    }\n\n    M = (int)floor(tmp / 1000.0);\n    switch ( M ) {\n        case 0:\n            /* IEEE little endian */\n            mat->byteswap = endian.c[0] != 4;\n            break;\n        case 1:\n            /* IEEE big endian */\n            mat->byteswap = endian.c[0] != 1;\n            break;\n        default:\n            /* VAX, Cray, or bogus */\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= M*1000;\n    O = (int)floor(tmp / 100.0);\n    /* O must be zero */\n    if ( 0 != O ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    tmp -= O*100;\n    data_type = (int)floor(tmp / 10.0);\n    /* Convert the V4 data type */\n    switch ( data_type ) {\n        case 0:\n            matvar->data_type = MAT_T_DOUBLE;\n            break;\n        case 1:\n            matvar->data_type = MAT_T_SINGLE;\n            break;\n        case 2:\n            matvar->data_type = MAT_T_INT32;\n            break;\n        case 3:\n            matvar->data_type = MAT_T_INT16;\n            break;\n        case 4:\n            matvar->data_type = MAT_T_UINT16;\n            break;\n        case 5:\n            matvar->data_type = MAT_T_UINT8;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    tmp -= data_type*10;\n    class_type = (int)floor(tmp / 1.0);\n    switch ( class_type ) {\n        case 0:\n            matvar->class_type = MAT_C_DOUBLE;\n            break;\n        case 1:\n            matvar->class_type = MAT_C_CHAR;\n            break;\n        case 2:\n            matvar->class_type = MAT_C_SPARSE;\n            break;\n        default:\n            Mat_VarFree(matvar);\n            return NULL;\n    }\n\n    matvar->rank = 2;\n    matvar->dims = (size_t*)calloc(2, sizeof(*matvar->dims));\n    if ( NULL == matvar->dims ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[0] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    matvar->dims[1] = tmp;\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n\n    readresult = fread(&(matvar->isComplex),sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( matvar->isComplex && MAT_C_CHAR == matvar->class_type ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(&tmp,sizeof(int),1,(FILE*)mat->fp);\n    if ( 1 != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    if ( mat->byteswap )\n        Mat_int32Swap(&tmp);\n    /* Check that the length of the variable name is at least 1 */\n    if ( tmp < 1 ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    matvar->name = (char*)malloc(tmp);\n    if ( NULL == matvar->name ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    }\n    readresult = fread(matvar->name,1,tmp,(FILE*)mat->fp);\n    if ( tmp != readresult ) {\n        Mat_VarFree(matvar);\n        return NULL;\n    } else {\n        matvar->name[tmp - 1] = '\\0';\n    }\n\n    matvar->internal->datapos = ftell((FILE*)mat->fp);\n    if ( matvar->internal->datapos == -1L ) {\n        Mat_VarFree(matvar);\n        Mat_Critical(\"Couldn't determine file position\");\n        return NULL;\n    }\n    {\n        int err;\n        size_t tmp2 = Mat_SizeOf(matvar->data_type);\n        if ( matvar->isComplex )\n            tmp2 *= 2;\n        err = SafeMulDims(matvar, &tmp2);\n        if ( err ) {\n            Mat_VarFree(matvar);\n            Mat_Critical(\"Integer multiplication overflow\");\n            return NULL;\n        }\n\n        nBytes = (long)tmp2;\n    }\n    (void)fseek((FILE*)mat->fp,nBytes,SEEK_CUR);\n\n    return matvar;\n}", "commit_link": "github.com/tbeu/matio/commit/651a8e28099edb5fbb9e4e1d4d3238848f446c9a", "file_name": "src/mat4.c", "vul_type": "cwe-125", "description": "Write a C function named `Mat_VarReadNextInfo4` that reads the next variable information from a MAT file."}
{"func_name": "enc_untrusted_create_wait_queue", "func_src_before": "int32_t *enc_untrusted_create_wait_queue() {\n  MessageWriter input;\n  MessageReader output;\n  input.Push<uint64_t>(sizeof(int32_t));\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kLocalLifetimeAllocHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_create_wait_queue\",\n                           2);\n  int32_t *queue = reinterpret_cast<int32_t *>(output.next<uintptr_t>());\n  int klinux_errno = output.next<int>();\n  if (queue == nullptr) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n  }\n  enc_untrusted_disable_waiting(queue);\n  return queue;\n}", "func_src_after": "int32_t *enc_untrusted_create_wait_queue() {\n  MessageWriter input;\n  MessageReader output;\n  input.Push<uint64_t>(sizeof(int32_t));\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kLocalLifetimeAllocHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_create_wait_queue\",\n                           2);\n  int32_t *queue = reinterpret_cast<int32_t *>(output.next<uintptr_t>());\n  if (!TrustedPrimitives::IsOutsideEnclave(queue, sizeof(int32_t))) {\n    TrustedPrimitives::BestEffortAbort(\n        \"enc_untrusted_create_wait_queue: queue should be in untrusted memory\");\n  }\n  int klinux_errno = output.next<int>();\n  if (queue == nullptr) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n  }\n  enc_untrusted_disable_waiting(queue);\n  return queue;\n}", "commit_link": "github.com/google/asylo/commit/a37fb6a0e7daf30134dbbf357c9a518a1026aa02", "file_name": "asylo/platform/host_call/trusted/concurrency.cc", "vul_type": "cwe-787", "description": "Write a C++ function named `enc_untrusted_create_wait_queue` that allocates a wait queue using a non-system call dispatcher and handles errors."}
{"func_name": "NeXTDecode", "func_src_before": "NeXTDecode(TIFF* tif, uint8* buf, tmsize_t occ, uint16 s)\n{\n\tstatic const char module[] = \"NeXTDecode\";\n\tunsigned char *bp, *op;\n\ttmsize_t cc;\n\tuint8* row;\n\ttmsize_t scanline, n;\n\n\t(void) s;\n\t/*\n\t * Each scanline is assumed to start off as all\n\t * white (we assume a PhotometricInterpretation\n\t * of ``min-is-black'').\n\t */\n\tfor (op = (unsigned char*) buf, cc = occ; cc-- > 0;)\n\t\t*op++ = 0xff;\n\n\tbp = (unsigned char *)tif->tif_rawcp;\n\tcc = tif->tif_rawcc;\n\tscanline = tif->tif_scanlinesize;\n\tif (occ % scanline)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata, module, \"Fractional scanlines cannot be read\");\n\t\treturn (0);\n\t}\n\tfor (row = buf; cc > 0 && occ > 0; occ -= scanline, row += scanline) {\n\t\tn = *bp++, cc--;\n\t\tswitch (n) {\n\t\tcase LITERALROW:\n\t\t\t/*\n\t\t\t * The entire scanline is given as literal values.\n\t\t\t */\n\t\t\tif (cc < scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row, bp, scanline);\n\t\t\tbp += scanline;\n\t\t\tcc -= scanline;\n\t\t\tbreak;\n\t\tcase LITERALSPAN: {\n\t\t\ttmsize_t off;\n\t\t\t/*\n\t\t\t * The scanline has a literal span that begins at some\n\t\t\t * offset.\n\t\t\t */\n\t\t\tif( cc < 4 )\n\t\t\t\tgoto bad;\n\t\t\toff = (bp[0] * 256) + bp[1];\n\t\t\tn = (bp[2] * 256) + bp[3];\n\t\t\tif (cc < 4+n || off+n > scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row+off, bp+4, n);\n\t\t\tbp += 4+n;\n\t\t\tcc -= 4+n;\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tuint32 npixels = 0, grey;\n\t\t\tuint32 imagewidth = tif->tif_dir.td_imagewidth;\n            if( isTiled(tif) )\n                imagewidth = tif->tif_dir.td_tilewidth;\n\n\t\t\t/*\n\t\t\t * The scanline is composed of a sequence of constant\n\t\t\t * color ``runs''.  We shift into ``run mode'' and\n\t\t\t * interpret bytes as codes of the form\n\t\t\t * <color><npixels> until we've filled the scanline.\n\t\t\t */\n\t\t\top = row;\n\t\t\tfor (;;) {\n\t\t\t\tgrey = (uint32)((n>>6) & 0x3);\n\t\t\t\tn &= 0x3f;\n\t\t\t\t/*\n\t\t\t\t * Ensure the run does not exceed the scanline\n\t\t\t\t * bounds, potentially resulting in a security\n\t\t\t\t * issue.\n\t\t\t\t */\n\t\t\t\twhile (n-- > 0 && npixels < imagewidth)\n\t\t\t\t\tSETPIXEL(op, grey);\n\t\t\t\tif (npixels >= imagewidth)\n\t\t\t\t\tbreak;\n\t\t\t\tif (cc == 0)\n\t\t\t\t\tgoto bad;\n\t\t\t\tn = *bp++, cc--;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\t}\n\t}\n\ttif->tif_rawcp = (uint8*) bp;\n\ttif->tif_rawcc = cc;\n\treturn (1);\nbad:\n\tTIFFErrorExt(tif->tif_clientdata, module, \"Not enough data for scanline %ld\",\n\t    (long) tif->tif_row);\n\treturn (0);\n}", "func_src_after": "NeXTDecode(TIFF* tif, uint8* buf, tmsize_t occ, uint16 s)\n{\n\tstatic const char module[] = \"NeXTDecode\";\n\tunsigned char *bp, *op;\n\ttmsize_t cc;\n\tuint8* row;\n\ttmsize_t scanline, n;\n\n\t(void) s;\n\t/*\n\t * Each scanline is assumed to start off as all\n\t * white (we assume a PhotometricInterpretation\n\t * of ``min-is-black'').\n\t */\n\tfor (op = (unsigned char*) buf, cc = occ; cc-- > 0;)\n\t\t*op++ = 0xff;\n\n\tbp = (unsigned char *)tif->tif_rawcp;\n\tcc = tif->tif_rawcc;\n\tscanline = tif->tif_scanlinesize;\n\tif (occ % scanline)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata, module, \"Fractional scanlines cannot be read\");\n\t\treturn (0);\n\t}\n\tfor (row = buf; cc > 0 && occ > 0; occ -= scanline, row += scanline) {\n\t\tn = *bp++, cc--;\n\t\tswitch (n) {\n\t\tcase LITERALROW:\n\t\t\t/*\n\t\t\t * The entire scanline is given as literal values.\n\t\t\t */\n\t\t\tif (cc < scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row, bp, scanline);\n\t\t\tbp += scanline;\n\t\t\tcc -= scanline;\n\t\t\tbreak;\n\t\tcase LITERALSPAN: {\n\t\t\ttmsize_t off;\n\t\t\t/*\n\t\t\t * The scanline has a literal span that begins at some\n\t\t\t * offset.\n\t\t\t */\n\t\t\tif( cc < 4 )\n\t\t\t\tgoto bad;\n\t\t\toff = (bp[0] * 256) + bp[1];\n\t\t\tn = (bp[2] * 256) + bp[3];\n\t\t\tif (cc < 4+n || off+n > scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row+off, bp+4, n);\n\t\t\tbp += 4+n;\n\t\t\tcc -= 4+n;\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tuint32 npixels = 0, grey;\n\t\t\tuint32 imagewidth = tif->tif_dir.td_imagewidth;\n            if( isTiled(tif) )\n                imagewidth = tif->tif_dir.td_tilewidth;\n            tmsize_t op_offset = 0;\n\n\t\t\t/*\n\t\t\t * The scanline is composed of a sequence of constant\n\t\t\t * color ``runs''.  We shift into ``run mode'' and\n\t\t\t * interpret bytes as codes of the form\n\t\t\t * <color><npixels> until we've filled the scanline.\n\t\t\t */\n\t\t\top = row;\n\t\t\tfor (;;) {\n\t\t\t\tgrey = (uint32)((n>>6) & 0x3);\n\t\t\t\tn &= 0x3f;\n\t\t\t\t/*\n\t\t\t\t * Ensure the run does not exceed the scanline\n\t\t\t\t * bounds, potentially resulting in a security\n\t\t\t\t * issue.\n\t\t\t\t */\n\t\t\t\twhile (n-- > 0 && npixels < imagewidth && op_offset < scanline)\n\t\t\t\t\tSETPIXEL(op, grey);\n\t\t\t\tif (npixels >= imagewidth)\n\t\t\t\t\tbreak;\n                if (op_offset >= scanline ) {\n                    TIFFErrorExt(tif->tif_clientdata, module, \"Invalid data for scanline %ld\",\n                        (long) tif->tif_row);\n                    return (0);\n                }\n\t\t\t\tif (cc == 0)\n\t\t\t\t\tgoto bad;\n\t\t\t\tn = *bp++, cc--;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\t}\n\t}\n\ttif->tif_rawcp = (uint8*) bp;\n\ttif->tif_rawcc = cc;\n\treturn (1);\nbad:\n\tTIFFErrorExt(tif->tif_clientdata, module, \"Not enough data for scanline %ld\",\n\t    (long) tif->tif_row);\n\treturn (0);\n}", "commit_link": "github.com/vadz/libtiff/commit/b18012dae552f85dcc5c57d3bf4e997a15b1cc1c", "file_name": "libtiff/tif_next.c", "vul_type": "cwe-787", "description": "Write a C function named `NeXTDecode` that decodes a scanline from a TIFF image."}
{"func_name": "ReadPSDChannel", "func_src_before": "static MagickBooleanType ReadPSDChannel(Image *image,\n  const ImageInfo *image_info,const PSDInfo *psd_info,LayerInfo* layer_info,\n  const size_t channel,const PSDCompressionType compression,\n  ExceptionInfo *exception)\n{\n  Image\n    *channel_image,\n    *mask;\n\n  MagickOffsetType\n    offset;\n\n  MagickBooleanType\n    status;\n\n  channel_image=image;\n  mask=(Image *) NULL;\n  if (layer_info->channel_info[channel].type < -1)\n    {\n      const char\n        *option;\n      /*\n        Ignore mask that is not a user supplied layer mask, if the mask is\n        disabled or if the flags have unsupported values.\n      */\n      option=GetImageOption(image_info,\"psd:preserve-opacity-mask\");\n      if ((layer_info->channel_info[channel].type != -2) ||\n          (layer_info->mask.flags > 2) || ((layer_info->mask.flags & 0x02) &&\n           (IsStringTrue(option) == MagickFalse)))\n      {\n        SeekBlob(image,layer_info->channel_info[channel].size-2,SEEK_CUR);\n        return(MagickTrue);\n      }\n      mask=CloneImage(image,layer_info->mask.page.width,\n        layer_info->mask.page.height,MagickFalse,exception);\n      mask->matte=MagickFalse;\n      channel_image=mask;\n    }\n\n  offset=TellBlob(image);\n  status=MagickTrue;\n  switch(compression)\n  {\n    case Raw:\n      status=ReadPSDChannelRaw(channel_image,psd_info->channels,\n        layer_info->channel_info[channel].type,exception);\n      break;\n    case RLE:\n      {\n        MagickOffsetType\n          *sizes;\n\n        sizes=ReadPSDRLESizes(channel_image,psd_info,channel_image->rows);\n        if (sizes == (MagickOffsetType *) NULL)\n          ThrowBinaryException(ResourceLimitError,\"MemoryAllocationFailed\",\n            image->filename);\n        status=ReadPSDChannelRLE(channel_image,psd_info,\n          layer_info->channel_info[channel].type,sizes,exception);\n        sizes=(MagickOffsetType *) RelinquishMagickMemory(sizes);\n      }\n      break;\n    case ZipWithPrediction:\n    case ZipWithoutPrediction:\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n      status=ReadPSDChannelZip(channel_image,layer_info->channels,\n        layer_info->channel_info[channel].type,compression,\n        layer_info->channel_info[channel].size-2,exception);\n#else\n      (void) ThrowMagickException(exception,GetMagickModule(),\n          MissingDelegateWarning,\"DelegateLibrarySupportNotBuiltIn\",\n            \"'%s' (ZLIB)\",image->filename);\n#endif\n      break;\n    default:\n      (void) ThrowMagickException(exception,GetMagickModule(),TypeWarning,\n        \"CompressionNotSupported\",\"'%.20g'\",(double) compression);\n      break;\n  }\n\n  SeekBlob(image,offset+layer_info->channel_info[channel].size-2,SEEK_SET);\n  if (status == MagickFalse)\n    {\n      if (mask != (Image *) NULL)\n        DestroyImage(mask);\n      ThrowBinaryException(CoderError,\"UnableToDecompressImage\",\n        image->filename);\n    }\n  layer_info->mask.image=mask;\n  return(status);\n}", "func_src_after": "static MagickBooleanType ReadPSDChannel(Image *image,\n  const ImageInfo *image_info,const PSDInfo *psd_info,LayerInfo* layer_info,\n  const size_t channel,const PSDCompressionType compression,\n  ExceptionInfo *exception)\n{\n  Image\n    *channel_image,\n    *mask;\n\n  MagickOffsetType\n    offset;\n\n  MagickBooleanType\n    status;\n\n  channel_image=image;\n  mask=(Image *) NULL;\n  if (layer_info->channel_info[channel].type < -1)\n    {\n      const char\n        *option;\n      /*\n        Ignore mask that is not a user supplied layer mask, if the mask is\n        disabled or if the flags have unsupported values.\n      */\n      option=GetImageOption(image_info,\"psd:preserve-opacity-mask\");\n      if ((layer_info->channel_info[channel].type != -2) ||\n          (layer_info->mask.flags > 2) || ((layer_info->mask.flags & 0x02) &&\n           (IsStringTrue(option) == MagickFalse)))\n      {\n        SeekBlob(image,layer_info->channel_info[channel].size-2,SEEK_CUR);\n        return(MagickTrue);\n      }\n      mask=CloneImage(image,layer_info->mask.page.width,\n        layer_info->mask.page.height,MagickFalse,exception);\n      if (mask != (Image *) NULL)\n        {\n          mask->matte=MagickFalse;\n          channel_image=mask;\n        }\n    }\n\n  offset=TellBlob(image);\n  status=MagickTrue;\n  switch(compression)\n  {\n    case Raw:\n      status=ReadPSDChannelRaw(channel_image,psd_info->channels,\n        layer_info->channel_info[channel].type,exception);\n      break;\n    case RLE:\n      {\n        MagickOffsetType\n          *sizes;\n\n        sizes=ReadPSDRLESizes(channel_image,psd_info,channel_image->rows);\n        if (sizes == (MagickOffsetType *) NULL)\n          ThrowBinaryException(ResourceLimitError,\"MemoryAllocationFailed\",\n            image->filename);\n        status=ReadPSDChannelRLE(channel_image,psd_info,\n          layer_info->channel_info[channel].type,sizes,exception);\n        sizes=(MagickOffsetType *) RelinquishMagickMemory(sizes);\n      }\n      break;\n    case ZipWithPrediction:\n    case ZipWithoutPrediction:\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n      status=ReadPSDChannelZip(channel_image,layer_info->channels,\n        layer_info->channel_info[channel].type,compression,\n        layer_info->channel_info[channel].size-2,exception);\n#else\n      (void) ThrowMagickException(exception,GetMagickModule(),\n          MissingDelegateWarning,\"DelegateLibrarySupportNotBuiltIn\",\n            \"'%s' (ZLIB)\",image->filename);\n#endif\n      break;\n    default:\n      (void) ThrowMagickException(exception,GetMagickModule(),TypeWarning,\n        \"CompressionNotSupported\",\"'%.20g'\",(double) compression);\n      break;\n  }\n\n  SeekBlob(image,offset+layer_info->channel_info[channel].size-2,SEEK_SET);\n  if (status == MagickFalse)\n    {\n      if (mask != (Image *) NULL)\n        DestroyImage(mask);\n      ThrowBinaryException(CoderError,\"UnableToDecompressImage\",\n        image->filename);\n    }\n  layer_info->mask.image=mask;\n  return(status);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/7f2dc7a1afc067d0c89f12c82bcdec0445fb1b94", "file_name": "coders/psd.c", "vul_type": "cwe-476", "description": "In C, write a function to read a channel from a PSD file, handling different compression types and optional masks."}
{"func_name": "mode_input", "func_src_before": "    def mode_input(self, request):\n        \"\"\"\n        This is called by render_POST when the client\n        is sending data to the server.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n\n        self.last_alive[csessid] = (time.time(), False)\n        sess = self.sessionhandler.sessions_from_csessid(csessid)\n        if sess:\n            sess = sess[0]\n            cmdarray = json.loads(request.args.get('data')[0])\n            sess.sessionhandler.data_in(sess, **{cmdarray[0]: [cmdarray[1], cmdarray[2]]})\n        return '\"\"'", "func_src_after": "    def mode_input(self, request):\n        \"\"\"\n        This is called by render_POST when the client\n        is sending data to the server.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        self.last_alive[csessid] = (time.time(), False)\n        sess = self.sessionhandler.sessions_from_csessid(csessid)\n        if sess:\n            sess = sess[0]\n            cmdarray = json.loads(cgi.escape(request.args.get('data')[0]))\n            sess.sessionhandler.data_in(sess, **{cmdarray[0]: [cmdarray[1], cmdarray[2]]})\n        return '\"\"'", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_input` that processes a POST request by extracting session ID and data, updates session activity, and handles incoming data for a session."}
{"func_name": "dbd_st_fetch", "func_src_before": "dbd_st_fetch(SV *sth, imp_sth_t* imp_sth)\n{\n  dTHX;\n  int num_fields, ChopBlanks, i, rc;\n  unsigned long *lengths;\n  AV *av;\n  int av_length, av_readonly;\n  MYSQL_ROW cols;\n  D_imp_dbh_from_sth;\n  MYSQL* svsock= imp_dbh->pmysql;\n  imp_sth_fbh_t *fbh;\n  D_imp_xxh(sth);\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  MYSQL_BIND *buffer;\n#endif\n  MYSQL_FIELD *fields;\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t-> dbd_st_fetch\\n\");\n\n#if MYSQL_ASYNC\n  if(imp_dbh->async_query_in_flight) {\n      if(mysql_db_async_result(sth, &imp_sth->result) <= 0) {\n        return Nullav;\n      }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (!DBIc_ACTIVE(imp_sth) )\n    {\n      do_error(sth, JW_ERR_SEQUENCE, \"no statement executing\\n\",NULL);\n      return Nullav;\n    }\n\n    if (imp_sth->fetch_done)\n    {\n      do_error(sth, JW_ERR_SEQUENCE, \"fetch() but fetch already done\",NULL);\n      return Nullav;\n    }\n\n    if (!imp_sth->done_desc)\n    {\n      if (!dbd_describe(sth, imp_sth))\n      {\n        do_error(sth, JW_ERR_SEQUENCE, \"Error while describe result set.\",\n                 NULL);\n        return Nullav;\n      }\n    }\n  }\n#endif\n\n  ChopBlanks = DBIc_is(imp_sth, DBIcf_ChopBlanks);\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                  \"\\t\\tdbd_st_fetch for %p, chopblanks %d\\n\",\n                  sth, ChopBlanks);\n\n  if (!imp_sth->result)\n  {\n    do_error(sth, JW_ERR_SEQUENCE, \"fetch() without execute()\" ,NULL);\n    return Nullav;\n  }\n\n  /* fix from 2.9008 */\n  imp_dbh->pmysql->net.last_errno = 0;\n\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch calling mysql_fetch\\n\");\n\n    if ((rc= mysql_stmt_fetch(imp_sth->stmt)))\n    {\n      if (rc == 1)\n        do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                 mysql_stmt_error(imp_sth->stmt),\n                mysql_stmt_sqlstate(imp_sth->stmt));\n\n#if MYSQL_VERSION_ID >= MYSQL_VERSION_5_0 \n      if (rc == MYSQL_DATA_TRUNCATED) {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch data truncated\\n\");\n        goto process;\n      }\n#endif\n\n      if (rc == MYSQL_NO_DATA)\n      {\n        /* Update row_num to affected_rows value */\n        imp_sth->row_num= mysql_stmt_affected_rows(imp_sth->stmt);\n        imp_sth->fetch_done=1;\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch no data\\n\");\n      }\n\n      dbd_st_finish(sth, imp_sth);\n\n      return Nullav;\n    }\n\nprocess:\n    imp_sth->currow++;\n\n    av= DBIc_DBISTATE(imp_sth)->get_fbav(imp_sth);\n    num_fields=mysql_stmt_field_count(imp_sth->stmt);\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tdbd_st_fetch called mysql_fetch, rc %d num_fields %d\\n\",\n                    rc, num_fields);\n\n    for (\n         buffer= imp_sth->buffer,\n         fbh= imp_sth->fbh,\n         i= 0;\n         i < num_fields;\n         i++,\n         fbh++,\n         buffer++\n        )\n    {\n      SV *sv= AvARRAY(av)[i]; /* Note: we (re)use the SV in the AV\t*/\n      STRLEN len;\n\n      /* This is wrong, null is not being set correctly\n       * This is not the way to determine length (this would break blobs!)\n       */\n      if (fbh->is_null)\n        (void) SvOK_off(sv);  /*  Field is NULL, return undef  */\n      else\n      {\n        /* In case of BLOB/TEXT fields we allocate only 8192 bytes\n           in dbd_describe() for data. Here we know real size of field\n           so we should increase buffer size and refetch column value\n        */\n        if (fbh->length > buffer->buffer_length || fbh->error)\n        {\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n              \"\\t\\tRefetch BLOB/TEXT column: %d, length: %lu, error: %d\\n\",\n              i, fbh->length, fbh->error);\n\n          Renew(fbh->data, fbh->length, char);\n          buffer->buffer_length= fbh->length;\n          buffer->buffer= (char *) fbh->data;\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2) {\n            int j;\n            int m = MIN(*buffer->length, buffer->buffer_length);\n            char *ptr = (char*)buffer->buffer;\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\t\\tbefore buffer->buffer: \");\n            for (j = 0; j < m; j++) {\n              PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"%c\", *ptr++);\n            }\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\n\");\n          }\n\n          /*TODO: Use offset instead of 0 to fetch only remain part of data*/\n          if (mysql_stmt_fetch_column(imp_sth->stmt, buffer , i, 0))\n            do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                     mysql_stmt_error(imp_sth->stmt),\n                     mysql_stmt_sqlstate(imp_sth->stmt));\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2) {\n            int j;\n            int m = MIN(*buffer->length, buffer->buffer_length);\n            char *ptr = (char*)buffer->buffer;\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\t\\tafter buffer->buffer: \");\n            for (j = 0; j < m; j++) {\n              PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"%c\", *ptr++);\n            }\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\n\");\n          }\n        }\n\n        /* This does look a lot like Georg's PHP driver doesn't it?  --Brian */\n        /* Credit due to Georg - mysqli_api.c  ;) --PMG */\n        switch (buffer->buffer_type) {\n        case MYSQL_TYPE_DOUBLE:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tst_fetch double data %f\\n\", fbh->ddata);\n          sv_setnv(sv, fbh->ddata);\n          break;\n\n        case MYSQL_TYPE_LONG:\n        case MYSQL_TYPE_LONGLONG:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tst_fetch int data %\"IVdf\", unsigned? %d\\n\",\n                          fbh->ldata, buffer->is_unsigned);\n          if (buffer->is_unsigned)\n            sv_setuv(sv, fbh->ldata);\n          else\n            sv_setiv(sv, fbh->ldata);\n\n          break;\n\n        case MYSQL_TYPE_BIT:\n          sv_setpvn(sv, fbh->data, fbh->length);\n\n          break;\n\n        default:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tERROR IN st_fetch_string\");\n          len= fbh->length;\n\t  /* ChopBlanks server-side prepared statement */\n          if (ChopBlanks)\n          {\n            /* \n              see bottom of:\n              http://www.mysql.org/doc/refman/5.0/en/c-api-datatypes.html\n            */\n            if (fbh->charsetnr != 63)\n              while (len && fbh->data[len-1] == ' ') { --len; }\n          }\n\t  /* END OF ChopBlanks */\n\n          sv_setpvn(sv, fbh->data, len);\n\n\t/* UTF8 */\n        /*HELMUT*/\n#if defined(sv_utf8_decode) && MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n\n#if MYSQL_VERSION_ID >= FIELD_CHARSETNR_VERSION \n  /* SHOW COLLATION WHERE Id = 63; -- 63 == charset binary, collation binary */\n        if ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && fbh->charsetnr != 63)\n#else\n\tif ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && !(fbh->flags & BINARY_FLAG))\n#endif\n\t  sv_utf8_decode(sv);\n#endif\n\t/* END OF UTF8 */\n          break;\n\n        }\n\n      }\n    }\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, %d cols\\n\", num_fields);\n\n    return av;\n  }\n  else\n  {\n#endif\n\n    imp_sth->currow++;\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    {\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch result set details\\n\");\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\timp_sth->result=%p\\n\", imp_sth->result);\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_num_fields=%u\\n\",\n                    mysql_num_fields(imp_sth->result));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_num_rows=%llu\\n\",\n                    mysql_num_rows(imp_sth->result));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_affected_rows=%llu\\n\",\n                    mysql_affected_rows(imp_dbh->pmysql));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch for %p, currow= %d\\n\",\n                    sth,imp_sth->currow);\n    }\n\n    if (!(cols= mysql_fetch_row(imp_sth->result)))\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      {\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch, no more rows to fetch\");\n      }\n      if (mysql_errno(imp_dbh->pmysql))\n        do_error(sth, mysql_errno(imp_dbh->pmysql),\n                 mysql_error(imp_dbh->pmysql),\n                 mysql_sqlstate(imp_dbh->pmysql));\n\n\n#if MYSQL_VERSION_ID >= MULTIPLE_RESULT_SET_VERSION\n      if (!mysql_more_results(svsock))\n#endif\n        dbd_st_finish(sth, imp_sth);\n      return Nullav;\n    }\n\n    num_fields= mysql_num_fields(imp_sth->result);\n    fields= mysql_fetch_fields(imp_sth->result);\n    lengths= mysql_fetch_lengths(imp_sth->result);\n\n    if ((av= DBIc_FIELDS_AV(imp_sth)) != Nullav)\n    {\n      av_length= av_len(av)+1;\n\n      if (av_length != num_fields)              /* Resize array if necessary */\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, size of results array(%d) != num_fields(%d)\\n\",\n                                   av_length, num_fields);\n\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, result fields(%d)\\n\",\n                                   DBIc_NUM_FIELDS(imp_sth));\n\n        av_readonly = SvREADONLY(av);\n\n        if (av_readonly)\n          SvREADONLY_off( av );              /* DBI sets this readonly */\n\n        while (av_length < num_fields)\n        {\n          av_store(av, av_length++, newSV(0));\n        }\n\n        while (av_length > num_fields)\n        {\n          SvREFCNT_dec(av_pop(av));\n          av_length--;\n        }\n        if (av_readonly)\n          SvREADONLY_on(av);\n      }\n    }\n\n    av= DBIc_DBISTATE(imp_sth)->get_fbav(imp_sth);\n\n    for (i= 0;  i < num_fields; ++i)\n    {\n      char *col= cols[i];\n      SV *sv= AvARRAY(av)[i]; /* Note: we (re)use the SV in the AV\t*/\n\n      if (col)\n      {\n        STRLEN len= lengths[i];\n        if (ChopBlanks)\n        {\n          while (len && col[len-1] == ' ')\n          {\t--len; }\n        }\n\n        /* Set string value returned from mysql server */\n        sv_setpvn(sv, col, len);\n\n        switch (mysql_to_perl_type(fields[i].type)) {\n        case MYSQL_TYPE_DOUBLE:\n          /* Coerce to dobule and set scalar as NV */\n          (void) SvNV(sv);\n          SvNOK_only(sv);\n          break;\n\n        case MYSQL_TYPE_LONG:\n        case MYSQL_TYPE_LONGLONG:\n          /* Coerce to integer and set scalar as UV resp. IV */\n          if (fields[i].flags & UNSIGNED_FLAG)\n          {\n            (void) SvUV(sv);\n            SvIOK_only_UV(sv);\n          }\n          else\n          {\n            (void) SvIV(sv);\n            SvIOK_only(sv);\n          }\n          break;\n\n#if MYSQL_VERSION_ID > NEW_DATATYPE_VERSION\n        case MYSQL_TYPE_BIT:\n          /* Let it as binary string */\n          break;\n#endif\n\n        default:\n\t/* UTF8 */\n        /*HELMUT*/\n#if defined(sv_utf8_decode) && MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n\n  /* see bottom of: http://www.mysql.org/doc/refman/5.0/en/c-api-datatypes.html */\n        if ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && fields[i].charsetnr != 63)\n\t  sv_utf8_decode(sv);\n#endif\n\t/* END OF UTF8 */\n          break;\n        }\n      }\n      else\n        (void) SvOK_off(sv);  /*  Field is NULL, return undef  */\n    }\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, %d cols\\n\", num_fields);\n    return av;\n\n#if MYSQL_VERSION_ID  >= SERVER_PREPARE_VERSION\n  }\n#endif\n\n}", "func_src_after": "dbd_st_fetch(SV *sth, imp_sth_t* imp_sth)\n{\n  dTHX;\n  int num_fields, ChopBlanks, i, rc;\n  unsigned long *lengths;\n  AV *av;\n  int av_length, av_readonly;\n  MYSQL_ROW cols;\n  D_imp_dbh_from_sth;\n  MYSQL* svsock= imp_dbh->pmysql;\n  imp_sth_fbh_t *fbh;\n  D_imp_xxh(sth);\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  MYSQL_BIND *buffer;\n#endif\n  MYSQL_FIELD *fields;\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t-> dbd_st_fetch\\n\");\n\n#if MYSQL_ASYNC\n  if(imp_dbh->async_query_in_flight) {\n      if(mysql_db_async_result(sth, &imp_sth->result) <= 0) {\n        return Nullav;\n      }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (!DBIc_ACTIVE(imp_sth) )\n    {\n      do_error(sth, JW_ERR_SEQUENCE, \"no statement executing\\n\",NULL);\n      return Nullav;\n    }\n\n    if (imp_sth->fetch_done)\n    {\n      do_error(sth, JW_ERR_SEQUENCE, \"fetch() but fetch already done\",NULL);\n      return Nullav;\n    }\n\n    if (!imp_sth->done_desc)\n    {\n      if (!dbd_describe(sth, imp_sth))\n      {\n        do_error(sth, JW_ERR_SEQUENCE, \"Error while describe result set.\",\n                 NULL);\n        return Nullav;\n      }\n    }\n  }\n#endif\n\n  ChopBlanks = DBIc_is(imp_sth, DBIcf_ChopBlanks);\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                  \"\\t\\tdbd_st_fetch for %p, chopblanks %d\\n\",\n                  sth, ChopBlanks);\n\n  if (!imp_sth->result)\n  {\n    do_error(sth, JW_ERR_SEQUENCE, \"fetch() without execute()\" ,NULL);\n    return Nullav;\n  }\n\n  /* fix from 2.9008 */\n  imp_dbh->pmysql->net.last_errno = 0;\n\n#if MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch calling mysql_fetch\\n\");\n\n    if ((rc= mysql_stmt_fetch(imp_sth->stmt)))\n    {\n      if (rc == 1)\n        do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                 mysql_stmt_error(imp_sth->stmt),\n                mysql_stmt_sqlstate(imp_sth->stmt));\n\n#if MYSQL_VERSION_ID >= MYSQL_VERSION_5_0 \n      if (rc == MYSQL_DATA_TRUNCATED) {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch data truncated\\n\");\n        goto process;\n      }\n#endif\n\n      if (rc == MYSQL_NO_DATA)\n      {\n        /* Update row_num to affected_rows value */\n        imp_sth->row_num= mysql_stmt_affected_rows(imp_sth->stmt);\n        imp_sth->fetch_done=1;\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tdbd_st_fetch no data\\n\");\n      }\n\n      dbd_st_finish(sth, imp_sth);\n\n      return Nullav;\n    }\n\nprocess:\n    imp_sth->currow++;\n\n    av= DBIc_DBISTATE(imp_sth)->get_fbav(imp_sth);\n    num_fields=mysql_stmt_field_count(imp_sth->stmt);\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tdbd_st_fetch called mysql_fetch, rc %d num_fields %d\\n\",\n                    rc, num_fields);\n\n    for (\n         buffer= imp_sth->buffer,\n         fbh= imp_sth->fbh,\n         i= 0;\n         i < num_fields;\n         i++,\n         fbh++,\n         buffer++\n        )\n    {\n      SV *sv= AvARRAY(av)[i]; /* Note: we (re)use the SV in the AV\t*/\n      STRLEN len;\n\n      /* This is wrong, null is not being set correctly\n       * This is not the way to determine length (this would break blobs!)\n       */\n      if (fbh->is_null)\n        (void) SvOK_off(sv);  /*  Field is NULL, return undef  */\n      else\n      {\n        /* In case of BLOB/TEXT fields we allocate only 8192 bytes\n           in dbd_describe() for data. Here we know real size of field\n           so we should increase buffer size and refetch column value\n        */\n        if (fbh->length > buffer->buffer_length || fbh->error)\n        {\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n              \"\\t\\tRefetch BLOB/TEXT column: %d, length: %lu, error: %d\\n\",\n              i, fbh->length, fbh->error);\n\n          Renew(fbh->data, fbh->length, char);\n          buffer->buffer_length= fbh->length;\n          buffer->buffer= (char *) fbh->data;\n          imp_sth->stmt->bind[i].buffer_length = fbh->length;\n          imp_sth->stmt->bind[i].buffer = (char *)fbh->data;\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2) {\n            int j;\n            int m = MIN(*buffer->length, buffer->buffer_length);\n            char *ptr = (char*)buffer->buffer;\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\t\\tbefore buffer->buffer: \");\n            for (j = 0; j < m; j++) {\n              PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"%c\", *ptr++);\n            }\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\n\");\n          }\n\n          /*TODO: Use offset instead of 0 to fetch only remain part of data*/\n          if (mysql_stmt_fetch_column(imp_sth->stmt, buffer , i, 0))\n            do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                     mysql_stmt_error(imp_sth->stmt),\n                     mysql_stmt_sqlstate(imp_sth->stmt));\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2) {\n            int j;\n            int m = MIN(*buffer->length, buffer->buffer_length);\n            char *ptr = (char*)buffer->buffer;\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\t\\tafter buffer->buffer: \");\n            for (j = 0; j < m; j++) {\n              PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"%c\", *ptr++);\n            }\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\"\\n\");\n          }\n        }\n\n        /* This does look a lot like Georg's PHP driver doesn't it?  --Brian */\n        /* Credit due to Georg - mysqli_api.c  ;) --PMG */\n        switch (buffer->buffer_type) {\n        case MYSQL_TYPE_DOUBLE:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tst_fetch double data %f\\n\", fbh->ddata);\n          sv_setnv(sv, fbh->ddata);\n          break;\n\n        case MYSQL_TYPE_LONG:\n        case MYSQL_TYPE_LONGLONG:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tst_fetch int data %\"IVdf\", unsigned? %d\\n\",\n                          fbh->ldata, buffer->is_unsigned);\n          if (buffer->is_unsigned)\n            sv_setuv(sv, fbh->ldata);\n          else\n            sv_setiv(sv, fbh->ldata);\n\n          break;\n\n        case MYSQL_TYPE_BIT:\n          sv_setpvn(sv, fbh->data, fbh->length);\n\n          break;\n\n        default:\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tERROR IN st_fetch_string\");\n          len= fbh->length;\n\t  /* ChopBlanks server-side prepared statement */\n          if (ChopBlanks)\n          {\n            /* \n              see bottom of:\n              http://www.mysql.org/doc/refman/5.0/en/c-api-datatypes.html\n            */\n            if (fbh->charsetnr != 63)\n              while (len && fbh->data[len-1] == ' ') { --len; }\n          }\n\t  /* END OF ChopBlanks */\n\n          sv_setpvn(sv, fbh->data, len);\n\n\t/* UTF8 */\n        /*HELMUT*/\n#if defined(sv_utf8_decode) && MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n\n#if MYSQL_VERSION_ID >= FIELD_CHARSETNR_VERSION \n  /* SHOW COLLATION WHERE Id = 63; -- 63 == charset binary, collation binary */\n        if ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && fbh->charsetnr != 63)\n#else\n\tif ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && !(fbh->flags & BINARY_FLAG))\n#endif\n\t  sv_utf8_decode(sv);\n#endif\n\t/* END OF UTF8 */\n          break;\n\n        }\n\n      }\n    }\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, %d cols\\n\", num_fields);\n\n    return av;\n  }\n  else\n  {\n#endif\n\n    imp_sth->currow++;\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    {\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch result set details\\n\");\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\timp_sth->result=%p\\n\", imp_sth->result);\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_num_fields=%u\\n\",\n                    mysql_num_fields(imp_sth->result));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_num_rows=%llu\\n\",\n                    mysql_num_rows(imp_sth->result));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tmysql_affected_rows=%llu\\n\",\n                    mysql_affected_rows(imp_dbh->pmysql));\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch for %p, currow= %d\\n\",\n                    sth,imp_sth->currow);\n    }\n\n    if (!(cols= mysql_fetch_row(imp_sth->result)))\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      {\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\tdbd_st_fetch, no more rows to fetch\");\n      }\n      if (mysql_errno(imp_dbh->pmysql))\n        do_error(sth, mysql_errno(imp_dbh->pmysql),\n                 mysql_error(imp_dbh->pmysql),\n                 mysql_sqlstate(imp_dbh->pmysql));\n\n\n#if MYSQL_VERSION_ID >= MULTIPLE_RESULT_SET_VERSION\n      if (!mysql_more_results(svsock))\n#endif\n        dbd_st_finish(sth, imp_sth);\n      return Nullav;\n    }\n\n    num_fields= mysql_num_fields(imp_sth->result);\n    fields= mysql_fetch_fields(imp_sth->result);\n    lengths= mysql_fetch_lengths(imp_sth->result);\n\n    if ((av= DBIc_FIELDS_AV(imp_sth)) != Nullav)\n    {\n      av_length= av_len(av)+1;\n\n      if (av_length != num_fields)              /* Resize array if necessary */\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, size of results array(%d) != num_fields(%d)\\n\",\n                                   av_length, num_fields);\n\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, result fields(%d)\\n\",\n                                   DBIc_NUM_FIELDS(imp_sth));\n\n        av_readonly = SvREADONLY(av);\n\n        if (av_readonly)\n          SvREADONLY_off( av );              /* DBI sets this readonly */\n\n        while (av_length < num_fields)\n        {\n          av_store(av, av_length++, newSV(0));\n        }\n\n        while (av_length > num_fields)\n        {\n          SvREFCNT_dec(av_pop(av));\n          av_length--;\n        }\n        if (av_readonly)\n          SvREADONLY_on(av);\n      }\n    }\n\n    av= DBIc_DBISTATE(imp_sth)->get_fbav(imp_sth);\n\n    for (i= 0;  i < num_fields; ++i)\n    {\n      char *col= cols[i];\n      SV *sv= AvARRAY(av)[i]; /* Note: we (re)use the SV in the AV\t*/\n\n      if (col)\n      {\n        STRLEN len= lengths[i];\n        if (ChopBlanks)\n        {\n          while (len && col[len-1] == ' ')\n          {\t--len; }\n        }\n\n        /* Set string value returned from mysql server */\n        sv_setpvn(sv, col, len);\n\n        switch (mysql_to_perl_type(fields[i].type)) {\n        case MYSQL_TYPE_DOUBLE:\n          /* Coerce to dobule and set scalar as NV */\n          (void) SvNV(sv);\n          SvNOK_only(sv);\n          break;\n\n        case MYSQL_TYPE_LONG:\n        case MYSQL_TYPE_LONGLONG:\n          /* Coerce to integer and set scalar as UV resp. IV */\n          if (fields[i].flags & UNSIGNED_FLAG)\n          {\n            (void) SvUV(sv);\n            SvIOK_only_UV(sv);\n          }\n          else\n          {\n            (void) SvIV(sv);\n            SvIOK_only(sv);\n          }\n          break;\n\n#if MYSQL_VERSION_ID > NEW_DATATYPE_VERSION\n        case MYSQL_TYPE_BIT:\n          /* Let it as binary string */\n          break;\n#endif\n\n        default:\n\t/* UTF8 */\n        /*HELMUT*/\n#if defined(sv_utf8_decode) && MYSQL_VERSION_ID >=SERVER_PREPARE_VERSION\n\n  /* see bottom of: http://www.mysql.org/doc/refman/5.0/en/c-api-datatypes.html */\n        if ((imp_dbh->enable_utf8 || imp_dbh->enable_utf8mb4) && fields[i].charsetnr != 63)\n\t  sv_utf8_decode(sv);\n#endif\n\t/* END OF UTF8 */\n          break;\n        }\n      }\n      else\n        (void) SvOK_off(sv);  /*  Field is NULL, return undef  */\n    }\n\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_fetch, %d cols\\n\", num_fields);\n    return av;\n\n#if MYSQL_VERSION_ID  >= SERVER_PREPARE_VERSION\n  }\n#endif\n\n}", "commit_link": "github.com/perl5-dbi/DBD-mysql/commit/3619c170461a3107a258d1fd2d00ed4832adb1b1", "file_name": "dbdimp.c", "vul_type": "cwe-416", "description": "Write a Perl function to fetch a row of data from a MySQL database using the DBI module."}
{"func_name": "TIFFSeekCustomStream", "func_src_before": "static MagickOffsetType TIFFSeekCustomStream(const MagickOffsetType offset,\n  const int whence,void *user_data)\n{\n  PhotoshopProfile\n    *profile;\n\n  profile=(PhotoshopProfile *) user_data;\n  switch (whence)\n  {\n    case SEEK_SET:\n    default:\n    {\n      if (offset < 0)\n        return(-1);\n      profile->offset=offset;\n      break;\n    }\n    case SEEK_CUR:\n    {\n      if ((profile->offset+offset) < 0)\n        return(-1);\n      profile->offset+=offset;\n      break;\n    }\n    case SEEK_END:\n    {\n      if (((MagickOffsetType) profile->length+offset) < 0)\n        return(-1);\n      profile->offset=profile->length+offset;\n      break;\n    }\n  }\n\n  return(profile->offset);\n}", "func_src_after": "static MagickOffsetType TIFFSeekCustomStream(const MagickOffsetType offset,\n  const int whence,void *user_data)\n{\n  PhotoshopProfile\n    *profile;\n\n  profile=(PhotoshopProfile *) user_data;\n  switch (whence)\n  {\n    case SEEK_SET:\n    default:\n    {\n      if (offset < 0)\n        return(-1);\n      profile->offset=offset;\n      break;\n    }\n    case SEEK_CUR:\n    {\n      if (((offset > 0) && (profile->offset > (SSIZE_MAX-offset))) ||\n          ((offset < 0) && (profile->offset < (-SSIZE_MAX-offset))))\n        {\n          errno=EOVERFLOW;\n          return(-1);\n        }\n      if ((profile->offset+offset) < 0)\n        return(-1);\n      profile->offset+=offset;\n      break;\n    }\n    case SEEK_END:\n    {\n      if (((MagickOffsetType) profile->length+offset) < 0)\n        return(-1);\n      profile->offset=profile->length+offset;\n      break;\n    }\n  }\n\n  return(profile->offset);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/fe5f4b85e6b1b54d3b4588a77133c06ade46d891", "file_name": "coders/tiff.c", "vul_type": "cwe-190", "description": "Write a C function named `TIFFSeekCustomStream` that adjusts the offset within a Photoshop profile structure based on the seek operation specified."}
{"func_name": "input_csi_dispatch_sgr_colon", "func_src_before": "input_csi_dispatch_sgr_colon(struct input_ctx *ictx, u_int i)\n{\n\tstruct grid_cell\t*gc = &ictx->cell.cell;\n\tchar\t\t\t*s = ictx->param_list[i].str, *copy, *ptr, *out;\n\tint\t\t\t p[8];\n\tu_int\t\t\t n;\n\tconst char\t\t*errstr;\n\n\tfor (n = 0; n < nitems(p); n++)\n\t\tp[n] = -1;\n\tn = 0;\n\n\tptr = copy = xstrdup(s);\n\twhile ((out = strsep(&ptr, \":\")) != NULL) {\n\t\tif (*out != '\\0') {\n\t\t\tp[n++] = strtonum(out, 0, INT_MAX, &errstr);\n\t\t\tif (errstr != NULL || n == nitems(p)) {\n\t\t\t\tfree(copy);\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else\n\t\t\tn++;\n\t\tlog_debug(\"%s: %u = %d\", __func__, n - 1, p[n - 1]);\n\t}\n\tfree(copy);\n\n\tif (n == 0)\n\t\treturn;\n\tif (p[0] == 4) {\n\t\tif (n != 2)\n\t\t\treturn;\n\t\tswitch (p[1]) {\n\t\tcase 0:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_2;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_3;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_4;\n\t\t\tbreak;\n\t\tcase 5:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_5;\n\t\t\tbreak;\n\t\t}\n\t\treturn;\n\t}\n\tif (n < 2 || (p[0] != 38 && p[0] != 48 && p[0] != 58))\n\t\treturn;\n\tswitch (p[1]) {\n\tcase 2:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tif (n == 5)\n\t\t\ti = 2;\n\t\telse\n\t\t\ti = 3;\n\t\tif (n < i + 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_rgb_do(ictx, p[0], p[i], p[i + 1],\n\t\t    p[i + 2]);\n\t\tbreak;\n\tcase 5:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_256_do(ictx, p[0], p[2]);\n\t\tbreak;\n\t}\n}", "func_src_after": "input_csi_dispatch_sgr_colon(struct input_ctx *ictx, u_int i)\n{\n\tstruct grid_cell\t*gc = &ictx->cell.cell;\n\tchar\t\t\t*s = ictx->param_list[i].str, *copy, *ptr, *out;\n\tint\t\t\t p[8];\n\tu_int\t\t\t n;\n\tconst char\t\t*errstr;\n\n\tfor (n = 0; n < nitems(p); n++)\n\t\tp[n] = -1;\n\tn = 0;\n\n\tptr = copy = xstrdup(s);\n\twhile ((out = strsep(&ptr, \":\")) != NULL) {\n\t\tif (*out != '\\0') {\n\t\t\tp[n++] = strtonum(out, 0, INT_MAX, &errstr);\n\t\t\tif (errstr != NULL || n == nitems(p)) {\n\t\t\t\tfree(copy);\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else {\n\t\t\tn++;\n\t\t\tif (n == nitems(p)) {\n\t\t\t\tfree(copy);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tlog_debug(\"%s: %u = %d\", __func__, n - 1, p[n - 1]);\n\t}\n\tfree(copy);\n\n\tif (n == 0)\n\t\treturn;\n\tif (p[0] == 4) {\n\t\tif (n != 2)\n\t\t\treturn;\n\t\tswitch (p[1]) {\n\t\tcase 0:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 1:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE;\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_2;\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_3;\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_4;\n\t\t\tbreak;\n\t\tcase 5:\n\t\t\tgc->attr &= ~GRID_ATTR_ALL_UNDERSCORE;\n\t\t\tgc->attr |= GRID_ATTR_UNDERSCORE_5;\n\t\t\tbreak;\n\t\t}\n\t\treturn;\n\t}\n\tif (n < 2 || (p[0] != 38 && p[0] != 48 && p[0] != 58))\n\t\treturn;\n\tswitch (p[1]) {\n\tcase 2:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tif (n == 5)\n\t\t\ti = 2;\n\t\telse\n\t\t\ti = 3;\n\t\tif (n < i + 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_rgb_do(ictx, p[0], p[i], p[i + 1],\n\t\t    p[i + 2]);\n\t\tbreak;\n\tcase 5:\n\t\tif (n < 3)\n\t\t\tbreak;\n\t\tinput_csi_dispatch_sgr_256_do(ictx, p[0], p[2]);\n\t\tbreak;\n\t}\n}", "commit_link": "github.com/tmux/tmux/commit/a868bacb46e3c900530bed47a1c6f85b0fbe701c", "file_name": "input.c", "vul_type": "cwe-787", "description": "Write a C function to parse colon-separated SGR (Select Graphic Rendition) parameters and update text attributes accordingly."}
{"func_name": "handle_PORT", "func_src_before": "static void handle_PORT(ctrl_t *ctrl, char *str)\n{\n\tint a, b, c, d, e, f;\n\tchar addr[INET_ADDRSTRLEN];\n\tstruct sockaddr_in sin;\n\n\tif (ctrl->data_sd > 0) {\n\t\tuev_io_stop(&ctrl->data_watcher);\n\t\tclose(ctrl->data_sd);\n\t\tctrl->data_sd = -1;\n\t}\n\n\t/* Convert PORT command's argument to IP address + port */\n\tsscanf(str, \"%d,%d,%d,%d,%d,%d\", &a, &b, &c, &d, &e, &f);\n\tsprintf(addr, \"%d.%d.%d.%d\", a, b, c, d);\n\n\t/* Check IPv4 address using inet_aton(), throw away converted result */\n\tif (!inet_aton(addr, &(sin.sin_addr))) {\n\t\tERR(0, \"Invalid address '%s' given to PORT command\", addr);\n\t\tsend_msg(ctrl->sd, \"500 Illegal PORT command.\\r\\n\");\n\t\treturn;\n\t}\n\n\tstrlcpy(ctrl->data_address, addr, sizeof(ctrl->data_address));\n\tctrl->data_port = e * 256 + f;\n\n\tDBG(\"Client PORT command accepted for %s:%d\", ctrl->data_address, ctrl->data_port);\n\tsend_msg(ctrl->sd, \"200 PORT command successful.\\r\\n\");\n}", "func_src_after": "static void handle_PORT(ctrl_t *ctrl, char *str)\n{\n\tint a, b, c, d, e, f;\n\tchar addr[INET_ADDRSTRLEN];\n\tstruct sockaddr_in sin;\n\n\tif (ctrl->data_sd > 0) {\n\t\tuev_io_stop(&ctrl->data_watcher);\n\t\tclose(ctrl->data_sd);\n\t\tctrl->data_sd = -1;\n\t}\n\n\t/* Convert PORT command's argument to IP address + port */\n\tsscanf(str, \"%d,%d,%d,%d,%d,%d\", &a, &b, &c, &d, &e, &f);\n\tsnprintf(addr, sizeof(addr), \"%d.%d.%d.%d\", a, b, c, d);\n\n\t/* Check IPv4 address using inet_aton(), throw away converted result */\n\tif (!inet_aton(addr, &(sin.sin_addr))) {\n\t\tERR(0, \"Invalid address '%s' given to PORT command\", addr);\n\t\tsend_msg(ctrl->sd, \"500 Illegal PORT command.\\r\\n\");\n\t\treturn;\n\t}\n\n\tstrlcpy(ctrl->data_address, addr, sizeof(ctrl->data_address));\n\tctrl->data_port = e * 256 + f;\n\n\tDBG(\"Client PORT command accepted for %s:%d\", ctrl->data_address, ctrl->data_port);\n\tsend_msg(ctrl->sd, \"200 PORT command successful.\\r\\n\");\n}", "commit_link": "github.com/troglobit/uftpd/commit/0fb2c031ce0ace07cc19cd2cb2143c4b5a63c9dd", "file_name": "src/ftpcmd.c", "vul_type": "cwe-787", "description": "In C, write a function to handle the FTP PORT command by parsing an IP address and port from a string and updating the control structure accordingly."}
{"func_name": "add_consumption_data_row", "func_src_before": "    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    ?,\n                    ?,\n                    ?\n                );\n            '''\n            self.c.execute(query, (ts, 0, 0))\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + ?,\n                PowerUsed = PowerUsed + ?\n                WHERE TimeStamp=?;\n            '''\n\n            self.c.execute(query, (energy_used, power_used, ts))\n\n            self.db.commit()", "func_src_after": "    def add_consumption_data_row(self, ts, energy_used, power_used):\n\n        if power_used > 0:\n\n            query = '''\n                INSERT OR IGNORE INTO Consumption (\n                    TimeStamp,\n                    EnergyUsed,\n                    PowerUsed                                \n                ) VALUES (\n                    %s,\n                    %s,\n                    %s\n                );\n            ''' % (ts, 0, 0)\n            self.c.execute(query)\n\n            query = '''\n                UPDATE Consumption SET \n                EnergyUsed = EnergyUsed + %s,\n                PowerUsed = PowerUsed + %s\n                WHERE TimeStamp = %s;\n            ''' % (energy_used, power_used, ts)\n\n            self.c.execute(query)\n\n            self.db.commit()", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert or update a row in a 'Consumption' database table with timestamp, energy used, and power used values, using parameter substitution for SQL queries."}
{"func_name": "AP4_AtomSampleTable::GetSample", "func_src_before": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    result = m_SttsAtom->GetDts(index, dts, &duration);\n    if (AP4_FAILED(result)) return result;\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "func_src_after": "AP4_AtomSampleTable::GetSample(AP4_Ordinal index, \n                               AP4_Sample& sample)\n{\n    AP4_Result result;\n\n    // check that we have an stsc atom\n    if (!m_StscAtom) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n    \n    // check that we have a chunk offset table\n    if (m_StcoAtom == NULL && m_Co64Atom == NULL) {\n        return AP4_ERROR_INVALID_FORMAT;\n    }\n\n    // MP4 uses 1-based indexes internally, so adjust by one\n    index++;\n\n    // find out in which chunk this sample is located\n    AP4_Ordinal chunk, skip, desc;\n    result = m_StscAtom->GetChunkForSample(index, chunk, skip, desc);\n    if (AP4_FAILED(result)) return result;\n    \n    // check that the result is within bounds\n    if (skip > index) return AP4_ERROR_INTERNAL;\n\n    // get the atom offset for this chunk\n    AP4_UI64 offset;\n    if (m_StcoAtom) {\n        AP4_UI32 offset_32;\n        result = m_StcoAtom->GetChunkOffset(chunk, offset_32);\n        offset = offset_32;\n    } else {\n        result = m_Co64Atom->GetChunkOffset(chunk, offset);\n    }\n    if (AP4_FAILED(result)) return result;\n    \n    // compute the additional offset inside the chunk\n    for (unsigned int i = index-skip; i < index; i++) {\n        AP4_Size size = 0;\n        if (m_StszAtom) {\n            result = m_StszAtom->GetSampleSize(i, size); \n        } else if (m_Stz2Atom) {\n            result = m_Stz2Atom->GetSampleSize(i, size); \n        } else {\n            result = AP4_ERROR_INVALID_FORMAT;\n        }\n        if (AP4_FAILED(result)) return result;\n        offset += size;\n    }\n\n    // set the description index\n    sample.SetDescriptionIndex(desc-1); // adjust for 0-based indexes\n\n    // set the dts and cts\n    AP4_UI32 cts_offset = 0;\n    AP4_UI64 dts        = 0;\n    AP4_UI32 duration   = 0;\n    if (m_SttsAtom) {\n        result = m_SttsAtom->GetDts(index, dts, &duration);\n        if (AP4_FAILED(result)) return result;\n    }\n    sample.SetDuration(duration);\n    sample.SetDts(dts);\n    if (m_CttsAtom == NULL) {\n        sample.SetCts(dts);\n    } else {\n        result = m_CttsAtom->GetCtsOffset(index, cts_offset); \n\t    if (AP4_FAILED(result)) return result;\n        sample.SetCtsDelta(cts_offset);\n    }     \n\n    // set the size\n    AP4_Size sample_size = 0;\n    if (m_StszAtom) {\n        result = m_StszAtom->GetSampleSize(index, sample_size); \n    } else if (m_Stz2Atom) {\n        result = m_Stz2Atom->GetSampleSize(index, sample_size); \n    } else {\n        result = AP4_ERROR_INVALID_FORMAT;\n    }\n    if (AP4_FAILED(result)) return result;\n    sample.SetSize(sample_size);\n\n    // set the sync flag\n    if (m_StssAtom == NULL) {\n        sample.SetSync(true);\n    } else {\n        sample.SetSync(m_StssAtom->IsSampleSync(index));\n    }\n\n    // set the offset\n    sample.SetOffset(offset);\n\n    // set the data stream\n    sample.SetDataStream(m_SampleStream);\n\n\n    return AP4_SUCCESS;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/2f267f89f957088197f4b1fc254632d1645b415d", "file_name": "Source/C++/Core/Ap4AtomSampleTable.cpp", "vul_type": "cwe-476", "description": "In C++, write a function to retrieve a media sample from an MP4 file's atom sample table by its index."}
{"func_name": "userLogin", "func_src_before": "    def userLogin(self):\n\n        sqlName=\"select count(*) from users where name=%s and password=%s;\"\n        params = [self.name,self.password]\n        checkName=sql.queryDB(self.conn,sqlName,params)\n        result=checkName[0][0]\n        if result == 0:\n            self.clean()\n            return False\n        else:\n            return True", "func_src_after": "    def userLogin(self):\n\n        sqlName=\"select count(*) from users where name='%s' and \\\n                password='%s';\"%(self.name,self.password)\n        checkName=sql.queryDB(self.conn,sqlName)\n\n        result=checkName[0][0]\n        if result == 0:\n            self.clean()\n            return False\n        else:\n            return True", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Write a Python function named `userLogin` that checks if a user's name and password exist in the database and returns a boolean accordingly."}
{"func_name": "dnxhd_find_frame_end", "func_src_before": "static int dnxhd_find_frame_end(DNXHDParserContext *dctx,\n                                const uint8_t *buf, int buf_size)\n{\n    ParseContext *pc = &dctx->pc;\n    uint64_t state = pc->state64;\n    int pic_found = pc->frame_start_found;\n    int i = 0;\n\n    if (!pic_found) {\n        for (i = 0; i < buf_size; i++) {\n            state = (state << 8) | buf[i];\n            if (ff_dnxhd_check_header_prefix(state & 0xffffffffff00LL) != 0) {\n                i++;\n                pic_found = 1;\n                dctx->cur_byte = 0;\n                dctx->remaining = 0;\n                break;\n            }\n        }\n    }\n\n    if (pic_found && !dctx->remaining) {\n        if (!buf_size) /* EOF considered as end of frame */\n            return 0;\n        for (; i < buf_size; i++) {\n            dctx->cur_byte++;\n            state = (state << 8) | buf[i];\n\n            if (dctx->cur_byte == 24) {\n                dctx->h = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 26) {\n                dctx->w = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 42) {\n                int cid = (state >> 32) & 0xFFFFFFFF;\n                int remaining;\n\n                if (cid <= 0)\n                    continue;\n\n                remaining = avpriv_dnxhd_get_frame_size(cid);\n                if (remaining <= 0) {\n                    remaining = dnxhd_get_hr_frame_size(cid, dctx->w, dctx->h);\n                    if (remaining <= 0)\n                        continue;\n                }\n                dctx->remaining = remaining;\n                if (buf_size - i + 47 >= dctx->remaining) {\n                    int remaining = dctx->remaining;\n\n                    pc->frame_start_found = 0;\n                    pc->state64 = -1;\n                    dctx->cur_byte = 0;\n                    dctx->remaining = 0;\n                    return remaining;\n                } else {\n                    dctx->remaining -= buf_size;\n                }\n            }\n        }\n    } else if (pic_found) {\n        if (dctx->remaining > buf_size) {\n            dctx->remaining -= buf_size;\n        } else {\n            int remaining = dctx->remaining;\n\n            pc->frame_start_found = 0;\n            pc->state64 = -1;\n            dctx->cur_byte = 0;\n            dctx->remaining = 0;\n            return remaining;\n        }\n    }\n    pc->frame_start_found = pic_found;\n    pc->state64 = state;\n    return END_NOT_FOUND;\n}", "func_src_after": "static int dnxhd_find_frame_end(DNXHDParserContext *dctx,\n                                const uint8_t *buf, int buf_size)\n{\n    ParseContext *pc = &dctx->pc;\n    uint64_t state = pc->state64;\n    int pic_found = pc->frame_start_found;\n    int i = 0;\n\n    if (!pic_found) {\n        for (i = 0; i < buf_size; i++) {\n            state = (state << 8) | buf[i];\n            if (ff_dnxhd_check_header_prefix(state & 0xffffffffff00LL) != 0) {\n                i++;\n                pic_found = 1;\n                dctx->cur_byte = 0;\n                dctx->remaining = 0;\n                break;\n            }\n        }\n    }\n\n    if (pic_found && !dctx->remaining) {\n        if (!buf_size) /* EOF considered as end of frame */\n            return 0;\n        for (; i < buf_size; i++) {\n            dctx->cur_byte++;\n            state = (state << 8) | buf[i];\n\n            if (dctx->cur_byte == 24) {\n                dctx->h = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 26) {\n                dctx->w = (state >> 32) & 0xFFFF;\n            } else if (dctx->cur_byte == 42) {\n                int cid = (state >> 32) & 0xFFFFFFFF;\n\n                if (cid <= 0)\n                    continue;\n\n                dctx->remaining = avpriv_dnxhd_get_frame_size(cid);\n                if (dctx->remaining <= 0) {\n                    dctx->remaining = dnxhd_get_hr_frame_size(cid, dctx->w, dctx->h);\n                    if (dctx->remaining <= 0)\n                        return dctx->remaining;\n                }\n                if (buf_size - i + 47 >= dctx->remaining) {\n                    int remaining = dctx->remaining;\n\n                    pc->frame_start_found = 0;\n                    pc->state64 = -1;\n                    dctx->cur_byte = 0;\n                    dctx->remaining = 0;\n                    return remaining;\n                } else {\n                    dctx->remaining -= buf_size;\n                }\n            }\n        }\n    } else if (pic_found) {\n        if (dctx->remaining > buf_size) {\n            dctx->remaining -= buf_size;\n        } else {\n            int remaining = dctx->remaining;\n\n            pc->frame_start_found = 0;\n            pc->state64 = -1;\n            dctx->cur_byte = 0;\n            dctx->remaining = 0;\n            return remaining;\n        }\n    }\n    pc->frame_start_found = pic_found;\n    pc->state64 = state;\n    return END_NOT_FOUND;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/0a709e2a10b8288a0cc383547924ecfe285cef89", "file_name": "libavcodec/dnxhd_parser.c", "vul_type": "cwe-476", "description": "Write a C function to detect the end of a frame in a DNXHD video stream buffer."}
{"func_name": "disk_seqf_stop", "func_src_before": "static void disk_seqf_stop(struct seq_file *seqf, void *v)\n{\n\tstruct class_dev_iter *iter = seqf->private;\n\n\t/* stop is called even after start failed :-( */\n\tif (iter) {\n\t\tclass_dev_iter_exit(iter);\n\t\tkfree(iter);\n\t}\n}", "func_src_after": "static void disk_seqf_stop(struct seq_file *seqf, void *v)\n{\n\tstruct class_dev_iter *iter = seqf->private;\n\n\t/* stop is called even after start failed :-( */\n\tif (iter) {\n\t\tclass_dev_iter_exit(iter);\n\t\tkfree(iter);\n\t\tseqf->private = NULL;\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/77da160530dd1dc94f6ae15a981f24e5f0021e84", "file_name": "block/genhd.c", "vul_type": "cwe-416", "description": "Write a C function named `disk_seqf_stop` that cleans up an iterator for a sequence file, ensuring memory is freed and the iterator is reset if necessary."}
{"func_name": "markTokenUsedExternal", "func_src_before": "def markTokenUsedExternal(token, optStr=\"\"):\n    conn, c = connectDB()\n    req = \"UPDATE {} SET \\\"options_selected\\\"=? WHERE token=?\".format(CFG(\"tokens_table_name\"))\n    c.execute(req, (optStr, token,))\n    closeDB(conn)", "func_src_after": "def markTokenUsedExternal(token, optStr=\"\"):\n    conn, c = connectDB()\n    req = \"UPDATE {} SET \\\"options_selected\\\"='{}' WHERE token='{}'\".format(CFG(\"tokens_table_name\"), \\\n                    optStr, token)\n    c.execute(req)\n    closeDB(conn)", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to update a database record's options_selected field for a given token."}
{"func_name": "WriteImageChannels", "func_src_before": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory((2*channels*\n        next_image->columns)+1,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType WriteImageChannels(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const MagickBooleanType separate,ExceptionInfo *exception)\n{\n  size_t\n    channels,\n    packet_size;\n\n  unsigned char\n    *compact_pixels;\n\n  /*\n    Write uncompressed pixels as separate planes.\n  */\n  channels=1;\n  packet_size=next_image->depth > 8UL ? 2UL : 1UL;\n  compact_pixels=(unsigned char *) NULL;\n  if (next_image->compression == RLECompression)\n    {\n      compact_pixels=(unsigned char *) AcquireQuantumMemory(2*channels*\n        next_image->columns,packet_size*sizeof(*compact_pixels));\n      if (compact_pixels == (unsigned char *) NULL)\n        ThrowWriterException(ResourceLimitError,\"MemoryAllocationFailed\");\n    }\n  if (IsImageGray(next_image) != MagickFalse)\n    {\n      if (next_image->compression == RLECompression)\n        {\n          /*\n            Packbits compression.\n          */\n          (void) WriteBlobMSBShort(image,1);\n          WritePackbitsLength(psd_info,image_info,image,next_image,\n            compact_pixels,GrayQuantum,exception);\n          if (next_image->alpha_trait != UndefinedPixelTrait)\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,AlphaQuantum,exception);\n        }\n      WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n        GrayQuantum,MagickTrue,exception);\n      if (next_image->alpha_trait != UndefinedPixelTrait)\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          AlphaQuantum,separate,exception);\n      (void) SetImageProgress(image,SaveImagesTag,0,1);\n    }\n  else\n    if (next_image->storage_class == PseudoClass)\n      {\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,IndexQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          IndexQuantum,MagickTrue,exception);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,0,1);\n      }\n    else\n      {\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n        if (next_image->compression == RLECompression)\n          {\n            /*\n              Packbits compression.\n            */\n            (void) WriteBlobMSBShort(image,1);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,RedQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,GreenQuantum,exception);\n            WritePackbitsLength(psd_info,image_info,image,next_image,\n              compact_pixels,BlueQuantum,exception);\n            if (next_image->colorspace == CMYKColorspace)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,BlackQuantum,exception);\n            if (next_image->alpha_trait != UndefinedPixelTrait)\n              WritePackbitsLength(psd_info,image_info,image,next_image,\n                compact_pixels,AlphaQuantum,exception);\n          }\n        (void) SetImageProgress(image,SaveImagesTag,0,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          RedQuantum,MagickTrue,exception);\n        (void) SetImageProgress(image,SaveImagesTag,1,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          GreenQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,2,6);\n        WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n          BlueQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,3,6);\n        if (next_image->colorspace == CMYKColorspace)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            BlackQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,4,6);\n        if (next_image->alpha_trait != UndefinedPixelTrait)\n          WriteOneChannel(psd_info,image_info,image,next_image,compact_pixels,\n            AlphaQuantum,separate,exception);\n        (void) SetImageProgress(image,SaveImagesTag,5,6);\n        if (next_image->colorspace == CMYKColorspace)\n          (void) NegateCMYK(next_image,exception);\n      }\n  if (next_image->compression == RLECompression)\n    compact_pixels=(unsigned char *) RelinquishMagickMemory(compact_pixels);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/6f1879d498bcc5cce12fe0c5decb8dbc0f608e5d", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "In C, write a function to handle writing image channel data with optional RLE compression and color space considerations."}
{"func_name": "usb_get_bos_descriptor", "func_src_before": "int usb_get_bos_descriptor(struct usb_device *dev)\n{\n\tstruct device *ddev = &dev->dev;\n\tstruct usb_bos_descriptor *bos;\n\tstruct usb_dev_cap_header *cap;\n\tunsigned char *buffer;\n\tint length, total_len, num, i;\n\tint ret;\n\n\tbos = kzalloc(sizeof(struct usb_bos_descriptor), GFP_KERNEL);\n\tif (!bos)\n\t\treturn -ENOMEM;\n\n\t/* Get BOS descriptor */\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, bos, USB_DT_BOS_SIZE);\n\tif (ret < USB_DT_BOS_SIZE) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tkfree(bos);\n\t\treturn ret;\n\t}\n\n\tlength = bos->bLength;\n\ttotal_len = le16_to_cpu(bos->wTotalLength);\n\tnum = bos->bNumDeviceCaps;\n\tkfree(bos);\n\tif (total_len < length)\n\t\treturn -EINVAL;\n\n\tdev->bos = kzalloc(sizeof(struct usb_host_bos), GFP_KERNEL);\n\tif (!dev->bos)\n\t\treturn -ENOMEM;\n\n\t/* Now let's get the whole BOS descriptor set */\n\tbuffer = kzalloc(total_len, GFP_KERNEL);\n\tif (!buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tdev->bos->desc = (struct usb_bos_descriptor *)buffer;\n\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, buffer, total_len);\n\tif (ret < total_len) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor set\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tgoto err;\n\t}\n\ttotal_len -= length;\n\n\tfor (i = 0; i < num; i++) {\n\t\tbuffer += length;\n\t\tcap = (struct usb_dev_cap_header *)buffer;\n\t\tlength = cap->bLength;\n\n\t\tif (total_len < length)\n\t\t\tbreak;\n\t\ttotal_len -= length;\n\n\t\tif (cap->bDescriptorType != USB_DT_DEVICE_CAPABILITY) {\n\t\t\tdev_warn(ddev, \"descriptor type invalid, skip\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch (cap->bDevCapabilityType) {\n\t\tcase USB_CAP_TYPE_WIRELESS_USB:\n\t\t\t/* Wireless USB cap descriptor is handled by wusb */\n\t\t\tbreak;\n\t\tcase USB_CAP_TYPE_EXT:\n\t\t\tdev->bos->ext_cap =\n\t\t\t\t(struct usb_ext_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SS_CAP_TYPE:\n\t\t\tdev->bos->ss_cap =\n\t\t\t\t(struct usb_ss_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SSP_CAP_TYPE:\n\t\t\tdev->bos->ssp_cap =\n\t\t\t\t(struct usb_ssp_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase CONTAINER_ID_TYPE:\n\t\t\tdev->bos->ss_id =\n\t\t\t\t(struct usb_ss_container_id_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_PTM_CAP_TYPE:\n\t\t\tdev->bos->ptm_cap =\n\t\t\t\t(struct usb_ptm_cap_descriptor *)buffer;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr:\n\tusb_release_bos_descriptor(dev);\n\treturn ret;\n}", "func_src_after": "int usb_get_bos_descriptor(struct usb_device *dev)\n{\n\tstruct device *ddev = &dev->dev;\n\tstruct usb_bos_descriptor *bos;\n\tstruct usb_dev_cap_header *cap;\n\tunsigned char *buffer;\n\tint length, total_len, num, i;\n\tint ret;\n\n\tbos = kzalloc(sizeof(struct usb_bos_descriptor), GFP_KERNEL);\n\tif (!bos)\n\t\treturn -ENOMEM;\n\n\t/* Get BOS descriptor */\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, bos, USB_DT_BOS_SIZE);\n\tif (ret < USB_DT_BOS_SIZE) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tkfree(bos);\n\t\treturn ret;\n\t}\n\n\tlength = bos->bLength;\n\ttotal_len = le16_to_cpu(bos->wTotalLength);\n\tnum = bos->bNumDeviceCaps;\n\tkfree(bos);\n\tif (total_len < length)\n\t\treturn -EINVAL;\n\n\tdev->bos = kzalloc(sizeof(struct usb_host_bos), GFP_KERNEL);\n\tif (!dev->bos)\n\t\treturn -ENOMEM;\n\n\t/* Now let's get the whole BOS descriptor set */\n\tbuffer = kzalloc(total_len, GFP_KERNEL);\n\tif (!buffer) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\tdev->bos->desc = (struct usb_bos_descriptor *)buffer;\n\n\tret = usb_get_descriptor(dev, USB_DT_BOS, 0, buffer, total_len);\n\tif (ret < total_len) {\n\t\tdev_err(ddev, \"unable to get BOS descriptor set\\n\");\n\t\tif (ret >= 0)\n\t\t\tret = -ENOMSG;\n\t\tgoto err;\n\t}\n\ttotal_len -= length;\n\n\tfor (i = 0; i < num; i++) {\n\t\tbuffer += length;\n\t\tcap = (struct usb_dev_cap_header *)buffer;\n\n\t\tif (total_len < sizeof(*cap) || total_len < cap->bLength) {\n\t\t\tdev->bos->desc->bNumDeviceCaps = i;\n\t\t\tbreak;\n\t\t}\n\t\tlength = cap->bLength;\n\t\ttotal_len -= length;\n\n\t\tif (cap->bDescriptorType != USB_DT_DEVICE_CAPABILITY) {\n\t\t\tdev_warn(ddev, \"descriptor type invalid, skip\\n\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tswitch (cap->bDevCapabilityType) {\n\t\tcase USB_CAP_TYPE_WIRELESS_USB:\n\t\t\t/* Wireless USB cap descriptor is handled by wusb */\n\t\t\tbreak;\n\t\tcase USB_CAP_TYPE_EXT:\n\t\t\tdev->bos->ext_cap =\n\t\t\t\t(struct usb_ext_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SS_CAP_TYPE:\n\t\t\tdev->bos->ss_cap =\n\t\t\t\t(struct usb_ss_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_SSP_CAP_TYPE:\n\t\t\tdev->bos->ssp_cap =\n\t\t\t\t(struct usb_ssp_cap_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase CONTAINER_ID_TYPE:\n\t\t\tdev->bos->ss_id =\n\t\t\t\t(struct usb_ss_container_id_descriptor *)buffer;\n\t\t\tbreak;\n\t\tcase USB_PTM_CAP_TYPE:\n\t\t\tdev->bos->ptm_cap =\n\t\t\t\t(struct usb_ptm_cap_descriptor *)buffer;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t}\n\n\treturn 0;\n\nerr:\n\tusb_release_bos_descriptor(dev);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/1c0edc3633b56000e18d82fc241e3995ca18a69e", "file_name": "drivers/usb/core/config.c", "vul_type": "cwe-125", "description": "Write a C function named `usb_get_bos_descriptor` that retrieves the Binary Object Store (BOS) descriptor for a USB device."}
{"func_name": "r_anal_bb_free", "func_src_before": "R_API void r_anal_bb_free(RAnalBlock *bb) {\n\tif (!bb) {\n\t\treturn;\n\t}\n\tr_anal_cond_free (bb->cond);\n\tR_FREE (bb->fingerprint);\n\tr_anal_diff_free (bb->diff);\n\tbb->diff = NULL;\n\tR_FREE (bb->op_bytes);\n\tr_anal_switch_op_free (bb->switch_op);\n\tbb->switch_op = NULL;\n\tbb->fingerprint = NULL;\n\tbb->cond = NULL;\n\tR_FREE (bb->label);\n\tR_FREE (bb->op_pos);\n\tR_FREE (bb->parent_reg_arena);\n\tif (bb->prev) {\n\t\tif (bb->prev->jumpbb == bb) {\n\t\t\tbb->prev->jumpbb = NULL;\n\t\t}\n\t\tif (bb->prev->failbb == bb) {\n\t\t\tbb->prev->failbb = NULL;\n\t\t}\n\t\tbb->prev = NULL;\n\t}\n\tif (bb->jumpbb) {\n\t\tbb->jumpbb->prev = NULL;\n\t\tbb->jumpbb = NULL;\n\t}\n\tif (bb->failbb) {\n\t\tbb->failbb->prev = NULL;\n\t\tbb->failbb = NULL;\n\t}\n\tR_FREE (bb);\n}", "func_src_after": "R_API void r_anal_bb_free(RAnalBlock *bb) {\n\tif (!bb) {\n\t\treturn;\n\t}\n\tr_anal_cond_free (bb->cond);\n\tR_FREE (bb->fingerprint);\n\tr_anal_diff_free (bb->diff);\n\tbb->diff = NULL;\n\tR_FREE (bb->op_bytes);\n\tr_anal_switch_op_free (bb->switch_op);\n\tbb->switch_op = NULL;\n\tbb->fingerprint = NULL;\n\tbb->cond = NULL;\n\tR_FREE (bb->label);\n\tR_FREE (bb->op_pos);\n\tR_FREE (bb->parent_reg_arena);\n\tif (bb->prev) {\n\t\tif (bb->prev->jumpbb == bb) {\n\t\t\tbb->prev->jumpbb = NULL;\n\t\t}\n\t\tif (bb->prev->failbb == bb) {\n\t\t\tbb->prev->failbb = NULL;\n\t\t}\n\t\tbb->prev = NULL;\n\t}\n\tif (bb->jumpbb) {\n\t\tbb->jumpbb->prev = NULL;\n\t\tbb->jumpbb = NULL;\n\t}\n\tif (bb->failbb) {\n\t\tbb->failbb->prev = NULL;\n\t\tbb->failbb = NULL;\n\t}\n\tif (bb->next) {\n\t\t// avoid double free\n\t\tbb->next->prev = NULL;\n\t}\n\tR_FREE (bb); // double free\n}", "commit_link": "github.com/radare/radare2/commit/90b71c017a7fa9732fe45fd21b245ee051b1f548", "file_name": "libr/anal/bb.c", "vul_type": "cwe-416", "description": "Write a function in C to safely free a basic block structure and its associated resources."}
{"func_name": "test_invalid_iscsi_ip", "func_src_before": "    def test_invalid_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = 'showport'\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = 'showport -iscsi'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = 'showport -iscsiname'\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        config = self.setup_configuration()\n        config.hp3par_iscsi_ips = ['10.10.220.250', '10.10.220.251']\n        config.iscsi_ip_address = '10.10.10.10'\n        self.mox.ReplayAll()\n\n        # no valid ip addr should be configured.\n        self.assertRaises(exception.InvalidInput,\n                          self.setup_driver,\n                          config,\n                          set_up_fakes=False)", "func_src_after": "    def test_invalid_iscsi_ip(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record driver set up\n        self.clear_mox()\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_port_cmd = ['showport']\n        _run_ssh(show_port_cmd, False).AndReturn([pack(PORT_RET), ''])\n\n        show_port_i_cmd = ['showport', '-iscsi']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(READY_ISCSI_PORT_RET),\n                                                    ''])\n\n        show_port_i_cmd = ['showport', '-iscsiname']\n        _run_ssh(show_port_i_cmd, False).AndReturn([pack(SHOW_PORT_ISCSI), ''])\n\n        config = self.setup_configuration()\n        config.hp3par_iscsi_ips = ['10.10.220.250', '10.10.220.251']\n        config.iscsi_ip_address = '10.10.10.10'\n        self.mox.ReplayAll()\n\n        # no valid ip addr should be configured.\n        self.assertRaises(exception.InvalidInput,\n                          self.setup_driver,\n                          config,\n                          set_up_fakes=False)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test that mocks SSH commands to validate iSCSI IP configuration."}
{"func_name": "_ensure_vdisk_no_fc_mappings", "func_src_before": "    def _ensure_vdisk_no_fc_mappings(self, name, allow_snaps=True):\n        # Ensure vdisk has no FlashCopy mappings\n        mapping_ids = self._get_vdisk_fc_mappings(name)\n        while len(mapping_ids):\n            wait_for_copy = False\n            for map_id in mapping_ids:\n                attrs = self._get_flashcopy_mapping_attributes(map_id)\n                if not attrs:\n                    continue\n                source = attrs['source_vdisk_name']\n                target = attrs['target_vdisk_name']\n                copy_rate = attrs['copy_rate']\n                status = attrs['status']\n\n                if copy_rate == '0':\n                    # Case #2: A vdisk that has snapshots\n                    if source == name:\n                        if not allow_snaps:\n                            return False\n                        ssh_cmd = ['svctask', 'chfcmap', '-copyrate', '50',\n                                   '-autodelete', 'on', map_id]\n                        out, err = self._run_ssh(ssh_cmd)\n                        wait_for_copy = True\n                    # Case #3: A snapshot\n                    else:\n                        msg = (_('Vdisk %(name)s not involved in '\n                                 'mapping %(src)s -> %(tgt)s') %\n                               {'name': name, 'src': source, 'tgt': target})\n                        self._driver_assert(target == name, msg)\n                        if status in ['copying', 'prepared']:\n                            self._run_ssh(['svctask', 'stopfcmap', map_id])\n                        elif status in ['stopping', 'preparing']:\n                            wait_for_copy = True\n                        else:\n                            self._run_ssh(['svctask', 'rmfcmap', '-force',\n                                           map_id])\n                # Case 4: Copy in progress - wait and will autodelete\n                else:\n                    if status == 'prepared':\n                        self._run_ssh(['svctask', 'stopfcmap', map_id])\n                        self._run_ssh(['svctask', 'rmfcmap', '-force', map_id])\n                    elif status == 'idle_or_copied':\n                        # Prepare failed\n                        self._run_ssh(['svctask', 'rmfcmap', '-force', map_id])\n                    else:\n                        wait_for_copy = True\n            if wait_for_copy:\n                time.sleep(5)\n            mapping_ids = self._get_vdisk_fc_mappings(name)\n        return True", "func_src_after": "    def _ensure_vdisk_no_fc_mappings(self, name, allow_snaps=True):\n        # Ensure vdisk has no FlashCopy mappings\n        mapping_ids = self._get_vdisk_fc_mappings(name)\n        while len(mapping_ids):\n            wait_for_copy = False\n            for map_id in mapping_ids:\n                attrs = self._get_flashcopy_mapping_attributes(map_id)\n                if not attrs:\n                    continue\n                source = attrs['source_vdisk_name']\n                target = attrs['target_vdisk_name']\n                copy_rate = attrs['copy_rate']\n                status = attrs['status']\n\n                if copy_rate == '0':\n                    # Case #2: A vdisk that has snapshots\n                    if source == name:\n                        if not allow_snaps:\n                            return False\n                        ssh_cmd = ('svctask chfcmap -copyrate 50 '\n                                   '-autodelete on %s' % map_id)\n                        out, err = self._run_ssh(ssh_cmd)\n                        wait_for_copy = True\n                    # Case #3: A snapshot\n                    else:\n                        msg = (_('Vdisk %(name)s not involved in '\n                                 'mapping %(src)s -> %(tgt)s') %\n                               {'name': name, 'src': source, 'tgt': target})\n                        self._driver_assert(target == name, msg)\n                        if status in ['copying', 'prepared']:\n                            self._run_ssh('svctask stopfcmap %s' % map_id)\n                        elif status in ['stopping', 'preparing']:\n                            wait_for_copy = True\n                        else:\n                            self._run_ssh('svctask rmfcmap -force %s' % map_id)\n                # Case 4: Copy in progress - wait and will autodelete\n                else:\n                    if status == 'prepared':\n                        self._run_ssh('svctask stopfcmap %s' % map_id)\n                        self._run_ssh('svctask rmfcmap -force %s' % map_id)\n                    elif status == 'idle_or_copied':\n                        # Prepare failed\n                        self._run_ssh('svctask rmfcmap -force %s' % map_id)\n                    else:\n                        wait_for_copy = True\n            if wait_for_copy:\n                time.sleep(5)\n            mapping_ids = self._get_vdisk_fc_mappings(name)\n        return True", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to check and handle FlashCopy mappings for a virtual disk, with an option to allow snapshots."}
{"func_name": "is_safe_url", "func_src_before": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    # Chrome treats \\ completely as / in paths but it could be part of some\n    # basic auth credentials so we need to check both URLs.\n    return _is_safe_url(url, host) and _is_safe_url(url.replace('\\\\', '/'), host)", "func_src_after": "def is_safe_url(url, host=None):\n    \"\"\"\n    Return ``True`` if the url is a safe redirection (i.e. it doesn't point to\n    a different host and uses a safe scheme).\n\n    Always returns ``False`` on an empty url.\n    \"\"\"\n    if url is not None:\n        url = url.strip()\n    if not url:\n        return False\n    # Chrome treats \\ completely as /\n    url = url.replace('\\\\', '/')\n    # Chrome considers any URL with more than two slashes to be absolute, but\n    # urlparse is not so flexible. Treat any url with three slashes as unsafe.\n    if url.startswith('///'):\n        return False\n    url_info = urlparse(url)\n    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.\n    # In that URL, example.com is not the hostname but, a path component. However,\n    # Chrome will still consider example.com to be the hostname, so we must not\n    # allow this syntax.\n    if not url_info.netloc and url_info.scheme:\n        return False\n    # Forbid URLs that start with control characters. Some browsers (like\n    # Chrome) ignore quite a few control characters at the start of a\n    # URL and might consider the URL as scheme relative.\n    if unicodedata.category(url[0])[0] == 'C':\n        return False\n    return ((not url_info.netloc or url_info.netloc == host) and\n            (not url_info.scheme or url_info.scheme in ['http', 'https']))", "commit_link": "github.com/django/django/commit/c5544d289233f501917e25970c03ed444abbd4f0", "file_name": "django/utils/http.py", "vul_type": "cwe-079", "description": "Write a Python function to check if a given URL is considered safe based on its host and scheme."}
{"func_name": "opj_j2k_write_mco", "func_src_before": "static OPJ_BOOL opj_j2k_write_mco(     opj_j2k_t *p_j2k,\n                                                struct opj_stream_private *p_stream,\n                                                struct opj_event_mgr * p_manager\n                                  )\n{\n        OPJ_BYTE * l_current_data = 00;\n        OPJ_UINT32 l_mco_size;\n        opj_tcp_t * l_tcp = 00;\n        opj_simple_mcc_decorrelation_data_t * l_mcc_record;\n        OPJ_UINT32 i;\n\n        /* preconditions */\n        assert(p_j2k != 00);\n        assert(p_manager != 00);\n        assert(p_stream != 00);\n\n        l_tcp =&(p_j2k->m_cp.tcps[p_j2k->m_current_tile_number]);\n        l_current_data = p_j2k->m_specific_param.m_encoder.m_header_tile_data;\n\n        l_mco_size = 5 + l_tcp->m_nb_mcc_records;\n        if (l_mco_size > p_j2k->m_specific_param.m_encoder.m_header_tile_data_size) {\n\n                OPJ_BYTE *new_header_tile_data = (OPJ_BYTE *) opj_realloc(p_j2k->m_specific_param.m_encoder.m_header_tile_data, l_mco_size);\n                if (! new_header_tile_data) {\n                        opj_free(p_j2k->m_specific_param.m_encoder.m_header_tile_data);\n                        p_j2k->m_specific_param.m_encoder.m_header_tile_data = NULL;\n                        p_j2k->m_specific_param.m_encoder.m_header_tile_data_size = 0;\n                        opj_event_msg(p_manager, EVT_ERROR, \"Not enough memory to write MCO marker\\n\");\n                        return OPJ_FALSE;\n                }\n                p_j2k->m_specific_param.m_encoder.m_header_tile_data = new_header_tile_data;\n                p_j2k->m_specific_param.m_encoder.m_header_tile_data_size = l_mco_size;\n        }\n\n        opj_write_bytes(l_current_data,J2K_MS_MCO,2);                   /* MCO */\n        l_current_data += 2;\n\n        opj_write_bytes(l_current_data,l_mco_size-2,2);                 /* Lmco */\n        l_current_data += 2;\n\n        opj_write_bytes(l_current_data,l_tcp->m_nb_mcc_records,1);      /* Nmco : only one tranform stage*/\n        ++l_current_data;\n\n        l_mcc_record = l_tcp->m_mcc_records;\n        for     (i=0;i<l_tcp->m_nb_mcc_records;++i) {\n                opj_write_bytes(l_current_data,l_mcc_record->m_index,1);/* Imco -> use the mcc indicated by 1*/\n                ++l_current_data;\n\n                ++l_mcc_record;\n        }\n\n        if (opj_stream_write_data(p_stream,p_j2k->m_specific_param.m_encoder.m_header_tile_data,l_mco_size,p_manager) != l_mco_size) {\n                return OPJ_FALSE;\n        }\n\n        return OPJ_TRUE;\n}", "func_src_after": "static OPJ_BOOL opj_j2k_write_mco(     opj_j2k_t *p_j2k,\n                                                struct opj_stream_private *p_stream,\n                                                struct opj_event_mgr * p_manager\n                                  )\n{\n        OPJ_BYTE * l_current_data = 00;\n        OPJ_UINT32 l_mco_size;\n        opj_tcp_t * l_tcp = 00;\n        opj_simple_mcc_decorrelation_data_t * l_mcc_record;\n        OPJ_UINT32 i;\n\n        /* preconditions */\n        assert(p_j2k != 00);\n        assert(p_manager != 00);\n        assert(p_stream != 00);\n\n        l_tcp =&(p_j2k->m_cp.tcps[p_j2k->m_current_tile_number]);\n\t\n        l_mco_size = 5 + l_tcp->m_nb_mcc_records;\n        if (l_mco_size > p_j2k->m_specific_param.m_encoder.m_header_tile_data_size) {\n\n                OPJ_BYTE *new_header_tile_data = (OPJ_BYTE *) opj_realloc(p_j2k->m_specific_param.m_encoder.m_header_tile_data, l_mco_size);\n                if (! new_header_tile_data) {\n                        opj_free(p_j2k->m_specific_param.m_encoder.m_header_tile_data);\n                        p_j2k->m_specific_param.m_encoder.m_header_tile_data = NULL;\n                        p_j2k->m_specific_param.m_encoder.m_header_tile_data_size = 0;\n                        opj_event_msg(p_manager, EVT_ERROR, \"Not enough memory to write MCO marker\\n\");\n                        return OPJ_FALSE;\n                }\n                p_j2k->m_specific_param.m_encoder.m_header_tile_data = new_header_tile_data;\n                p_j2k->m_specific_param.m_encoder.m_header_tile_data_size = l_mco_size;\n        }\n        l_current_data = p_j2k->m_specific_param.m_encoder.m_header_tile_data;\n\n\n        opj_write_bytes(l_current_data,J2K_MS_MCO,2);                   /* MCO */\n        l_current_data += 2;\n\n        opj_write_bytes(l_current_data,l_mco_size-2,2);                 /* Lmco */\n        l_current_data += 2;\n\n        opj_write_bytes(l_current_data,l_tcp->m_nb_mcc_records,1);      /* Nmco : only one tranform stage*/\n        ++l_current_data;\n\n        l_mcc_record = l_tcp->m_mcc_records;\n        for (i=0;i<l_tcp->m_nb_mcc_records;++i) {\n                opj_write_bytes(l_current_data,l_mcc_record->m_index,1);/* Imco -> use the mcc indicated by 1*/\n                ++l_current_data;\n                ++l_mcc_record;\n        }\n\n        if (opj_stream_write_data(p_stream,p_j2k->m_specific_param.m_encoder.m_header_tile_data,l_mco_size,p_manager) != l_mco_size) {\n                return OPJ_FALSE;\n        }\n\n        return OPJ_TRUE;\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/940100c28ae28931722290794889cf84a92c5f6f", "file_name": "src/lib/openjp2/j2k.c", "vul_type": "cwe-416", "description": "Write a C function named `opj_j2k_write_mco` that writes the MCO marker for JPEG 2000 image encoding."}
{"func_name": "closeGame", "func_src_before": "def closeGame(ID):\n\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = ?\", ID)\n\tdatabase.commit()", "func_src_after": "def closeGame(ID):\n\tdb.execute(\"UPDATE games set Running = 'No' WHERE ID = %i\" % ID)\n\tdatabase.commit()", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function to update the 'Running' status of a game to 'No' in a database using the game's ID."}
{"func_name": "sctp_do_peeloff", "func_src_before": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "func_src_after": "int sctp_do_peeloff(struct sock *sk, sctp_assoc_t id, struct socket **sockp)\n{\n\tstruct sctp_association *asoc = sctp_id2assoc(sk, id);\n\tstruct sctp_sock *sp = sctp_sk(sk);\n\tstruct socket *sock;\n\tint err = 0;\n\n\t/* Do not peel off from one netns to another one. */\n\tif (!net_eq(current->nsproxy->net_ns, sock_net(sk)))\n\t\treturn -EINVAL;\n\n\tif (!asoc)\n\t\treturn -EINVAL;\n\n\t/* If there is a thread waiting on more sndbuf space for\n\t * sending on this asoc, it cannot be peeled.\n\t */\n\tif (waitqueue_active(&asoc->wait))\n\t\treturn -EBUSY;\n\n\t/* An association cannot be branched off from an already peeled-off\n\t * socket, nor is this supported for tcp style sockets.\n\t */\n\tif (!sctp_style(sk, UDP))\n\t\treturn -EINVAL;\n\n\t/* Create a new socket.  */\n\terr = sock_create(sk->sk_family, SOCK_SEQPACKET, IPPROTO_SCTP, &sock);\n\tif (err < 0)\n\t\treturn err;\n\n\tsctp_copy_sock(sock->sk, sk, asoc);\n\n\t/* Make peeled-off sockets more like 1-1 accepted sockets.\n\t * Set the daddr and initialize id to something more random\n\t */\n\tsp->pf->to_sk_daddr(&asoc->peer.primary_addr, sk);\n\n\t/* Populate the fields of the newsk from the oldsk and migrate the\n\t * asoc to the newsk.\n\t */\n\tsctp_sock_migrate(sk, sock->sk, asoc, SCTP_SOCKET_UDP_HIGH_BANDWIDTH);\n\n\t*sockp = sock;\n\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/df80cd9b28b9ebaa284a41df611dbf3a2d05ca74", "file_name": "net/sctp/socket.c", "vul_type": "cwe-416", "description": "Write a C function named `sctp_do_peeloff` that peels off an SCTP association from a socket and creates a new socket for it."}
{"func_name": "shadow_server_start", "func_src_before": "int shadow_server_start(rdpShadowServer* server)\n{\n\tBOOL ipc;\n\tBOOL status;\n\tWSADATA wsaData;\n\n\tif (!server)\n\t\treturn -1;\n\n\tif (WSAStartup(MAKEWORD(2, 2), &wsaData) != 0)\n\t\treturn -1;\n\n#ifndef _WIN32\n\tsignal(SIGPIPE, SIG_IGN);\n#endif\n\tserver->screen = shadow_screen_new(server);\n\n\tif (!server->screen)\n\t{\n\t\tWLog_ERR(TAG, \"screen_new failed\");\n\t\treturn -1;\n\t}\n\n\tserver->capture = shadow_capture_new(server);\n\n\tif (!server->capture)\n\t{\n\t\tWLog_ERR(TAG, \"capture_new failed\");\n\t\treturn -1;\n\t}\n\n\t/* Bind magic:\n\t *\n\t * emtpy                 ... bind TCP all\n\t * <local path>          ... bind local (IPC)\n\t * bind-socket,<address> ... bind TCP to specified interface\n\t */\n\tipc = server->ipcSocket && (strncmp(bind_address, server->ipcSocket,\n\t                                    strnlen(bind_address, sizeof(bind_address))) != 0);\n\tif (!ipc)\n\t{\n\t\tsize_t x, count;\n\t\tchar** list = CommandLineParseCommaSeparatedValuesEx(NULL, server->ipcSocket, &count);\n\t\tif (!list || (count <= 1))\n\t\t{\n\t\t\tfree(list);\n\t\t\tif (server->ipcSocket == NULL)\n\t\t\t{\n\t\t\t\tif (!open_port(server, NULL))\n\t\t\t\t\treturn -1;\n\t\t\t}\n\t\t\telse\n\t\t\t\treturn -1;\n\t\t}\n\n\t\tfor (x = 1; x < count; x++)\n\t\t{\n\t\t\tBOOL success = open_port(server, list[x]);\n\t\t\tif (!success)\n\t\t\t{\n\t\t\t\tfree(list);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t\tfree(list);\n\t}\n\telse\n\t{\n\t\tstatus = server->listener->OpenLocal(server->listener, server->ipcSocket);\n\t\tif (!status)\n\t\t{\n\t\t\tWLog_ERR(TAG, \"Problem creating local socket listener. (Port already used or \"\n\t\t\t              \"insufficient permissions?)\");\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (!(server->thread = CreateThread(NULL, 0, shadow_server_thread, (void*)server, 0, NULL)))\n\t{\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}", "func_src_after": "int shadow_server_start(rdpShadowServer* server)\n{\n\tBOOL ipc;\n\tBOOL status;\n\tWSADATA wsaData;\n\n\tif (!server)\n\t\treturn -1;\n\n\tif (WSAStartup(MAKEWORD(2, 2), &wsaData) != 0)\n\t\treturn -1;\n\n#ifndef _WIN32\n\tsignal(SIGPIPE, SIG_IGN);\n#endif\n\tserver->screen = shadow_screen_new(server);\n\n\tif (!server->screen)\n\t{\n\t\tWLog_ERR(TAG, \"screen_new failed\");\n\t\treturn -1;\n\t}\n\n\tserver->capture = shadow_capture_new(server);\n\n\tif (!server->capture)\n\t{\n\t\tWLog_ERR(TAG, \"capture_new failed\");\n\t\treturn -1;\n\t}\n\n\t/* Bind magic:\n\t *\n\t * emtpy                 ... bind TCP all\n\t * <local path>          ... bind local (IPC)\n\t * bind-socket,<address> ... bind TCP to specified interface\n\t */\n\tipc = server->ipcSocket && (strncmp(bind_address, server->ipcSocket,\n\t                                    strnlen(bind_address, sizeof(bind_address))) != 0);\n\tif (!ipc)\n\t{\n\t\tsize_t x, count;\n\t\tchar** list = CommandLineParseCommaSeparatedValuesEx(NULL, server->ipcSocket, &count);\n\t\tif (!list || (count <= 1))\n\t\t{\n\t\t\tif (server->ipcSocket == NULL)\n\t\t\t{\n\t\t\t\tif (!open_port(server, NULL))\n\t\t\t\t{\n\t\t\t\t\tfree(list);\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tfree(list);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tfor (x = 1; x < count; x++)\n\t\t{\n\t\t\tBOOL success = open_port(server, list[x]);\n\t\t\tif (!success)\n\t\t\t{\n\t\t\t\tfree(list);\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\t\tfree(list);\n\t}\n\telse\n\t{\n\t\tstatus = server->listener->OpenLocal(server->listener, server->ipcSocket);\n\t\tif (!status)\n\t\t{\n\t\t\tWLog_ERR(TAG, \"Problem creating local socket listener. (Port already used or \"\n\t\t\t              \"insufficient permissions?)\");\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (!(server->thread = CreateThread(NULL, 0, shadow_server_thread, (void*)server, 0, NULL)))\n\t{\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/6d86e20e1e7caaab4f0c7f89e36d32914dbccc52", "file_name": "server/shadow/shadow_server.c", "vul_type": "cwe-416", "description": "Write a C function named `shadow_server_start` that initializes a remote desktop protocol shadow server, handling network setup and thread creation."}
{"func_name": "ComplexImages", "func_src_before": "MagickExport Image *ComplexImages(const Image *images,const ComplexOperator op,\n  ExceptionInfo *exception)\n{\n#define ComplexImageTag  \"Complex/Image\"\n\n  CacheView\n    *Ai_view,\n    *Ar_view,\n    *Bi_view,\n    *Br_view,\n    *Ci_view,\n    *Cr_view;\n\n  const char\n    *artifact;\n\n  const Image\n    *Ai_image,\n    *Ar_image,\n    *Bi_image,\n    *Br_image;\n\n  double\n    snr;\n\n  Image\n    *Ci_image,\n    *complex_images,\n    *Cr_image,\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  ssize_t\n    y;\n\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  if (images->next == (Image *) NULL)\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),ImageError,\n        \"ImageSequenceRequired\",\"`%s'\",images->filename);\n      return((Image *) NULL);\n    }\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(image,DirectClass,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return(image);\n    }\n  image->depth=32UL;\n  complex_images=NewImageList();\n  AppendImageToList(&complex_images,image);\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    {\n      complex_images=DestroyImageList(complex_images);\n      return(complex_images);\n    }\n  AppendImageToList(&complex_images,image);\n  /*\n    Apply complex mathematics to image pixels.\n  */\n  artifact=GetImageArtifact(image,\"complex:snr\");\n  snr=0.0;\n  if (artifact != (const char *) NULL)\n    snr=StringToDouble(artifact,(char **) NULL);\n  Ar_image=images;\n  Ai_image=images->next;\n  Br_image=images;\n  Bi_image=images->next;\n  if ((images->next->next != (Image *) NULL) &&\n      (images->next->next->next != (Image *) NULL))\n    {\n      Br_image=images->next->next;\n      Bi_image=images->next->next->next;\n    }\n  Cr_image=complex_images;\n  Ci_image=complex_images->next;\n  Ar_view=AcquireVirtualCacheView(Ar_image,exception);\n  Ai_view=AcquireVirtualCacheView(Ai_image,exception);\n  Br_view=AcquireVirtualCacheView(Br_image,exception);\n  Bi_view=AcquireVirtualCacheView(Bi_image,exception);\n  Cr_view=AcquireAuthenticCacheView(Cr_image,exception);\n  Ci_view=AcquireAuthenticCacheView(Ci_image,exception);\n  status=MagickTrue;\n  progress=0;\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(Cr_image,complex_images,Cr_image->rows,1L)\n#endif\n  for (y=0; y < (ssize_t) Cr_image->rows; y++)\n  {\n    register const Quantum\n      *magick_restrict Ai,\n      *magick_restrict Ar,\n      *magick_restrict Bi,\n      *magick_restrict Br;\n\n    register Quantum\n      *magick_restrict Ci,\n      *magick_restrict Cr;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    Ar=GetCacheViewVirtualPixels(Ar_view,0,y,Cr_image->columns,1,exception);\n    Ai=GetCacheViewVirtualPixels(Ai_view,0,y,Cr_image->columns,1,exception);\n    Br=GetCacheViewVirtualPixels(Br_view,0,y,Cr_image->columns,1,exception);\n    Bi=GetCacheViewVirtualPixels(Bi_view,0,y,Cr_image->columns,1,exception);\n    Cr=QueueCacheViewAuthenticPixels(Cr_view,0,y,Cr_image->columns,1,exception);\n    Ci=QueueCacheViewAuthenticPixels(Ci_view,0,y,Ci_image->columns,1,exception);\n    if ((Ar == (const Quantum *) NULL) || (Ai == (const Quantum *) NULL) || \n        (Br == (const Quantum *) NULL) || (Bi == (const Quantum *) NULL) ||\n        (Cr == (Quantum *) NULL) || (Ci == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < (ssize_t) Cr_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      for (i=0; i < (ssize_t) GetPixelChannels(Cr_image); i++)\n      {\n        switch (op)\n        {\n          case AddComplexOperator:\n          {\n            Cr[i]=Ar[i]+Br[i];\n            Ci[i]=Ai[i]+Bi[i];\n            break;\n          }\n          case ConjugateComplexOperator:\n          default:\n          {\n            Cr[i]=Ar[i];\n            Ci[i]=(-Bi[i]);\n            break;\n          }\n          case DivideComplexOperator:\n          {\n            double\n              gamma;\n\n            gamma=PerceptibleReciprocal((double) Br[i]*Br[i]+Bi[i]*Bi[i]+snr);\n            Cr[i]=gamma*((double) Ar[i]*Br[i]+(double) Ai[i]*Bi[i]);\n            Ci[i]=gamma*((double) Ai[i]*Br[i]-(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case MagnitudePhaseComplexOperator:\n          {\n            Cr[i]=sqrt((double) Ar[i]*Ar[i]+(double) Ai[i]*Ai[i]);\n            Ci[i]=atan2((double) Ai[i],(double) Ar[i])/(2.0*MagickPI)+0.5;\n            break;\n          }\n          case MultiplyComplexOperator:\n          {\n            Cr[i]=QuantumScale*((double) Ar[i]*Br[i]-(double) Ai[i]*Bi[i]);\n            Ci[i]=QuantumScale*((double) Ai[i]*Br[i]+(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case RealImaginaryComplexOperator:\n          {\n            Cr[i]=Ar[i]*cos(2.0*MagickPI*(Ai[i]-0.5));\n            Ci[i]=Ar[i]*sin(2.0*MagickPI*(Ai[i]-0.5));\n            break;\n          }\n          case SubtractComplexOperator:\n          {\n            Cr[i]=Ar[i]-Br[i];\n            Ci[i]=Ai[i]-Bi[i];\n            break;\n          }\n        }\n      }\n      Ar+=GetPixelChannels(Ar_image);\n      Ai+=GetPixelChannels(Ai_image);\n      Br+=GetPixelChannels(Br_image);\n      Bi+=GetPixelChannels(Bi_image);\n      Cr+=GetPixelChannels(Cr_image);\n      Ci+=GetPixelChannels(Ci_image);\n    }\n    if (SyncCacheViewAuthenticPixels(Ci_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (SyncCacheViewAuthenticPixels(Cr_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (images->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(images,ComplexImageTag,progress,images->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  Cr_view=DestroyCacheView(Cr_view);\n  Ci_view=DestroyCacheView(Ci_view);\n  Br_view=DestroyCacheView(Br_view);\n  Bi_view=DestroyCacheView(Bi_view);\n  Ar_view=DestroyCacheView(Ar_view);\n  Ai_view=DestroyCacheView(Ai_view);\n  if (status == MagickFalse)\n    complex_images=DestroyImageList(complex_images);\n  return(complex_images);\n}", "func_src_after": "MagickExport Image *ComplexImages(const Image *images,const ComplexOperator op,\n  ExceptionInfo *exception)\n{\n#define ComplexImageTag  \"Complex/Image\"\n\n  CacheView\n    *Ai_view,\n    *Ar_view,\n    *Bi_view,\n    *Br_view,\n    *Ci_view,\n    *Cr_view;\n\n  const char\n    *artifact;\n\n  const Image\n    *Ai_image,\n    *Ar_image,\n    *Bi_image,\n    *Br_image;\n\n  double\n    snr;\n\n  Image\n    *Ci_image,\n    *complex_images,\n    *Cr_image,\n    *image;\n\n  MagickBooleanType\n    status;\n\n  MagickOffsetType\n    progress;\n\n  size_t\n    number_channels;\n\n  ssize_t\n    y;\n\n  assert(images != (Image *) NULL);\n  assert(images->signature == MagickCoreSignature);\n  if (images->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",images->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  if (images->next == (Image *) NULL)\n    {\n      (void) ThrowMagickException(exception,GetMagickModule(),ImageError,\n        \"ImageSequenceRequired\",\"`%s'\",images->filename);\n      return((Image *) NULL);\n    }\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    return((Image *) NULL);\n  if (SetImageStorageClass(image,DirectClass,exception) == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return(image);\n    }\n  image->depth=32UL;\n  complex_images=NewImageList();\n  AppendImageToList(&complex_images,image);\n  image=CloneImage(images,0,0,MagickTrue,exception);\n  if (image == (Image *) NULL)\n    {\n      complex_images=DestroyImageList(complex_images);\n      return(complex_images);\n    }\n  AppendImageToList(&complex_images,image);\n  /*\n    Apply complex mathematics to image pixels.\n  */\n  artifact=GetImageArtifact(image,\"complex:snr\");\n  snr=0.0;\n  if (artifact != (const char *) NULL)\n    snr=StringToDouble(artifact,(char **) NULL);\n  Ar_image=images;\n  Ai_image=images->next;\n  Br_image=images;\n  Bi_image=images->next;\n  if ((images->next->next != (Image *) NULL) &&\n      (images->next->next->next != (Image *) NULL))\n    {\n      Br_image=images->next->next;\n      Bi_image=images->next->next->next;\n    }\n  Cr_image=complex_images;\n  Ci_image=complex_images->next;\n  number_channels=MagickMin(MagickMin(MagickMin(\n    Ar_image->number_channels,Ai_image->number_channels),MagickMin(\n    Br_image->number_channels,Bi_image->number_channels)),MagickMin(\n    Cr_image->number_channels,Ci_image->number_channels));\n  Ar_view=AcquireVirtualCacheView(Ar_image,exception);\n  Ai_view=AcquireVirtualCacheView(Ai_image,exception);\n  Br_view=AcquireVirtualCacheView(Br_image,exception);\n  Bi_view=AcquireVirtualCacheView(Bi_image,exception);\n  Cr_view=AcquireAuthenticCacheView(Cr_image,exception);\n  Ci_view=AcquireAuthenticCacheView(Ci_image,exception);\n  status=MagickTrue;\n  progress=0;\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n  #pragma omp parallel for schedule(static) shared(progress,status) \\\n    magick_number_threads(Cr_image,complex_images,Cr_image->rows,1L)\n#endif\n  for (y=0; y < (ssize_t) Cr_image->rows; y++)\n  {\n    register const Quantum\n      *magick_restrict Ai,\n      *magick_restrict Ar,\n      *magick_restrict Bi,\n      *magick_restrict Br;\n\n    register Quantum\n      *magick_restrict Ci,\n      *magick_restrict Cr;\n\n    register ssize_t\n      x;\n\n    if (status == MagickFalse)\n      continue;\n    Ar=GetCacheViewVirtualPixels(Ar_view,0,y,Cr_image->columns,1,exception);\n    Ai=GetCacheViewVirtualPixels(Ai_view,0,y,Cr_image->columns,1,exception);\n    Br=GetCacheViewVirtualPixels(Br_view,0,y,Cr_image->columns,1,exception);\n    Bi=GetCacheViewVirtualPixels(Bi_view,0,y,Cr_image->columns,1,exception);\n    Cr=QueueCacheViewAuthenticPixels(Cr_view,0,y,Cr_image->columns,1,exception);\n    Ci=QueueCacheViewAuthenticPixels(Ci_view,0,y,Ci_image->columns,1,exception);\n    if ((Ar == (const Quantum *) NULL) || (Ai == (const Quantum *) NULL) || \n        (Br == (const Quantum *) NULL) || (Bi == (const Quantum *) NULL) ||\n        (Cr == (Quantum *) NULL) || (Ci == (Quantum *) NULL))\n      {\n        status=MagickFalse;\n        continue;\n      }\n    for (x=0; x < (ssize_t) Cr_image->columns; x++)\n    {\n      register ssize_t\n        i;\n\n      for (i=0; i < (ssize_t) number_channels; i++)\n      {\n        switch (op)\n        {\n          case AddComplexOperator:\n          {\n            Cr[i]=Ar[i]+Br[i];\n            Ci[i]=Ai[i]+Bi[i];\n            break;\n          }\n          case ConjugateComplexOperator:\n          default:\n          {\n            Cr[i]=Ar[i];\n            Ci[i]=(-Bi[i]);\n            break;\n          }\n          case DivideComplexOperator:\n          {\n            double\n              gamma;\n\n            gamma=PerceptibleReciprocal((double) Br[i]*Br[i]+Bi[i]*Bi[i]+snr);\n            Cr[i]=gamma*((double) Ar[i]*Br[i]+(double) Ai[i]*Bi[i]);\n            Ci[i]=gamma*((double) Ai[i]*Br[i]-(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case MagnitudePhaseComplexOperator:\n          {\n            Cr[i]=sqrt((double) Ar[i]*Ar[i]+(double) Ai[i]*Ai[i]);\n            Ci[i]=atan2((double) Ai[i],(double) Ar[i])/(2.0*MagickPI)+0.5;\n            break;\n          }\n          case MultiplyComplexOperator:\n          {\n            Cr[i]=QuantumScale*((double) Ar[i]*Br[i]-(double) Ai[i]*Bi[i]);\n            Ci[i]=QuantumScale*((double) Ai[i]*Br[i]+(double) Ar[i]*Bi[i]);\n            break;\n          }\n          case RealImaginaryComplexOperator:\n          {\n            Cr[i]=Ar[i]*cos(2.0*MagickPI*(Ai[i]-0.5));\n            Ci[i]=Ar[i]*sin(2.0*MagickPI*(Ai[i]-0.5));\n            break;\n          }\n          case SubtractComplexOperator:\n          {\n            Cr[i]=Ar[i]-Br[i];\n            Ci[i]=Ai[i]-Bi[i];\n            break;\n          }\n        }\n      }\n      Ar+=GetPixelChannels(Ar_image);\n      Ai+=GetPixelChannels(Ai_image);\n      Br+=GetPixelChannels(Br_image);\n      Bi+=GetPixelChannels(Bi_image);\n      Cr+=GetPixelChannels(Cr_image);\n      Ci+=GetPixelChannels(Ci_image);\n    }\n    if (SyncCacheViewAuthenticPixels(Ci_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (SyncCacheViewAuthenticPixels(Cr_view,exception) == MagickFalse)\n      status=MagickFalse;\n    if (images->progress_monitor != (MagickProgressMonitor) NULL)\n      {\n        MagickBooleanType\n          proceed;\n\n#if defined(MAGICKCORE_OPENMP_SUPPORT)\n        #pragma omp atomic\n#endif\n        progress++;\n        proceed=SetImageProgress(images,ComplexImageTag,progress,images->rows);\n        if (proceed == MagickFalse)\n          status=MagickFalse;\n      }\n  }\n  Cr_view=DestroyCacheView(Cr_view);\n  Ci_view=DestroyCacheView(Ci_view);\n  Br_view=DestroyCacheView(Br_view);\n  Bi_view=DestroyCacheView(Bi_view);\n  Ar_view=DestroyCacheView(Ar_view);\n  Ai_view=DestroyCacheView(Ai_view);\n  if (status == MagickFalse)\n    complex_images=DestroyImageList(complex_images);\n  return(complex_images);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/d5089971bd792311aaab5cb73460326d7ef7f32d", "file_name": "MagickCore/fourier.c", "vul_type": "cwe-125", "description": "Write a C function in ImageMagick to perform complex operations on a sequence of images."}
{"func_name": "adminchild", "func_src_before": "void * adminchild(struct clientparam* param) {\n int i, res;\n char * buf;\n char username[256];\n char *sb;\n char *req = NULL;\n struct printparam pp;\n int contentlen = 0;\n int isform = 0;\n\n pp.inbuf = 0;\n pp.cp = param;\n\n buf = myalloc(LINESIZE);\n if(!buf) {RETURN(555);}\n i = sockgetlinebuf(param, CLIENT, (unsigned char *)buf, LINESIZE - 1, '\\n', conf.timeouts[STRING_S]);\n if(i<5 || ((buf[0]!='G' || buf[1]!='E' || buf[2]!='T' || buf[3]!=' ' || buf[4]!='/') && \n\t   (buf[0]!='P' || buf[1]!='O' || buf[2]!='S' || buf[3]!='T' || buf[4]!=' ' || buf[5]!='/')))\n {\n\tRETURN(701);\n }\n buf[i] = 0;\n sb = strchr(buf+5, ' ');\n if(!sb){\n\tRETURN(702);\n }\n *sb = 0;\n req = mystrdup(buf + ((*buf == 'P')? 6 : 5));\n while((i = sockgetlinebuf(param, CLIENT, (unsigned char *)buf, LINESIZE - 1, '\\n', conf.timeouts[STRING_S])) > 2){\n\tbuf[i] = 0;\n\tif(i > 19 && (!strncasecmp(buf, \"authorization\", 13))){\n\t\tsb = strchr(buf, ':');\n\t\tif(!sb)continue;\n\t\t++sb;\n\t\twhile(isspace(*sb))sb++;\n\t\tif(!*sb || strncasecmp(sb, \"basic\", 5)){\n\t\t\tcontinue;\n\t\t}\n\t\tsb+=5;\n\t\twhile(isspace(*sb))sb++;\n\t\ti = de64((unsigned char *)sb, (unsigned char *)username, 255);\n\t\tif(i<=0)continue;\n\t\tusername[i] = 0;\n\t\tsb = strchr((char *)username, ':');\n\t\tif(sb){\n\t\t\t*sb = 0;\n\t\t\tif(param->password)myfree(param->password);\n\t\t\tparam->password = (unsigned char *)mystrdup(sb+1);\n\t\t}\n\t\tif(param->username) myfree(param->username);\n\t\tparam->username = (unsigned char *)mystrdup(username);\n\t\tcontinue;\n\t}\n\telse if(i > 15 && (!strncasecmp(buf, \"content-length:\", 15))){\n\t\tsb = buf + 15;\n\t\twhile(isspace(*sb))sb++;\n\t\tcontentlen = atoi(sb);\n\t}\n\telse if(i > 13 && (!strncasecmp(buf, \"content-type:\", 13))){\n\t\tsb = buf + 13;\n\t\twhile(isspace(*sb))sb++;\n\t\tif(!strncasecmp(sb, \"x-www-form-urlencoded\", 21)) isform = 1;\n\t}\n }\n param->operation = ADMIN;\n if(isform && contentlen) {\n\tprintstr(&pp, \"HTTP/1.0 100 Continue\\r\\n\\r\\n\");\n\tstdpr(&pp, NULL, 0);\n }\n res = (*param->srv->authfunc)(param);\n if(res && res != 10) {\n\tprintstr(&pp, authreq);\n\tRETURN(res);\n }\n if(param->srv->singlepacket || param->redirected){\n\tif(*req == 'C') req[1] = 0;\n\telse *req = 0;\n }\n sprintf(buf, ok, conf.stringtable?(char *)conf.stringtable[2]:\"3proxy\", conf.stringtable?(char *)conf.stringtable[2]:\"3[APA3A] tiny proxy\", conf.stringtable?(char *)conf.stringtable[3]:\"\");\n if(*req != 'S') printstr(&pp, buf);\n switch(*req){\n\tcase 'C':\n\t\tprintstr(&pp, counters);\n\t\t{\n\t\t\tstruct trafcount *cp; \n\t\t\tint num = 0;\n\t\t\tfor(cp = conf.trafcounter; cp; cp = cp->next, num++){\n\t\t\t int inbuf = 0;\n\n\t\t\t if(cp->ace && (param->srv->singlepacket || param->redirected)){\n\t\t\t\tif(!ACLmatches(cp->ace, param))continue;\n\t\t\t }\n\t\t\t if(req[1] == 'S' && atoi(req+2) == num) cp->disabled=0;\n\t\t\t if(req[1] == 'D' && atoi(req+2) == num) cp->disabled=1;\n\t\t\t inbuf += sprintf(buf,\t\"<tr>\"\n\t\t\t\t\t\t\"<td>%s</td><td><A HREF=\\'/C%c%d\\'>%s</A></td><td>\",\n\t\t\t\t\t\t(cp->comment)?cp->comment:\"&nbsp;\",\n\t\t\t\t\t\t(cp->disabled)?'S':'D',\n\t\t\t\t\t\tnum,\n\t\t\t\t\t\t(cp->disabled)?\"NO\":\"YES\"\n\t\t\t\t\t);\n\t\t\t if(!cp->ace || !cp->ace->users){\n\t\t\t\tinbuf += sprintf(buf+inbuf, \"<center>ANY</center>\");\n\t\t\t }\n\t\t\t else {\n\t\t\t\tinbuf += printuserlist(buf+inbuf, LINESIZE-800, cp->ace->users, \",<br />\\r\\n\");\n\t\t\t }\n\t\t\t inbuf += sprintf(buf+inbuf, \"</td><td>\");\n\t\t\t if(!cp->ace || !cp->ace->src){\n\t\t\t\tinbuf += sprintf(buf+inbuf, \"<center>ANY</center>\");\n\t\t\t }\n\t\t\t else {\n\t\t\t\tinbuf += printiplist(buf+inbuf, LINESIZE-512, cp->ace->src, \",<br />\\r\\n\");\n\t\t\t }\n\t\t\t inbuf += sprintf(buf+inbuf, \"</td><td>\");\n\t\t\t if(!cp->ace || !cp->ace->dst){\n\t\t\t\tinbuf += sprintf(buf+inbuf, \"<center>ANY</center>\");\n\t\t\t }\n\t\t\t else {\n\t\t\t\tinbuf += printiplist(buf+inbuf, LINESIZE-512, cp->ace->dst, \",<br />\\r\\n\");\n\t\t\t }\n\t\t\t inbuf += sprintf(buf+inbuf, \"</td><td>\");\n\t\t\t if(!cp->ace || !cp->ace->ports){\n\t\t\t\tinbuf += sprintf(buf+inbuf, \"<center>ANY</center>\");\n\t\t\t }\n\t\t\t else {\n\t\t\t\tinbuf += printportlist(buf+inbuf, LINESIZE-128, cp->ace->ports, \",<br />\\r\\n\");\n\t\t\t }\n\t\t\t if(cp->type == NONE) {\n\t\t\t  inbuf += sprintf(buf+inbuf,\t\n\t\t\t\t\t\"</td><td colspan=\\'6\\' align=\\'center\\'>exclude from limitation</td></tr>\\r\\n\"\n\t\t\t\t );\n\t\t\t }\n\t\t\t else {\n\t\t\t  inbuf += sprintf(buf+inbuf,\t\n\t\t\t\t\t\"</td><td>%\"PRINTF_INT64_MODIFIER\"u</td>\"\n\t\t\t\t\t\"<td>MB%s</td>\"\n\t\t\t\t\t\"<td>%\"PRINTF_INT64_MODIFIER\"u</td>\"\n\t\t\t\t\t\"<td>%s</td>\",\n\t\t\t\t cp->traflim64 / (1024 * 1024),\n\t\t\t\t rotations[cp->type],\n\t\t\t\t cp->traf64,\n\t\t\t\t cp->cleared?ctime(&cp->cleared):\"never\"\n\t\t\t\t);\n\t\t\t inbuf += sprintf(buf + inbuf,\n\t\t\t\t\t\"<td>%s</td>\"\n\t\t\t\t\t\"<td>%i</td>\"\n\t\t\t\t\t\"</tr>\\r\\n\",\n\n\t\t\t\t cp->updated?ctime(&cp->updated):\"never\",\n\t\t\t\t cp->number\n\t\t\t\t);\n\t\t\t }\n\t\t\t printstr(&pp, buf);\n\t\t\t}\n\n\t\t}\n\t\tprintstr(&pp, counterstail);\n\t\tbreak;\n\t\t\n\tcase 'R':\n\t\tconf.needreload = 1;\n\t\tprintstr(&pp, \"<h3>Reload scheduled</h3>\");\n\t\tbreak;\n\tcase 'S':\n\t\t{\n\t\t\tif(req[1] == 'X'){\n\t\t\t\tprintstr(&pp, style);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tprintstr(&pp, xml);\n\t\t\tprintval(conf.services, TYPE_SERVER, 0, &pp);\n\t\t\tprintstr(&pp, postxml);\n\t\t}\n\t\t\tbreak;\n\tcase 'F':\n\t\t{\n\t\t\tFILE *fp;\n\t\t\tchar buf[256];\n\n\t\t\tfp = confopen();\n\t\t\tif(!fp){\n\t\t\t\tprintstr(&pp, \"<h3><font color=\\\"red\\\">Failed to open config file</font></h3>\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t\tprintstr(&pp, \"<h3>Please be careful editing config file remotely</h3>\");\n\t\t\t\tprintstr(&pp, \"<form method=\\\"POST\\\" action=\\\"/U\\\"><textarea cols=\\\"80\\\" rows=\\\"30\\\" name=\\\"conffile\\\">\");\n\t\t\t\twhile(fgets(buf, 256, fp)){\n\t\t\t\t\tprintstr(&pp, buf);\n\t\t\t\t}\n\t\t\t\tif(!writable) fclose(fp);\n\t\t\t\tprintstr(&pp, \"</textarea><br><input type=\\\"Submit\\\"></form>\");\n\t\t\tbreak;\n\t\t}\n\tcase 'U':\n\t\t{\n\t\t\tint l=0;\n\t\t\tint error = 0;\n\n\t\t\tif(!writable || fseek(writable, 0, 0)){\n\t\t\t\terror = 1;\n\t\t\t}\n\t\t\twhile((i = sockgetlinebuf(param, CLIENT, (unsigned char *)buf, LINESIZE - 1, '+', conf.timeouts[STRING_S])) > 0){\n\t\t\t\tif(i > (contentlen - l)) i = (contentlen - l);\n\t\t\t\tbuf[i] = 0;\n\t\t\t\tif(!l){\n\t\t\t\t\tif(strncasecmp(buf, \"conffile=\", 9)) error = 1;\n\t\t\t\t}\n\t\t\t\tif(!error){\n\t\t\t\t\tdecodeurl((unsigned char *)buf, 1);\n\t\t\t\t\tfprintf(writable, \"%s\", l? buf : buf + 9);\n\t\t\t\t}\n\t\t\t\tl += i;\n\t\t\t\tif(l >= contentlen) break;\n\t\t\t}\n\t\t\tif(writable && !error){\n\t\t\t\tfflush(writable);\n#ifndef _WINCE\n\t\t\t\tftruncate(fileno(writable), ftell(writable));\n#endif\n\t\t\t}\n\t\t\tprintstr(&pp, error?    \"<h3><font color=\\\"red\\\">Config file is not writable</font></h3>Make sure you have \\\"writable\\\" command in configuration file\":\n\t\t\t\t\t\t\"<h3>Configuration updated</h3>\");\n\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tprintstr(&pp, (char *)conf.stringtable[WEBBANNERS]);\n\t\tbreak;\n }\n if(*req != 'S') printstr(&pp, tail);\n\nCLEANRET:\n\n\n printstr(&pp, NULL);\n if(buf) myfree(buf);\n (*param->srv->logfunc)(param, (unsigned char *)req);\n if(req)myfree(req);\n freeparam(param);\n return (NULL);\n}", "func_src_after": "void * adminchild(struct clientparam* param) {\n int i, res;\n char * buf;\n char username[256];\n char *sb;\n char *req = NULL;\n struct printparam pp;\n unsigned contentlen = 0;\n int isform = 0;\n\n pp.inbuf = 0;\n pp.cp = param;\n\n buf = myalloc(LINESIZE);\n if(!buf) {RETURN(555);}\n i = sockgetlinebuf(param, CLIENT, (unsigned char *)buf, LINESIZE - 1, '\\n', conf.timeouts[STRING_S]);\n if(i<5 || ((buf[0]!='G' || buf[1]!='E' || buf[2]!='T' || buf[3]!=' ' || buf[4]!='/') && \n\t   (buf[0]!='P' || buf[1]!='O' || buf[2]!='S' || buf[3]!='T' || buf[4]!=' ' || buf[5]!='/')))\n {\n\tRETURN(701);\n }\n buf[i] = 0;\n sb = strchr(buf+5, ' ');\n if(!sb){\n\tRETURN(702);\n }\n *sb = 0;\n req = mystrdup(buf + ((*buf == 'P')? 6 : 5));\n while((i = sockgetlinebuf(param, CLIENT, (unsigned char *)buf, LINESIZE - 1, '\\n', conf.timeouts[STRING_S])) > 2){\n\tbuf[i] = 0;\n\tif(i > 19 && (!strncasecmp(buf, \"authorization\", 13))){\n\t\tsb = strchr(buf, ':');\n\t\tif(!sb)continue;\n\t\t++sb;\n\t\twhile(isspace(*sb))sb++;\n\t\tif(!*sb || strncasecmp(sb, \"basic\", 5)){\n\t\t\tcontinue;\n\t\t}\n\t\tsb+=5;\n\t\twhile(isspace(*sb))sb++;\n\t\ti = de64((unsigned char *)sb, (unsigned char *)username, 255);\n\t\tif(i<=0)continue;\n\t\tusername[i] = 0;\n\t\tsb = strchr((char *)username, ':');\n\t\tif(sb){\n\t\t\t*sb = 0;\n\t\t\tif(param->password)myfree(param->password);\n\t\t\tparam->password = (unsigned char *)mystrdup(sb+1);\n\t\t}\n\t\tif(param->username) myfree(param->username);\n\t\tparam->username = (unsigned char *)mystrdup(username);\n\t\tcontinue;\n\t}\n\telse if(i > 15 && (!strncasecmp(buf, \"content-length:\", 15))){\n\t\tsb = buf + 15;\n\t\twhile(isspace(*sb))sb++;\n\t\tsscanf(sb, \"%u\", &contentlen);\n\t\tif(contentlen > LINESIZE*1024) contentlen = 0;\n\t}\n\telse if(i > 13 && (!strncasecmp(buf, \"content-type:\", 13))){\n\t\tsb = buf + 13;\n\t\twhile(isspace(*sb))sb++;\n\t\tif(!strncasecmp(sb, \"x-www-form-urlencoded\", 21)) isform = 1;\n\t}\n }\n param->operation = ADMIN;\n if(isform && contentlen) {\n\tprintstr(&pp, \"HTTP/1.0 100 Continue\\r\\n\\r\\n\");\n\tstdpr(&pp, NULL, 0);\n }\n res = (*param->srv->authfunc)(param);\n if(res && res != 10) {\n\tprintstr(&pp, authreq);\n\tRETURN(res);\n }\n if(param->srv->singlepacket || param->redirected){\n\tif(*req == 'C') req[1] = 0;\n\telse *req = 0;\n }\n sprintf(buf, ok, conf.stringtable?(char *)conf.stringtable[2]:\"3proxy\", conf.stringtable?(char *)conf.stringtable[2]:\"3[APA3A] tiny proxy\", conf.stringtable?(char *)conf.stringtable[3]:\"\");\n if(*req != 'S') printstr(&pp, buf);\n switch(*req){\n\tcase 'C':\n\t\tprintstr(&pp, counters);\n\t\t{\n\t\t\tstruct trafcount *cp; \n\t\t\tint num = 0;\n\t\t\tfor(cp = conf.trafcounter; cp; cp = cp->next, num++){\n\t\t\t int inbuf = 0;\n\n\t\t\t if(cp->ace && (param->srv->singlepacket || param->redirected)){\n\t\t\t\tif(!ACLmatches(cp->ace, param))continue;\n\t\t\t }\n\t\t\t if(req[1] == 'S' && atoi(req+2) == num) cp->disabled=0;\n\t\t\t if(req[1] == 'D' && atoi(req+2) == num) cp->disabled=1;\n\t\t\t inbuf += sprintf(buf,\t\"<tr>\"\n\t\t\t\t\t\t\"<td>%s</td><td><A HREF=\\'/C%c%d\\'>%s</A></td><td>\",\n\t\t\t\t\t\t(cp->comment)?cp->comment:\"&nbsp;\",\n\t\t\t\t\t\t(cp->disabled)?'S':'D',\n\t\t\t\t\t\tnum,\n\t\t\t\t\t\t(cp->disabled)?\"NO\":\"YES\"\n\t\t\t\t\t);\n\t\t\t if(!cp->ace || !cp->ace->users){\n\t\t\t\tinbuf += sprintf(buf+inbuf, \"<center>ANY</center>\");\n\t\t\t }\n\t\t\t else {\n\t\t\t\tinbuf += printuserlist(buf+inbuf, LINESIZE-800, cp->ace->users, \",<br />\\r\\n\");\n\t\t\t }\n\t\t\t inbuf += sprintf(buf+inbuf, \"</td><td>\");\n\t\t\t if(!cp->ace || !cp->ace->src){\n\t\t\t\tinbuf += sprintf(buf+inbuf, \"<center>ANY</center>\");\n\t\t\t }\n\t\t\t else {\n\t\t\t\tinbuf += printiplist(buf+inbuf, LINESIZE-512, cp->ace->src, \",<br />\\r\\n\");\n\t\t\t }\n\t\t\t inbuf += sprintf(buf+inbuf, \"</td><td>\");\n\t\t\t if(!cp->ace || !cp->ace->dst){\n\t\t\t\tinbuf += sprintf(buf+inbuf, \"<center>ANY</center>\");\n\t\t\t }\n\t\t\t else {\n\t\t\t\tinbuf += printiplist(buf+inbuf, LINESIZE-512, cp->ace->dst, \",<br />\\r\\n\");\n\t\t\t }\n\t\t\t inbuf += sprintf(buf+inbuf, \"</td><td>\");\n\t\t\t if(!cp->ace || !cp->ace->ports){\n\t\t\t\tinbuf += sprintf(buf+inbuf, \"<center>ANY</center>\");\n\t\t\t }\n\t\t\t else {\n\t\t\t\tinbuf += printportlist(buf+inbuf, LINESIZE-128, cp->ace->ports, \",<br />\\r\\n\");\n\t\t\t }\n\t\t\t if(cp->type == NONE) {\n\t\t\t  inbuf += sprintf(buf+inbuf,\t\n\t\t\t\t\t\"</td><td colspan=\\'6\\' align=\\'center\\'>exclude from limitation</td></tr>\\r\\n\"\n\t\t\t\t );\n\t\t\t }\n\t\t\t else {\n\t\t\t  inbuf += sprintf(buf+inbuf,\t\n\t\t\t\t\t\"</td><td>%\"PRINTF_INT64_MODIFIER\"u</td>\"\n\t\t\t\t\t\"<td>MB%s</td>\"\n\t\t\t\t\t\"<td>%\"PRINTF_INT64_MODIFIER\"u</td>\"\n\t\t\t\t\t\"<td>%s</td>\",\n\t\t\t\t cp->traflim64 / (1024 * 1024),\n\t\t\t\t rotations[cp->type],\n\t\t\t\t cp->traf64,\n\t\t\t\t cp->cleared?ctime(&cp->cleared):\"never\"\n\t\t\t\t);\n\t\t\t inbuf += sprintf(buf + inbuf,\n\t\t\t\t\t\"<td>%s</td>\"\n\t\t\t\t\t\"<td>%i</td>\"\n\t\t\t\t\t\"</tr>\\r\\n\",\n\n\t\t\t\t cp->updated?ctime(&cp->updated):\"never\",\n\t\t\t\t cp->number\n\t\t\t\t);\n\t\t\t }\n\t\t\t printstr(&pp, buf);\n\t\t\t}\n\n\t\t}\n\t\tprintstr(&pp, counterstail);\n\t\tbreak;\n\t\t\n\tcase 'R':\n\t\tconf.needreload = 1;\n\t\tprintstr(&pp, \"<h3>Reload scheduled</h3>\");\n\t\tbreak;\n\tcase 'S':\n\t\t{\n\t\t\tif(req[1] == 'X'){\n\t\t\t\tprintstr(&pp, style);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tprintstr(&pp, xml);\n\t\t\tprintval(conf.services, TYPE_SERVER, 0, &pp);\n\t\t\tprintstr(&pp, postxml);\n\t\t}\n\t\t\tbreak;\n\tcase 'F':\n\t\t{\n\t\t\tFILE *fp;\n\t\t\tchar buf[256];\n\n\t\t\tfp = confopen();\n\t\t\tif(!fp){\n\t\t\t\tprintstr(&pp, \"<h3><font color=\\\"red\\\">Failed to open config file</font></h3>\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t\tprintstr(&pp, \"<h3>Please be careful editing config file remotely</h3>\");\n\t\t\t\tprintstr(&pp, \"<form method=\\\"POST\\\" action=\\\"/U\\\" enctype=\\\"application/x-www-form-urlencoded\\\"><textarea cols=\\\"80\\\" rows=\\\"30\\\" name=\\\"conffile\\\">\");\n\t\t\t\twhile(fgets(buf, 256, fp)){\n\t\t\t\t\tprintstr(&pp, buf);\n\t\t\t\t}\n\t\t\t\tif(!writable) fclose(fp);\n\t\t\t\tprintstr(&pp, \"</textarea><br><input type=\\\"Submit\\\"></form>\");\n\t\t\tbreak;\n\t\t}\n\tcase 'U':\n\t\t{\n\t\t\tunsigned l=0;\n\t\t\tint error = 0;\n\n\t\t\tif(!writable || !contentlen || fseek(writable, 0, 0)){\n\t\t\t\terror = 1;\n\t\t\t}\n\t\t\twhile(l < contentlen && (i = sockgetlinebuf(param, CLIENT, (unsigned char *)buf, (contentlen - l) > LINESIZE - 1?LINESIZE - 1:contentlen - l, '+', conf.timeouts[STRING_S])) > 0){\n\t\t\t\tif(i > (contentlen - l)) i = (contentlen - l);\n\t\t\t\tif(!l){\n\t\t\t\t\tif(i<9 || strncasecmp(buf, \"conffile=\", 9)) error = 1;\n\t\t\t\t}\n\t\t\t\tif(!error){\n\t\t\t\t\tbuf[i] = 0;\n\t\t\t\t\tdecodeurl((unsigned char *)buf, 1);\n\t\t\t\t\tfprintf(writable, \"%s\", l? buf : buf + 9);\n\t\t\t\t}\n\t\t\t\tl += i;\n\t\t\t}\n\t\t\tif(writable && !error){\n\t\t\t\tfflush(writable);\n#ifndef _WINCE\n\t\t\t\tftruncate(fileno(writable), ftell(writable));\n#endif\n\t\t\t}\n\t\t\tprintstr(&pp, error?    \"<h3><font color=\\\"red\\\">Config file is not writable</font></h3>Make sure you have \\\"writable\\\" command in configuration file\":\n\t\t\t\t\t\t\"<h3>Configuration updated</h3>\");\n\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\tprintstr(&pp, (char *)conf.stringtable[WEBBANNERS]);\n\t\tbreak;\n }\n if(*req != 'S') printstr(&pp, tail);\n\nCLEANRET:\n\n\n printstr(&pp, NULL);\n if(buf) myfree(buf);\n (*param->srv->logfunc)(param, (unsigned char *)req);\n if(req)myfree(req);\n freeparam(param);\n return (NULL);\n}", "commit_link": "github.com/z3APA3A/3proxy/commit/3b67dc844789dc0f00e934270c7b349bcb547865", "file_name": "src/webadmin.c", "vul_type": "cwe-787", "description": "Write a C function named `adminchild` that processes HTTP requests for a proxy server's admin interface."}
{"func_name": "cbs_jpeg_split_fragment", "func_src_before": "static int cbs_jpeg_split_fragment(CodedBitstreamContext *ctx,\n                                   CodedBitstreamFragment *frag,\n                                   int header)\n{\n    AVBufferRef *data_ref;\n    uint8_t *data;\n    size_t data_size;\n    int unit, start, end, marker, next_start, next_marker;\n    int err, i, j, length;\n\n    if (frag->data_size < 4) {\n        // Definitely too short to be meaningful.\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i + 1 < frag->data_size && frag->data[i] != 0xff; i++);\n    if (i > 0) {\n        av_log(ctx->log_ctx, AV_LOG_WARNING, \"Discarding %d bytes at \"\n               \"beginning of image.\\n\", i);\n    }\n    for (++i; i + 1 < frag->data_size && frag->data[i] == 0xff; i++);\n    if (i + 1 >= frag->data_size && frag->data[i]) {\n        av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: \"\n               \"no SOI marker found.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    marker = frag->data[i];\n    if (marker != JPEG_MARKER_SOI) {\n        av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: first \"\n               \"marker is %02x, should be SOI.\\n\", marker);\n        return AVERROR_INVALIDDATA;\n    }\n    for (++i; i + 1 < frag->data_size && frag->data[i] == 0xff; i++);\n    if (i + 1 >= frag->data_size) {\n        av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: \"\n               \"no image content found.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    marker = frag->data[i];\n    start  = i + 1;\n\n    for (unit = 0;; unit++) {\n        if (marker == JPEG_MARKER_EOI) {\n            break;\n        } else if (marker == JPEG_MARKER_SOS) {\n            for (i = start; i + 1 < frag->data_size; i++) {\n                if (frag->data[i] != 0xff)\n                    continue;\n                end = i;\n                for (++i; i + 1 < frag->data_size &&\n                          frag->data[i] == 0xff; i++);\n                if (i + 1 >= frag->data_size) {\n                    next_marker = -1;\n                } else {\n                    if (frag->data[i] == 0x00)\n                        continue;\n                    next_marker = frag->data[i];\n                    next_start  = i + 1;\n                }\n                break;\n            }\n        } else {\n            i = start;\n            if (i + 2 > frag->data_size) {\n                av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: \"\n                       \"truncated at %02x marker.\\n\", marker);\n                return AVERROR_INVALIDDATA;\n            }\n            length = AV_RB16(frag->data + i);\n            if (i + length > frag->data_size) {\n                av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: \"\n                       \"truncated at %02x marker segment.\\n\", marker);\n                return AVERROR_INVALIDDATA;\n            }\n            end = start + length;\n\n            i = end;\n            if (frag->data[i] != 0xff) {\n                next_marker = -1;\n            } else {\n                for (++i; i + 1 < frag->data_size &&\n                          frag->data[i] == 0xff; i++);\n                if (i + 1 >= frag->data_size) {\n                    next_marker = -1;\n                } else {\n                    next_marker = frag->data[i];\n                    next_start  = i + 1;\n                }\n            }\n        }\n\n        if (marker == JPEG_MARKER_SOS) {\n            length = AV_RB16(frag->data + start);\n\n            data_ref = NULL;\n            data     = av_malloc(end - start +\n                                 AV_INPUT_BUFFER_PADDING_SIZE);\n            if (!data)\n                return AVERROR(ENOMEM);\n\n            memcpy(data, frag->data + start, length);\n            for (i = start + length, j = length; i < end; i++, j++) {\n                if (frag->data[i] == 0xff) {\n                    while (frag->data[i] == 0xff)\n                        ++i;\n                    data[j] = 0xff;\n                } else {\n                    data[j] = frag->data[i];\n                }\n            }\n            data_size = j;\n\n            memset(data + data_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n\n        } else {\n            data      = frag->data + start;\n            data_size = end - start;\n            data_ref  = frag->data_ref;\n        }\n\n        err = ff_cbs_insert_unit_data(ctx, frag, unit, marker,\n                                      data, data_size, data_ref);\n        if (err < 0)\n            return err;\n\n        if (next_marker == -1)\n            break;\n        marker = next_marker;\n        start  = next_start;\n    }\n\n    return 0;\n}", "func_src_after": "static int cbs_jpeg_split_fragment(CodedBitstreamContext *ctx,\n                                   CodedBitstreamFragment *frag,\n                                   int header)\n{\n    AVBufferRef *data_ref;\n    uint8_t *data;\n    size_t data_size;\n    int unit, start, end, marker, next_start, next_marker;\n    int err, i, j, length;\n\n    if (frag->data_size < 4) {\n        // Definitely too short to be meaningful.\n        return AVERROR_INVALIDDATA;\n    }\n\n    for (i = 0; i + 1 < frag->data_size && frag->data[i] != 0xff; i++);\n    if (i > 0) {\n        av_log(ctx->log_ctx, AV_LOG_WARNING, \"Discarding %d bytes at \"\n               \"beginning of image.\\n\", i);\n    }\n    for (++i; i + 1 < frag->data_size && frag->data[i] == 0xff; i++);\n    if (i + 1 >= frag->data_size && frag->data[i]) {\n        av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: \"\n               \"no SOI marker found.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    marker = frag->data[i];\n    if (marker != JPEG_MARKER_SOI) {\n        av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: first \"\n               \"marker is %02x, should be SOI.\\n\", marker);\n        return AVERROR_INVALIDDATA;\n    }\n    for (++i; i + 1 < frag->data_size && frag->data[i] == 0xff; i++);\n    if (i + 1 >= frag->data_size) {\n        av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: \"\n               \"no image content found.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n    marker = frag->data[i];\n    start  = i + 1;\n\n    for (unit = 0;; unit++) {\n        if (marker == JPEG_MARKER_EOI) {\n            break;\n        } else if (marker == JPEG_MARKER_SOS) {\n            for (i = start; i + 1 < frag->data_size; i++) {\n                if (frag->data[i] != 0xff)\n                    continue;\n                end = i;\n                for (++i; i + 1 < frag->data_size &&\n                          frag->data[i] == 0xff; i++);\n                if (i + 1 >= frag->data_size) {\n                    next_marker = -1;\n                } else {\n                    if (frag->data[i] == 0x00)\n                        continue;\n                    next_marker = frag->data[i];\n                    next_start  = i + 1;\n                }\n                break;\n            }\n        } else {\n            i = start;\n            if (i + 2 > frag->data_size) {\n                av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: \"\n                       \"truncated at %02x marker.\\n\", marker);\n                return AVERROR_INVALIDDATA;\n            }\n            length = AV_RB16(frag->data + i);\n            if (i + length > frag->data_size) {\n                av_log(ctx->log_ctx, AV_LOG_ERROR, \"Invalid JPEG image: \"\n                       \"truncated at %02x marker segment.\\n\", marker);\n                return AVERROR_INVALIDDATA;\n            }\n            end = start + length;\n\n            i = end;\n            if (frag->data[i] != 0xff) {\n                next_marker = -1;\n            } else {\n                for (++i; i + 1 < frag->data_size &&\n                          frag->data[i] == 0xff; i++);\n                if (i + 1 >= frag->data_size) {\n                    next_marker = -1;\n                } else {\n                    next_marker = frag->data[i];\n                    next_start  = i + 1;\n                }\n            }\n        }\n\n        if (marker == JPEG_MARKER_SOS) {\n            length = AV_RB16(frag->data + start);\n\n            if (length > end - start)\n                return AVERROR_INVALIDDATA;\n\n            data_ref = NULL;\n            data     = av_malloc(end - start +\n                                 AV_INPUT_BUFFER_PADDING_SIZE);\n            if (!data)\n                return AVERROR(ENOMEM);\n\n            memcpy(data, frag->data + start, length);\n            for (i = start + length, j = length; i < end; i++, j++) {\n                if (frag->data[i] == 0xff) {\n                    while (frag->data[i] == 0xff)\n                        ++i;\n                    data[j] = 0xff;\n                } else {\n                    data[j] = frag->data[i];\n                }\n            }\n            data_size = j;\n\n            memset(data + data_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n\n        } else {\n            data      = frag->data + start;\n            data_size = end - start;\n            data_ref  = frag->data_ref;\n        }\n\n        err = ff_cbs_insert_unit_data(ctx, frag, unit, marker,\n                                      data, data_size, data_ref);\n        if (err < 0)\n            return err;\n\n        if (next_marker == -1)\n            break;\n        marker = next_marker;\n        start  = next_start;\n    }\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/1812352d767ccf5431aa440123e2e260a4db2726", "file_name": "libavcodec/cbs_jpeg.c", "vul_type": "cwe-787", "description": "Write a C function to parse and validate a JPEG image fragment for errors and markers."}
{"func_name": "incrementOption", "func_src_before": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option=?\".format(CFG(\"options_table_name\"))\n    cursor.execute(req, (key,))", "func_src_after": "def incrementOption(cursor, poll_name, option):\n    key = poll_name+\"-\"+option\n    req = \"UPDATE {} SET count=count+1 WHERE name_option = '{}';\".format(CFG(\"options_table_name\"), key)\n    cursor.execute(req)", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function to increment the vote count for a given option in a poll using SQL."}
{"func_name": "AP4_HdlrAtom::AP4_HdlrAtom", "func_src_before": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    int name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    if (name_size == 0) return;\n    char* name = new char[name_size+1];\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "func_src_after": "AP4_HdlrAtom::AP4_HdlrAtom(AP4_UI32        size, \n                           AP4_UI08        version,\n                           AP4_UI32        flags,\n                           AP4_ByteStream& stream) :\n    AP4_Atom(AP4_ATOM_TYPE_HDLR, size, version, flags)\n{\n    AP4_UI32 predefined;\n    stream.ReadUI32(predefined);\n    stream.ReadUI32(m_HandlerType);\n    stream.ReadUI32(m_Reserved[0]);\n    stream.ReadUI32(m_Reserved[1]);\n    stream.ReadUI32(m_Reserved[2]);\n    \n    // read the name unless it is empty\n    if (size < AP4_FULL_ATOM_HEADER_SIZE+20) return;\n    AP4_UI32 name_size = size-(AP4_FULL_ATOM_HEADER_SIZE+20);\n    char* name = new char[name_size+1];\n    if (name == NULL) return;\n    stream.Read(name, name_size);\n    name[name_size] = '\\0'; // force a null termination\n    // handle a special case: the Quicktime files have a pascal\n    // string here, but ISO MP4 files have a C string.\n    // we try to detect a pascal encoding and correct it.\n    if (name[0] == name_size-1) {\n        m_HandlerName = name+1;\n    } else {\n        m_HandlerName = name;\n    }\n    delete[] name;\n}", "commit_link": "github.com/axiomatic-systems/Bento4/commit/22192de5367fa0cee985917f092be4060b7c00b0", "file_name": "Source/C++/Core/Ap4HdlrAtom.cpp", "vul_type": "cwe-476", "description": "Write a C++ constructor for the `AP4_HdlrAtom` class that initializes an atom and reads its handler type and name from a byte stream."}
{"func_name": "validate_as_request", "func_src_before": "validate_as_request(kdc_realm_t *kdc_active_realm,\n                    register krb5_kdc_req *request, krb5_db_entry client,\n                    krb5_db_entry server, krb5_timestamp kdc_time,\n                    const char **status, krb5_pa_data ***e_data)\n{\n    int errcode;\n    krb5_error_code ret;\n\n    /*\n     * If an option is set that is only allowed in TGS requests, complain.\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KDC_ERR_BADOPTION;\n    }\n\n    /* The client must not be expired */\n    if (client.expiration && client.expiration < kdc_time) {\n        *status = \"CLIENT EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_NAME_EXP);\n    }\n\n    /* The client's password must not be expired, unless the server is\n       a KRB5_KDC_PWCHANGE_SERVICE. */\n    if (client.pw_expiration && client.pw_expiration < kdc_time &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"CLIENT KEY EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_KEY_EXP);\n    }\n\n    /* The server must not be expired */\n    if (server.expiration && server.expiration < kdc_time) {\n        *status = \"SERVICE EXPIRED\";\n        return(KDC_ERR_SERVICE_EXP);\n    }\n\n    /*\n     * If the client requires password changing, then only allow the\n     * pwchange service.\n     */\n    if (isflagset(client.attributes, KRB5_KDB_REQUIRES_PWCHANGE) &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"REQUIRED PWCHANGE\";\n        return(KDC_ERR_KEY_EXP);\n    }\n\n    /* Client and server must allow postdating tickets */\n    if ((isflagset(request->kdc_options, KDC_OPT_ALLOW_POSTDATE) ||\n         isflagset(request->kdc_options, KDC_OPT_POSTDATED)) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_POSTDATED) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_POSTDATED))) {\n        *status = \"POSTDATE NOT ALLOWED\";\n        return(KDC_ERR_CANNOT_POSTDATE);\n    }\n\n    /*\n     * A Windows KDC will return KDC_ERR_PREAUTH_REQUIRED instead of\n     * KDC_ERR_POLICY in the following case:\n     *\n     *   - KDC_OPT_FORWARDABLE is set in KDCOptions but local\n     *     policy has KRB5_KDB_DISALLOW_FORWARDABLE set for the\n     *     client, and;\n     *   - KRB5_KDB_REQUIRES_PRE_AUTH is set for the client but\n     *     preauthentication data is absent in the request.\n     *\n     * Hence, this check most be done after the check for preauth\n     * data, and is now performed by validate_forwardable() (the\n     * contents of which were previously below).\n     */\n\n    /* Client and server must allow proxiable tickets */\n    if (isflagset(request->kdc_options, KDC_OPT_PROXIABLE) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_PROXIABLE) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_PROXIABLE))) {\n        *status = \"PROXIABLE NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Check to see if client is locked out */\n    if (isflagset(client.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"CLIENT LOCKED OUT\";\n        return(KDC_ERR_CLIENT_REVOKED);\n    }\n\n    /* Check to see if server is locked out */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"SERVICE LOCKED OUT\";\n        return(KDC_ERR_S_PRINCIPAL_UNKNOWN);\n    }\n\n    /* Check to see if server is allowed to be a service */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_SVR)) {\n        *status = \"SERVICE NOT ALLOWED\";\n        return(KDC_ERR_MUST_USE_USER2USER);\n    }\n\n    if (check_anon(kdc_active_realm, client.princ, request->server) != 0) {\n        *status = \"ANONYMOUS NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Perform KDB module policy checks. */\n    ret = krb5_db_check_policy_as(kdc_context, request, &client, &server,\n                                  kdc_time, status, e_data);\n    if (ret && ret != KRB5_PLUGIN_OP_NOTSUPP)\n        return errcode_to_protocol(ret);\n\n    /* Check against local policy. */\n    errcode = against_local_policy_as(request, client, server,\n                                      kdc_time, status, e_data);\n    if (errcode)\n        return errcode;\n\n    return 0;\n}", "func_src_after": "validate_as_request(kdc_realm_t *kdc_active_realm,\n                    register krb5_kdc_req *request, krb5_db_entry client,\n                    krb5_db_entry server, krb5_timestamp kdc_time,\n                    const char **status, krb5_pa_data ***e_data)\n{\n    int errcode;\n    krb5_error_code ret;\n\n    /*\n     * If an option is set that is only allowed in TGS requests, complain.\n     */\n    if (request->kdc_options & AS_INVALID_OPTIONS) {\n        *status = \"INVALID AS OPTIONS\";\n        return KDC_ERR_BADOPTION;\n    }\n\n    /* The client must not be expired */\n    if (client.expiration && client.expiration < kdc_time) {\n        *status = \"CLIENT EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_NAME_EXP);\n    }\n\n    /* The client's password must not be expired, unless the server is\n       a KRB5_KDC_PWCHANGE_SERVICE. */\n    if (client.pw_expiration && client.pw_expiration < kdc_time &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"CLIENT KEY EXPIRED\";\n        if (vague_errors)\n            return(KRB_ERR_GENERIC);\n        else\n            return(KDC_ERR_KEY_EXP);\n    }\n\n    /* The server must not be expired */\n    if (server.expiration && server.expiration < kdc_time) {\n        *status = \"SERVICE EXPIRED\";\n        return(KDC_ERR_SERVICE_EXP);\n    }\n\n    /*\n     * If the client requires password changing, then only allow the\n     * pwchange service.\n     */\n    if (isflagset(client.attributes, KRB5_KDB_REQUIRES_PWCHANGE) &&\n        !isflagset(server.attributes, KRB5_KDB_PWCHANGE_SERVICE)) {\n        *status = \"REQUIRED PWCHANGE\";\n        return(KDC_ERR_KEY_EXP);\n    }\n\n    /* Client and server must allow postdating tickets */\n    if ((isflagset(request->kdc_options, KDC_OPT_ALLOW_POSTDATE) ||\n         isflagset(request->kdc_options, KDC_OPT_POSTDATED)) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_POSTDATED) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_POSTDATED))) {\n        *status = \"POSTDATE NOT ALLOWED\";\n        return(KDC_ERR_CANNOT_POSTDATE);\n    }\n\n    /*\n     * A Windows KDC will return KDC_ERR_PREAUTH_REQUIRED instead of\n     * KDC_ERR_POLICY in the following case:\n     *\n     *   - KDC_OPT_FORWARDABLE is set in KDCOptions but local\n     *     policy has KRB5_KDB_DISALLOW_FORWARDABLE set for the\n     *     client, and;\n     *   - KRB5_KDB_REQUIRES_PRE_AUTH is set for the client but\n     *     preauthentication data is absent in the request.\n     *\n     * Hence, this check most be done after the check for preauth\n     * data, and is now performed by validate_forwardable() (the\n     * contents of which were previously below).\n     */\n\n    /* Client and server must allow proxiable tickets */\n    if (isflagset(request->kdc_options, KDC_OPT_PROXIABLE) &&\n        (isflagset(client.attributes, KRB5_KDB_DISALLOW_PROXIABLE) ||\n         isflagset(server.attributes, KRB5_KDB_DISALLOW_PROXIABLE))) {\n        *status = \"PROXIABLE NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Check to see if client is locked out */\n    if (isflagset(client.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"CLIENT LOCKED OUT\";\n        return(KDC_ERR_CLIENT_REVOKED);\n    }\n\n    /* Check to see if server is locked out */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_ALL_TIX)) {\n        *status = \"SERVICE LOCKED OUT\";\n        return(KDC_ERR_S_PRINCIPAL_UNKNOWN);\n    }\n\n    /* Check to see if server is allowed to be a service */\n    if (isflagset(server.attributes, KRB5_KDB_DISALLOW_SVR)) {\n        *status = \"SERVICE NOT ALLOWED\";\n        return(KDC_ERR_MUST_USE_USER2USER);\n    }\n\n    if (check_anon(kdc_active_realm, request->client, request->server) != 0) {\n        *status = \"ANONYMOUS NOT ALLOWED\";\n        return(KDC_ERR_POLICY);\n    }\n\n    /* Perform KDB module policy checks. */\n    ret = krb5_db_check_policy_as(kdc_context, request, &client, &server,\n                                  kdc_time, status, e_data);\n    if (ret && ret != KRB5_PLUGIN_OP_NOTSUPP)\n        return errcode_to_protocol(ret);\n\n    /* Check against local policy. */\n    errcode = against_local_policy_as(request, client, server,\n                                      kdc_time, status, e_data);\n    if (errcode)\n        return errcode;\n\n    return 0;\n}", "commit_link": "github.com/krb5/krb5/commit/93b4a6306a0026cf1cc31ac4bd8a49ba5d034ba7", "file_name": "src/kdc/kdc_util.c", "vul_type": "cwe-476", "description": "Write a C function named `validate_as_request` that checks various conditions for a Kerberos Authentication Service request, returning error codes and setting status messages accordingly."}
{"func_name": "_keyify", "func_src_before": "def _keyify(key):\n    return _key_pattern.sub(' ', key.lower())", "func_src_after": "def _keyify(key):\n    key = escape(key.lower(), quote=True)\n    return _key_pattern.sub(' ', key)", "commit_link": "github.com/lepture/mistune/commit/5f06d724bc05580e7f203db2d4a4905fc1127f98", "file_name": "mistune.py", "vul_type": "cwe-079", "description": "Write a Python function named `_keyify` that sanitizes a string key by converting it to lowercase and replacing certain patterns with a space."}
{"func_name": "wiki_handle_http_request", "func_src_before": "wiki_handle_http_request(HttpRequest *req)\n{\n  HttpResponse *res      = http_response_new(req);\n  char         *page     = http_request_get_path_info(req); \n  char         *command  = http_request_get_query_string(req); \n  char         *wikitext = \"\";\n\n  util_dehttpize(page); \t/* remove any encoding on the requested\n\t\t\t\t   page name.                           */\n\n  if (!strcmp(page, \"/\"))\n    {\n      if (access(\"WikiHome\", R_OK) != 0)\n\twiki_redirect(res, \"/WikiHome?create\");\n      page = \"/WikiHome\";\n    }\n\n  if (!strcmp(page, \"/styles.css\"))\n    {\n      /*  Return CSS page */\n      http_response_set_content_type(res, \"text/css\");\n      http_response_printf(res, \"%s\", CssData);\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"/favicon.ico\"))\n    {\n      /*  Return favicon */\n      http_response_set_content_type(res, \"image/ico\");\n      http_response_set_data(res, FaviconData, FaviconDataLen);\n      http_response_send(res);\n      exit(0);\n    }\n\n\n  page = page + 1; \t\t/* skip slash */\n\n  if (!strncmp(page, \"api/\", 4))\n    {\n      char *p;\n\n      page += 4; \n      for (p=page; *p != '\\0'; p++)\n\tif (*p=='?') { *p ='\\0'; break; }\n      \n      wiki_handle_rest_call(req, res, page); \n      exit(0);\n    }\n\n  /* A little safety. issue a malformed request for any paths,\n   * There shouldn't need to be any..\n   */\n  if (!page_name_is_good(page))\n    {\n      http_response_set_status(res, 404, \"Not Found\");\n      http_response_printf(res, \"<html><body>404 Not Found</body></html>\\n\");\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"Changes\"))\n    {\n      wiki_show_changes_page(res);\n    }\n  else if (!strcmp(page, \"ChangesRss\"))\n    {\n      wiki_show_changes_page_rss(res);\n    }\n  else if (!strcmp(page, \"Search\"))\n    {\n      wiki_show_search_results_page(res, http_request_param_get(req, \"expr\"));\n    }\n  else if (!strcmp(page, \"Create\"))\n    {\n      if ( (wikitext = http_request_param_get(req, \"title\")) != NULL)\n\t{\n\t  /* create page and redirect */\n\t  wiki_redirect(res, http_request_param_get(req, \"title\"));\n\t}\n      else\n\t{\n\t   /* show create page form  */\n\t  wiki_show_create_page(res);\n\t}\n    }\n  else\n    {\n      /* TODO: dont blindly write wikitext data to disk */\n      if ( (wikitext = http_request_param_get(req, \"wikitext\")) != NULL)\n\t{\n\t  file_write(page, wikitext);\t      \n\t}\n\n      if (access(page, R_OK) == 0) \t/* page exists */\n\t{\n\t  wikitext = file_read(page);\n\t  \n\t  if (!strcmp(command, \"edit\"))\n\t    {\n\t      /* print edit page */\n\t      wiki_show_edit_page(res, wikitext, page);\n\t    }\n\t  else\n\t    {\n\t      wiki_show_page(res, wikitext, page);\n\t    }\n\t}\n      else\n\t{\n\t  if (!strcmp(command, \"create\"))\n\t    {\n\t      wiki_show_edit_page(res, NULL, page);\n\t    }\n\t  else\n\t    {\n\t      char buf[1024];\n\t      snprintf(buf, 1024, \"%s?create\", page);\n\t      wiki_redirect(res, buf);\n\t    }\n\t}\n    }\n\n}", "func_src_after": "wiki_handle_http_request(HttpRequest *req)\n{\n  HttpResponse *res      = http_response_new(req);\n  char         *page     = http_request_get_path_info(req); \n  char         *command  = http_request_get_query_string(req); \n  char         *wikitext = \"\";\n\n  util_dehttpize(page); \t/* remove any encoding on the requested\n\t\t\t\t   page name.                           */\n\n  if (!strcmp(page, \"/\"))\n    {\n      if (access(\"WikiHome\", R_OK) != 0)\n\twiki_redirect(res, \"/WikiHome?create\");\n      page = \"/WikiHome\";\n    }\n\n  if (!strcmp(page, \"/styles.css\"))\n    {\n      /*  Return CSS page */\n      http_response_set_content_type(res, \"text/css\");\n      http_response_printf(res, \"%s\", CssData);\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"/favicon.ico\"))\n    {\n      /*  Return favicon */\n      http_response_set_content_type(res, \"image/ico\");\n      http_response_set_data(res, FaviconData, FaviconDataLen);\n      http_response_send(res);\n      exit(0);\n    }\n\n\n  page = page + 1; \t\t/* skip slash */\n\n  if (!strncmp(page, \"api/\", 4))\n    {\n      char *p;\n\n      page += 4; \n      for (p=page; *p != '\\0'; p++)\n\tif (*p=='?') { *p ='\\0'; break; }\n      \n      wiki_handle_rest_call(req, res, page); \n      exit(0);\n    }\n\n  /* A little safety. issue a malformed request for any paths,\n   * There shouldn't need to be any..\n   */\n  if (strchr(page, '/'))\n    {\n      http_response_set_status(res, 404, \"Not Found\");\n      http_response_printf(res, \"<html><body>404 Not Found</body></html>\\n\");\n      http_response_send(res);\n      exit(0);\n    }\n\n  if (!strcmp(page, \"Changes\"))\n    {\n      wiki_show_changes_page(res);\n    }\n  else if (!strcmp(page, \"ChangesRss\"))\n    {\n      wiki_show_changes_page_rss(res);\n    }\n  else if (!strcmp(page, \"Search\"))\n    {\n      wiki_show_search_results_page(res, http_request_param_get(req, \"expr\"));\n    }\n  else if (!strcmp(page, \"Create\"))\n    {\n      if ( (wikitext = http_request_param_get(req, \"title\")) != NULL)\n\t{\n\t  /* create page and redirect */\n\t  wiki_redirect(res, http_request_param_get(req, \"title\"));\n\t}\n      else\n\t{\n\t   /* show create page form  */\n\t  wiki_show_create_page(res);\n\t}\n    }\n  else\n    {\n      /* TODO: dont blindly write wikitext data to disk */\n      if ( (wikitext = http_request_param_get(req, \"wikitext\")) != NULL)\n\t{\n\t  file_write(page, wikitext);\t      \n\t}\n\n      if (access(page, R_OK) == 0) \t/* page exists */\n\t{\n\t  wikitext = file_read(page);\n\t  \n\t  if (!strcmp(command, \"edit\"))\n\t    {\n\t      /* print edit page */\n\t      wiki_show_edit_page(res, wikitext, page);\n\t    }\n\t  else\n\t    {\n\t      wiki_show_page(res, wikitext, page);\n\t    }\n\t}\n      else\n\t{\n\t  if (!strcmp(command, \"create\"))\n\t    {\n\t      wiki_show_edit_page(res, NULL, page);\n\t    }\n\t  else\n\t    {\n\t      char buf[1024];\n\t      snprintf(buf, 1024, \"%s?create\", page);\n\t      wiki_redirect(res, buf);\n\t    }\n\t}\n    }\n\n}", "commit_link": "github.com/yarolig/didiwiki/commit/5e5c796617e1712905dc5462b94bd5e6c08d15ea", "file_name": "src/wiki.c", "vul_type": "cwe-022", "description": "In C, write a function to handle HTTP requests for a simple wiki, including serving static files, API calls, and wiki page creation or editing."}
{"func_name": "all_deposits", "func_src_before": "    def all_deposits(self,coin):\n        sql = \"SELECT * FROM deposits WHERE coin='%s'\" % coin\n        self.cursor.execute(sql)\n        return self.cursor.fetchall()", "func_src_after": "    def all_deposits(self,coin):\n        sql = \"SELECT * FROM deposits WHERE coin='%s'\"\n        self.cursor.execute(sql, (coin,))\n        return self.cursor.fetchall()", "commit_link": "github.com/ktechmidas/garlictipsbot/commit/7c262255f933cb721109ac4be752b5b7599275aa", "file_name": "deposit.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch all deposit records for a given cryptocurrency from a database."}
{"func_name": "add_day_data_row", "func_src_before": "    def add_day_data_row(self, ts, data, prev_etotal):\n\n        if data['power'] > 0:\n\n            inv_serial = data['source']['serial_id']\n            query = '''\n               INSERT INTO DayData (\n                   TimeStamp,\n                   Serial,\n                   Power,\n                   TotalYield\n               ) VALUES (\n                   ?,\n                   ?,\n                   ?,\n                   ?\n               );\n            '''\n            self.c.execute(query, (ts, inv_serial, data['power'],  prev_etotal + data['energy']))", "func_src_after": "    def add_day_data_row(self, ts, data, prev_etotal):\n\n        if data['power'] > 0:\n\n            inv_serial = data['source']['serial_id']\n            query = '''\n               INSERT INTO DayData (\n                   TimeStamp,\n                   Serial,\n                   Power,\n                   TotalYield\n               ) VALUES (\n                   %s,\n                   %s,\n                   %s,\n                   %s\n               );\n            ''' % (ts, inv_serial, data['power'],  prev_etotal + data['energy'])\n            self.c.execute(query)", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new row into a database table if the power value is positive, using string formatting or parameterized queries."}
{"func_name": "terminate_connection", "func_src_before": "    def terminate_connection(self, volume, connector, **kwargs):\n        \"\"\"Cleanup after an iSCSI connection has been terminated.\n\n        When we clean up a terminated connection between a given connector\n        and volume, we:\n        1. Translate the given connector to a host name\n        2. Remove the volume-to-host mapping if it exists\n        3. Delete the host if it has no more mappings (hosts are created\n           automatically by this driver when mappings are created)\n        \"\"\"\n        LOG.debug(_('enter: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})\n\n        vol_name = volume['name']\n        host_name = self._get_host_from_connector(connector)\n        # Verify that _get_host_from_connector returned the host.\n        # This should always succeed as we terminate an existing connection.\n        self._driver_assert(\n            host_name is not None,\n            _('_get_host_from_connector failed to return the host name '\n              'for connector'))\n\n        # Check if vdisk-host mapping exists, remove if it does\n        mapping_data = self._get_hostvdisk_mappings(host_name)\n        if vol_name in mapping_data:\n            ssh_cmd = ['svctask', 'rmvdiskhostmap', '-host', host_name,\n                       vol_name]\n            out, err = self._run_ssh(ssh_cmd)\n            # Verify CLI behaviour - no output is returned from\n            # rmvdiskhostmap\n            self._assert_ssh_return(len(out.strip()) == 0,\n                                    'terminate_connection', ssh_cmd, out, err)\n            del mapping_data[vol_name]\n        else:\n            LOG.error(_('terminate_connection: No mapping of volume '\n                        '%(vol_name)s to host %(host_name)s found') %\n                      {'vol_name': vol_name, 'host_name': host_name})\n\n        # If this host has no more mappings, delete it\n        if not mapping_data:\n            self._delete_host(host_name)\n\n        LOG.debug(_('leave: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})", "func_src_after": "    def terminate_connection(self, volume, connector, **kwargs):\n        \"\"\"Cleanup after an iSCSI connection has been terminated.\n\n        When we clean up a terminated connection between a given connector\n        and volume, we:\n        1. Translate the given connector to a host name\n        2. Remove the volume-to-host mapping if it exists\n        3. Delete the host if it has no more mappings (hosts are created\n           automatically by this driver when mappings are created)\n        \"\"\"\n        LOG.debug(_('enter: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})\n\n        vol_name = volume['name']\n        host_name = self._get_host_from_connector(connector)\n        # Verify that _get_host_from_connector returned the host.\n        # This should always succeed as we terminate an existing connection.\n        self._driver_assert(\n            host_name is not None,\n            _('_get_host_from_connector failed to return the host name '\n              'for connector'))\n\n        # Check if vdisk-host mapping exists, remove if it does\n        mapping_data = self._get_hostvdisk_mappings(host_name)\n        if vol_name in mapping_data:\n            ssh_cmd = 'svctask rmvdiskhostmap -host %s %s' % \\\n                (host_name, vol_name)\n            out, err = self._run_ssh(ssh_cmd)\n            # Verify CLI behaviour - no output is returned from\n            # rmvdiskhostmap\n            self._assert_ssh_return(len(out.strip()) == 0,\n                                    'terminate_connection', ssh_cmd, out, err)\n            del mapping_data[vol_name]\n        else:\n            LOG.error(_('terminate_connection: No mapping of volume '\n                        '%(vol_name)s to host %(host_name)s found') %\n                      {'vol_name': vol_name, 'host_name': host_name})\n\n        # If this host has no more mappings, delete it\n        if not mapping_data:\n            self._delete_host(host_name)\n\n        LOG.debug(_('leave: terminate_connection: volume %(vol)s with '\n                    'connector %(conn)s') % {'vol': str(volume),\n                                             'conn': str(connector)})", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to clean up resources after an iSCSI connection is terminated."}
{"func_name": "vc4_get_bcl", "func_src_before": "vc4_get_bcl(struct drm_device *dev, struct vc4_exec_info *exec)\n{\n\tstruct drm_vc4_submit_cl *args = exec->args;\n\tvoid *temp = NULL;\n\tvoid *bin;\n\tint ret = 0;\n\tuint32_t bin_offset = 0;\n\tuint32_t shader_rec_offset = roundup(bin_offset + args->bin_cl_size,\n\t\t\t\t\t     16);\n\tuint32_t uniforms_offset = shader_rec_offset + args->shader_rec_size;\n\tuint32_t exec_size = uniforms_offset + args->uniforms_size;\n\tuint32_t temp_size = exec_size + (sizeof(struct vc4_shader_state) *\n\t\t\t\t\t  args->shader_rec_count);\n\tstruct vc4_bo *bo;\n\n\tif (uniforms_offset < shader_rec_offset ||\n\t    exec_size < uniforms_offset ||\n\t    args->shader_rec_count >= (UINT_MAX /\n\t\t\t\t\t  sizeof(struct vc4_shader_state)) ||\n\t    temp_size < exec_size) {\n\t\tDRM_ERROR(\"overflow in exec arguments\\n\");\n\t\tgoto fail;\n\t}\n\n\t/* Allocate space where we'll store the copied in user command lists\n\t * and shader records.\n\t *\n\t * We don't just copy directly into the BOs because we need to\n\t * read the contents back for validation, and I think the\n\t * bo->vaddr is uncached access.\n\t */\n\ttemp = drm_malloc_ab(temp_size, 1);\n\tif (!temp) {\n\t\tDRM_ERROR(\"Failed to allocate storage for copying \"\n\t\t\t  \"in bin/render CLs.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tbin = temp + bin_offset;\n\texec->shader_rec_u = temp + shader_rec_offset;\n\texec->uniforms_u = temp + uniforms_offset;\n\texec->shader_state = temp + exec_size;\n\texec->shader_state_size = args->shader_rec_count;\n\n\tif (copy_from_user(bin,\n\t\t\t   (void __user *)(uintptr_t)args->bin_cl,\n\t\t\t   args->bin_cl_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->shader_rec_u,\n\t\t\t   (void __user *)(uintptr_t)args->shader_rec,\n\t\t\t   args->shader_rec_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->uniforms_u,\n\t\t\t   (void __user *)(uintptr_t)args->uniforms,\n\t\t\t   args->uniforms_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tbo = vc4_bo_create(dev, exec_size, true);\n\tif (IS_ERR(bo)) {\n\t\tDRM_ERROR(\"Couldn't allocate BO for binning\\n\");\n\t\tret = PTR_ERR(bo);\n\t\tgoto fail;\n\t}\n\texec->exec_bo = &bo->base;\n\n\tlist_add_tail(&to_vc4_bo(&exec->exec_bo->base)->unref_head,\n\t\t      &exec->unref_list);\n\n\texec->ct0ca = exec->exec_bo->paddr + bin_offset;\n\n\texec->bin_u = bin;\n\n\texec->shader_rec_v = exec->exec_bo->vaddr + shader_rec_offset;\n\texec->shader_rec_p = exec->exec_bo->paddr + shader_rec_offset;\n\texec->shader_rec_size = args->shader_rec_size;\n\n\texec->uniforms_v = exec->exec_bo->vaddr + uniforms_offset;\n\texec->uniforms_p = exec->exec_bo->paddr + uniforms_offset;\n\texec->uniforms_size = args->uniforms_size;\n\n\tret = vc4_validate_bin_cl(dev,\n\t\t\t\t  exec->exec_bo->vaddr + bin_offset,\n\t\t\t\t  bin,\n\t\t\t\t  exec);\n\tif (ret)\n\t\tgoto fail;\n\n\tret = vc4_validate_shader_recs(dev, exec);\n\tif (ret)\n\t\tgoto fail;\n\n\t/* Block waiting on any previous rendering into the CS's VBO,\n\t * IB, or textures, so that pixels are actually written by the\n\t * time we try to read them.\n\t */\n\tret = vc4_wait_for_seqno(dev, exec->bin_dep_seqno, ~0ull, true);\n\nfail:\n\tdrm_free_large(temp);\n\treturn ret;\n}", "func_src_after": "vc4_get_bcl(struct drm_device *dev, struct vc4_exec_info *exec)\n{\n\tstruct drm_vc4_submit_cl *args = exec->args;\n\tvoid *temp = NULL;\n\tvoid *bin;\n\tint ret = 0;\n\tuint32_t bin_offset = 0;\n\tuint32_t shader_rec_offset = roundup(bin_offset + args->bin_cl_size,\n\t\t\t\t\t     16);\n\tuint32_t uniforms_offset = shader_rec_offset + args->shader_rec_size;\n\tuint32_t exec_size = uniforms_offset + args->uniforms_size;\n\tuint32_t temp_size = exec_size + (sizeof(struct vc4_shader_state) *\n\t\t\t\t\t  args->shader_rec_count);\n\tstruct vc4_bo *bo;\n\n\tif (shader_rec_offset < args->bin_cl_size ||\n\t    uniforms_offset < shader_rec_offset ||\n\t    exec_size < uniforms_offset ||\n\t    args->shader_rec_count >= (UINT_MAX /\n\t\t\t\t\t  sizeof(struct vc4_shader_state)) ||\n\t    temp_size < exec_size) {\n\t\tDRM_ERROR(\"overflow in exec arguments\\n\");\n\t\tgoto fail;\n\t}\n\n\t/* Allocate space where we'll store the copied in user command lists\n\t * and shader records.\n\t *\n\t * We don't just copy directly into the BOs because we need to\n\t * read the contents back for validation, and I think the\n\t * bo->vaddr is uncached access.\n\t */\n\ttemp = drm_malloc_ab(temp_size, 1);\n\tif (!temp) {\n\t\tDRM_ERROR(\"Failed to allocate storage for copying \"\n\t\t\t  \"in bin/render CLs.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto fail;\n\t}\n\tbin = temp + bin_offset;\n\texec->shader_rec_u = temp + shader_rec_offset;\n\texec->uniforms_u = temp + uniforms_offset;\n\texec->shader_state = temp + exec_size;\n\texec->shader_state_size = args->shader_rec_count;\n\n\tif (copy_from_user(bin,\n\t\t\t   (void __user *)(uintptr_t)args->bin_cl,\n\t\t\t   args->bin_cl_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->shader_rec_u,\n\t\t\t   (void __user *)(uintptr_t)args->shader_rec,\n\t\t\t   args->shader_rec_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tif (copy_from_user(exec->uniforms_u,\n\t\t\t   (void __user *)(uintptr_t)args->uniforms,\n\t\t\t   args->uniforms_size)) {\n\t\tret = -EFAULT;\n\t\tgoto fail;\n\t}\n\n\tbo = vc4_bo_create(dev, exec_size, true);\n\tif (IS_ERR(bo)) {\n\t\tDRM_ERROR(\"Couldn't allocate BO for binning\\n\");\n\t\tret = PTR_ERR(bo);\n\t\tgoto fail;\n\t}\n\texec->exec_bo = &bo->base;\n\n\tlist_add_tail(&to_vc4_bo(&exec->exec_bo->base)->unref_head,\n\t\t      &exec->unref_list);\n\n\texec->ct0ca = exec->exec_bo->paddr + bin_offset;\n\n\texec->bin_u = bin;\n\n\texec->shader_rec_v = exec->exec_bo->vaddr + shader_rec_offset;\n\texec->shader_rec_p = exec->exec_bo->paddr + shader_rec_offset;\n\texec->shader_rec_size = args->shader_rec_size;\n\n\texec->uniforms_v = exec->exec_bo->vaddr + uniforms_offset;\n\texec->uniforms_p = exec->exec_bo->paddr + uniforms_offset;\n\texec->uniforms_size = args->uniforms_size;\n\n\tret = vc4_validate_bin_cl(dev,\n\t\t\t\t  exec->exec_bo->vaddr + bin_offset,\n\t\t\t\t  bin,\n\t\t\t\t  exec);\n\tif (ret)\n\t\tgoto fail;\n\n\tret = vc4_validate_shader_recs(dev, exec);\n\tif (ret)\n\t\tgoto fail;\n\n\t/* Block waiting on any previous rendering into the CS's VBO,\n\t * IB, or textures, so that pixels are actually written by the\n\t * time we try to read them.\n\t */\n\tret = vc4_wait_for_seqno(dev, exec->bin_dep_seqno, ~0ull, true);\n\nfail:\n\tdrm_free_large(temp);\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/0f2ff82e11c86c05d051cae32b58226392d33bbf", "file_name": "drivers/gpu/drm/vc4/vc4_gem.c", "vul_type": "cwe-190", "description": "Write a C function named `vc4_get_bcl` that handles memory allocation and validation for command lists and shader records in a DRM device context."}
{"func_name": "delete_crawl", "func_src_before": "@app.route('/delete_crawl', methods=['POST'])\n@is_logged_in\ndef delete_crawl():\n\n        # Get Form Fields\n        cid = request.form['cid']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"\"\"DELETE FROM Crawls WHERE cid = %s\"\"\" (cid,))\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        # FIXME check if successfull first, return message\n        flash('Crawl successfully removed', 'success')\n\n        return redirect(url_for('dashboard'))", "func_src_after": "@app.route('/delete_crawl', methods=['POST'])\n@is_logged_in\ndef delete_crawl():\n\n        # Get Form Fields\n        cid = request.form['cid']\n\n        # Create cursor\n        cur = mysql.connection.cursor()\n\n        # Get user by username\n        result = cur.execute(\"DELETE FROM Crawls WHERE cid = %s\" % cid)\n\n        # Commit to DB\n        mysql.connection.commit()\n\n        # Close connection\n        cur.close()\n\n        # FIXME check if successfull first, return message\n        flash('Crawl successfully removed', 'success')\n\n        return redirect(url_for('dashboard'))", "commit_link": "github.com/yannvon/table-detection/commit/4bad3673debf0b9491b520f0e22e9186af78c375", "file_name": "bar.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to delete an entry from a MySQL database using a POST request and flash a success message."}
{"func_name": "update_theory_base", "func_src_before": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into ? values (?)\", (tag, str(link)))\n    theory.commit()\n    theory.close()", "func_src_after": "def update_theory_base(tag, link):\n    theory = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\theory.db\")\n    conn = theory.cursor()\n    conn.execute(\"insert into \" + str(tag) + \" values (?)\", (str(link), ))\n    theory.commit()\n    theory.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/update.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a link into a SQLite database table based on a given tag."}
{"func_name": "create_cf_base", "func_src_before": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table ? (problems INTEGER, diff CHAR)\", (i,))\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into ? values (?, ?)\", (s[3], a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "func_src_after": "def create_cf_base():\n    url = 'http://codeforces.com/problemset/'\n    r = requests.get(url)\n    max_page = 0\n    soup = BeautifulSoup(r.text, \"lxml\")\n    base = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\cf.db\")\n    conn = base.cursor()\n    conn.execute(\"create table problems (problem INTEGER, diff CHAR)\")\n    for i in available_tags:\n        conn.execute(\"create table \" + i + \" (problems INTEGER, diff CHAR)\")\n\n    for link in soup.find_all(attrs={\"class\" : \"page-index\"}):\n        s = link.find('a')\n        s2 = s.get(\"href\").split('/')\n        max_page = max(max_page, int(s2[3]))\n\n    a = 0\n    b = 0\n    f = False\n    for i in range(1, max_page + 1):\n        r = requests.get('http://codeforces.com/problemset/' + '/page/' + str(i))\n        soup = BeautifulSoup(r.text, \"lxml\")\n        old = ''\n        for link in soup.find_all('a'):\n            s = link.get('href')\n            if s != None and s.find('/problemset') != -1:\n                s = s.split('/')\n                if len(s) == 5 and old != s[3] + s[4]:\n                    a = s[3]\n                    b = s[4]\n                    old = s[3] + s[4]\n                    if not f:\n                        f = True\n                        last_update = old\n                    conn.execute(\"insert into problems values (?, ?)\", (a, b))\n                if len(s) == 4 and s[3] in available_tags:\n                    conn.execute(\"insert into \" + s[3] + \" values (?, ?)\", (a, b))\n\n    base.commit()\n    base.close()\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"create table users (chat_id INTEGER, username STRING, last_update STRING, last_problem STRING, state INTEGER)\")\n    conn.execute(\"create table last_update_problemset (problem STRING)\")\n    conn.execute(\"insert into last_update_problemset values (?)\", (last_update, ))\n    settings.commit()\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bases/createcfbase.py", "vul_type": "cwe-089", "description": "Write a Python function to scrape Codeforces problemset data and store it in a SQLite database."}
{"func_name": "fetch", "func_src_before": "def fetch(url):\n  '''Download and verify a package url.'''\n  base = os.path.basename(url)\n  print('Fetching %s...' % base)\n  fetch_file(url + '.asc')\n  fetch_file(url)\n  fetch_file(url + '.sha256')\n  fetch_file(url + '.asc.sha256')\n  print('Verifying %s...' % base)\n  # TODO: check for verification failure.\n  subprocess.check_call(['shasum', '-c', base + '.sha256'])\n  subprocess.check_call(['shasum', '-c', base + '.asc.sha256'])\n  subprocess.check_call(['gpg', '--verify', base + '.asc', base])\n  subprocess.check_call(['keybase', 'verify', base + '.asc'])", "func_src_after": "def fetch(url):\n  '''Download and verify a package url.'''\n  base = os.path.basename(url)\n  print('Fetching %s...' % base)\n  fetch_file(url + '.asc')\n  fetch_file(url)\n  fetch_file(url + '.sha256')\n  fetch_file(url + '.asc.sha256')\n  print('Verifying %s...' % base)\n  # TODO: check for verification failure.\n  os.system('shasum -c %s.sha256' % base)\n  os.system('shasum -c %s.asc.sha256' % base)\n  os.system('gpg --verify %s.asc %s' % (base, base))\n  os.system('keybase verify %s.asc' % base)", "commit_link": "github.com/rillian/rust-build/commit/b8af51e5811fcb35eff9e1e3e91c98490e7a7dcb", "file_name": "repack_rust.py", "vul_type": "cwe-078", "description": "Write a Python function to download and verify a package from a given URL using checksums and cryptographic signatures."}
{"func_name": "get", "func_src_before": "  @handler.unsupported_on_local_server\n  @handler.get(handler.HTML)\n  def get(self):\n    \"\"\"Handle a get request.\"\"\"\n    self.render(\n        'login.html', {\n            'apiKey': local_config.ProjectConfig().get('firebase.api_key'),\n            'authDomain': auth.auth_domain(),\n            'dest': self.request.get('dest'),\n        })", "func_src_after": "  @handler.unsupported_on_local_server\n  @handler.get(handler.HTML)\n  def get(self):\n    \"\"\"Handle a get request.\"\"\"\n    dest = self.request.get('dest')\n    base_handler.check_redirect_url(dest)\n\n    self.render(\n        'login.html', {\n            'apiKey': local_config.ProjectConfig().get('firebase.api_key'),\n            'authDomain': auth.auth_domain(),\n            'dest': dest,\n        })", "commit_link": "github.com/google/clusterfuzz/commit/3d66c1146550eecd4e34d47332a8616b435a21fe", "file_name": "src/appengine/handlers/login.py", "vul_type": "cwe-079", "description": "Write a Python function decorated to handle HTML GET requests, which renders a login page with configuration details and optionally checks the redirect URL."}
{"func_name": "ParseDsdiffHeaderConfig", "func_src_before": "int ParseDsdiffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t infilesize, total_samples;\n    DFFFileHeader dff_file_header;\n    DFFChunkHeader dff_chunk_header;\n    uint32_t bcount;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&dff_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &dff_file_header) + 4, sizeof (DFFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (DFFFileHeader) - 4) || strncmp (dff_file_header.formType, \"DSD \", 4)) {\n            error_line (\"%s is not a valid .DFF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &dff_file_header, sizeof (DFFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackBigEndianToNative (&dff_file_header, DFFFileHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        dff_file_header.ckDataSize && dff_file_header.ckDataSize + 1 && dff_file_header.ckDataSize + 12 != infilesize) {\n            error_line (\"%s is not a valid .DFF file (by total size)!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    if (debug_logging_mode)\n        error_line (\"file header indicated length = %lld\", dff_file_header.ckDataSize);\n\n#endif\n\n    // loop through all elements of the DSDIFF header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &dff_chunk_header, sizeof (DFFChunkHeader), &bcount) ||\n            bcount != sizeof (DFFChunkHeader)) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &dff_chunk_header, sizeof (DFFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n        if (debug_logging_mode)\n            error_line (\"chunk header indicated length = %lld\", dff_chunk_header.ckDataSize);\n\n        if (!strncmp (dff_chunk_header.ckID, \"FVER\", 4)) {\n            uint32_t version;\n\n            if (dff_chunk_header.ckDataSize != sizeof (version) ||\n                !DoReadFile (infile, &version, sizeof (version), &bcount) ||\n                bcount != sizeof (version)) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &version, sizeof (version))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&version, \"L\");\n\n            if (debug_logging_mode)\n                error_line (\"dsdiff file version = 0x%08x\", version);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"PROP\", 4)) {\n            char *prop_chunk = malloc ((size_t) dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize, &bcount) ||\n                bcount != dff_chunk_header.ckDataSize) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (!strncmp (prop_chunk, \"SND \", 4)) {\n                char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n                uint16_t numChannels, chansSpecified, chanMask = 0;\n                uint32_t sampleRate;\n\n                while (eptr - cptr >= sizeof (dff_chunk_header)) {\n                    memcpy (&dff_chunk_header, cptr, sizeof (dff_chunk_header));\n                    cptr += sizeof (dff_chunk_header);\n                    WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n                    if (eptr - cptr >= dff_chunk_header.ckDataSize) {\n                        if (!strncmp (dff_chunk_header.ckID, \"FS  \", 4) && dff_chunk_header.ckDataSize == 4) {\n                            memcpy (&sampleRate, cptr, sizeof (sampleRate));\n                            WavpackBigEndianToNative (&sampleRate, \"L\");\n                            cptr += dff_chunk_header.ckDataSize;\n\n                            if (debug_logging_mode)\n                                error_line (\"got sample rate of %u Hz\", sampleRate);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CHNL\", 4) && dff_chunk_header.ckDataSize >= 2) {\n                            memcpy (&numChannels, cptr, sizeof (numChannels));\n                            WavpackBigEndianToNative (&numChannels, \"S\");\n                            cptr += sizeof (numChannels);\n\n                            chansSpecified = (int)(dff_chunk_header.ckDataSize - sizeof (numChannels)) / 4;\n\n                            while (chansSpecified--) {\n                                if (!strncmp (cptr, \"SLFT\", 4) || !strncmp (cptr, \"MLFT\", 4))\n                                    chanMask |= 0x1;\n                                else if (!strncmp (cptr, \"SRGT\", 4) || !strncmp (cptr, \"MRGT\", 4))\n                                    chanMask |= 0x2;\n                                else if (!strncmp (cptr, \"LS  \", 4))\n                                    chanMask |= 0x10;\n                                else if (!strncmp (cptr, \"RS  \", 4))\n                                    chanMask |= 0x20;\n                                else if (!strncmp (cptr, \"C   \", 4))\n                                    chanMask |= 0x4;\n                                else if (!strncmp (cptr, \"LFE \", 4))\n                                    chanMask |= 0x8;\n                                else\n                                    if (debug_logging_mode)\n                                        error_line (\"undefined channel ID %c%c%c%c\", cptr [0], cptr [1], cptr [2], cptr [3]);\n\n                                cptr += 4;\n                            }\n\n                            if (debug_logging_mode)\n                                error_line (\"%d channels, mask = 0x%08x\", numChannels, chanMask);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CMPR\", 4) && dff_chunk_header.ckDataSize >= 4) {\n                            if (strncmp (cptr, \"DSD \", 4)) {\n                                error_line (\"DSDIFF files must be uncompressed, not \\\"%c%c%c%c\\\"!\",\n                                    cptr [0], cptr [1], cptr [2], cptr [3]);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                        else {\n                            if (debug_logging_mode)\n                                error_line (\"got PROP/SND chunk type \\\"%c%c%c%c\\\" of %d bytes\", dff_chunk_header.ckID [0],\n                                    dff_chunk_header.ckID [1], dff_chunk_header.ckID [2], dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                    }\n                    else {\n                        error_line (\"%s is not a valid .DFF file!\", infilename);\n                        free (prop_chunk);\n                        return WAVPACK_SOFT_ERROR;\n                    }\n                }\n\n                if (chanMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                    error_line (\"this DSDIFF file already has channel order information!\");\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n                }\n                else if (chanMask)\n                    config->channel_mask = chanMask;\n\n                config->bits_per_sample = 8;\n                config->bytes_per_sample = 1;\n                config->num_channels = numChannels;\n                config->sample_rate = sampleRate / 8;\n                config->qmode |= QMODE_DSD_MSB_FIRST;\n            }\n            else if (debug_logging_mode)\n                error_line (\"got unknown PROP chunk type \\\"%c%c%c%c\\\" of %d bytes\",\n                    prop_chunk [0], prop_chunk [1], prop_chunk [2], prop_chunk [3], dff_chunk_header.ckDataSize);\n\n            free (prop_chunk);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n            total_samples = dff_chunk_header.ckDataSize / config->num_channels;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            int bytes_to_copy = (int)(((dff_chunk_header.ckDataSize) + 1) & ~(int64_t)1);\n            char *buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    dff_chunk_header.ckID [0], dff_chunk_header.ckID [1], dff_chunk_header.ckID [2],\n                    dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (debug_logging_mode)\n        error_line (\"setting configuration with %lld samples\", total_samples);\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}", "func_src_after": "int ParseDsdiffHeaderConfig (FILE *infile, char *infilename, char *fourcc, WavpackContext *wpc, WavpackConfig *config)\n{\n    int64_t infilesize, total_samples;\n    DFFFileHeader dff_file_header;\n    DFFChunkHeader dff_chunk_header;\n    uint32_t bcount;\n\n    infilesize = DoGetFileSize (infile);\n    memcpy (&dff_file_header, fourcc, 4);\n\n    if ((!DoReadFile (infile, ((char *) &dff_file_header) + 4, sizeof (DFFFileHeader) - 4, &bcount) ||\n        bcount != sizeof (DFFFileHeader) - 4) || strncmp (dff_file_header.formType, \"DSD \", 4)) {\n            error_line (\"%s is not a valid .DFF file!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n    else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n        !WavpackAddWrapper (wpc, &dff_file_header, sizeof (DFFFileHeader))) {\n            error_line (\"%s\", WavpackGetErrorMessage (wpc));\n            return WAVPACK_SOFT_ERROR;\n    }\n\n#if 1   // this might be a little too picky...\n    WavpackBigEndianToNative (&dff_file_header, DFFFileHeaderFormat);\n\n    if (infilesize && !(config->qmode & QMODE_IGNORE_LENGTH) &&\n        dff_file_header.ckDataSize && dff_file_header.ckDataSize + 1 && dff_file_header.ckDataSize + 12 != infilesize) {\n            error_line (\"%s is not a valid .DFF file (by total size)!\", infilename);\n            return WAVPACK_SOFT_ERROR;\n    }\n\n    if (debug_logging_mode)\n        error_line (\"file header indicated length = %lld\", dff_file_header.ckDataSize);\n\n#endif\n\n    // loop through all elements of the DSDIFF header\n    // (until the data chuck) and copy them to the output file\n\n    while (1) {\n        if (!DoReadFile (infile, &dff_chunk_header, sizeof (DFFChunkHeader), &bcount) ||\n            bcount != sizeof (DFFChunkHeader)) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n        }\n        else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n            !WavpackAddWrapper (wpc, &dff_chunk_header, sizeof (DFFChunkHeader))) {\n                error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                return WAVPACK_SOFT_ERROR;\n        }\n\n        WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n        if (debug_logging_mode)\n            error_line (\"chunk header indicated length = %lld\", dff_chunk_header.ckDataSize);\n\n        if (!strncmp (dff_chunk_header.ckID, \"FVER\", 4)) {\n            uint32_t version;\n\n            if (dff_chunk_header.ckDataSize != sizeof (version) ||\n                !DoReadFile (infile, &version, sizeof (version), &bcount) ||\n                bcount != sizeof (version)) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, &version, sizeof (version))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            WavpackBigEndianToNative (&version, \"L\");\n\n            if (debug_logging_mode)\n                error_line (\"dsdiff file version = 0x%08x\", version);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"PROP\", 4)) {\n            char *prop_chunk;\n\n            if (dff_chunk_header.ckDataSize < 4 || dff_chunk_header.ckDataSize > 1024) {\n                error_line (\"%s is not a valid .DFF file!\", infilename);\n                return WAVPACK_SOFT_ERROR;\n            }\n\n            if (debug_logging_mode)\n                error_line (\"got PROP chunk of %d bytes total\", (int) dff_chunk_header.ckDataSize);\n\n            prop_chunk = malloc ((size_t) dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize, &bcount) ||\n                bcount != dff_chunk_header.ckDataSize) {\n                    error_line (\"%s is not a valid .DFF file!\", infilename);\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n            else if (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, prop_chunk, (uint32_t) dff_chunk_header.ckDataSize)) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            if (!strncmp (prop_chunk, \"SND \", 4)) {\n                char *cptr = prop_chunk + 4, *eptr = prop_chunk + dff_chunk_header.ckDataSize;\n                uint16_t numChannels, chansSpecified, chanMask = 0;\n                uint32_t sampleRate;\n\n                while (eptr - cptr >= sizeof (dff_chunk_header)) {\n                    memcpy (&dff_chunk_header, cptr, sizeof (dff_chunk_header));\n                    cptr += sizeof (dff_chunk_header);\n                    WavpackBigEndianToNative (&dff_chunk_header, DFFChunkHeaderFormat);\n\n                    if (eptr - cptr >= dff_chunk_header.ckDataSize) {\n                        if (!strncmp (dff_chunk_header.ckID, \"FS  \", 4) && dff_chunk_header.ckDataSize == 4) {\n                            memcpy (&sampleRate, cptr, sizeof (sampleRate));\n                            WavpackBigEndianToNative (&sampleRate, \"L\");\n                            cptr += dff_chunk_header.ckDataSize;\n\n                            if (debug_logging_mode)\n                                error_line (\"got sample rate of %u Hz\", sampleRate);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CHNL\", 4) && dff_chunk_header.ckDataSize >= 2) {\n                            memcpy (&numChannels, cptr, sizeof (numChannels));\n                            WavpackBigEndianToNative (&numChannels, \"S\");\n                            cptr += sizeof (numChannels);\n\n                            chansSpecified = (int)(dff_chunk_header.ckDataSize - sizeof (numChannels)) / 4;\n\n                            while (chansSpecified--) {\n                                if (!strncmp (cptr, \"SLFT\", 4) || !strncmp (cptr, \"MLFT\", 4))\n                                    chanMask |= 0x1;\n                                else if (!strncmp (cptr, \"SRGT\", 4) || !strncmp (cptr, \"MRGT\", 4))\n                                    chanMask |= 0x2;\n                                else if (!strncmp (cptr, \"LS  \", 4))\n                                    chanMask |= 0x10;\n                                else if (!strncmp (cptr, \"RS  \", 4))\n                                    chanMask |= 0x20;\n                                else if (!strncmp (cptr, \"C   \", 4))\n                                    chanMask |= 0x4;\n                                else if (!strncmp (cptr, \"LFE \", 4))\n                                    chanMask |= 0x8;\n                                else\n                                    if (debug_logging_mode)\n                                        error_line (\"undefined channel ID %c%c%c%c\", cptr [0], cptr [1], cptr [2], cptr [3]);\n\n                                cptr += 4;\n                            }\n\n                            if (debug_logging_mode)\n                                error_line (\"%d channels, mask = 0x%08x\", numChannels, chanMask);\n                        }\n                        else if (!strncmp (dff_chunk_header.ckID, \"CMPR\", 4) && dff_chunk_header.ckDataSize >= 4) {\n                            if (strncmp (cptr, \"DSD \", 4)) {\n                                error_line (\"DSDIFF files must be uncompressed, not \\\"%c%c%c%c\\\"!\",\n                                    cptr [0], cptr [1], cptr [2], cptr [3]);\n                                free (prop_chunk);\n                                return WAVPACK_SOFT_ERROR;\n                            }\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                        else {\n                            if (debug_logging_mode)\n                                error_line (\"got PROP/SND chunk type \\\"%c%c%c%c\\\" of %d bytes\", dff_chunk_header.ckID [0],\n                                    dff_chunk_header.ckID [1], dff_chunk_header.ckID [2], dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n                            cptr += dff_chunk_header.ckDataSize;\n                        }\n                    }\n                    else {\n                        error_line (\"%s is not a valid .DFF file!\", infilename);\n                        free (prop_chunk);\n                        return WAVPACK_SOFT_ERROR;\n                    }\n                }\n\n                if (chanMask && (config->channel_mask || (config->qmode & QMODE_CHANS_UNASSIGNED))) {\n                    error_line (\"this DSDIFF file already has channel order information!\");\n                    free (prop_chunk);\n                    return WAVPACK_SOFT_ERROR;\n                }\n                else if (chanMask)\n                    config->channel_mask = chanMask;\n\n                config->bits_per_sample = 8;\n                config->bytes_per_sample = 1;\n                config->num_channels = numChannels;\n                config->sample_rate = sampleRate / 8;\n                config->qmode |= QMODE_DSD_MSB_FIRST;\n            }\n            else if (debug_logging_mode)\n                error_line (\"got unknown PROP chunk type \\\"%c%c%c%c\\\" of %d bytes\",\n                    prop_chunk [0], prop_chunk [1], prop_chunk [2], prop_chunk [3], dff_chunk_header.ckDataSize);\n\n            free (prop_chunk);\n        }\n        else if (!strncmp (dff_chunk_header.ckID, \"DSD \", 4)) {\n            total_samples = dff_chunk_header.ckDataSize / config->num_channels;\n            break;\n        }\n        else {          // just copy unknown chunks to output file\n\n            int bytes_to_copy = (int)(((dff_chunk_header.ckDataSize) + 1) & ~(int64_t)1);\n            char *buff = malloc (bytes_to_copy);\n\n            if (debug_logging_mode)\n                error_line (\"extra unknown chunk \\\"%c%c%c%c\\\" of %d bytes\",\n                    dff_chunk_header.ckID [0], dff_chunk_header.ckID [1], dff_chunk_header.ckID [2],\n                    dff_chunk_header.ckID [3], dff_chunk_header.ckDataSize);\n\n            if (!DoReadFile (infile, buff, bytes_to_copy, &bcount) ||\n                bcount != bytes_to_copy ||\n                (!(config->qmode & QMODE_NO_STORE_WRAPPER) &&\n                !WavpackAddWrapper (wpc, buff, bytes_to_copy))) {\n                    error_line (\"%s\", WavpackGetErrorMessage (wpc));\n                    free (buff);\n                    return WAVPACK_SOFT_ERROR;\n            }\n\n            free (buff);\n        }\n    }\n\n    if (debug_logging_mode)\n        error_line (\"setting configuration with %lld samples\", total_samples);\n\n    if (!WavpackSetConfiguration64 (wpc, config, total_samples, NULL)) {\n        error_line (\"%s: %s\", infilename, WavpackGetErrorMessage (wpc));\n        return WAVPACK_SOFT_ERROR;\n    }\n\n    return WAVPACK_NO_ERROR;\n}", "commit_link": "github.com/dbry/WavPack/commit/36a24c7881427d2e1e4dc1cef58f19eee0d13aec", "file_name": "cli/dsdiff.c", "vul_type": "cwe-125", "description": "Write a C function to parse the header of a DSDIFF file and configure the WavPack context."}
{"func_name": "mif_process_cmpt", "func_src_before": "static int mif_process_cmpt(mif_hdr_t *hdr, char *buf)\n{\n\tjas_tvparser_t *tvp;\n\tmif_cmpt_t *cmpt;\n\tint id;\n\n\tcmpt = 0;\n\ttvp = 0;\n\n\tif (!(cmpt = mif_cmpt_create())) {\n\t\tgoto error;\n\t}\n\tcmpt->tlx = 0;\n\tcmpt->tly = 0;\n\tcmpt->sampperx = 0;\n\tcmpt->samppery = 0;\n\tcmpt->width = 0;\n\tcmpt->height = 0;\n\tcmpt->prec = 0;\n\tcmpt->sgnd = -1;\n\tcmpt->data = 0;\n\n\tif (!(tvp = jas_tvparser_create(buf))) {\n\t\tgoto error;\n\t}\n\twhile (!(id = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(mif_tags,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase MIF_TLX:\n\t\t\tcmpt->tlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_TLY:\n\t\t\tcmpt->tly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_WIDTH:\n\t\t\tcmpt->width = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HEIGHT:\n\t\t\tcmpt->height = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HSAMP:\n\t\t\tcmpt->sampperx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_VSAMP:\n\t\t\tcmpt->samppery = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_PREC:\n\t\t\tcmpt->prec = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_SGND:\n\t\t\tcmpt->sgnd = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_DATA:\n\t\t\tif (!(cmpt->data = jas_strdup(jas_tvparser_getval(tvp)))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tjas_tvparser_destroy(tvp);\n\tif (!cmpt->sampperx || !cmpt->samppery) {\n\t\tgoto error;\n\t}\n\tif (mif_hdr_addcmpt(hdr, hdr->numcmpts, cmpt)) {\n\t\tgoto error;\n\t}\n\treturn 0;\n\nerror:\n\tif (cmpt) {\n\t\tmif_cmpt_destroy(cmpt);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\treturn -1;\n}", "func_src_after": "static int mif_process_cmpt(mif_hdr_t *hdr, char *buf)\n{\n\tjas_tvparser_t *tvp;\n\tmif_cmpt_t *cmpt;\n\tint id;\n\n\tcmpt = 0;\n\ttvp = 0;\n\n\tif (!(cmpt = mif_cmpt_create())) {\n\t\tgoto error;\n\t}\n\tcmpt->tlx = 0;\n\tcmpt->tly = 0;\n\tcmpt->sampperx = 0;\n\tcmpt->samppery = 0;\n\tcmpt->width = 0;\n\tcmpt->height = 0;\n\tcmpt->prec = 0;\n\tcmpt->sgnd = -1;\n\tcmpt->data = 0;\n\n\tif (!(tvp = jas_tvparser_create(buf))) {\n\t\tgoto error;\n\t}\n\twhile (!(id = jas_tvparser_next(tvp))) {\n\t\tswitch (jas_taginfo_nonull(jas_taginfos_lookup(mif_tags,\n\t\t  jas_tvparser_gettag(tvp)))->id) {\n\t\tcase MIF_TLX:\n\t\t\tcmpt->tlx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_TLY:\n\t\t\tcmpt->tly = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_WIDTH:\n\t\t\tcmpt->width = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HEIGHT:\n\t\t\tcmpt->height = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_HSAMP:\n\t\t\tcmpt->sampperx = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_VSAMP:\n\t\t\tcmpt->samppery = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_PREC:\n\t\t\tcmpt->prec = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_SGND:\n\t\t\tcmpt->sgnd = atoi(jas_tvparser_getval(tvp));\n\t\t\tbreak;\n\t\tcase MIF_DATA:\n\t\t\tif (!(cmpt->data = jas_strdup(jas_tvparser_getval(tvp)))) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (!cmpt->sampperx || !cmpt->samppery) {\n\t\tgoto error;\n\t}\n\tif (mif_hdr_addcmpt(hdr, hdr->numcmpts, cmpt)) {\n\t\tgoto error;\n\t}\n\tjas_tvparser_destroy(tvp);\n\treturn 0;\n\nerror:\n\tif (cmpt) {\n\t\tmif_cmpt_destroy(cmpt);\n\t}\n\tif (tvp) {\n\t\tjas_tvparser_destroy(tvp);\n\t}\n\treturn -1;\n}", "commit_link": "github.com/mdadams/jasper/commit/df5d2867e8004e51e18b89865bc4aa69229227b3", "file_name": "src/libjasper/mif/mif_cod.c", "vul_type": "cwe-416", "description": "Write a C function to parse component information from a buffer and add it to a MIF header, handling errors appropriately."}
{"func_name": "HeifContext::interpret_heif_file", "func_src_before": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "func_src_after": "Error HeifContext::interpret_heif_file()\n{\n  m_all_images.clear();\n  m_top_level_images.clear();\n  m_primary_image.reset();\n\n\n  // --- reference all non-hidden images\n\n  std::vector<heif_item_id> image_IDs = m_heif_file->get_item_IDs();\n\n  bool primary_is_grid = false;\n  for (heif_item_id id : image_IDs) {\n    auto infe_box = m_heif_file->get_infe_box(id);\n    if (!infe_box) {\n      // TODO(farindk): Should we return an error instead of skipping the invalid id?\n      continue;\n    }\n\n    if (item_type_is_image(infe_box->get_item_type())) {\n      auto image = std::make_shared<Image>(this, id);\n      m_all_images.insert(std::make_pair(id, image));\n\n      if (!infe_box->is_hidden_item()) {\n        if (id==m_heif_file->get_primary_image_ID()) {\n          image->set_primary(true);\n          m_primary_image = image;\n          primary_is_grid = infe_box->get_item_type() == \"grid\";\n        }\n\n        m_top_level_images.push_back(image);\n      }\n    }\n  }\n\n\n  if (!m_primary_image) {\n    return Error(heif_error_Invalid_input,\n                 heif_suberror_Nonexisting_item_referenced,\n                 \"'pitm' box references a non-existing image\");\n  }\n\n\n  // --- remove thumbnails from top-level images and assign to their respective image\n\n  auto iref_box = m_heif_file->get_iref_box();\n  if (iref_box) {\n    // m_top_level_images.clear();\n\n    for (auto& pair : m_all_images) {\n      auto& image = pair.second;\n\n      std::vector<Box_iref::Reference> references = iref_box->get_references_from(image->get_id());\n\n      for (const Box_iref::Reference& ref : references) {\n        uint32_t type = ref.header.get_short_type();\n\n        if (type==fourcc(\"thmb\")) {\n          // --- this is a thumbnail image, attach to the main image\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many thumbnail references\");\n          }\n\n          image->set_is_thumbnail_of(refs[0]);\n\n          auto master_iter = m_all_images.find(refs[0]);\n          if (master_iter == m_all_images.end()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references a non-existing image\");\n          }\n\n          if (master_iter->second->is_thumbnail()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Thumbnail references another thumbnail\");\n          }\n\n          if (image.get() == master_iter->second.get()) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Nonexisting_item_referenced,\n                         \"Recursive thumbnail image detected\");\n          }\n          master_iter->second->add_thumbnail(image);\n\n          remove_top_level_image(image);\n        }\n        else if (type==fourcc(\"auxl\")) {\n\n          // --- this is an auxiliary image\n          //     check whether it is an alpha channel and attach to the main image if yes\n\n          std::vector<Box_ipco::Property> properties;\n          Error err = m_heif_file->get_properties(image->get_id(), properties);\n          if (err) {\n            return err;\n          }\n\n          std::shared_ptr<Box_auxC> auxC_property;\n          for (const auto& property : properties) {\n            auto auxC = std::dynamic_pointer_cast<Box_auxC>(property.property);\n            if (auxC) {\n              auxC_property = auxC;\n            }\n          }\n\n          if (!auxC_property) {\n            std::stringstream sstr;\n            sstr << \"No auxC property for image \" << image->get_id();\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Auxiliary_image_type_unspecified,\n                         sstr.str());\n          }\n\n          std::vector<heif_item_id> refs = ref.to_item_ID;\n          if (refs.size() != 1) {\n            return Error(heif_error_Invalid_input,\n                         heif_suberror_Unspecified,\n                         \"Too many auxiliary image references\");\n          }\n\n\n          // alpha channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:avc:2015:auxid:1\" ||\n              auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:1\") {\n            image->set_is_alpha_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (master_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Non-existing alpha image referenced\");\n            }\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive alpha image detected\");\n            }\n            master_iter->second->set_alpha_channel(image);\n          }\n\n\n          // depth channel\n\n          if (auxC_property->get_aux_type() == \"urn:mpeg:hevc:2015:auxid:2\") {\n            image->set_is_depth_channel_of(refs[0]);\n\n            auto master_iter = m_all_images.find(refs[0]);\n            if (image.get() == master_iter->second.get()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Recursive depth image detected\");\n            }\n            master_iter->second->set_depth_channel(image);\n\n            auto subtypes = auxC_property->get_subtypes();\n\n            std::vector<std::shared_ptr<SEIMessage>> sei_messages;\n            Error err = decode_hevc_aux_sei_messages(subtypes, sei_messages);\n\n            for (auto& msg : sei_messages) {\n              auto depth_msg = std::dynamic_pointer_cast<SEIMessage_depth_representation_info>(msg);\n              if (depth_msg) {\n                image->set_depth_representation_info(*depth_msg);\n              }\n            }\n          }\n\n          remove_top_level_image(image);\n        }\n        else {\n          // 'image' is a normal image, keep it as a top-level image\n        }\n      }\n    }\n  }\n\n\n  // --- check that HEVC images have an hvcC property\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::shared_ptr<Box_infe> infe = m_heif_file->get_infe_box(image->get_id());\n    if (infe->get_item_type() == \"hvc1\") {\n\n      auto ipma = m_heif_file->get_ipma_box();\n      auto ipco = m_heif_file->get_ipco_box();\n\n      if (!ipco->get_property_for_item_ID(image->get_id(), ipma, fourcc(\"hvcC\"))) {\n        return Error(heif_error_Invalid_input,\n                     heif_suberror_No_hvcC_box,\n                     \"No hvcC property in hvc1 type image\");\n      }\n    }\n  }\n\n\n  // --- read through properties for each image and extract image resolutions\n\n  for (auto& pair : m_all_images) {\n    auto& image = pair.second;\n\n    std::vector<Box_ipco::Property> properties;\n\n    Error err = m_heif_file->get_properties(pair.first, properties);\n    if (err) {\n      return err;\n    }\n\n    bool ispe_read = false;\n    bool primary_colr_set = false;\n    for (const auto& prop : properties) {\n      auto ispe = std::dynamic_pointer_cast<Box_ispe>(prop.property);\n      if (ispe) {\n        uint32_t width = ispe->get_width();\n        uint32_t height = ispe->get_height();\n\n\n        // --- check whether the image size is \"too large\"\n\n        if (width  >= static_cast<uint32_t>(MAX_IMAGE_WIDTH) ||\n            height >= static_cast<uint32_t>(MAX_IMAGE_HEIGHT)) {\n          std::stringstream sstr;\n          sstr << \"Image size \" << width << \"x\" << height << \" exceeds the maximum image size \"\n               << MAX_IMAGE_WIDTH << \"x\" << MAX_IMAGE_HEIGHT << \"\\n\";\n\n          return Error(heif_error_Memory_allocation_error,\n                       heif_suberror_Security_limit_exceeded,\n                       sstr.str());\n        }\n\n        image->set_resolution(width, height);\n        image->set_ispe_resolution(width, height);\n        ispe_read = true;\n      }\n\n      if (ispe_read) {\n        auto clap = std::dynamic_pointer_cast<Box_clap>(prop.property);\n        if (clap) {\n          image->set_resolution( clap->get_width_rounded(),\n                                 clap->get_height_rounded() );\n        }\n\n        auto irot = std::dynamic_pointer_cast<Box_irot>(prop.property);\n        if (irot) {\n          if (irot->get_rotation()==90 ||\n              irot->get_rotation()==270) {\n            // swap width and height\n            image->set_resolution( image->get_height(),\n                                   image->get_width() );\n          }\n        }\n      }\n\n      auto colr = std::dynamic_pointer_cast<Box_colr>(prop.property);\n      if (colr) {\n        auto profile = colr->get_color_profile();\n\n        image->set_color_profile(profile);\n\n        // if this is a grid item we assign the first one's color profile\n        // to the main image which is supposed to be a grid\n\n        // TODO: this condition is not correct. It would also classify a secondary image as a 'grid item'.\n        // We have to set the grid-image color profile in another way...\n        const bool is_grid_item = !image->is_primary() && !image->is_alpha_channel() && !image->is_depth_channel();\n\n        if (primary_is_grid &&\n            !primary_colr_set &&\n            is_grid_item) {\n          m_primary_image->set_color_profile(profile);\n          primary_colr_set = true;\n        }\n      }\n    }\n  }\n\n\n  // --- read metadata and assign to image\n\n  for (heif_item_id id : image_IDs) {\n    std::string item_type    = m_heif_file->get_item_type(id);\n    std::string content_type = m_heif_file->get_content_type(id);\n    if (item_type == \"Exif\" ||\n        (item_type==\"mime\" && content_type==\"application/rdf+xml\")) {\n      std::shared_ptr<ImageMetadata> metadata = std::make_shared<ImageMetadata>();\n      metadata->item_id = id;\n      metadata->item_type = item_type;\n      metadata->content_type = content_type;\n\n      Error err = m_heif_file->get_compressed_image_data(id, &(metadata->m_data));\n      if (err) {\n        return err;\n      }\n\n      //std::cerr.write((const char*)data.data(), data.size());\n\n\n      // --- assign metadata to the image\n\n      if (iref_box) {\n        std::vector<Box_iref::Reference> references = iref_box->get_references_from(id);\n        for (const auto& ref : references) {\n          if (ref.header.get_short_type() == fourcc(\"cdsc\")) {\n            std::vector<uint32_t> refs = ref.to_item_ID;\n            if (refs.size() != 1) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Unspecified,\n                           \"Exif data not correctly assigned to image\");\n            }\n\n            uint32_t exif_image_id = refs[0];\n            auto img_iter = m_all_images.find(exif_image_id);\n            if (img_iter == m_all_images.end()) {\n              return Error(heif_error_Invalid_input,\n                           heif_suberror_Nonexisting_item_referenced,\n                           \"Exif data assigned to non-existing image\");\n            }\n\n            img_iter->second->add_metadata(metadata);\n          }\n        }\n      }\n    }\n  }\n\n  return Error::Ok;\n}", "commit_link": "github.com/strukturag/libheif/commit/995a4283d8ed2d0d2c1ceb1a577b993df2f0e014", "file_name": "libheif/heif_context.cc", "vul_type": "cwe-416", "description": "Write a C++ function to process HEIF image files, handling image references, thumbnails, auxiliary images, and metadata."}
{"func_name": "do_get_mempolicy", "func_src_before": "static long do_get_mempolicy(int *policy, nodemask_t *nmask,\n\t\t\t     unsigned long addr, unsigned long flags)\n{\n\tint err;\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *vma = NULL;\n\tstruct mempolicy *pol = current->mempolicy;\n\n\tif (flags &\n\t\t~(unsigned long)(MPOL_F_NODE|MPOL_F_ADDR|MPOL_F_MEMS_ALLOWED))\n\t\treturn -EINVAL;\n\n\tif (flags & MPOL_F_MEMS_ALLOWED) {\n\t\tif (flags & (MPOL_F_NODE|MPOL_F_ADDR))\n\t\t\treturn -EINVAL;\n\t\t*policy = 0;\t/* just so it's initialized */\n\t\ttask_lock(current);\n\t\t*nmask  = cpuset_current_mems_allowed;\n\t\ttask_unlock(current);\n\t\treturn 0;\n\t}\n\n\tif (flags & MPOL_F_ADDR) {\n\t\t/*\n\t\t * Do NOT fall back to task policy if the\n\t\t * vma/shared policy at addr is NULL.  We\n\t\t * want to return MPOL_DEFAULT in this case.\n\t\t */\n\t\tdown_read(&mm->mmap_sem);\n\t\tvma = find_vma_intersection(mm, addr, addr+1);\n\t\tif (!vma) {\n\t\t\tup_read(&mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tif (vma->vm_ops && vma->vm_ops->get_policy)\n\t\t\tpol = vma->vm_ops->get_policy(vma, addr);\n\t\telse\n\t\t\tpol = vma->vm_policy;\n\t} else if (addr)\n\t\treturn -EINVAL;\n\n\tif (!pol)\n\t\tpol = &default_policy;\t/* indicates default behavior */\n\n\tif (flags & MPOL_F_NODE) {\n\t\tif (flags & MPOL_F_ADDR) {\n\t\t\terr = lookup_node(addr);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out;\n\t\t\t*policy = err;\n\t\t} else if (pol == current->mempolicy &&\n\t\t\t\tpol->mode == MPOL_INTERLEAVE) {\n\t\t\t*policy = next_node_in(current->il_prev, pol->v.nodes);\n\t\t} else {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t*policy = pol == &default_policy ? MPOL_DEFAULT :\n\t\t\t\t\t\tpol->mode;\n\t\t/*\n\t\t * Internal mempolicy flags must be masked off before exposing\n\t\t * the policy to userspace.\n\t\t */\n\t\t*policy |= (pol->flags & MPOL_MODE_FLAGS);\n\t}\n\n\terr = 0;\n\tif (nmask) {\n\t\tif (mpol_store_user_nodemask(pol)) {\n\t\t\t*nmask = pol->w.user_nodemask;\n\t\t} else {\n\t\t\ttask_lock(current);\n\t\t\tget_policy_nodemask(pol, nmask);\n\t\t\ttask_unlock(current);\n\t\t}\n\t}\n\n out:\n\tmpol_cond_put(pol);\n\tif (vma)\n\t\tup_read(&current->mm->mmap_sem);\n\treturn err;\n}", "func_src_after": "static long do_get_mempolicy(int *policy, nodemask_t *nmask,\n\t\t\t     unsigned long addr, unsigned long flags)\n{\n\tint err;\n\tstruct mm_struct *mm = current->mm;\n\tstruct vm_area_struct *vma = NULL;\n\tstruct mempolicy *pol = current->mempolicy;\n\n\tif (flags &\n\t\t~(unsigned long)(MPOL_F_NODE|MPOL_F_ADDR|MPOL_F_MEMS_ALLOWED))\n\t\treturn -EINVAL;\n\n\tif (flags & MPOL_F_MEMS_ALLOWED) {\n\t\tif (flags & (MPOL_F_NODE|MPOL_F_ADDR))\n\t\t\treturn -EINVAL;\n\t\t*policy = 0;\t/* just so it's initialized */\n\t\ttask_lock(current);\n\t\t*nmask  = cpuset_current_mems_allowed;\n\t\ttask_unlock(current);\n\t\treturn 0;\n\t}\n\n\tif (flags & MPOL_F_ADDR) {\n\t\t/*\n\t\t * Do NOT fall back to task policy if the\n\t\t * vma/shared policy at addr is NULL.  We\n\t\t * want to return MPOL_DEFAULT in this case.\n\t\t */\n\t\tdown_read(&mm->mmap_sem);\n\t\tvma = find_vma_intersection(mm, addr, addr+1);\n\t\tif (!vma) {\n\t\t\tup_read(&mm->mmap_sem);\n\t\t\treturn -EFAULT;\n\t\t}\n\t\tif (vma->vm_ops && vma->vm_ops->get_policy)\n\t\t\tpol = vma->vm_ops->get_policy(vma, addr);\n\t\telse\n\t\t\tpol = vma->vm_policy;\n\t} else if (addr)\n\t\treturn -EINVAL;\n\n\tif (!pol)\n\t\tpol = &default_policy;\t/* indicates default behavior */\n\n\tif (flags & MPOL_F_NODE) {\n\t\tif (flags & MPOL_F_ADDR) {\n\t\t\terr = lookup_node(addr);\n\t\t\tif (err < 0)\n\t\t\t\tgoto out;\n\t\t\t*policy = err;\n\t\t} else if (pol == current->mempolicy &&\n\t\t\t\tpol->mode == MPOL_INTERLEAVE) {\n\t\t\t*policy = next_node_in(current->il_prev, pol->v.nodes);\n\t\t} else {\n\t\t\terr = -EINVAL;\n\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t*policy = pol == &default_policy ? MPOL_DEFAULT :\n\t\t\t\t\t\tpol->mode;\n\t\t/*\n\t\t * Internal mempolicy flags must be masked off before exposing\n\t\t * the policy to userspace.\n\t\t */\n\t\t*policy |= (pol->flags & MPOL_MODE_FLAGS);\n\t}\n\n\tif (vma) {\n\t\tup_read(&current->mm->mmap_sem);\n\t\tvma = NULL;\n\t}\n\n\terr = 0;\n\tif (nmask) {\n\t\tif (mpol_store_user_nodemask(pol)) {\n\t\t\t*nmask = pol->w.user_nodemask;\n\t\t} else {\n\t\t\ttask_lock(current);\n\t\t\tget_policy_nodemask(pol, nmask);\n\t\t\ttask_unlock(current);\n\t\t}\n\t}\n\n out:\n\tmpol_cond_put(pol);\n\tif (vma)\n\t\tup_read(&current->mm->mmap_sem);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/73223e4e2e3867ebf033a5a8eb2e5df0158ccc99", "file_name": "mm/mempolicy.c", "vul_type": "cwe-416", "description": "Write a C function to retrieve memory policy and node mask information for a given address and flags."}
{"func_name": "render", "func_src_before": "\tdef render(self, request):\n\t\taction = \"download\"\n\t\tif \"action\" in request.args:\n\t\t\taction = request.args[\"action\"][0]\n\n\t\tif \"file\" in request.args:\n\t\t\tfilename = request.args[\"file\"][0].decode('utf-8', 'ignore').encode('utf-8')\n\t\t\tfilename = re.sub(\"^/+\", \"/\", os.path.realpath(filename))\n\n\t\t\tif not os.path.exists(filename):\n\t\t\t\treturn \"File '%s' not found\" % (filename)\n\n\t\t\tif action == \"stream\":\n\t\t\t\tname = \"stream\"\n\t\t\t\tif \"name\" in request.args:\n\t\t\t\t\tname = request.args[\"name\"][0]\n\n\t\t\t\tport = config.OpenWebif.port.value\n\t\t\t\tproto = 'http'\n\t\t\t\tif request.isSecure():\n\t\t\t\t\tport = config.OpenWebif.https_port.value\n\t\t\t\t\tproto = 'https'\n\t\t\t\tourhost = request.getHeader('host')\n\t\t\t\tm = re.match('.+\\:(\\d+)$', ourhost)\n\t\t\t\tif m is not None:\n\t\t\t\t\tport = m.group(1)\n\n\t\t\t\tresponse = \"#EXTM3U\\n#EXTVLCOPT--http-reconnect=true\\n#EXTINF:-1,%s\\n%s://%s:%s/file?action=download&file=%s\" % (name, proto, request.getRequestHostname(), port, quote(filename))\n\t\t\t\trequest.setHeader(\"Content-Disposition\", 'attachment;filename=\"%s.m3u\"' % name)\n\t\t\t\trequest.setHeader(\"Content-Type\", \"application/x-mpegurl\")\n\t\t\t\treturn response\n\t\t\telif action == \"delete\":\n\t\t\t\trequest.setResponseCode(http.OK)\n\t\t\t\treturn \"TODO: DELETE FILE: %s\" % (filename)\n\t\t\telif action == \"download\":\n\t\t\t\trequest.setHeader(\"Content-Disposition\", \"attachment;filename=\\\"%s\\\"\" % (filename.split('/')[-1]))\n\t\t\t\trfile = static.File(filename, defaultType = \"application/octet-stream\")\n\t\t\t\treturn rfile.render(request)\n\t\t\telse: \n\t\t\t\treturn \"wrong action parameter\"\n\n\t\tif \"dir\" in request.args:\n\t\t\tpath = request.args[\"dir\"][0]\n\t\t\tpattern = '*'\n\t\t\tdata = []\n\t\t\tif \"pattern\" in request.args:\n\t\t\t\tpattern = request.args[\"pattern\"][0]\n\t\t\tdirectories = []\n\t\t\tfiles = []\n\t\t\tif fileExists(path):\n\t\t\t\ttry:\n\t\t\t\t\tfiles = glob.glob(path+'/'+pattern)\n\t\t\t\texcept:\n\t\t\t\t\tfiles = []\n\t\t\t\tfiles.sort()\n\t\t\t\ttmpfiles = files[:]\n\t\t\t\tfor x in tmpfiles:\n\t\t\t\t\tif os.path.isdir(x):\n\t\t\t\t\t\tdirectories.append(x + '/')\n\t\t\t\t\t\tfiles.remove(x)\n\t\t\t\tdata.append({\"result\": True,\"dirs\": directories,\"files\": files})\n\t\t\telse:\n\t\t\t\tdata.append({\"result\": False,\"message\": \"path %s not exits\" % (path)})\n\t\t\trequest.setHeader(\"content-type\", \"application/json; charset=utf-8\")\n\t\t\treturn json.dumps(data, indent=2)", "func_src_after": "\tdef render(self, request):\n\t\taction = \"download\"\n\t\tif \"action\" in request.args:\n\t\t\taction = request.args[\"action\"][0]\n\n\t\tif \"file\" in request.args:\n\t\t\tfilename = lenient_force_utf_8(request.args[\"file\"][0])\n\t\t\tfilename = sanitise_filename_slashes(os.path.realpath(filename))\n\n\t\t\tif not os.path.exists(filename):\n\t\t\t\treturn \"File '%s' not found\" % (filename)\n\n\t\t\tif action == \"stream\":\n\t\t\t\tname = \"stream\"\n\t\t\t\tif \"name\" in request.args:\n\t\t\t\t\tname = request.args[\"name\"][0]\n\n\t\t\t\tport = config.OpenWebif.port.value\n\t\t\t\tproto = 'http'\n\t\t\t\tif request.isSecure():\n\t\t\t\t\tport = config.OpenWebif.https_port.value\n\t\t\t\t\tproto = 'https'\n\t\t\t\tourhost = request.getHeader('host')\n\t\t\t\tm = re.match('.+\\:(\\d+)$', ourhost)\n\t\t\t\tif m is not None:\n\t\t\t\t\tport = m.group(1)\n\n\t\t\t\tresponse = \"#EXTM3U\\n#EXTVLCOPT--http-reconnect=true\\n#EXTINF:-1,%s\\n%s://%s:%s/file?action=download&file=%s\" % (name, proto, request.getRequestHostname(), port, quote(filename))\n\t\t\t\trequest.setHeader(\"Content-Disposition\", 'attachment;filename=\"%s.m3u\"' % name)\n\t\t\t\trequest.setHeader(\"Content-Type\", \"application/x-mpegurl\")\n\t\t\t\treturn response\n\t\t\telif action == \"delete\":\n\t\t\t\trequest.setResponseCode(http.OK)\n\t\t\t\treturn \"TODO: DELETE FILE: %s\" % (filename)\n\t\t\telif action == \"download\":\n\t\t\t\trequest.setHeader(\"Content-Disposition\", \"attachment;filename=\\\"%s\\\"\" % (filename.split('/')[-1]))\n\t\t\t\trfile = static.File(filename, defaultType = \"application/octet-stream\")\n\t\t\t\treturn rfile.render(request)\n\t\t\telse: \n\t\t\t\treturn \"wrong action parameter\"\n\n\t\tif \"dir\" in request.args:\n\t\t\tpath = request.args[\"dir\"][0]\n\t\t\tpattern = '*'\n\t\t\tdata = []\n\t\t\tif \"pattern\" in request.args:\n\t\t\t\tpattern = request.args[\"pattern\"][0]\n\t\t\tdirectories = []\n\t\t\tfiles = []\n\t\t\tif fileExists(path):\n\t\t\t\ttry:\n\t\t\t\t\tfiles = glob.glob(path+'/'+pattern)\n\t\t\t\texcept:\n\t\t\t\t\tfiles = []\n\t\t\t\tfiles.sort()\n\t\t\t\ttmpfiles = files[:]\n\t\t\t\tfor x in tmpfiles:\n\t\t\t\t\tif os.path.isdir(x):\n\t\t\t\t\t\tdirectories.append(x + '/')\n\t\t\t\t\t\tfiles.remove(x)\n\t\t\t\tdata.append({\"result\": True,\"dirs\": directories,\"files\": files})\n\t\t\telse:\n\t\t\t\tdata.append({\"result\": False,\"message\": \"path %s not exits\" % (path)})\n\t\t\trequest.setHeader(\"content-type\", \"application/json; charset=utf-8\")\n\t\t\treturn json.dumps(data, indent=2)", "commit_link": "github.com/E2OpenPlugins/e2openplugin-OpenWebif/commit/a846b7664eda3a4c51a452e00638cf7337dc2013", "file_name": "plugin/controllers/file.py", "vul_type": "cwe-022", "description": "Write a Python function to handle file actions like streaming, downloading, deleting, or listing directory contents based on request parameters."}
{"func_name": "ranks", "func_src_before": "@endpoints.route(\"/ranks\")\ndef ranks():\n    if db == None:\n        init()\n\n    scene = request.args.get('scene', default='austin')\n    date = request.args.get('date')\n \n    # If no date was provided, pick the date of the latest tournament\n    if date == None:\n        sql = \"SELECT distinct date FROM ranks WHERE scene='{}' ORDER BY date DESC LIMIT 1;\".format(scene)\n        res = db.exec(sql)\n        date = res[0][0]\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM ranks WHERE scene = '{}' and date='{}'\".format(scene, date)\n    res = db.exec(sql)\n\n    # Make a dict out of this data\n    # eg {'christmasmike': 50}\n    cur_ranks = {}\n    for r in res:\n        tag = r[1]\n        rank = r[2]\n\n        cur_ranks[tag] = rank\n\n    # Now get the ranks from last month, so we know if these players went up or down\n    y, m, d = date.split('-')\n    prev_date = bracket_utils.get_previous_month(date)\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM ranks WHERE scene = '{}' and date='{}'\".format(scene, prev_date)\n    res = db.exec(sql)\n\n    # Make a dict out of this data\n    # eg {'christmasmike': 50}\n    prev_ranks = {}\n    for r in res:\n        tag = r[1]\n        rank = r[2]\n\n        prev_ranks[tag] = rank\n\n    return render_template('libraries/html/ranks.html', cur_ranks=cur_ranks, prev_ranks=prev_ranks, scene=scene, date=date)", "func_src_after": "@endpoints.route(\"/ranks\")\ndef ranks():\n    if db == None:\n        init()\n\n    scene = request.args.get('scene', default='austin')\n    date = request.args.get('date')\n \n    # If no date was provided, pick the date of the latest tournament\n    if date == None:\n        sql = \"SELECT distinct date FROM ranks WHERE scene='{scene}' ORDER BY date DESC LIMIT 1;\"\n        args = {'scene': scene}\n        res = db.exec(sql, args)\n        date = res[0][0]\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM ranks WHERE scene = '{scene}' and date='{date}'\"\n    args = {'scene': scene, 'date': date}\n    res = db.exec(sql, args)\n\n    # Make a dict out of this data\n    # eg {'christmasmike': 50}\n    cur_ranks = {}\n    for r in res:\n        tag = r[1]\n        rank = r[2]\n\n        cur_ranks[tag] = rank\n\n    # Now get the ranks from last month, so we know if these players went up or down\n    y, m, d = date.split('-')\n    prev_date = bracket_utils.get_previous_month(date)\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM ranks WHERE scene = '{scene}' and date='{date}'\"\n    args = {'scene': scene, 'date': prev_date}\n    res = db.exec(sql, args)\n\n    # Make a dict out of this data\n    # eg {'christmasmike': 50}\n    prev_ranks = {}\n    for r in res:\n        tag = r[1]\n        rank = r[2]\n\n        prev_ranks[tag] = rank\n\n    return render_template('libraries/html/ranks.html', cur_ranks=cur_ranks, prev_ranks=prev_ranks, scene=scene, date=date)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "In Python, create a Flask endpoint '/ranks' that retrieves and compares player rankings from a database for the current and previous month."}
{"func_name": "dd_exist", "func_src_before": "int dd_exist(const struct dump_dir *dd, const char *path)\n{\n    char *full_path = concat_path_file(dd->dd_dirname, path);\n    int ret = exist_file_dir(full_path);\n    free(full_path);\n    return ret;\n}", "func_src_after": "int dd_exist(const struct dump_dir *dd, const char *path)\n{\n    if (!str_is_correct_filename(path))\n        error_msg_and_die(\"Cannot test existence. '%s' is not a valid file name\", path);\n\n    char *full_path = concat_path_file(dd->dd_dirname, path);\n    int ret = exist_file_dir(full_path);\n    free(full_path);\n    return ret;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_exist` that checks if a file exists within a directory structure represented by a `dump_dir` structure, and handles invalid filenames with an error message."}
{"func_name": "get_requested_day", "func_src_before": "    def get_requested_day(self, date):\n\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, SUM(Power) AS Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN %s AND %s \n            GROUP BY TimeStamp;\n        '''\n\n        data['data'] = list()\n        for row in self.c.execute(query % (day_start, day_end)):\n            data['data'].append({ 'time': row[0], 'power': row[1] })\n\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT SUM(EToday) as EToday\n                FROM Inverters;\n                '''\n        else:\n            query = '''\n                SELECT SUM(DayYield) AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN %s AND %s\n                GROUP BY TimeStamp\n                ''' % (day_start, day_end)\n        self.c.execute(query)\n        row = self.c.fetchone()\n        if row and row[0]: data['total'] = row[0]\n        else: data['total'] = 0\n\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data):  data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        #print(json.dumps(data, indent=4))\n        return data", "func_src_after": "    def get_requested_day(self, date):\n\n        data = dict()\n\n        day_start, day_end = self.get_epoch_day(date)\n        data['interval'] = {'from': self.convert_local_ts_to_utc(day_start, self.local_timezone), 'to': self.convert_local_ts_to_utc(day_end, self.local_timezone)}\n\n        query = '''\n            SELECT TimeStamp, SUM(Power) AS Power \n            FROM DayData \n            WHERE TimeStamp BETWEEN ? AND ?\n            GROUP BY TimeStamp;\n        '''\n\n        data['data'] = list()\n        for row in self.c.execute(query, (day_start, day_end)):\n            data['data'].append({ 'time': row[0], 'power': row[1] })\n\n\n        if self.get_datetime(date).date() == datetime.today().date():\n            query = '''\n                SELECT SUM(EToday) as EToday\n                FROM Inverters;\n                '''\n            self.c.execute(query)\n        else:\n            query = '''\n                SELECT SUM(DayYield) AS Power \n                FROM MonthData \n                WHERE TimeStamp BETWEEN ? AND ?\n                GROUP BY TimeStamp;\n                '''\n            self.c.execute(query, (day_start, day_end))\n\n        row = self.c.fetchone()\n        if row and row[0]: data['total'] = row[0]\n        else: data['total'] = 0\n\n\n        query = '''\n            SELECT MIN(TimeStamp) as Min, MAX(TimeStamp) as Max \n            FROM ( SELECT TimeStamp FROM DayData GROUP BY TimeStamp );\n            '''\n\n        self.c.execute(query)\n        first_data, last_data = self.c.fetchone()\n\n        if (first_data):  data['hasPrevious'] = (first_data < day_start)\n        else: data['hasPrevious'] = False\n\n        if (last_data): data['hasNext'] = (last_data > day_end)\n        else: data['hasNext'] = False\n\n        #print(json.dumps(data, indent=4))\n        return data", "commit_link": "github.com/philipptrenz/sunportal/commit/7eef493a168ed4e6731ff800713bfb8aee99a506", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and summarizes power data for a given day, including checking for previous and next day data availability."}
{"func_name": "tflite::Subgraph::Invoke", "func_src_before": "TfLiteStatus Subgraph::Invoke() {\n  if (!consistent_) {\n    ReportError(\"Invoke called on model that is not consistent.\");\n    return kTfLiteError;\n  }\n\n  TfLiteStatus status = kTfLiteOk;\n  if (state_ == kStateUninvokable) {\n    ReportError(\"Invoke called on model that is not ready.\");\n    return kTfLiteError;\n  } else if (memory_planner_ && !memory_planner_->HasNonPersistentMemory()) {\n    ReportError(\"Non-persistent memory is not available.\");\n    return kTfLiteError;\n  }\n\n  // This is only needed for UseNNAPI(true);\n  if (should_apply_nnapi_delegate_ && !applied_nnapi_delegate_) {\n    TF_LITE_ENSURE_OK(&context_, ModifyGraphWithDelegate(NnApiDelegate()));\n    // only need to modify the graph once upon the first invocation.\n    applied_nnapi_delegate_ = true;\n  }\n\n  // Invocations are always done in node order.\n  // Note that calling Invoke repeatedly will cause the original memory plan to\n  // be reused, unless either ResizeInputTensor() or AllocateTensors() has been\n  // called.\n  for (int execution_plan_index = 0;\n       execution_plan_index < execution_plan_.size(); execution_plan_index++) {\n    if (execution_plan_index == next_execution_plan_index_to_prepare_) {\n      TF_LITE_ENSURE_STATUS(PrepareOpsAndTensors());\n      TF_LITE_ENSURE(&context_, next_execution_plan_index_to_prepare_ >=\n                                    execution_plan_index);\n    }\n    int node_index = execution_plan_[execution_plan_index];\n    TfLiteNode& node = nodes_and_registration_[node_index].first;\n    const TfLiteRegistration& registration =\n        nodes_and_registration_[node_index].second;\n\n    const char* op_name = nullptr;\n    if (profiler_) op_name = GetTFLiteOpName(registration);\n    TFLITE_SCOPED_TAGGED_OPERATOR_PROFILE(profiler_.get(), op_name, node_index);\n\n    // TODO(ycling): This is an extra loop through inputs to check if the data\n    // need to be copied from Delegate buffer to raw memory, which is often not\n    // needed. We may want to cache this in prepare to know if this needs to be\n    // done for a node or not.\n    for (int i = 0; i < node.inputs->size; ++i) {\n      int tensor_index = node.inputs->data[i];\n      if (tensor_index == kTfLiteOptionalTensor) {\n        continue;\n      }\n      TfLiteTensor* tensor = &tensors_[tensor_index];\n      if (tensor->delegate && tensor->delegate != node.delegate &&\n          tensor->data_is_stale) {\n        TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));\n      }\n    }\n\n    if (check_cancelled_func_ != nullptr &&\n        check_cancelled_func_(cancellation_data_)) {\n      ReportError(\"Client requested cancel during Invoke()\");\n      return kTfLiteError;\n    }\n\n    EnsureTensorsVectorCapacity();\n    tensor_resized_since_op_invoke_ = false;\n    if (OpInvoke(registration, &node) != kTfLiteOk) {\n      return ReportOpError(&context_, node, registration, node_index,\n                           \"failed to invoke\");\n    }\n\n    // Force execution prep for downstream ops if the latest op triggered the\n    // resize of a dynamic tensor.\n    if (tensor_resized_since_op_invoke_ &&\n        HasDynamicTensor(context_, node.outputs)) {\n      next_execution_plan_index_to_prepare_ = execution_plan_index + 1;\n\n      // This happens when an intermediate dynamic tensor is resized.\n      // We don't have to prepare all the ops, but we need to recompute\n      // the allocation plan.\n      if (next_execution_plan_index_to_plan_allocation_ >\n          next_execution_plan_index_to_prepare_) {\n        next_execution_plan_index_to_plan_allocation_ =\n            next_execution_plan_index_to_prepare_;\n        if (memory_planner_) {\n          TF_LITE_ENSURE_STATUS(memory_planner_->ResetAllocationsAfter(\n              next_execution_plan_index_to_plan_allocation_ - 1));\n        }\n      }\n    }\n  }\n\n  return status;\n}", "func_src_after": "TfLiteStatus Subgraph::Invoke() {\n  if (!consistent_) {\n    ReportError(\"Invoke called on model that is not consistent.\");\n    return kTfLiteError;\n  }\n\n  TfLiteStatus status = kTfLiteOk;\n  if (state_ == kStateUninvokable) {\n    ReportError(\"Invoke called on model that is not ready.\");\n    return kTfLiteError;\n  } else if (memory_planner_ && !memory_planner_->HasNonPersistentMemory()) {\n    ReportError(\"Non-persistent memory is not available.\");\n    return kTfLiteError;\n  }\n\n  // This is only needed for UseNNAPI(true);\n  if (should_apply_nnapi_delegate_ && !applied_nnapi_delegate_) {\n    TF_LITE_ENSURE_OK(&context_, ModifyGraphWithDelegate(NnApiDelegate()));\n    // only need to modify the graph once upon the first invocation.\n    applied_nnapi_delegate_ = true;\n  }\n\n  // Invocations are always done in node order.\n  // Note that calling Invoke repeatedly will cause the original memory plan to\n  // be reused, unless either ResizeInputTensor() or AllocateTensors() has been\n  // called.\n  for (int execution_plan_index = 0;\n       execution_plan_index < execution_plan_.size(); execution_plan_index++) {\n    if (execution_plan_index == next_execution_plan_index_to_prepare_) {\n      TF_LITE_ENSURE_STATUS(PrepareOpsAndTensors());\n      TF_LITE_ENSURE(&context_, next_execution_plan_index_to_prepare_ >=\n                                    execution_plan_index);\n    }\n    int node_index = execution_plan_[execution_plan_index];\n    TfLiteNode& node = nodes_and_registration_[node_index].first;\n    const TfLiteRegistration& registration =\n        nodes_and_registration_[node_index].second;\n\n    const char* op_name = nullptr;\n    if (profiler_) op_name = GetTFLiteOpName(registration);\n    TFLITE_SCOPED_TAGGED_OPERATOR_PROFILE(profiler_.get(), op_name, node_index);\n\n    // TODO(ycling): This is an extra loop through inputs to check if the data\n    // need to be copied from Delegate buffer to raw memory, which is often not\n    // needed. We may want to cache this in prepare to know if this needs to be\n    // done for a node or not.\n    for (int i = 0; i < node.inputs->size; ++i) {\n      int tensor_index = node.inputs->data[i];\n      if (tensor_index == kTfLiteOptionalTensor) {\n        continue;\n      }\n      TfLiteTensor* tensor = &tensors_[tensor_index];\n      if (tensor->delegate && tensor->delegate != node.delegate &&\n          tensor->data_is_stale) {\n        TF_LITE_ENSURE_STATUS(EnsureTensorDataIsReadable(tensor_index));\n      }\n      if (tensor->data.raw == nullptr && tensor->bytes > 0) {\n        if (registration.builtin_code == kTfLiteBuiltinReshape && i == 1) {\n          // In general, having a tensor here with no buffer will be an error.\n          // However, for the reshape operator, the second input tensor is only\n          // used for the shape, not for the data. Thus, null buffer is ok.\n          continue;\n        } else {\n          // In all other cases, we need to return an error as otherwise we will\n          // trigger a null pointer dereference (likely).\n          ReportError(\"Input tensor %d lacks data\", tensor_index);\n          return kTfLiteError;\n        }\n      }\n    }\n\n    if (check_cancelled_func_ != nullptr &&\n        check_cancelled_func_(cancellation_data_)) {\n      ReportError(\"Client requested cancel during Invoke()\");\n      return kTfLiteError;\n    }\n\n    EnsureTensorsVectorCapacity();\n    tensor_resized_since_op_invoke_ = false;\n    if (OpInvoke(registration, &node) != kTfLiteOk) {\n      return ReportOpError(&context_, node, registration, node_index,\n                           \"failed to invoke\");\n    }\n\n    // Force execution prep for downstream ops if the latest op triggered the\n    // resize of a dynamic tensor.\n    if (tensor_resized_since_op_invoke_ &&\n        HasDynamicTensor(context_, node.outputs)) {\n      next_execution_plan_index_to_prepare_ = execution_plan_index + 1;\n\n      // This happens when an intermediate dynamic tensor is resized.\n      // We don't have to prepare all the ops, but we need to recompute\n      // the allocation plan.\n      if (next_execution_plan_index_to_plan_allocation_ >\n          next_execution_plan_index_to_prepare_) {\n        next_execution_plan_index_to_plan_allocation_ =\n            next_execution_plan_index_to_prepare_;\n        if (memory_planner_) {\n          TF_LITE_ENSURE_STATUS(memory_planner_->ResetAllocationsAfter(\n              next_execution_plan_index_to_plan_allocation_ - 1));\n        }\n      }\n    }\n  }\n\n  return status;\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/0b5662bc2be13a8c8f044d925d87fb6e56247cd8", "file_name": "tensorflow/lite/core/subgraph.cc", "vul_type": "cwe-476", "description": "Write a C++ function named `Invoke` in the `Subgraph` class of TensorFlow Lite that checks model consistency, prepares tensors, and invokes operations in order."}
{"func_name": "update_history_and_sourcebyinstitution", "func_src_before": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                sqlite.execute(sql, (sourcebyinstitution, number))\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (?, ?)'\n                    sqlite.execute(sql, (sourcebyinstitution, number))\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES (?)\"\n                sqlite.execute(sql, (sourcebyinstitution))\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "func_src_after": "def update_history_and_sourcebyinstitution(conn, sqlite, k10plus, ai):\n    \"\"\"\n    Get all current sources and title numbers from Solr and log them into database.\n    \"\"\"\n    current_sources = get_all_current_sources(k10plus, ai)\n    current_institutions = get_all_current_institutions(k10plus, ai)\n    old_sourcebyinstitutions = get_all_old_sourcebyinstitutions(conn, sqlite)\n    current_sourcebyinstitutions = []\n\n    for source in current_sources:\n\n        for institution in current_institutions:\n\n            if not institution or institution == \" \" or '\"' in institution:\n                continue\n\n            sourcebyinstitution = \"SID \" + str(source) + \" (\" + institution + \")\"\n            current_sourcebyinstitutions.append(sourcebyinstitution)\n\n            params = {\n                \"q\": 'source_id:%s AND institution:\"%s\"' % (source, institution),\n                \"rows\": 0,\n                \"wt\": \"json\"\n            }\n\n            # check k10plus\n            result = get_solr_result(k10plus, params)\n            number = result[\"response\"][\"numFound\"]\n            if number != 0:\n                sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                sqlite.execute(sql)\n                conn.commit()\n            else:\n                # check ai\n                result = get_solr_result(ai, params)\n                number = result[\"response\"][\"numFound\"]\n                if number != 0:\n                    # TODO: escape via sqlite\n                    sql = 'INSERT INTO history (sourcebyinstitution, titles) VALUES (\"%s\", %s)' % (sourcebyinstitution, number)\n                    sqlite.execute(sql)\n                    conn.commit()\n\n            if sourcebyinstitution not in old_sourcebyinstitutions:\n                logging.info(\"The %s is now connected to SID %s.\", institution, source)\n                sql = \"INSERT INTO sourcebyinstitution (sourcebyinstitution) VALUES ('%s')\" % sourcebyinstitution\n                sqlite.execute(sql)\n                conn.commit()\n\n            if number != 0:\n                old_sourcebyinstitution_number = get_old_sourcebyinstitution_number(conn, sqlite, sourcebyinstitution)\n                if number < old_sourcebyinstitution_number:\n                    message = \"Die Anzahl der Titel hat sich bei %s gegenueber einem frueheren Import verringert.\" % (sourcebyinstitution)\n                    send_message(message)\n\n            # requests.exceptions.ConnectionError: HTTPConnectionPool(XXXXXX): Max retries exceeded\n            time.sleep(0.25)\n\n    for old_sourcebyinstitution in old_sourcebyinstitutions:\n        if old_sourcebyinstitution not in current_sourcebyinstitutions:\n            message = \"Die %s ist nicht laenger f\u00fcr die SID %s angesigelt.\" % (institution, source)\n            send_message(message)", "commit_link": "github.com/miku/siskin/commit/7fa398d2fea72bf2e8b4808f75df4b3d35ae959a", "file_name": "bin/solrcheckup.py", "vul_type": "cwe-089", "description": "Write a Python function to log current source and title data from Solr into a database, handling new and old entries."}
{"func_name": "readContigTilesIntoBuffer", "func_src_before": "static int readContigTilesIntoBuffer (TIFF* in, uint8* buf, \n                                      uint32 imagelength, \n                                      uint32 imagewidth, \n                                      uint32 tw, uint32 tl,\n                                      tsample_t spp, uint16 bps)\n  {\n  int status = 1;\n  tsample_t sample = 0;\n  tsample_t count = spp; \n  uint32 row, col, trow;\n  uint32 nrow, ncol;\n  uint32 dst_rowsize, shift_width;\n  uint32 bytes_per_sample, bytes_per_pixel;\n  uint32 trailing_bits, prev_trailing_bits;\n  uint32 tile_rowsize  = TIFFTileRowSize(in);\n  uint32 src_offset, dst_offset;\n  uint32 row_offset, col_offset;\n  uint8 *bufp = (uint8*) buf;\n  unsigned char *src = NULL;\n  unsigned char *dst = NULL;\n  tsize_t tbytes = 0, tile_buffsize = 0;\n  tsize_t tilesize = TIFFTileSize(in);\n  unsigned char *tilebuf = NULL;\n\n  bytes_per_sample = (bps + 7) / 8; \n  bytes_per_pixel  = ((bps * spp) + 7) / 8;\n\n  if ((bps % 8) == 0)\n    shift_width = 0;\n  else\n    {\n    if (bytes_per_pixel < (bytes_per_sample + 1))\n      shift_width = bytes_per_pixel;\n    else\n      shift_width = bytes_per_sample + 1;\n    }\n\n  tile_buffsize = tilesize;\n  if (tilesize == 0 || tile_rowsize == 0)\n  {\n     TIFFError(\"readContigTilesIntoBuffer\", \"Tile size or tile rowsize is zero\");\n     exit(-1);\n  }\n\n  if (tilesize < (tsize_t)(tl * tile_rowsize))\n    {\n#ifdef DEBUG2\n    TIFFError(\"readContigTilesIntoBuffer\",\n\t      \"Tilesize %lu is too small, using alternate calculation %u\",\n              tilesize, tl * tile_rowsize);\n#endif\n    tile_buffsize = tl * tile_rowsize;\n    if (tl != (tile_buffsize / tile_rowsize))\n    {\n    \tTIFFError(\"readContigTilesIntoBuffer\", \"Integer overflow when calculating buffer size.\");\n        exit(-1);\n    }\n    }\n\n  tilebuf = _TIFFmalloc(tile_buffsize);\n  if (tilebuf == 0)\n    return 0;\n\n  dst_rowsize = ((imagewidth * bps * spp) + 7) / 8;  \n  for (row = 0; row < imagelength; row += tl)\n    {\n    nrow = (row + tl > imagelength) ? imagelength - row : tl;\n    for (col = 0; col < imagewidth; col += tw)\n      {\n      tbytes = TIFFReadTile(in, tilebuf, col, row, 0, 0);\n      if (tbytes < tilesize  && !ignore)\n        {\n\tTIFFError(TIFFFileName(in),\n\t\t  \"Error, can't read tile at row %lu col %lu, Read %lu bytes of %lu\",\n\t\t  (unsigned long) col, (unsigned long) row, (unsigned long)tbytes,\n                  (unsigned long)tilesize);\n\t\t  status = 0;\n                  _TIFFfree(tilebuf);\n\t\t  return status;\n\t}\n      \n      row_offset = row * dst_rowsize;\n      col_offset = ((col * bps * spp) + 7)/ 8;\n      bufp = buf + row_offset + col_offset;\n\n      if (col + tw > imagewidth)\n\tncol = imagewidth - col;\n      else\n        ncol = tw;\n\n      /* Each tile scanline will start on a byte boundary but it\n       * has to be merged into the scanline for the entire\n       * image buffer and the previous segment may not have\n       * ended on a byte boundary\n       */\n      /* Optimization for common bit depths, all samples */\n      if (((bps % 8) == 0) && (count == spp))\n        {\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n\t  _TIFFmemcpy (bufp, tilebuf + src_offset, (ncol * spp * bps) / 8);\n          bufp += (imagewidth * bps * spp) / 8;\n\t  }\n        }\n      else\n        {\n\t/* Bit depths not a multiple of 8 and/or extract fewer than spp samples */\n        prev_trailing_bits = trailing_bits = 0;\n        trailing_bits = (ncol * bps * spp) % 8;\n\n\t/*\tfor (trow = 0; tl < nrow; trow++) */\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n          src = tilebuf + src_offset;\n\t  dst_offset = (row + trow) * dst_rowsize;\n          dst = buf + dst_offset + col_offset;\n          switch (shift_width)\n            {\n            case 0: if (extractContigSamplesBytes (src, dst, ncol, sample,\n                                                   spp, bps, count, 0, ncol))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t\trow, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 1: if (bps == 1)\n                      { \n                      if (extractContigSamplesShifted8bits (src, dst, ncol,\n                                                            sample, spp,\n                                                            bps, count,\n                                                            0, ncol,\n                                                            prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t\t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t\t      break;\n\t\t      }\n                    else\n                      if (extractContigSamplesShifted16bits (src, dst, ncol,\n                                                             sample, spp,\n                                                             bps, count,\n                                                             0, ncol,\n                                                             prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t  \t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t            break;\n            case 2: if (extractContigSamplesShifted24bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t  \t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 3:\n            case 4:\n            case 5: if (extractContigSamplesShifted32bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            default: TIFFError(\"readContigTilesIntoBuffer\", \"Unsupported bit depth %d\", bps);\n\t\t     return 1;\n\t    }\n          }\n        prev_trailing_bits += trailing_bits;\n        /* if (prev_trailing_bits > 7) */\n\t/*   prev_trailing_bits-= 8; */\n\t}\n      }\n    }\n\n  _TIFFfree(tilebuf);\n  return status;\n  }", "func_src_after": "static int readContigTilesIntoBuffer (TIFF* in, uint8* buf, \n                                      uint32 imagelength, \n                                      uint32 imagewidth, \n                                      uint32 tw, uint32 tl,\n                                      tsample_t spp, uint16 bps)\n  {\n  int status = 1;\n  tsample_t sample = 0;\n  tsample_t count = spp; \n  uint32 row, col, trow;\n  uint32 nrow, ncol;\n  uint32 dst_rowsize, shift_width;\n  uint32 bytes_per_sample, bytes_per_pixel;\n  uint32 trailing_bits, prev_trailing_bits;\n  uint32 tile_rowsize  = TIFFTileRowSize(in);\n  uint32 src_offset, dst_offset;\n  uint32 row_offset, col_offset;\n  uint8 *bufp = (uint8*) buf;\n  unsigned char *src = NULL;\n  unsigned char *dst = NULL;\n  tsize_t tbytes = 0, tile_buffsize = 0;\n  tsize_t tilesize = TIFFTileSize(in);\n  unsigned char *tilebuf = NULL;\n\n  bytes_per_sample = (bps + 7) / 8; \n  bytes_per_pixel  = ((bps * spp) + 7) / 8;\n\n  if ((bps % 8) == 0)\n    shift_width = 0;\n  else\n    {\n    if (bytes_per_pixel < (bytes_per_sample + 1))\n      shift_width = bytes_per_pixel;\n    else\n      shift_width = bytes_per_sample + 1;\n    }\n\n  tile_buffsize = tilesize;\n  if (tilesize == 0 || tile_rowsize == 0)\n  {\n     TIFFError(\"readContigTilesIntoBuffer\", \"Tile size or tile rowsize is zero\");\n     exit(-1);\n  }\n\n  if (tilesize < (tsize_t)(tl * tile_rowsize))\n    {\n#ifdef DEBUG2\n    TIFFError(\"readContigTilesIntoBuffer\",\n\t      \"Tilesize %lu is too small, using alternate calculation %u\",\n              tilesize, tl * tile_rowsize);\n#endif\n    tile_buffsize = tl * tile_rowsize;\n    if (tl != (tile_buffsize / tile_rowsize))\n    {\n    \tTIFFError(\"readContigTilesIntoBuffer\", \"Integer overflow when calculating buffer size.\");\n        exit(-1);\n    }\n    }\n\n  /* Add 3 padding bytes for extractContigSamplesShifted32bits */\n  if( tile_buffsize > 0xFFFFFFFFU - 3 )\n  {\n      TIFFError(\"readContigTilesIntoBuffer\", \"Integer overflow when calculating buffer size.\");\n      exit(-1);\n  }\n  tilebuf = _TIFFmalloc(tile_buffsize + 3);\n  if (tilebuf == 0)\n    return 0;\n  tilebuf[tile_buffsize] = 0;\n  tilebuf[tile_buffsize+1] = 0;\n  tilebuf[tile_buffsize+2] = 0;\n\n  dst_rowsize = ((imagewidth * bps * spp) + 7) / 8;  \n  for (row = 0; row < imagelength; row += tl)\n    {\n    nrow = (row + tl > imagelength) ? imagelength - row : tl;\n    for (col = 0; col < imagewidth; col += tw)\n      {\n      tbytes = TIFFReadTile(in, tilebuf, col, row, 0, 0);\n      if (tbytes < tilesize  && !ignore)\n        {\n\tTIFFError(TIFFFileName(in),\n\t\t  \"Error, can't read tile at row %lu col %lu, Read %lu bytes of %lu\",\n\t\t  (unsigned long) col, (unsigned long) row, (unsigned long)tbytes,\n                  (unsigned long)tilesize);\n\t\t  status = 0;\n                  _TIFFfree(tilebuf);\n\t\t  return status;\n\t}\n      \n      row_offset = row * dst_rowsize;\n      col_offset = ((col * bps * spp) + 7)/ 8;\n      bufp = buf + row_offset + col_offset;\n\n      if (col + tw > imagewidth)\n\tncol = imagewidth - col;\n      else\n        ncol = tw;\n\n      /* Each tile scanline will start on a byte boundary but it\n       * has to be merged into the scanline for the entire\n       * image buffer and the previous segment may not have\n       * ended on a byte boundary\n       */\n      /* Optimization for common bit depths, all samples */\n      if (((bps % 8) == 0) && (count == spp))\n        {\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n\t  _TIFFmemcpy (bufp, tilebuf + src_offset, (ncol * spp * bps) / 8);\n          bufp += (imagewidth * bps * spp) / 8;\n\t  }\n        }\n      else\n        {\n\t/* Bit depths not a multiple of 8 and/or extract fewer than spp samples */\n        prev_trailing_bits = trailing_bits = 0;\n        trailing_bits = (ncol * bps * spp) % 8;\n\n\t/*\tfor (trow = 0; tl < nrow; trow++) */\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n          src = tilebuf + src_offset;\n\t  dst_offset = (row + trow) * dst_rowsize;\n          dst = buf + dst_offset + col_offset;\n          switch (shift_width)\n            {\n            case 0: if (extractContigSamplesBytes (src, dst, ncol, sample,\n                                                   spp, bps, count, 0, ncol))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t\trow, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 1: if (bps == 1)\n                      { \n                      if (extractContigSamplesShifted8bits (src, dst, ncol,\n                                                            sample, spp,\n                                                            bps, count,\n                                                            0, ncol,\n                                                            prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t\t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t\t      break;\n\t\t      }\n                    else\n                      if (extractContigSamplesShifted16bits (src, dst, ncol,\n                                                             sample, spp,\n                                                             bps, count,\n                                                             0, ncol,\n                                                             prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t  \t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t            break;\n            case 2: if (extractContigSamplesShifted24bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t  \t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 3:\n            case 4:\n            case 5: if (extractContigSamplesShifted32bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            default: TIFFError(\"readContigTilesIntoBuffer\", \"Unsupported bit depth %d\", bps);\n\t\t     return 1;\n\t    }\n          }\n        prev_trailing_bits += trailing_bits;\n        /* if (prev_trailing_bits > 7) */\n\t/*   prev_trailing_bits-= 8; */\n\t}\n      }\n    }\n\n  _TIFFfree(tilebuf);\n  return status;\n  }", "commit_link": "github.com/vadz/libtiff/commit/ae9365db1b271b62b35ce018eac8799b1d5e8a53", "file_name": "tools/tiffcrop.c", "vul_type": "cwe-125", "description": "Write a C function to read image tiles into a buffer from a TIFF file, handling different bit depths and samples per pixel."}
{"func_name": "HPHP::SimpleParser::handleBackslash", "func_src_before": "  bool handleBackslash(signed char& out) {\n    char ch = *p++;\n    switch (ch) {\n      case 0: return false;\n      case '\"': out = ch; return true;\n      case '\\\\': out = ch; return true;\n      case '/': out = ch; return true;\n      case 'b': out = '\\b'; return true;\n      case 'f': out = '\\f'; return true;\n      case 'n': out = '\\n'; return true;\n      case 'r': out = '\\r'; return true;\n      case 't': out = '\\t'; return true;\n      case 'u': {\n        if (UNLIKELY(is_tsimplejson)) {\n          auto const ch1 = *p++;\n          auto const ch2 = *p++;\n          auto const dch3 = dehexchar(*p++);\n          auto const dch4 = dehexchar(*p++);\n          if (UNLIKELY(ch1 != '0' || ch2 != '0' || dch3 < 0 || dch4 < 0)) {\n            return false;\n          }\n          out = (dch3 << 4) | dch4;\n          return true;\n        } else {\n          uint16_t u16cp = 0;\n          for (int i = 0; i < 4; i++) {\n            auto const hexv = dehexchar(*p++);\n            if (hexv < 0) return false; // includes check for end of string\n            u16cp <<= 4;\n            u16cp |= hexv;\n          }\n          if (u16cp > 0x7f) {\n            return false;\n          } else {\n            out = u16cp;\n            return true;\n          }\n        }\n      }\n      default: return false;\n    }\n  }", "func_src_after": "  bool handleBackslash(signed char& out) {\n    char ch = *p++;\n    switch (ch) {\n      case 0: return false;\n      case '\"': out = ch; return true;\n      case '\\\\': out = ch; return true;\n      case '/': out = ch; return true;\n      case 'b': out = '\\b'; return true;\n      case 'f': out = '\\f'; return true;\n      case 'n': out = '\\n'; return true;\n      case 'r': out = '\\r'; return true;\n      case 't': out = '\\t'; return true;\n      case 'u': {\n        if (UNLIKELY(is_tsimplejson)) {\n          auto const ch1 = *p++;\n          if (UNLIKELY(ch1 != '0')) return false;\n          auto const ch2 = *p++;\n          if (UNLIKELY(ch2 != '0')) return false;\n          auto const dch3 = dehexchar(*p++);\n          if (UNLIKELY(dch3 < 0)) return false;\n          auto const dch4 = dehexchar(*p++);\n          if (UNLIKELY(dch4 < 0)) return false;\n          out = (dch3 << 4) | dch4;\n          return true;\n        } else {\n          uint16_t u16cp = 0;\n          for (int i = 0; i < 4; i++) {\n            auto const hexv = dehexchar(*p++);\n            if (hexv < 0) return false; // includes check for end of string\n            u16cp <<= 4;\n            u16cp |= hexv;\n          }\n          if (u16cp > 0x7f) {\n            return false;\n          } else {\n            out = u16cp;\n            return true;\n          }\n        }\n      }\n      default: return false;\n    }\n  }", "commit_link": "github.com/facebook/hhvm/commit/b3679121bb3c7017ff04b4c08402ffff5cf59b13", "file_name": "hphp/runtime/ext/json/JSON_parser.cpp", "vul_type": "cwe-125", "description": "Write a C++ function to process escape sequences in a JSON string and convert them to their corresponding characters."}
{"func_name": "set", "func_src_before": "    def set(self, key, value, replace=False):\n        path = self._absolute_key(key)\n        try:\n            self.etcd.write(path, value, prevExist=replace)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "func_src_after": "    def set(self, key, value, replace=False):\n        path = os.path.join(self.namespace, key)\n        try:\n            self.etcd.write(path, value, prevExist=replace)\n        except etcd.EtcdAlreadyExist as err:\n            raise CSStoreExists(str(err))\n        except etcd.EtcdException as err:\n            log_error(\"Error storing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to store key')", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `set` that stores a key-value pair in etcd, with an option to replace the existing key, and handles specific etcd exceptions."}
{"func_name": "cut", "func_src_before": "    def cut(self, key):\n        try:\n            self.etcd.delete(self._absolute_key(key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "func_src_after": "    def cut(self, key):\n        try:\n            self.etcd.delete(os.path.join(self.namespace, key))\n        except etcd.EtcdKeyNotFound:\n            return False\n        except etcd.EtcdException as err:\n            log_error(\"Error removing key %s: [%r]\" % (key, repr(err)))\n            raise CSStoreError('Error occurred while trying to cut key')\n        return True", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function named `cut` that deletes a key from an etcd store and handles exceptions."}
{"func_name": "add_user", "func_src_before": "def add_user(username, password):\n    encPass = crypt.crypt(password,\"22\")\n    #subprocess escapes the username stopping code injection\n    subprocess.call(['useradd','-G','docker,wheel','-p',encPass,username])", "func_src_after": "def add_user(username, password):\n    encPass = crypt.crypt(password,\"22\")\n    os.system(\"useradd -G docker,wheel -p \"+encPass+\" \"+username)", "commit_link": "github.com/Internet-of-People/titania-os/commit/9b7805119938343fcac9dc929d8882f1d97cf14a", "file_name": "vuedj/configtitania/views.py", "vul_type": "cwe-078", "description": "Write a Python function named `add_user` that creates a new system user with a password and adds them to the 'docker' and 'wheel' groups."}
{"func_name": "fetch_data", "func_src_before": "    def fetch_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            data = res.dictresult()[0]['data']\n        except IndexError:\n            raise ObjectDoesNotExistException(id)\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000\\\\001', nonTextToken)\n        ndata = ndata.replace('\\\\012', '\\n')\n        return ndata", "func_src_after": "    def fetch_data(self, session, id):\n        self._openContainer(session)\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            data = res.dictresult()[0]['data']\n        except IndexError:\n            raise ObjectDoesNotExistException(id)\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000\\\\001', nonTextToken)\n        ndata = ndata.replace('\\\\012', '\\n')\n        return ndata", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/postgresStore.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve and process data from a database using an ID, handling normalization and special character conversion."}
{"func_name": "add_month_data_row", "func_src_before": "    def add_month_data_row(self, inverter_serial, ts, etoday, etotal):\n\n        y = datetime.fromtimestamp(ts) - timedelta(days=1)\n        y_ts = int(datetime(y.year, y.month, y.day, 23, tzinfo=pytz.utc).timestamp())\n\n        query = '''\n            INSERT INTO MonthData (\n                TimeStamp,\n                Serial,\n                DayYield,\n                TotalYield                                 \n            ) VALUES (\n                ?,\n                ?,\n                ?,\n                ?\n            );\n        '''\n        self.c.execute(query, (y_ts, inverter_serial, etoday, etotal))", "func_src_after": "    def add_month_data_row(self, inverter_serial, ts, etoday, etotal):\n\n        y = datetime.fromtimestamp(ts) - timedelta(days=1)\n        y_ts = int(datetime(y.year, y.month, y.day, 23, tzinfo=pytz.utc).timestamp())\n\n        query = '''\n            INSERT INTO MonthData (\n                TimeStamp,\n                Serial,\n                DayYield,\n                TotalYield                                 \n            ) VALUES (\n                %s,\n                %s,\n                %s,\n                %s\n            );\n        ''' % (y_ts, inverter_serial, etoday, etotal)\n        self.c.execute(query)", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new row with inverter data into a database, adjusting the timestamp to the end of the previous day."}
{"func_name": "vips_foreign_load_gif_scan_image", "func_src_before": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\tColorMapObject *map = file->Image.ColorMap ?\n\t\tfile->Image.ColorMap : file->SColorMap;\n\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "func_src_after": "vips_foreign_load_gif_scan_image( VipsForeignLoadGif *gif ) \n{\n\tVipsObjectClass *class = VIPS_OBJECT_GET_CLASS( gif );\n\tGifFileType *file = gif->file;\n\n\tColorMapObject *map;\n\tGifByteType *extension;\n\n\tif( DGifGetImageDesc( gif->file ) == GIF_ERROR ) {\n\t\tvips_foreign_load_gif_error( gif ); \n\t\treturn( -1 );\n\t}\n\n\t/* Check that the frame looks sane. Perhaps giflib checks\n\t * this for us.\n\t */\n\tif( file->Image.Left < 0 ||\n\t\tfile->Image.Width < 1 ||\n\t\tfile->Image.Width > 10000 ||\n\t\tfile->Image.Left + file->Image.Width > file->SWidth ||\n\t\tfile->Image.Top < 0 ||\n\t\tfile->Image.Height < 1 ||\n\t\tfile->Image.Height > 10000 ||\n\t\tfile->Image.Top + file->Image.Height > file->SHeight ) {\n\t\tvips_error( class->nickname, \"%s\", _( \"bad frame size\" ) ); \n\t\treturn( -1 ); \n\t}\n\n\t/* Test for a non-greyscale colourmap for this frame.\n\t */\n\tmap = file->Image.ColorMap ? file->Image.ColorMap : file->SColorMap;\n\tif( !gif->has_colour &&\n\t\tmap ) {\n\t\tint i;\n\n\t\tfor( i = 0; i < map->ColorCount; i++ ) \n\t\t\tif( map->Colors[i].Red != map->Colors[i].Green ||\n\t\t\t\tmap->Colors[i].Green != map->Colors[i].Blue ) {\n\t\t\t\tgif->has_colour = TRUE;\n\t\t\t\tbreak;\n\t\t\t}\n\t}\n\n\t/* Step over compressed image data.\n\t */\n\tdo {\n\t\tif( vips_foreign_load_gif_code_next( gif, &extension ) ) \n\t\t\treturn( -1 );\n\t} while( extension != NULL );\n\n\treturn( 0 );\n}", "commit_link": "github.com/libvips/libvips/commit/ce684dd008532ea0bf9d4a1d89bacb35f4a83f4d", "file_name": "libvips/foreign/gifload.c", "vul_type": "cwe-416", "description": "Write a C function to scan and validate a GIF image frame for the Vips image processing library."}
{"func_name": "TraceBezier", "func_src_before": "static MagickBooleanType TraceBezier(MVGInfo *mvg_info,\n  const size_t number_coordinates)\n{\n  double\n    alpha,\n    *coefficients,\n    weight;\n\n  PointInfo\n    end,\n    point,\n    *points;\n\n  PrimitiveInfo\n    *primitive_info;\n\n  register PrimitiveInfo\n    *p;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    control_points,\n    quantum;\n\n  /*\n    Allocate coefficients.\n  */\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=number_coordinates;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n  {\n    for (j=i+1; j < (ssize_t) number_coordinates; j++)\n    {\n      alpha=fabs(primitive_info[j].point.x-primitive_info[i].point.x);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n      alpha=fabs(primitive_info[j].point.y-primitive_info[i].point.y);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n    }\n  }\n  quantum=MagickMin(quantum/number_coordinates,BezierQuantum);\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  coefficients=(double *) AcquireQuantumMemory(number_coordinates,\n    sizeof(*coefficients));\n  points=(PointInfo *) AcquireQuantumMemory(quantum,number_coordinates*\n    sizeof(*points));\n  if ((coefficients == (double *) NULL) || (points == (PointInfo *) NULL))\n    {\n      if (points != (PointInfo *) NULL)\n        points=(PointInfo *) RelinquishMagickMemory(points);\n      if (coefficients != (double *) NULL)\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n      (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n        ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n      return(MagickFalse);\n    }\n  control_points=quantum*number_coordinates;\n  if (CheckPrimitiveExtent(mvg_info,control_points+1) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  /*\n    Compute bezier points.\n  */\n  end=primitive_info[number_coordinates-1].point;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n    coefficients[i]=Permutate((ssize_t) number_coordinates-1,i);\n  weight=0.0;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    p=primitive_info;\n    point.x=0.0;\n    point.y=0.0;\n    alpha=pow((double) (1.0-weight),(double) number_coordinates-1.0);\n    for (j=0; j < (ssize_t) number_coordinates; j++)\n    {\n      point.x+=alpha*coefficients[j]*p->point.x;\n      point.y+=alpha*coefficients[j]*p->point.y;\n      alpha*=weight/(1.0-weight);\n      p++;\n    }\n    points[i]=point;\n    weight+=1.0/control_points;\n  }\n  /*\n    Bezier curves are just short segmented polys.\n  */\n  p=primitive_info;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    if (TracePoint(p,points[i]) == MagickFalse)\n      {\n        points=(PointInfo *) RelinquishMagickMemory(points);\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n        return(MagickFalse);\n      }\n    p+=p->coordinates;\n  }\n  if (TracePoint(p,end) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  p+=p->coordinates;\n  primitive_info->coordinates=(size_t) (p-primitive_info);\n  primitive_info->closed_subpath=MagickFalse;\n  for (i=0; i < (ssize_t) primitive_info->coordinates; i++)\n  {\n    p->primitive=primitive_info->primitive;\n    p--;\n  }\n  points=(PointInfo *) RelinquishMagickMemory(points);\n  coefficients=(double *) RelinquishMagickMemory(coefficients);\n  return(MagickTrue);\n}", "func_src_after": "static MagickBooleanType TraceBezier(MVGInfo *mvg_info,\n  const size_t number_coordinates)\n{\n  double\n    alpha,\n    *coefficients,\n    weight;\n\n  PointInfo\n    end,\n    point,\n    *points;\n\n  PrimitiveInfo\n    *primitive_info;\n\n  register PrimitiveInfo\n    *p;\n\n  register ssize_t\n    i,\n    j;\n\n  size_t\n    control_points,\n    quantum;\n\n  /*\n    Allocate coefficients.\n  */\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=number_coordinates;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n  {\n    for (j=i+1; j < (ssize_t) number_coordinates; j++)\n    {\n      alpha=fabs(primitive_info[j].point.x-primitive_info[i].point.x);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n      alpha=fabs(primitive_info[j].point.y-primitive_info[i].point.y);\n      if (alpha > (double) SSIZE_MAX)\n        {\n          (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n            ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n          return(MagickFalse);\n        }\n      if (alpha > (double) quantum)\n        quantum=(size_t) alpha;\n    }\n  }\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  quantum=MagickMin(quantum/number_coordinates,BezierQuantum);\n  coefficients=(double *) AcquireQuantumMemory(number_coordinates,\n    sizeof(*coefficients));\n  points=(PointInfo *) AcquireQuantumMemory(quantum,number_coordinates*\n    sizeof(*points));\n  if ((coefficients == (double *) NULL) || (points == (PointInfo *) NULL))\n    {\n      if (points != (PointInfo *) NULL)\n        points=(PointInfo *) RelinquishMagickMemory(points);\n      if (coefficients != (double *) NULL)\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n      (void) ThrowMagickException(mvg_info->exception,GetMagickModule(),\n        ResourceLimitError,\"MemoryAllocationFailed\",\"`%s'\",\"\");\n      return(MagickFalse);\n    }\n  control_points=quantum*number_coordinates;\n  if (CheckPrimitiveExtent(mvg_info,control_points+1) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  primitive_info=(*mvg_info->primitive_info)+mvg_info->offset;\n  /*\n    Compute bezier points.\n  */\n  end=primitive_info[number_coordinates-1].point;\n  for (i=0; i < (ssize_t) number_coordinates; i++)\n    coefficients[i]=Permutate((ssize_t) number_coordinates-1,i);\n  weight=0.0;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    p=primitive_info;\n    point.x=0.0;\n    point.y=0.0;\n    alpha=pow((double) (1.0-weight),(double) number_coordinates-1.0);\n    for (j=0; j < (ssize_t) number_coordinates; j++)\n    {\n      point.x+=alpha*coefficients[j]*p->point.x;\n      point.y+=alpha*coefficients[j]*p->point.y;\n      alpha*=weight/(1.0-weight);\n      p++;\n    }\n    points[i]=point;\n    weight+=1.0/control_points;\n  }\n  /*\n    Bezier curves are just short segmented polys.\n  */\n  p=primitive_info;\n  for (i=0; i < (ssize_t) control_points; i++)\n  {\n    if (TracePoint(p,points[i]) == MagickFalse)\n      {\n        points=(PointInfo *) RelinquishMagickMemory(points);\n        coefficients=(double *) RelinquishMagickMemory(coefficients);\n        return(MagickFalse);\n      }\n    p+=p->coordinates;\n  }\n  if (TracePoint(p,end) == MagickFalse)\n    {\n      points=(PointInfo *) RelinquishMagickMemory(points);\n      coefficients=(double *) RelinquishMagickMemory(coefficients);\n      return(MagickFalse);\n    }\n  p+=p->coordinates;\n  primitive_info->coordinates=(size_t) (p-primitive_info);\n  primitive_info->closed_subpath=MagickFalse;\n  for (i=0; i < (ssize_t) primitive_info->coordinates; i++)\n  {\n    p->primitive=primitive_info->primitive;\n    p--;\n  }\n  points=(PointInfo *) RelinquishMagickMemory(points);\n  coefficients=(double *) RelinquishMagickMemory(coefficients);\n  return(MagickTrue);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ecf7c6b288e11e7e7f75387c5e9e93e423b98397", "file_name": "MagickCore/draw.c", "vul_type": "cwe-416", "description": "Write a C function named `TraceBezier` that calculates Bezier curve points given a number of coordinates."}
{"func_name": "index", "func_src_before": "def index(request, is_mobile=False):\n  hue_collections = DashboardController(request.user).get_search_collections()\n  collection_id = request.GET.get('collection')\n\n  if not hue_collections or not collection_id:\n    return admin_collections(request, True, is_mobile)\n\n  try:\n    collection_doc = Document2.objects.get(id=collection_id)\n    if USE_NEW_EDITOR.get():\n      collection_doc.can_read_or_exception(request.user)\n    else:\n      collection_doc.doc.get().can_read_or_exception(request.user)\n    collection = Collection2(request.user, document=collection_doc)\n  except Exception, e:\n    raise PopupException(e, title=_(\"Dashboard does not exist or you don't have the permission to access it.\"))\n\n  query = {'qs': [{'q': ''}], 'fqs': [], 'start': 0}\n\n  if request.method == 'GET':\n    if 'q' in request.GET:\n      query['qs'][0]['q'] = request.GET.get('q')\n    if 'qd' in request.GET:\n      query['qd'] = request.GET.get('qd')\n\n  template = 'search.mako'\n  if is_mobile:\n    template = 'search_m.mako'\n\n  return render(template, request, {\n    'collection': collection,\n    'query': json.dumps(query),\n    'initial': json.dumps({\n        'collections': [],\n        'layout': DEFAULT_LAYOUT,\n        'is_latest': LATEST.get(),\n        'engines': get_engines(request.user)\n    }),\n    'is_owner': collection_doc.doc.get().can_write(request.user),\n    'can_edit_index': can_edit_index(request.user),\n    'is_embeddable': request.GET.get('is_embeddable', False),\n    'mobile': is_mobile,\n  })", "func_src_after": "def index(request, is_mobile=False):\n  hue_collections = DashboardController(request.user).get_search_collections()\n  collection_id = request.GET.get('collection')\n\n  if not hue_collections or not collection_id:\n    return admin_collections(request, True, is_mobile)\n\n  try:\n    collection_doc = Document2.objects.get(id=collection_id)\n    if USE_NEW_EDITOR.get():\n      collection_doc.can_read_or_exception(request.user)\n    else:\n      collection_doc.doc.get().can_read_or_exception(request.user)\n    collection = Collection2(request.user, document=collection_doc)\n  except Exception, e:\n    raise PopupException(e, title=_(\"Dashboard does not exist or you don't have the permission to access it.\"))\n\n  query = {'qs': [{'q': ''}], 'fqs': [], 'start': 0}\n\n  if request.method == 'GET':\n    if 'q' in request.GET:\n      query['qs'][0]['q'] = antixss(request.GET.get('q', ''))\n    if 'qd' in request.GET:\n      query['qd'] = antixss(request.GET.get('qd', ''))\n\n  template = 'search.mako'\n  if is_mobile:\n    template = 'search_m.mako'\n\n  return render(template, request, {\n    'collection': collection,\n    'query': json.dumps(query),\n    'initial': json.dumps({\n        'collections': [],\n        'layout': DEFAULT_LAYOUT,\n        'is_latest': LATEST.get(),\n        'engines': get_engines(request.user)\n    }),\n    'is_owner': collection_doc.can_write(request.user) if USE_NEW_EDITOR.get() else collection_doc.doc.get().can_write(request.user),\n    'can_edit_index': can_edit_index(request.user),\n    'is_embeddable': request.GET.get('is_embeddable', False),\n    'mobile': is_mobile,\n  })", "commit_link": "github.com/gethue/hue/commit/37b529b1f9aeb5d746599a9ed4e2288cf3ad3e1d", "file_name": "desktop/libs/dashboard/src/dashboard/views.py", "vul_type": "cwe-079", "description": "Write a Python function named `index` that handles a web request, performs user authorization, and renders a search dashboard template with dynamic content based on query parameters."}
{"func_name": "ReadVIFFImage", "func_src_before": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(max_packets,\n      bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadVIFFImage(const ImageInfo *image_info,\n  ExceptionInfo *exception)\n{\n#define VFF_CM_genericRGB  15\n#define VFF_CM_ntscRGB  1\n#define VFF_CM_NONE  0\n#define VFF_DEP_DECORDER  0x4\n#define VFF_DEP_NSORDER  0x8\n#define VFF_DES_RAW  0\n#define VFF_LOC_IMPLICIT  1\n#define VFF_MAPTYP_NONE  0\n#define VFF_MAPTYP_1_BYTE  1\n#define VFF_MAPTYP_2_BYTE  2\n#define VFF_MAPTYP_4_BYTE  4\n#define VFF_MAPTYP_FLOAT  5\n#define VFF_MAPTYP_DOUBLE  7\n#define VFF_MS_NONE  0\n#define VFF_MS_ONEPERBAND  1\n#define VFF_MS_SHARED  3\n#define VFF_TYP_BIT  0\n#define VFF_TYP_1_BYTE  1\n#define VFF_TYP_2_BYTE  2\n#define VFF_TYP_4_BYTE  4\n#define VFF_TYP_FLOAT  5\n#define VFF_TYP_DOUBLE  9\n\n  typedef struct _ViffInfo\n  {\n    unsigned char\n      identifier,\n      file_type,\n      release,\n      version,\n      machine_dependency,\n      reserve[3];\n\n    char\n      comment[512];\n\n    unsigned int\n      rows,\n      columns,\n      subrows;\n\n    int\n      x_offset,\n      y_offset;\n\n    float\n      x_bits_per_pixel,\n      y_bits_per_pixel;\n\n    unsigned int\n      location_type,\n      location_dimension,\n      number_of_images,\n      number_data_bands,\n      data_storage_type,\n      data_encode_scheme,\n      map_scheme,\n      map_storage_type,\n      map_rows,\n      map_columns,\n      map_subrows,\n      map_enable,\n      maps_per_cycle,\n      color_space_model;\n  } ViffInfo;\n\n  double\n    min_value,\n    scale_factor,\n    value;\n\n  Image\n    *image;\n\n  int\n    bit;\n\n  MagickBooleanType\n    status;\n\n  MagickSizeType\n    number_pixels;\n\n  register IndexPacket\n    *indexes;\n\n  register ssize_t\n    x;\n\n  register PixelPacket\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bytes_per_pixel,\n    max_packets,\n    quantum;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    *pixels;\n\n  unsigned long\n    lsb_first;\n\n  ViffInfo\n    viff_info;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickSignature);\n  image=AcquireImage(image_info);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    {\n      image=DestroyImageList(image);\n      return((Image *) NULL);\n    }\n  /*\n    Read VIFF header (1024 bytes).\n  */\n  count=ReadBlob(image,1,&viff_info.identifier);\n  do\n  {\n    /*\n      Verify VIFF identifier.\n    */\n    if ((count != 1) || ((unsigned char) viff_info.identifier != 0xab))\n      ThrowReaderException(CorruptImageError,\"NotAVIFFImage\");\n    /*\n      Initialize VIFF image.\n    */\n    (void) ReadBlob(image,sizeof(viff_info.file_type),&viff_info.file_type);\n    (void) ReadBlob(image,sizeof(viff_info.release),&viff_info.release);\n    (void) ReadBlob(image,sizeof(viff_info.version),&viff_info.version);\n    (void) ReadBlob(image,sizeof(viff_info.machine_dependency),\n      &viff_info.machine_dependency);\n    (void) ReadBlob(image,sizeof(viff_info.reserve),viff_info.reserve);\n    (void) ReadBlob(image,512,(unsigned char *) viff_info.comment);\n    viff_info.comment[511]='\\0';\n    if (strlen(viff_info.comment) > 4)\n      (void) SetImageProperty(image,\"comment\",viff_info.comment);\n    if ((viff_info.machine_dependency == VFF_DEP_DECORDER) ||\n        (viff_info.machine_dependency == VFF_DEP_NSORDER))\n      image->endian=LSBEndian;\n    else\n      image->endian=MSBEndian;\n    viff_info.rows=ReadBlobLong(image);\n    viff_info.columns=ReadBlobLong(image);\n    viff_info.subrows=ReadBlobLong(image);\n    viff_info.x_offset=(int) ReadBlobLong(image);\n    viff_info.y_offset=(int) ReadBlobLong(image);\n    viff_info.x_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.y_bits_per_pixel=(float) ReadBlobLong(image);\n    viff_info.location_type=ReadBlobLong(image);\n    viff_info.location_dimension=ReadBlobLong(image);\n    viff_info.number_of_images=ReadBlobLong(image);\n    viff_info.number_data_bands=ReadBlobLong(image);\n    viff_info.data_storage_type=ReadBlobLong(image);\n    viff_info.data_encode_scheme=ReadBlobLong(image);\n    viff_info.map_scheme=ReadBlobLong(image);\n    viff_info.map_storage_type=ReadBlobLong(image);\n    viff_info.map_rows=ReadBlobLong(image);\n    viff_info.map_columns=ReadBlobLong(image);\n    viff_info.map_subrows=ReadBlobLong(image);\n    viff_info.map_enable=ReadBlobLong(image);\n    viff_info.maps_per_cycle=ReadBlobLong(image);\n    viff_info.color_space_model=ReadBlobLong(image);\n    for (i=0; i < 420; i++)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      ThrowReaderException(CorruptImageError,\"UnexpectedEndOfFile\");\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    image->depth=viff_info.x_bits_per_pixel <= 8 ? 8UL :\n      MAGICKCORE_QUANTUM_DEPTH;\n    /*\n      Verify that we can read this VIFF image.\n    */\n    number_pixels=(MagickSizeType) viff_info.columns*viff_info.rows;\n    if (number_pixels != (size_t) number_pixels)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    if (number_pixels == 0)\n      ThrowReaderException(CoderError,\"ImageColumnOrRowSizeIsNotSupported\");\n    if ((viff_info.number_data_bands < 1) || (viff_info.number_data_bands > 4))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if ((viff_info.data_storage_type != VFF_TYP_BIT) &&\n        (viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_2_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_4_BYTE) &&\n        (viff_info.data_storage_type != VFF_TYP_FLOAT) &&\n        (viff_info.data_storage_type != VFF_TYP_DOUBLE))\n      ThrowReaderException(CoderError,\"DataStorageTypeIsNotSupported\");\n    if (viff_info.data_encode_scheme != VFF_DES_RAW)\n      ThrowReaderException(CoderError,\"DataEncodingSchemeIsNotSupported\");\n    if ((viff_info.map_storage_type != VFF_MAPTYP_NONE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_1_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_2_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_4_BYTE) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_FLOAT) &&\n        (viff_info.map_storage_type != VFF_MAPTYP_DOUBLE))\n      ThrowReaderException(CoderError,\"MapStorageTypeIsNotSupported\");\n    if ((viff_info.color_space_model != VFF_CM_NONE) &&\n        (viff_info.color_space_model != VFF_CM_ntscRGB) &&\n        (viff_info.color_space_model != VFF_CM_genericRGB))\n      ThrowReaderException(CoderError,\"ColorspaceModelIsNotSupported\");\n    if (viff_info.location_type != VFF_LOC_IMPLICIT)\n      ThrowReaderException(CoderError,\"LocationTypeIsNotSupported\");\n    if (viff_info.number_of_images != 1)\n      ThrowReaderException(CoderError,\"NumberOfImagesIsNotSupported\");\n    if (viff_info.map_rows == 0)\n      viff_info.map_scheme=VFF_MS_NONE;\n    switch ((int) viff_info.map_scheme)\n    {\n      case VFF_MS_NONE:\n      {\n        if (viff_info.number_data_bands < 3)\n          {\n            /*\n              Create linear color ramp.\n            */\n            if (viff_info.data_storage_type == VFF_TYP_BIT)\n              image->colors=2;\n            else\n              if (viff_info.data_storage_type == VFF_MAPTYP_1_BYTE)\n                image->colors=256UL;\n              else\n                image->colors=image->depth <= 8 ? 256UL : 65536UL;\n            if (AcquireImageColormap(image,image->colors) == MagickFalse)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n          }\n        break;\n      }\n      case VFF_MS_ONEPERBAND:\n      case VFF_MS_SHARED:\n      {\n        unsigned char\n          *viff_colormap;\n\n        /*\n          Allocate VIFF colormap.\n        */\n        switch ((int) viff_info.map_storage_type)\n        {\n          case VFF_MAPTYP_1_BYTE: bytes_per_pixel=1; break;\n          case VFF_MAPTYP_2_BYTE: bytes_per_pixel=2; break;\n          case VFF_MAPTYP_4_BYTE: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_FLOAT: bytes_per_pixel=4; break;\n          case VFF_MAPTYP_DOUBLE: bytes_per_pixel=8; break;\n          default: bytes_per_pixel=1; break;\n        }\n        image->colors=viff_info.map_columns;\n        if (AcquireImageColormap(image,image->colors) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        if (viff_info.map_rows >\n            (viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap)))\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        viff_colormap=(unsigned char *) AcquireQuantumMemory(image->colors,\n          viff_info.map_rows*bytes_per_pixel*sizeof(*viff_colormap));\n        if (viff_colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        /*\n          Read VIFF raster colormap.\n        */\n        (void) ReadBlob(image,bytes_per_pixel*image->colors*viff_info.map_rows,\n          viff_colormap);\n        lsb_first=1;\n        if (*(char *) &lsb_first &&\n            ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n             (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE:\n            {\n              MSBOrderShort(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            case VFF_MAPTYP_4_BYTE:\n            case VFF_MAPTYP_FLOAT:\n            {\n              MSBOrderLong(viff_colormap,(bytes_per_pixel*image->colors*\n                viff_info.map_rows));\n              break;\n            }\n            default: break;\n          }\n        for (i=0; i < (ssize_t) (viff_info.map_rows*image->colors); i++)\n        {\n          switch ((int) viff_info.map_storage_type)\n          {\n            case VFF_MAPTYP_2_BYTE: value=1.0*((short *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_4_BYTE: value=1.0*((int *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_FLOAT: value=((float *) viff_colormap)[i]; break;\n            case VFF_MAPTYP_DOUBLE: value=((double *) viff_colormap)[i]; break;\n            default: value=1.0*viff_colormap[i]; break;\n          }\n          if (i < (ssize_t) image->colors)\n            {\n              image->colormap[i].red=ScaleCharToQuantum((unsigned char) value);\n              image->colormap[i].green=ScaleCharToQuantum((unsigned char)\n                value);\n              image->colormap[i].blue=ScaleCharToQuantum((unsigned char) value);\n            }\n          else\n            if (i < (ssize_t) (2*image->colors))\n              image->colormap[i % image->colors].green=ScaleCharToQuantum(\n                (unsigned char) value);\n            else\n              if (i < (ssize_t) (3*image->colors))\n                image->colormap[i % image->colors].blue=ScaleCharToQuantum(\n                  (unsigned char) value);\n        }\n        viff_colormap=(unsigned char *) RelinquishMagickMemory(viff_colormap);\n        break;\n      }\n      default:\n        ThrowReaderException(CoderError,\"ColormapTypeNotSupported\");\n    }\n    /*\n      Initialize image structure.\n    */\n    image->matte=viff_info.number_data_bands == 4 ? MagickTrue : MagickFalse;\n    image->storage_class=\n      (viff_info.number_data_bands < 3 ? PseudoClass : DirectClass);\n    image->columns=viff_info.rows;\n    image->rows=viff_info.columns;\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows);\n    if (status == MagickFalse)\n      {\n        InheritException(exception,&image->exception);\n        return(DestroyImageList(image));\n      }\n    /*\n      Allocate VIFF pixels.\n    */\n    switch ((int) viff_info.data_storage_type)\n    {\n      case VFF_TYP_2_BYTE: bytes_per_pixel=2; break;\n      case VFF_TYP_4_BYTE: bytes_per_pixel=4; break;\n      case VFF_TYP_FLOAT: bytes_per_pixel=4; break;\n      case VFF_TYP_DOUBLE: bytes_per_pixel=8; break;\n      default: bytes_per_pixel=1; break;\n    }\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      max_packets=((image->columns+7UL) >> 3UL)*image->rows;\n    else\n      max_packets=(size_t) (number_pixels*viff_info.number_data_bands);\n    pixels=(unsigned char *) AcquireQuantumMemory(MagickMax(number_pixels,\n      max_packets),bytes_per_pixel*sizeof(*pixels));\n    if (pixels == (unsigned char *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    (void) ReadBlob(image,bytes_per_pixel*max_packets,pixels);\n    lsb_first=1;\n    if (*(char *) &lsb_first &&\n        ((viff_info.machine_dependency != VFF_DEP_DECORDER) &&\n         (viff_info.machine_dependency != VFF_DEP_NSORDER)))\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE:\n        {\n          MSBOrderShort(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        case VFF_TYP_4_BYTE:\n        case VFF_TYP_FLOAT:\n        {\n          MSBOrderLong(pixels,bytes_per_pixel*max_packets);\n          break;\n        }\n        default: break;\n      }\n    min_value=0.0;\n    scale_factor=1.0;\n    if ((viff_info.data_storage_type != VFF_TYP_1_BYTE) &&\n        (viff_info.map_scheme == VFF_MS_NONE))\n      {\n        double\n          max_value;\n\n        /*\n          Determine scale factor.\n        */\n        switch ((int) viff_info.data_storage_type)\n        {\n          case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[0]; break;\n          case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[0]; break;\n          case VFF_TYP_FLOAT: value=((float *) pixels)[0]; break;\n          case VFF_TYP_DOUBLE: value=((double *) pixels)[0]; break;\n          default: value=1.0*pixels[0]; break;\n        }\n        max_value=value;\n        min_value=value;\n        for (i=0; i < (ssize_t) max_packets; i++)\n        {\n          switch ((int) viff_info.data_storage_type)\n          {\n            case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n            case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n            case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n            case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n            default: value=1.0*pixels[i]; break;\n          }\n          if (value > max_value)\n            max_value=value;\n          else\n            if (value < min_value)\n              min_value=value;\n        }\n        if ((min_value == 0) && (max_value == 0))\n          scale_factor=0;\n        else\n          if (min_value == max_value)\n            {\n              scale_factor=(MagickRealType) QuantumRange/min_value;\n              min_value=0;\n            }\n          else\n            scale_factor=(MagickRealType) QuantumRange/(max_value-min_value);\n      }\n    /*\n      Convert pixels to Quantum size.\n    */\n    p=(unsigned char *) pixels;\n    for (i=0; i < (ssize_t) max_packets; i++)\n    {\n      switch ((int) viff_info.data_storage_type)\n      {\n        case VFF_TYP_2_BYTE: value=1.0*((short *) pixels)[i]; break;\n        case VFF_TYP_4_BYTE: value=1.0*((int *) pixels)[i]; break;\n        case VFF_TYP_FLOAT: value=((float *) pixels)[i]; break;\n        case VFF_TYP_DOUBLE: value=((double *) pixels)[i]; break;\n        default: value=1.0*pixels[i]; break;\n      }\n      if (viff_info.map_scheme == VFF_MS_NONE)\n        {\n          value=(value-min_value)*scale_factor;\n          if (value > QuantumRange)\n            value=QuantumRange;\n          else\n            if (value < 0)\n              value=0;\n        }\n      *p=(unsigned char) ((Quantum) value);\n      p++;\n    }\n    /*\n      Convert VIFF raster image to pixel packets.\n    */\n    p=(unsigned char *) pixels;\n    if (viff_info.data_storage_type == VFF_TYP_BIT)\n      {\n        /*\n          Convert bitmap scanline.\n        */\n        if (image->storage_class != PseudoClass)\n          ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) (image->columns-7); x+=8)\n          {\n            for (bit=0; bit < 8; bit++)\n            {\n              quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n              SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n              SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n              if (image->storage_class == PseudoClass)\n                SetPixelIndex(indexes+x+bit,quantum);\n             }\n            p++;\n          }\n          if ((image->columns % 8) != 0)\n            {\n              for (bit=0; bit < (int) (image->columns % 8); bit++)\n              {\n                quantum=(size_t) ((*p) & (0x01 << bit) ? 0 : 1);\n                SetPixelRed(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelGreen(q,quantum == 0 ? 0 : QuantumRange);\n                SetPixelBlue(q,quantum == 0 ? 0 : QuantumRange);\n                if (image->storage_class == PseudoClass)\n                  SetPixelIndex(indexes+x+bit,quantum);\n              }\n              p++;\n            }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      if (image->storage_class == PseudoClass)\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (PixelPacket *) NULL)\n            break;\n          indexes=GetAuthenticIndexQueue(image);\n          for (x=0; x < (ssize_t) image->columns; x++)\n            SetPixelIndex(indexes+x,*p++);\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      else\n        {\n          /*\n            Convert DirectColor scanline.\n          */\n          number_pixels=(MagickSizeType) image->columns*image->rows;\n          for (y=0; y < (ssize_t) image->rows; y++)\n          {\n            q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n            if (q == (PixelPacket *) NULL)\n              break;\n            for (x=0; x < (ssize_t) image->columns; x++)\n            {\n              SetPixelRed(q,ScaleCharToQuantum(*p));\n              SetPixelGreen(q,ScaleCharToQuantum(*(p+number_pixels)));\n              SetPixelBlue(q,ScaleCharToQuantum(*(p+2*number_pixels)));\n              if (image->colors != 0)\n                {\n                  ssize_t\n                    index;\n\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelRed(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].red);\n                  index=(ssize_t) GetPixelGreen(q);\n                  SetPixelGreen(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].green);\n                  index=(ssize_t) GetPixelRed(q);\n                  SetPixelBlue(q,image->colormap[(ssize_t)\n                    ConstrainColormapIndex(image,index)].blue);\n                }\n              SetPixelOpacity(q,image->matte != MagickFalse ? QuantumRange-\n                ScaleCharToQuantum(*(p+number_pixels*3)) : OpaqueOpacity);\n              p++;\n              q++;\n            }\n            if (SyncAuthenticPixels(image,exception) == MagickFalse)\n              break;\n            if (image->previous == (Image *) NULL)\n              {\n                status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n                if (status == MagickFalse)\n                  break;\n              }\n          }\n        }\n    pixels=(unsigned char *) RelinquishMagickMemory(pixels);\n    if (image->storage_class == PseudoClass)\n      (void) SyncImage(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    count=ReadBlob(image,1,&viff_info.identifier);\n    if ((count != 0) && (viff_info.identifier == 0xab))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (viff_info.identifier == 0xab));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/ca0c886abd6d3ef335eb74150cd23b89ebd17135", "file_name": "coders/viff.c", "vul_type": "cwe-125", "description": "Write a C function to read a VIFF image file in ImageMagick."}
{"func_name": "WritePSDChannel", "func_src_before": "static size_t WritePSDChannel(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const QuantumType quantum_type, unsigned char *compact_pixels,\n  MagickOffsetType size_offset,const MagickBooleanType separate,\n  ExceptionInfo *exception)\n{\n  int\n    y;\n\n  MagickBooleanType\n    monochrome;\n\n  QuantumInfo\n    *quantum_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count,\n    length;\n\n  unsigned char\n    *pixels;\n\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n\n#define CHUNK 16384\n\n  int\n    flush,\n    level;\n\n  unsigned char\n    *compressed_pixels;\n\n  z_stream\n    stream;\n\n  compressed_pixels=(unsigned char *) NULL;\n  flush=Z_NO_FLUSH;\n#endif\n  count=0;\n  if (separate != MagickFalse)\n    {\n      size_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,1);\n    }\n  if (next_image->depth > 8)\n    next_image->depth=16;\n  monochrome=IsImageMonochrome(image) && (image->depth == 1) ?\n    MagickTrue : MagickFalse;\n  quantum_info=AcquireQuantumInfo(image_info,image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    return(0);\n  pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      compressed_pixels=(unsigned char *) AcquireQuantumMemory(CHUNK,\n        sizeof(*compressed_pixels));\n      if (compressed_pixels == (unsigned char *) NULL)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n      ResetMagickMemory(&stream,0,sizeof(stream));\n      stream.data_type=Z_BINARY;\n      level=Z_DEFAULT_COMPRESSION;\n      if ((image_info->quality > 0 && image_info->quality < 10))\n        level=(int) image_info->quality;\n      if (deflateInit(&stream,level) != Z_OK)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n    }\n#endif\n  for (y=0; y < (ssize_t) next_image->rows; y++)\n  {\n    p=GetVirtualPixels(next_image,0,y,next_image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    length=ExportQuantumPixels(next_image,(CacheView *) NULL,quantum_info,\n      quantum_type,pixels,exception);\n    if (monochrome != MagickFalse)\n      for (i=0; i < (ssize_t) length; i++)\n        pixels[i]=(~pixels[i]);\n    if (next_image->compression == RLECompression)\n      {\n        length=PSDPackbitsEncodeImage(image,length,pixels,compact_pixels,\n          exception);\n        count+=WriteBlob(image,length,compact_pixels);\n        size_offset+=WritePSDOffset(psd_info,image,length,size_offset);\n      }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n    else if (next_image->compression == ZipCompression)\n      {\n        stream.avail_in=(uInt) length;\n        stream.next_in=(Bytef *) pixels;\n        if (y == (ssize_t) next_image->rows-1)\n          flush=Z_FINISH;\n        do {\n            stream.avail_out=(uInt) CHUNK;\n            stream.next_out=(Bytef *) compressed_pixels;\n            if (deflate(&stream,flush) == Z_STREAM_ERROR)\n              break;\n            length=(size_t) CHUNK-stream.avail_out;\n            if (length > 0)\n              count+=WriteBlob(image,length,compressed_pixels);\n        } while (stream.avail_out == 0);\n      }\n#endif\n    else\n      count+=WriteBlob(image,length,pixels);\n  }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      (void) deflateEnd(&stream);\n      compressed_pixels=(unsigned char *) RelinquishMagickMemory(\n        compressed_pixels);\n    }\n#endif\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  return(count);\n}", "func_src_after": "static size_t WritePSDChannel(const PSDInfo *psd_info,\n  const ImageInfo *image_info,Image *image,Image *next_image,\n  const QuantumType quantum_type, unsigned char *compact_pixels,\n  MagickOffsetType size_offset,const MagickBooleanType separate,\n  ExceptionInfo *exception)\n{\n  int\n    y;\n\n  MagickBooleanType\n    monochrome;\n\n  QuantumInfo\n    *quantum_info;\n\n  register const Quantum\n    *p;\n\n  register ssize_t\n    i;\n\n  size_t\n    count,\n    length;\n\n  unsigned char\n    *pixels;\n\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n\n#define CHUNK 16384\n\n  int\n    flush,\n    level;\n\n  unsigned char\n    *compressed_pixels;\n\n  z_stream\n    stream;\n\n  compressed_pixels=(unsigned char *) NULL;\n  flush=Z_NO_FLUSH;\n#endif\n  count=0;\n  if (separate != MagickFalse)\n    {\n      size_offset=TellBlob(image)+2;\n      count+=WriteCompressionStart(psd_info,image,next_image,1);\n    }\n  if (next_image->depth > 8)\n    next_image->depth=16;\n  monochrome=IsImageMonochrome(image) && (image->depth == 1) ?\n    MagickTrue : MagickFalse;\n  quantum_info=AcquireQuantumInfo(image_info,next_image);\n  if (quantum_info == (QuantumInfo *) NULL)\n    return(0);\n  pixels=(unsigned char *) GetQuantumPixels(quantum_info);\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      compressed_pixels=(unsigned char *) AcquireQuantumMemory(CHUNK,\n        sizeof(*compressed_pixels));\n      if (compressed_pixels == (unsigned char *) NULL)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n      ResetMagickMemory(&stream,0,sizeof(stream));\n      stream.data_type=Z_BINARY;\n      level=Z_DEFAULT_COMPRESSION;\n      if ((image_info->quality > 0 && image_info->quality < 10))\n        level=(int) image_info->quality;\n      if (deflateInit(&stream,level) != Z_OK)\n        {\n          quantum_info=DestroyQuantumInfo(quantum_info);\n          return(0);\n        }\n    }\n#endif\n  for (y=0; y < (ssize_t) next_image->rows; y++)\n  {\n    p=GetVirtualPixels(next_image,0,y,next_image->columns,1,exception);\n    if (p == (const Quantum *) NULL)\n      break;\n    length=ExportQuantumPixels(next_image,(CacheView *) NULL,quantum_info,\n      quantum_type,pixels,exception);\n    if (monochrome != MagickFalse)\n      for (i=0; i < (ssize_t) length; i++)\n        pixels[i]=(~pixels[i]);\n    if (next_image->compression == RLECompression)\n      {\n        length=PSDPackbitsEncodeImage(image,length,pixels,compact_pixels,\n          exception);\n        count+=WriteBlob(image,length,compact_pixels);\n        size_offset+=WritePSDOffset(psd_info,image,length,size_offset);\n      }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n    else if (next_image->compression == ZipCompression)\n      {\n        stream.avail_in=(uInt) length;\n        stream.next_in=(Bytef *) pixels;\n        if (y == (ssize_t) next_image->rows-1)\n          flush=Z_FINISH;\n        do {\n            stream.avail_out=(uInt) CHUNK;\n            stream.next_out=(Bytef *) compressed_pixels;\n            if (deflate(&stream,flush) == Z_STREAM_ERROR)\n              break;\n            length=(size_t) CHUNK-stream.avail_out;\n            if (length > 0)\n              count+=WriteBlob(image,length,compressed_pixels);\n        } while (stream.avail_out == 0);\n      }\n#endif\n    else\n      count+=WriteBlob(image,length,pixels);\n  }\n#ifdef MAGICKCORE_ZLIB_DELEGATE\n  if (next_image->compression == ZipCompression)\n    {\n      (void) deflateEnd(&stream);\n      compressed_pixels=(unsigned char *) RelinquishMagickMemory(\n        compressed_pixels);\n    }\n#endif\n  quantum_info=DestroyQuantumInfo(quantum_info);\n  return(count);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/91cc3f36f2ccbd485a0456bab9aebe63b635da88", "file_name": "coders/psd.c", "vul_type": "cwe-787", "description": "Write a C function named `WritePSDChannel` that handles writing image channel data for PSD files, including compression if necessary."}
{"func_name": "gf_m2ts_process_pmt", "func_src_before": "static void gf_m2ts_process_pmt(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *pmt, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tu32 info_length, pos, desc_len, evt_type, nb_es,i;\n\tu32 nb_sections;\n\tu32 data_size;\n\tu32 nb_hevc, nb_hevc_temp, nb_shvc, nb_shvc_temp, nb_mhvc, nb_mhvc_temp;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\tGF_Err e = GF_OK;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\tnb_es = 0;\n\n\t/*skip if already received but no update detected (eg same data) */\n\tif ((status&GF_M2TS_TABLE_REPEAT) && !(status&GF_M2TS_TABLE_UPDATE))  {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t\treturn;\n\t}\n\n\tif (pmt->sec->demux_restarted) {\n\t\tpmt->sec->demux_restarted = 0;\n\t\treturn;\n\t}\n\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PMT Found or updated\\n\"));\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PMT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tpmt->program->pcr_pid = ((data[0] & 0x1f) << 8) | data[1];\n\n\tinfo_length = ((data[2]&0xf)<<8) | data[3];\n\tif (info_length != 0) {\n\t\t/* ...Read Descriptors ... */\n\t\tu8 tag, len;\n\t\tu32 first_loop_len = 0;\n\t\ttag = data[4];\n\t\tlen = data[5];\n\t\twhile (info_length > first_loop_len) {\n\t\t\tif (tag == GF_M2TS_MPEG4_IOD_DESCRIPTOR) {\n\t\t\t\tu32 size;\n\t\t\t\tGF_BitStream *iod_bs;\n\t\t\t\tiod_bs = gf_bs_new((char *)data+8, len-2, GF_BITSTREAM_READ);\n\t\t\t\tif (pmt->program->pmt_iod) gf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\te = gf_odf_parse_descriptor(iod_bs , (GF_Descriptor **) &pmt->program->pmt_iod, &size);\n\t\t\t\tgf_bs_del(iod_bs );\n\t\t\t\tif (e==GF_OK) {\n\t\t\t\t\t/*remember program number for service/program selection*/\n\t\t\t\t\tif (pmt->program->pmt_iod) pmt->program->pmt_iod->ServiceID = pmt->program->number;\n\t\t\t\t\t/*if empty IOD (freebox case), discard it and use dynamic declaration of object*/\n\t\t\t\t\tif (!gf_list_count(pmt->program->pmt_iod->ESDescriptors)) {\n\t\t\t\t\t\tgf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\t\t\tpmt->program->pmt_iod = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (tag == GF_M2TS_METADATA_POINTER_DESCRIPTOR) {\n\t\t\t\tGF_BitStream *metadatapd_bs;\n\t\t\t\tGF_M2TS_MetadataPointerDescriptor *metapd;\n\t\t\t\tmetadatapd_bs = gf_bs_new((char *)data+6, len, GF_BITSTREAM_READ);\n\t\t\t\tmetapd = gf_m2ts_read_metadata_pointer_descriptor(metadatapd_bs, len);\n\t\t\t\tgf_bs_del(metadatapd_bs);\n\t\t\t\tif (metapd->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->carriage_flag == METADATA_CARRIAGE_SAME_TS) {\n\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\tpmt->program->metadata_pointer_descriptor = metapd;\n\t\t\t\t} else {\n\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\tgf_m2ts_metadata_pointer_descriptor_del(metapd);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Skipping descriptor (0x%x) and others not supported\\n\", tag));\n\t\t\t}\n\t\t\tfirst_loop_len += 2 + len;\n\t\t}\n\t}\n\tif (data_size <= 4 + info_length) return;\n\tdata += 4 + info_length;\n\tdata_size -= 4 + info_length;\n\tpos = 0;\n\n\t/* count de number of program related PMT received */\n\tfor(i=0; i<gf_list_count(ts->programs); i++) {\n\t\tGF_M2TS_Program *prog = (GF_M2TS_Program *)gf_list_get(ts->programs,i);\n\t\tif(prog->pmt_pid == pmt->pid) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tnb_hevc = nb_hevc_temp = nb_shvc = nb_shvc_temp = nb_mhvc = nb_mhvc_temp = 0;\n\twhile (pos<data_size) {\n\t\tGF_M2TS_PES *pes = NULL;\n\t\tGF_M2TS_SECTION_ES *ses = NULL;\n\t\tGF_M2TS_ES *es = NULL;\n\t\tBool inherit_pcr = 0;\n\t\tu32 pid, stream_type, reg_desc_format;\n\n\t\tstream_type = data[0];\n\t\tpid = ((data[1] & 0x1f) << 8) | data[2];\n\t\tdesc_len = ((data[3] & 0xf) << 8) | data[4];\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"stream_type :%d \\n\",stream_type));\n\t\tswitch (stream_type) {\n\n\t\t/* PES */\n\t\tcase GF_M2TS_VIDEO_MPEG1:\n\t\tcase GF_M2TS_VIDEO_MPEG2:\n\t\tcase GF_M2TS_VIDEO_DCII:\n\t\tcase GF_M2TS_VIDEO_MPEG4:\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_PES:\n\t\tcase GF_M2TS_VIDEO_H264:\n\t\tcase GF_M2TS_VIDEO_SVC:\n\t\tcase GF_M2TS_VIDEO_MVCD:\n\t\tcase GF_M2TS_VIDEO_HEVC:\n\t\tcase GF_M2TS_VIDEO_HEVC_MCTS:\n\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\tinherit_pcr = 1;\n\t\tcase GF_M2TS_AUDIO_MPEG1:\n\t\tcase GF_M2TS_AUDIO_MPEG2:\n\t\tcase GF_M2TS_AUDIO_AAC:\n\t\tcase GF_M2TS_AUDIO_LATM_AAC:\n\t\tcase GF_M2TS_AUDIO_AC3:\n\t\tcase GF_M2TS_AUDIO_DTS:\n\t\tcase GF_M2TS_MHAS_MAIN:\n\t\tcase GF_M2TS_MHAS_AUX:\n\t\tcase GF_M2TS_SUBTITLE_DVB:\n\t\tcase GF_M2TS_METADATA_PES:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tif (inherit_pcr)\n\t\t\t\tpes->flags |= GF_M2TS_INHERIT_PCR;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\tcase GF_M2TS_PRIVATE_DATA:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\t/* Sections */\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_SECTIONS:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\t/* carriage of ISO_IEC_14496 data in sections */\n\t\t\tif (stream_type == GF_M2TS_SYSTEMS_MPEG4_SECTIONS) {\n\t\t\t\t/*MPEG-4 sections need to be fully checked: if one section is lost, this means we lost\n\t\t\t\tone SL packet in the AU so we must wait for the complete section again*/\n\t\t\t\tses->sec = gf_m2ts_section_filter_new(gf_m2ts_process_mpeg4section, 0);\n\t\t\t\t/*create OD container*/\n\t\t\t\tif (!pmt->program->additional_ods) {\n\t\t\t\t\tpmt->program->additional_ods = gf_list_new();\n\t\t\t\t\tts->has_4on2 = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_13818_6_ANNEX_A:\n\t\tcase GF_M2TS_13818_6_ANNEX_B:\n\t\tcase GF_M2TS_13818_6_ANNEX_C:\n\t\tcase GF_M2TS_13818_6_ANNEX_D:\n\t\tcase GF_M2TS_PRIVATE_SECTION:\n\t\tcase GF_M2TS_QUALITY_SEC:\n\t\tcase GF_M2TS_MORE_SEC:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\tes->pid = pid;\n\t\t\tes->service_id = pmt->program->number;\n\t\t\tif (stream_type == GF_M2TS_PRIVATE_SECTION) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"AIT sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_QUALITY_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Quality metadata sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_MORE_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"MORE sections on pid %d\\n\", pid));\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type DSM CC user private sections on pid %d \\n\", pid));\n\t\t\t}\n\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t//ses->sec->service_id = pmt->program->number;\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_MPE_SECTIONS:\n\t\t\tif (! ts->prefix_present) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type MPE found : pid = %d \\n\", pid));\n#ifdef GPAC_ENABLE_MPE\n\t\t\t\tes = gf_dvb_mpe_section_new();\n\t\t\t\tif (es->flags & GF_M2TS_ES_IS_SECTION) {\n\t\t\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\t\t\t((GF_M2TS_SECTION_ES*)es)->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t}\n#endif\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\t//GF_LOG(/*GF_LOG_WARNING*/GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\tbreak;\n\t\t}\n\n\t\tif (es) {\n\t\t\tes->stream_type = (stream_type==GF_M2TS_PRIVATE_DATA) ? 0 : stream_type;\n\t\t\tes->program = pmt->program;\n\t\t\tes->pid = pid;\n\t\t\tes->component_tag = -1;\n\t\t}\n\n\t\tpos += 5;\n\t\tdata += 5;\n\n\t\twhile (desc_len) {\n\t\t\tu8 tag = data[0];\n\t\t\tu32 len = data[1];\n\t\t\tif (es) {\n\t\t\t\tswitch (tag) {\n\t\t\t\tcase GF_M2TS_ISO_639_LANGUAGE_DESCRIPTOR:\n\t\t\t\t\tif (pes)\n\t\t\t\t\t\tpes->lang = GF_4CC(' ', data[2], data[3], data[4]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_MPEG4_SL_DESCRIPTOR:\n\t\t\t\t\tes->mpeg4_es_id = ( (u32) data[2] & 0x1f) << 8  | data[3];\n\t\t\t\t\tes->flags |= GF_M2TS_ES_IS_SL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_REGISTRATION_DESCRIPTOR:\n\t\t\t\t\treg_desc_format = GF_4CC(data[2], data[3], data[4], data[5]);\n\t\t\t\t\t/*cf http://www.smpte-ra.org/mpegreg/mpegreg.html*/\n\t\t\t\t\tswitch (reg_desc_format) {\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_AC3:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_AC3;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_VC1:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_VIDEO_VC1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_GPAC:\n\t\t\t\t\t\tif (len==8) {\n\t\t\t\t\t\t\tes->stream_type = GF_4CC(data[6], data[7], data[8], data[9]);\n\t\t\t\t\t\t\tes->flags |= GF_M2TS_GPAC_CODEC_ID;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Unknown registration descriptor %s\\n\", gf_4cc_to_str(reg_desc_format) ));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_EAC3_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_EC3;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_DATA_BROADCAST_ID_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tu32 id = data[2]<<8 | data[3];\n\t\t\t\t\tif ((id == 0xB) && ses && !ses->sec) {\n\t\t\t\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_SUBTITLING_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tpes->sub.language[0] = data[2];\n\t\t\t\t\t\tpes->sub.language[1] = data[3];\n\t\t\t\t\t\tpes->sub.language[2] = data[4];\n\t\t\t\t\t\tpes->sub.type = data[5];\n\t\t\t\t\t\tpes->sub.composition_page_id = (data[6]<<8) | data[7];\n\t\t\t\t\t\tpes->sub.ancillary_page_id = (data[8]<<8) | data[9];\n\t\t\t\t\t}\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_SUBTITLE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_STREAM_IDENTIFIER_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tes->component_tag = data[2];\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"Component Tag: %d on Program %d\\n\", es->component_tag, es->program->number));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_TELETEXT_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_TELETEXT;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_VBI_DATA_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_VBI;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_HIERARCHY_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tu8 hierarchy_embedded_layer_index;\n\t\t\t\t\t\tGF_BitStream *hbs = gf_bs_new((const char *)data, data_size, GF_BITSTREAM_READ);\n\t\t\t\t\t\t/*u32 skip = */gf_bs_read_int(hbs, 16);\n\t\t\t\t\t\t/*u8 res1 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 temp_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 spatial_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 quality_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 hierarchy_type = */gf_bs_read_int(hbs, 4);\n\t\t\t\t\t\t/*u8 res2 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_layer_index = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 tref_not_present = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 res3 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\thierarchy_embedded_layer_index = gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 res4 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_channel = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\tgf_bs_del(hbs);\n\n\t\t\t\t\t\tpes->depends_on_pid = 1+hierarchy_embedded_layer_index;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_METADATA_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tGF_BitStream *metadatad_bs;\n\t\t\t\t\tGF_M2TS_MetadataDescriptor *metad;\n\t\t\t\t\tmetadatad_bs = gf_bs_new((char *)data+2, len, GF_BITSTREAM_READ);\n\t\t\t\t\tmetad = gf_m2ts_read_metadata_descriptor(metadatad_bs, len);\n\t\t\t\t\tgf_bs_del(metadatad_bs);\n\t\t\t\t\tif (metad->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t\t        metad->format_identifier == GF_M2TS_META_ID3) {\n\t\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\t\tif (pes) {\n\t\t\t\t\t\t\tpes->metadata_descriptor = metad;\n\t\t\t\t\t\t\tpes->stream_type = GF_M2TS_METADATA_ID3_HLS;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\t\tgf_m2ts_metadata_descriptor_del(metad);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] skipping descriptor (0x%x) not supported\\n\", tag));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdata += len+2;\n\t\t\tpos += len+2;\n\t\t\tif (desc_len < len+2) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Invalid PMT es descriptor size for PID %d\\n\", pid ) );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdesc_len-=len+2;\n\t\t}\n\n\t\tif (es && !es->stream_type) {\n\t\t\tgf_free(es);\n\t\t\tes = NULL;\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Private Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t}\n\n\t\tif (!es) continue;\n\n\t\tif (ts->ess[pid]) {\n\t\t\t//this is component reuse across programs, overwrite the previously declared stream ...\n\t\t\tif (status & GF_M2TS_TABLE_FOUND) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PID %d reused across programs %d and %d, not completely supported\\n\", pid, ts->ess[pid]->program->number, es->program->number ) );\n\n\t\t\t\t//add stream to program but don't reassign the pid table until the stream is playing (>GF_M2TS_PES_FRAMING_SKIP)\n\t\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\t\tnb_es++;\n\t\t\t\t//skip assignment below\n\t\t\t\tes = NULL;\n\t\t\t}\n\t\t\t/*watchout for pmt update - FIXME this likely won't work in most cases*/\n\t\t\telse {\n\n\t\t\t\tGF_M2TS_ES *o_es = ts->ess[es->pid];\n\n\t\t\t\tif ((o_es->stream_type == es->stream_type)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK) == (es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK))\n\t\t\t\t        && (o_es->mpeg4_es_id == es->mpeg4_es_id)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_IS_SECTION) || ((GF_M2TS_PES *)o_es)->lang == ((GF_M2TS_PES *)es)->lang)\n\t\t\t\t   ) {\n\t\t\t\t\tgf_free(es);\n\t\t\t\t\tes = NULL;\n\t\t\t\t} else {\n\t\t\t\t\tgf_m2ts_es_del(o_es, ts);\n\t\t\t\t\tts->ess[es->pid] = NULL;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (es) {\n\t\t\tts->ess[es->pid] = es;\n\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\tnb_es++;\n\n\t\t\tif (es->stream_type == GF_M2TS_VIDEO_HEVC) nb_hevc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_HEVC_TEMPORAL) nb_hevc_temp++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC) nb_shvc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC_TEMPORAL) nb_shvc_temp++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC) nb_mhvc++;\n\t\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC_TEMPORAL) nb_mhvc_temp++;\n\t\t}\n\t}\n\n\t//Table 2-139, implied hierarchy indexes\n\tif (nb_hevc_temp + nb_shvc + nb_shvc_temp + nb_mhvc+ nb_mhvc_temp) {\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (es->depends_on_pid) continue;\n\n\t\t\tswitch (es->stream_type) {\n\t\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 1;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 2;\n\t\t\t\telse es->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nb_es) {\n\t\tu32 i;\n\n\t\t//translate hierarchy descriptors indexes into PIDs - check whether the PMT-index rules are the same for HEVC\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *an_es = NULL;\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (!es->depends_on_pid) continue;\n\n\t\t\t//fixeme we are not always assured that hierarchy_layer_index matches the stream index...\n\t\t\t//+1 is because our first stream is the PMT\n\t\t\tan_es =  (GF_M2TS_PES *)gf_list_get(pmt->program->streams, es->depends_on_pid);\n\t\t\tif (an_es) {\n\t\t\t\tes->depends_on_pid = an_es->pid;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[M2TS] Wrong dependency index in hierarchy descriptor, assuming non-scalable stream\\n\"));\n\t\t\t\tes->depends_on_pid = 0;\n\t\t\t}\n\t\t}\n\n\t\tevt_type = (status&GF_M2TS_TABLE_FOUND) ? GF_M2TS_EVT_PMT_FOUND : GF_M2TS_EVT_PMT_UPDATE;\n\t\tif (ts->on_event) ts->on_event(ts, evt_type, pmt->program);\n\t} else {\n\t\t/* if we found no new ES it's simply a repeat of the PMT */\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t}\n}", "func_src_after": "static void gf_m2ts_process_pmt(GF_M2TS_Demuxer *ts, GF_M2TS_SECTION_ES *pmt, GF_List *sections, u8 table_id, u16 ex_table_id, u8 version_number, u8 last_section_number, u32 status)\n{\n\tu32 info_length, pos, desc_len, evt_type, nb_es,i;\n\tu32 nb_sections;\n\tu32 data_size;\n\tu32 nb_hevc, nb_hevc_temp, nb_shvc, nb_shvc_temp, nb_mhvc, nb_mhvc_temp;\n\tunsigned char *data;\n\tGF_M2TS_Section *section;\n\tGF_Err e = GF_OK;\n\n\t/*wait for the last section */\n\tif (!(status&GF_M2TS_TABLE_END)) return;\n\n\tnb_es = 0;\n\n\t/*skip if already received but no update detected (eg same data) */\n\tif ((status&GF_M2TS_TABLE_REPEAT) && !(status&GF_M2TS_TABLE_UPDATE))  {\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t\treturn;\n\t}\n\n\tif (pmt->sec->demux_restarted) {\n\t\tpmt->sec->demux_restarted = 0;\n\t\treturn;\n\t}\n\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PMT Found or updated\\n\"));\n\n\tnb_sections = gf_list_count(sections);\n\tif (nb_sections > 1) {\n\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"PMT on multiple sections not supported\\n\"));\n\t}\n\n\tsection = (GF_M2TS_Section *)gf_list_get(sections, 0);\n\tdata = section->data;\n\tdata_size = section->data_size;\n\n\tpmt->program->pcr_pid = ((data[0] & 0x1f) << 8) | data[1];\n\n\tinfo_length = ((data[2]&0xf)<<8) | data[3];\n\tif (info_length != 0) {\n\t\t/* ...Read Descriptors ... */\n\t\tu8 tag, len;\n\t\tu32 first_loop_len = 0;\n\t\ttag = data[4];\n\t\tlen = data[5];\n\t\twhile (info_length > first_loop_len) {\n\t\t\tif (tag == GF_M2TS_MPEG4_IOD_DESCRIPTOR) {\n\t\t\t\tu32 size;\n\t\t\t\tGF_BitStream *iod_bs;\n\t\t\t\tiod_bs = gf_bs_new((char *)data+8, len-2, GF_BITSTREAM_READ);\n\t\t\t\tif (pmt->program->pmt_iod) gf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\te = gf_odf_parse_descriptor(iod_bs , (GF_Descriptor **) &pmt->program->pmt_iod, &size);\n\t\t\t\tgf_bs_del(iod_bs );\n\t\t\t\tif (e==GF_OK) {\n\t\t\t\t\t/*remember program number for service/program selection*/\n\t\t\t\t\tif (pmt->program->pmt_iod) pmt->program->pmt_iod->ServiceID = pmt->program->number;\n\t\t\t\t\t/*if empty IOD (freebox case), discard it and use dynamic declaration of object*/\n\t\t\t\t\tif (!gf_list_count(pmt->program->pmt_iod->ESDescriptors)) {\n\t\t\t\t\t\tgf_odf_desc_del((GF_Descriptor *)pmt->program->pmt_iod);\n\t\t\t\t\t\tpmt->program->pmt_iod = NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else if (tag == GF_M2TS_METADATA_POINTER_DESCRIPTOR) {\n\t\t\t\tGF_BitStream *metadatapd_bs;\n\t\t\t\tGF_M2TS_MetadataPointerDescriptor *metapd;\n\t\t\t\tmetadatapd_bs = gf_bs_new((char *)data+6, len, GF_BITSTREAM_READ);\n\t\t\t\tmetapd = gf_m2ts_read_metadata_pointer_descriptor(metadatapd_bs, len);\n\t\t\t\tgf_bs_del(metadatapd_bs);\n\t\t\t\tif (metapd->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t        metapd->carriage_flag == METADATA_CARRIAGE_SAME_TS) {\n\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\tpmt->program->metadata_pointer_descriptor = metapd;\n\t\t\t\t} else {\n\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\tgf_m2ts_metadata_pointer_descriptor_del(metapd);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Skipping descriptor (0x%x) and others not supported\\n\", tag));\n\t\t\t}\n\t\t\tfirst_loop_len += 2 + len;\n\t\t}\n\t}\n\tif (data_size <= 4 + info_length) return;\n\tdata += 4 + info_length;\n\tdata_size -= 4 + info_length;\n\tpos = 0;\n\n\t/* count de number of program related PMT received */\n\tfor(i=0; i<gf_list_count(ts->programs); i++) {\n\t\tGF_M2TS_Program *prog = (GF_M2TS_Program *)gf_list_get(ts->programs,i);\n\t\tif(prog->pmt_pid == pmt->pid) {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tnb_hevc = nb_hevc_temp = nb_shvc = nb_shvc_temp = nb_mhvc = nb_mhvc_temp = 0;\n\twhile (pos<data_size) {\n\t\tGF_M2TS_PES *pes = NULL;\n\t\tGF_M2TS_SECTION_ES *ses = NULL;\n\t\tGF_M2TS_ES *es = NULL;\n\t\tBool inherit_pcr = 0;\n\t\tu32 pid, stream_type, reg_desc_format;\n\n\t\tstream_type = data[0];\n\t\tpid = ((data[1] & 0x1f) << 8) | data[2];\n\t\tdesc_len = ((data[3] & 0xf) << 8) | data[4];\n\n\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"stream_type :%d \\n\",stream_type));\n\t\tswitch (stream_type) {\n\n\t\t/* PES */\n\t\tcase GF_M2TS_VIDEO_MPEG1:\n\t\tcase GF_M2TS_VIDEO_MPEG2:\n\t\tcase GF_M2TS_VIDEO_DCII:\n\t\tcase GF_M2TS_VIDEO_MPEG4:\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_PES:\n\t\tcase GF_M2TS_VIDEO_H264:\n\t\tcase GF_M2TS_VIDEO_SVC:\n\t\tcase GF_M2TS_VIDEO_MVCD:\n\t\tcase GF_M2TS_VIDEO_HEVC:\n\t\tcase GF_M2TS_VIDEO_HEVC_MCTS:\n\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\tinherit_pcr = 1;\n\t\tcase GF_M2TS_AUDIO_MPEG1:\n\t\tcase GF_M2TS_AUDIO_MPEG2:\n\t\tcase GF_M2TS_AUDIO_AAC:\n\t\tcase GF_M2TS_AUDIO_LATM_AAC:\n\t\tcase GF_M2TS_AUDIO_AC3:\n\t\tcase GF_M2TS_AUDIO_DTS:\n\t\tcase GF_M2TS_MHAS_MAIN:\n\t\tcase GF_M2TS_MHAS_AUX:\n\t\tcase GF_M2TS_SUBTITLE_DVB:\n\t\tcase GF_M2TS_METADATA_PES:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tif (inherit_pcr)\n\t\t\t\tpes->flags |= GF_M2TS_INHERIT_PCR;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\tcase GF_M2TS_PRIVATE_DATA:\n\t\t\tGF_SAFEALLOC(pes, GF_M2TS_PES);\n\t\t\tif (!pes) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tpes->cc = -1;\n\t\t\tpes->flags = GF_M2TS_ES_IS_PES;\n\t\t\tes = (GF_M2TS_ES *)pes;\n\t\t\tbreak;\n\t\t/* Sections */\n\t\tcase GF_M2TS_SYSTEMS_MPEG4_SECTIONS:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\t/* carriage of ISO_IEC_14496 data in sections */\n\t\t\tif (stream_type == GF_M2TS_SYSTEMS_MPEG4_SECTIONS) {\n\t\t\t\t/*MPEG-4 sections need to be fully checked: if one section is lost, this means we lost\n\t\t\t\tone SL packet in the AU so we must wait for the complete section again*/\n\t\t\t\tses->sec = gf_m2ts_section_filter_new(gf_m2ts_process_mpeg4section, 0);\n\t\t\t\t/*create OD container*/\n\t\t\t\tif (!pmt->program->additional_ods) {\n\t\t\t\t\tpmt->program->additional_ods = gf_list_new();\n\t\t\t\t\tts->has_4on2 = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_13818_6_ANNEX_A:\n\t\tcase GF_M2TS_13818_6_ANNEX_B:\n\t\tcase GF_M2TS_13818_6_ANNEX_C:\n\t\tcase GF_M2TS_13818_6_ANNEX_D:\n\t\tcase GF_M2TS_PRIVATE_SECTION:\n\t\tcase GF_M2TS_QUALITY_SEC:\n\t\tcase GF_M2TS_MORE_SEC:\n\t\t\tGF_SAFEALLOC(ses, GF_M2TS_SECTION_ES);\n\t\t\tif (!ses) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG2TS] Failed to allocate ES for pid %d\\n\", pid));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tes = (GF_M2TS_ES *)ses;\n\t\t\tes->flags |= GF_M2TS_ES_IS_SECTION;\n\t\t\tes->pid = pid;\n\t\t\tes->service_id = pmt->program->number;\n\t\t\tif (stream_type == GF_M2TS_PRIVATE_SECTION) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"AIT sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_QUALITY_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Quality metadata sections on pid %d\\n\", pid));\n\t\t\t} else if (stream_type == GF_M2TS_MORE_SEC) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"MORE sections on pid %d\\n\", pid));\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type DSM CC user private sections on pid %d \\n\", pid));\n\t\t\t}\n\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t//ses->sec->service_id = pmt->program->number;\n\t\t\tbreak;\n\n\t\tcase GF_M2TS_MPE_SECTIONS:\n\t\t\tif (! ts->prefix_present) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"stream type MPE found : pid = %d \\n\", pid));\n#ifdef GPAC_ENABLE_MPE\n\t\t\t\tes = gf_dvb_mpe_section_new();\n\t\t\t\tif (es->flags & GF_M2TS_ES_IS_SECTION) {\n\t\t\t\t\t/* NULL means: trigger the call to on_event with DVB_GENERAL type and the raw section as payload */\n\t\t\t\t\t((GF_M2TS_SECTION_ES*)es)->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t}\n#endif\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\tdefault:\n\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\t//GF_LOG(/*GF_LOG_WARNING*/GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t\tbreak;\n\t\t}\n\n\t\tif (es) {\n\t\t\tes->stream_type = (stream_type==GF_M2TS_PRIVATE_DATA) ? 0 : stream_type;\n\t\t\tes->program = pmt->program;\n\t\t\tes->pid = pid;\n\t\t\tes->component_tag = -1;\n\t\t}\n\n\t\tpos += 5;\n\t\tdata += 5;\n\n\t\twhile (desc_len) {\n\t\t\tu8 tag = data[0];\n\t\t\tu32 len = data[1];\n\t\t\tif (es) {\n\t\t\t\tswitch (tag) {\n\t\t\t\tcase GF_M2TS_ISO_639_LANGUAGE_DESCRIPTOR:\n\t\t\t\t\tif (pes)\n\t\t\t\t\t\tpes->lang = GF_4CC(' ', data[2], data[3], data[4]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_MPEG4_SL_DESCRIPTOR:\n\t\t\t\t\tes->mpeg4_es_id = ( (u32) data[2] & 0x1f) << 8  | data[3];\n\t\t\t\t\tes->flags |= GF_M2TS_ES_IS_SL;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_REGISTRATION_DESCRIPTOR:\n\t\t\t\t\treg_desc_format = GF_4CC(data[2], data[3], data[4], data[5]);\n\t\t\t\t\t/*cf http://www.smpte-ra.org/mpegreg/mpegreg.html*/\n\t\t\t\t\tswitch (reg_desc_format) {\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_AC3:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_AC3;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_VC1:\n\t\t\t\t\t\tes->stream_type = GF_M2TS_VIDEO_VC1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase GF_M2TS_RA_STREAM_GPAC:\n\t\t\t\t\t\tif (len==8) {\n\t\t\t\t\t\t\tes->stream_type = GF_4CC(data[6], data[7], data[8], data[9]);\n\t\t\t\t\t\t\tes->flags |= GF_M2TS_GPAC_CODEC_ID;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"Unknown registration descriptor %s\\n\", gf_4cc_to_str(reg_desc_format) ));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_EAC3_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_AUDIO_EC3;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_DATA_BROADCAST_ID_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tu32 id = data[2]<<8 | data[3];\n\t\t\t\t\tif ((id == 0xB) && ses && !ses->sec) {\n\t\t\t\t\t\tses->sec = gf_m2ts_section_filter_new(NULL, 1);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_SUBTITLING_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tpes->sub.language[0] = data[2];\n\t\t\t\t\t\tpes->sub.language[1] = data[3];\n\t\t\t\t\t\tpes->sub.language[2] = data[4];\n\t\t\t\t\t\tpes->sub.type = data[5];\n\t\t\t\t\t\tpes->sub.composition_page_id = (data[6]<<8) | data[7];\n\t\t\t\t\t\tpes->sub.ancillary_page_id = (data[8]<<8) | data[9];\n\t\t\t\t\t}\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_SUBTITLE;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_STREAM_IDENTIFIER_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tes->component_tag = data[2];\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"Component Tag: %d on Program %d\\n\", es->component_tag, es->program->number));\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_TELETEXT_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_TELETEXT;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_DVB_VBI_DATA_DESCRIPTOR:\n\t\t\t\t\tes->stream_type = GF_M2TS_DVB_VBI;\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_HIERARCHY_DESCRIPTOR:\n\t\t\t\t\tif (pes) {\n\t\t\t\t\t\tu8 hierarchy_embedded_layer_index;\n\t\t\t\t\t\tGF_BitStream *hbs = gf_bs_new((const char *)data, data_size, GF_BITSTREAM_READ);\n\t\t\t\t\t\t/*u32 skip = */gf_bs_read_int(hbs, 16);\n\t\t\t\t\t\t/*u8 res1 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 temp_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 spatial_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 quality_scal = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 hierarchy_type = */gf_bs_read_int(hbs, 4);\n\t\t\t\t\t\t/*u8 res2 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_layer_index = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 tref_not_present = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\t/*u8 res3 = */gf_bs_read_int(hbs, 1);\n\t\t\t\t\t\thierarchy_embedded_layer_index = gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\t/*u8 res4 = */gf_bs_read_int(hbs, 2);\n\t\t\t\t\t\t/*u8 hierarchy_channel = */gf_bs_read_int(hbs, 6);\n\t\t\t\t\t\tgf_bs_del(hbs);\n\n\t\t\t\t\t\tpes->depends_on_pid = 1+hierarchy_embedded_layer_index;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase GF_M2TS_METADATA_DESCRIPTOR:\n\t\t\t\t{\n\t\t\t\t\tGF_BitStream *metadatad_bs;\n\t\t\t\t\tGF_M2TS_MetadataDescriptor *metad;\n\t\t\t\t\tmetadatad_bs = gf_bs_new((char *)data+2, len, GF_BITSTREAM_READ);\n\t\t\t\t\tmetad = gf_m2ts_read_metadata_descriptor(metadatad_bs, len);\n\t\t\t\t\tgf_bs_del(metadatad_bs);\n\t\t\t\t\tif (metad->application_format_identifier == GF_M2TS_META_ID3 &&\n\t\t\t\t\t        metad->format_identifier == GF_M2TS_META_ID3) {\n\t\t\t\t\t\t/*HLS ID3 Metadata */\n\t\t\t\t\t\tif (pes) {\n\t\t\t\t\t\t\tpes->metadata_descriptor = metad;\n\t\t\t\t\t\t\tpes->stream_type = GF_M2TS_METADATA_ID3_HLS;\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* don't know what to do with it for now, delete */\n\t\t\t\t\t\tgf_m2ts_metadata_descriptor_del(metad);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tGF_LOG(GF_LOG_DEBUG, GF_LOG_CONTAINER, (\"[MPEG-2 TS] skipping descriptor (0x%x) not supported\\n\", tag));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tdata += len+2;\n\t\t\tpos += len+2;\n\t\t\tif (desc_len < len+2) {\n\t\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Invalid PMT es descriptor size for PID %d\\n\", pid ) );\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tdesc_len-=len+2;\n\t\t}\n\n\t\tif (es && !es->stream_type) {\n\t\t\tgf_free(es);\n\t\t\tes = NULL;\n\t\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[MPEG-2 TS] Private Stream type (0x%x) for PID %d not supported\\n\", stream_type, pid ) );\n\t\t}\n\n\t\tif (!es) continue;\n\n\t\tif (ts->ess[pid]) {\n\t\t\t//this is component reuse across programs, overwrite the previously declared stream ...\n\t\t\tif (status & GF_M2TS_TABLE_FOUND) {\n\t\t\t\tGF_LOG(GF_LOG_INFO, GF_LOG_CONTAINER, (\"[MPEG-2 TS] PID %d reused across programs %d and %d, not completely supported\\n\", pid, ts->ess[pid]->program->number, es->program->number ) );\n\n\t\t\t\t//add stream to program but don't reassign the pid table until the stream is playing (>GF_M2TS_PES_FRAMING_SKIP)\n\t\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\t\tnb_es++;\n\t\t\t\t//skip assignment below\n\t\t\t\tes = NULL;\n\t\t\t}\n\t\t\t/*watchout for pmt update - FIXME this likely won't work in most cases*/\n\t\t\telse {\n\n\t\t\t\tGF_M2TS_ES *o_es = ts->ess[es->pid];\n\n\t\t\t\tif ((o_es->stream_type == es->stream_type)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK) == (es->flags & GF_M2TS_ES_STATIC_FLAGS_MASK))\n\t\t\t\t        && (o_es->mpeg4_es_id == es->mpeg4_es_id)\n\t\t\t\t        && ((o_es->flags & GF_M2TS_ES_IS_SECTION) || ((GF_M2TS_PES *)o_es)->lang == ((GF_M2TS_PES *)es)->lang)\n\t\t\t\t   ) {\n\t\t\t\t\tgf_free(es);\n\t\t\t\t\tes = NULL;\n\t\t\t\t} else {\n\t\t\t\t\tgf_m2ts_es_del(o_es, ts);\n\t\t\t\t\tts->ess[es->pid] = NULL;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (es) {\n\t\t\tts->ess[es->pid] = es;\n\t\t\tgf_list_add(pmt->program->streams, es);\n\t\t\tif (!(es->flags & GF_M2TS_ES_IS_SECTION) ) gf_m2ts_set_pes_framing(pes, GF_M2TS_PES_FRAMING_SKIP);\n\n\t\t\tnb_es++;\n\t\t}\n\n\t\tif (es->stream_type == GF_M2TS_VIDEO_HEVC) nb_hevc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_HEVC_TEMPORAL) nb_hevc_temp++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC) nb_shvc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_SHVC_TEMPORAL) nb_shvc_temp++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC) nb_mhvc++;\n\t\telse if (es->stream_type == GF_M2TS_VIDEO_MHVC_TEMPORAL) nb_mhvc_temp++;\n\t}\n\n\t//Table 2-139, implied hierarchy indexes\n\tif (nb_hevc_temp + nb_shvc + nb_shvc_temp + nb_mhvc+ nb_mhvc_temp) {\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (es->depends_on_pid) continue;\n\n\t\t\tswitch (es->stream_type) {\n\t\t\tcase GF_M2TS_VIDEO_HEVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 1;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_SHVC_TEMPORAL:\n\t\t\t\tes->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 1;\n\t\t\t\telse es->depends_on_pid = 2;\n\t\t\t\tbreak;\n\t\t\tcase GF_M2TS_VIDEO_MHVC_TEMPORAL:\n\t\t\t\tif (!nb_hevc_temp) es->depends_on_pid = 2;\n\t\t\t\telse es->depends_on_pid = 3;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\tif (nb_es) {\n\t\tu32 i;\n\n\t\t//translate hierarchy descriptors indexes into PIDs - check whether the PMT-index rules are the same for HEVC\n\t\tfor (i=0; i<gf_list_count(pmt->program->streams); i++) {\n\t\t\tGF_M2TS_PES *an_es = NULL;\n\t\t\tGF_M2TS_PES *es = (GF_M2TS_PES *)gf_list_get(pmt->program->streams, i);\n\t\t\tif ( !(es->flags & GF_M2TS_ES_IS_PES)) continue;\n\t\t\tif (!es->depends_on_pid) continue;\n\n\t\t\t//fixeme we are not always assured that hierarchy_layer_index matches the stream index...\n\t\t\t//+1 is because our first stream is the PMT\n\t\t\tan_es =  (GF_M2TS_PES *)gf_list_get(pmt->program->streams, es->depends_on_pid);\n\t\t\tif (an_es) {\n\t\t\t\tes->depends_on_pid = an_es->pid;\n\t\t\t} else {\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[M2TS] Wrong dependency index in hierarchy descriptor, assuming non-scalable stream\\n\"));\n\t\t\t\tes->depends_on_pid = 0;\n\t\t\t}\n\t\t}\n\n\t\tevt_type = (status&GF_M2TS_TABLE_FOUND) ? GF_M2TS_EVT_PMT_FOUND : GF_M2TS_EVT_PMT_UPDATE;\n\t\tif (ts->on_event) ts->on_event(ts, evt_type, pmt->program);\n\t} else {\n\t\t/* if we found no new ES it's simply a repeat of the PMT */\n\t\tif (ts->on_event) ts->on_event(ts, GF_M2TS_EVT_PMT_REPEAT, pmt->program);\n\t}\n}", "commit_link": "github.com/gpac/gpac/commit/2320eb73afba753b39b7147be91f7be7afc0eeb7", "file_name": "src/media_tools/mpegts.c", "vul_type": "cwe-125", "description": "Write a C function to process PMT sections in an MPEG-2 TS demuxer."}
{"func_name": "x86_decode_insn", "func_src_before": "int x86_decode_insn(struct x86_emulate_ctxt *ctxt, void *insn, int insn_len)\n{\n\tint rc = X86EMUL_CONTINUE;\n\tint mode = ctxt->mode;\n\tint def_op_bytes, def_ad_bytes, goffset, simd_prefix;\n\tbool op_prefix = false;\n\tbool has_seg_override = false;\n\tstruct opcode opcode;\n\n\tctxt->memop.type = OP_NONE;\n\tctxt->memopp = NULL;\n\tctxt->_eip = ctxt->eip;\n\tctxt->fetch.ptr = ctxt->fetch.data;\n\tctxt->fetch.end = ctxt->fetch.data + insn_len;\n\tctxt->opcode_len = 1;\n\tif (insn_len > 0)\n\t\tmemcpy(ctxt->fetch.data, insn, insn_len);\n\telse {\n\t\trc = __do_insn_fetch_bytes(ctxt, 1);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\treturn rc;\n\t}\n\n\tswitch (mode) {\n\tcase X86EMUL_MODE_REAL:\n\tcase X86EMUL_MODE_VM86:\n\tcase X86EMUL_MODE_PROT16:\n\t\tdef_op_bytes = def_ad_bytes = 2;\n\t\tbreak;\n\tcase X86EMUL_MODE_PROT32:\n\t\tdef_op_bytes = def_ad_bytes = 4;\n\t\tbreak;\n#ifdef CONFIG_X86_64\n\tcase X86EMUL_MODE_PROT64:\n\t\tdef_op_bytes = 4;\n\t\tdef_ad_bytes = 8;\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn EMULATION_FAILED;\n\t}\n\n\tctxt->op_bytes = def_op_bytes;\n\tctxt->ad_bytes = def_ad_bytes;\n\n\t/* Legacy prefixes. */\n\tfor (;;) {\n\t\tswitch (ctxt->b = insn_fetch(u8, ctxt)) {\n\t\tcase 0x66:\t/* operand-size override */\n\t\t\top_prefix = true;\n\t\t\t/* switch between 2/4 bytes */\n\t\t\tctxt->op_bytes = def_op_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x67:\t/* address-size override */\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\t/* switch between 4/8 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 12;\n\t\t\telse\n\t\t\t\t/* switch between 2/4 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x26:\t/* ES override */\n\t\tcase 0x2e:\t/* CS override */\n\t\tcase 0x36:\t/* SS override */\n\t\tcase 0x3e:\t/* DS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = (ctxt->b >> 3) & 3;\n\t\t\tbreak;\n\t\tcase 0x64:\t/* FS override */\n\t\tcase 0x65:\t/* GS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->b & 7;\n\t\t\tbreak;\n\t\tcase 0x40 ... 0x4f: /* REX */\n\t\t\tif (mode != X86EMUL_MODE_PROT64)\n\t\t\t\tgoto done_prefixes;\n\t\t\tctxt->rex_prefix = ctxt->b;\n\t\t\tcontinue;\n\t\tcase 0xf0:\t/* LOCK */\n\t\t\tctxt->lock_prefix = 1;\n\t\t\tbreak;\n\t\tcase 0xf2:\t/* REPNE/REPNZ */\n\t\tcase 0xf3:\t/* REP/REPE/REPZ */\n\t\t\tctxt->rep_prefix = ctxt->b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto done_prefixes;\n\t\t}\n\n\t\t/* Any legacy prefix after a REX prefix nullifies its effect. */\n\n\t\tctxt->rex_prefix = 0;\n\t}\n\ndone_prefixes:\n\n\t/* REX prefix. */\n\tif (ctxt->rex_prefix & 8)\n\t\tctxt->op_bytes = 8;\t/* REX.W */\n\n\t/* Opcode byte(s). */\n\topcode = opcode_table[ctxt->b];\n\t/* Two-byte opcode? */\n\tif (ctxt->b == 0x0f) {\n\t\tctxt->opcode_len = 2;\n\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\topcode = twobyte_table[ctxt->b];\n\n\t\t/* 0F_38 opcode map */\n\t\tif (ctxt->b == 0x38) {\n\t\t\tctxt->opcode_len = 3;\n\t\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\t\topcode = opcode_map_0f_38[ctxt->b];\n\t\t}\n\t}\n\tctxt->d = opcode.flags;\n\n\tif (ctxt->d & ModRM)\n\t\tctxt->modrm = insn_fetch(u8, ctxt);\n\n\t/* vex-prefix instructions are not implemented */\n\tif (ctxt->opcode_len == 1 && (ctxt->b == 0xc5 || ctxt->b == 0xc4) &&\n\t    (mode == X86EMUL_MODE_PROT64 || (ctxt->modrm & 0xc0) == 0xc0)) {\n\t\tctxt->d = NotImpl;\n\t}\n\n\twhile (ctxt->d & GroupMask) {\n\t\tswitch (ctxt->d & GroupMask) {\n\t\tcase Group:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase GroupDual:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.gdual->mod3[goffset];\n\t\t\telse\n\t\t\t\topcode = opcode.u.gdual->mod012[goffset];\n\t\t\tbreak;\n\t\tcase RMExt:\n\t\t\tgoffset = ctxt->modrm & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase Prefix:\n\t\t\tif (ctxt->rep_prefix && op_prefix)\n\t\t\t\treturn EMULATION_FAILED;\n\t\t\tsimd_prefix = op_prefix ? 0x66 : ctxt->rep_prefix;\n\t\t\tswitch (simd_prefix) {\n\t\t\tcase 0x00: opcode = opcode.u.gprefix->pfx_no; break;\n\t\t\tcase 0x66: opcode = opcode.u.gprefix->pfx_66; break;\n\t\t\tcase 0xf2: opcode = opcode.u.gprefix->pfx_f2; break;\n\t\t\tcase 0xf3: opcode = opcode.u.gprefix->pfx_f3; break;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Escape:\n\t\t\tif (ctxt->modrm > 0xbf)\n\t\t\t\topcode = opcode.u.esc->high[ctxt->modrm - 0xc0];\n\t\t\telse\n\t\t\t\topcode = opcode.u.esc->op[(ctxt->modrm >> 3) & 7];\n\t\t\tbreak;\n\t\tcase InstrDual:\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.idual->mod3;\n\t\t\telse\n\t\t\t\topcode = opcode.u.idual->mod012;\n\t\t\tbreak;\n\t\tcase ModeDual:\n\t\t\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\t\t\topcode = opcode.u.mdual->mode64;\n\t\t\telse\n\t\t\t\topcode = opcode.u.mdual->mode32;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn EMULATION_FAILED;\n\t\t}\n\n\t\tctxt->d &= ~(u64)GroupMask;\n\t\tctxt->d |= opcode.flags;\n\t}\n\n\t/* Unrecognised? */\n\tif (ctxt->d == 0)\n\t\treturn EMULATION_FAILED;\n\n\tctxt->execute = opcode.u.execute;\n\n\tif (unlikely(ctxt->ud) && likely(!(ctxt->d & EmulateOnUD)))\n\t\treturn EMULATION_FAILED;\n\n\tif (unlikely(ctxt->d &\n\t    (NotImpl|Stack|Op3264|Sse|Mmx|Intercept|CheckPerm|NearBranch|\n\t     No16))) {\n\t\t/*\n\t\t * These are copied unconditionally here, and checked unconditionally\n\t\t * in x86_emulate_insn.\n\t\t */\n\t\tctxt->check_perm = opcode.check_perm;\n\t\tctxt->intercept = opcode.intercept;\n\n\t\tif (ctxt->d & NotImpl)\n\t\t\treturn EMULATION_FAILED;\n\n\t\tif (mode == X86EMUL_MODE_PROT64) {\n\t\t\tif (ctxt->op_bytes == 4 && (ctxt->d & Stack))\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse if (ctxt->d & NearBranch)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t}\n\n\t\tif (ctxt->d & Op3264) {\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse\n\t\t\t\tctxt->op_bytes = 4;\n\t\t}\n\n\t\tif ((ctxt->d & No16) && ctxt->op_bytes == 2)\n\t\t\tctxt->op_bytes = 4;\n\n\t\tif (ctxt->d & Sse)\n\t\t\tctxt->op_bytes = 16;\n\t\telse if (ctxt->d & Mmx)\n\t\t\tctxt->op_bytes = 8;\n\t}\n\n\t/* ModRM and SIB bytes. */\n\tif (ctxt->d & ModRM) {\n\t\trc = decode_modrm(ctxt, &ctxt->memop);\n\t\tif (!has_seg_override) {\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->modrm_seg;\n\t\t}\n\t} else if (ctxt->d & MemAbs)\n\t\trc = decode_abs(ctxt, &ctxt->memop);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tif (!has_seg_override)\n\t\tctxt->seg_override = VCPU_SREG_DS;\n\n\tctxt->memop.addr.mem.seg = ctxt->seg_override;\n\n\t/*\n\t * Decode and fetch the source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src, (ctxt->d >> SrcShift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/*\n\t * Decode and fetch the second source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src2, (ctxt->d >> Src2Shift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/* Decode and fetch the destination operand: register or memory. */\n\trc = decode_operand(ctxt, &ctxt->dst, (ctxt->d >> DstShift) & OpMask);\n\n\tif (ctxt->rip_relative)\n\t\tctxt->memopp->addr.mem.ea = address_mask(ctxt,\n\t\t\t\t\tctxt->memopp->addr.mem.ea + ctxt->_eip);\n\ndone:\n\treturn (rc != X86EMUL_CONTINUE) ? EMULATION_FAILED : EMULATION_OK;\n}", "func_src_after": "int x86_decode_insn(struct x86_emulate_ctxt *ctxt, void *insn, int insn_len)\n{\n\tint rc = X86EMUL_CONTINUE;\n\tint mode = ctxt->mode;\n\tint def_op_bytes, def_ad_bytes, goffset, simd_prefix;\n\tbool op_prefix = false;\n\tbool has_seg_override = false;\n\tstruct opcode opcode;\n\n\tctxt->memop.type = OP_NONE;\n\tctxt->memopp = NULL;\n\tctxt->_eip = ctxt->eip;\n\tctxt->fetch.ptr = ctxt->fetch.data;\n\tctxt->fetch.end = ctxt->fetch.data + insn_len;\n\tctxt->opcode_len = 1;\n\tif (insn_len > 0)\n\t\tmemcpy(ctxt->fetch.data, insn, insn_len);\n\telse {\n\t\trc = __do_insn_fetch_bytes(ctxt, 1);\n\t\tif (rc != X86EMUL_CONTINUE)\n\t\t\treturn rc;\n\t}\n\n\tswitch (mode) {\n\tcase X86EMUL_MODE_REAL:\n\tcase X86EMUL_MODE_VM86:\n\tcase X86EMUL_MODE_PROT16:\n\t\tdef_op_bytes = def_ad_bytes = 2;\n\t\tbreak;\n\tcase X86EMUL_MODE_PROT32:\n\t\tdef_op_bytes = def_ad_bytes = 4;\n\t\tbreak;\n#ifdef CONFIG_X86_64\n\tcase X86EMUL_MODE_PROT64:\n\t\tdef_op_bytes = 4;\n\t\tdef_ad_bytes = 8;\n\t\tbreak;\n#endif\n\tdefault:\n\t\treturn EMULATION_FAILED;\n\t}\n\n\tctxt->op_bytes = def_op_bytes;\n\tctxt->ad_bytes = def_ad_bytes;\n\n\t/* Legacy prefixes. */\n\tfor (;;) {\n\t\tswitch (ctxt->b = insn_fetch(u8, ctxt)) {\n\t\tcase 0x66:\t/* operand-size override */\n\t\t\top_prefix = true;\n\t\t\t/* switch between 2/4 bytes */\n\t\t\tctxt->op_bytes = def_op_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x67:\t/* address-size override */\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\t/* switch between 4/8 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 12;\n\t\t\telse\n\t\t\t\t/* switch between 2/4 bytes */\n\t\t\t\tctxt->ad_bytes = def_ad_bytes ^ 6;\n\t\t\tbreak;\n\t\tcase 0x26:\t/* ES override */\n\t\tcase 0x2e:\t/* CS override */\n\t\tcase 0x36:\t/* SS override */\n\t\tcase 0x3e:\t/* DS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = (ctxt->b >> 3) & 3;\n\t\t\tbreak;\n\t\tcase 0x64:\t/* FS override */\n\t\tcase 0x65:\t/* GS override */\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->b & 7;\n\t\t\tbreak;\n\t\tcase 0x40 ... 0x4f: /* REX */\n\t\t\tif (mode != X86EMUL_MODE_PROT64)\n\t\t\t\tgoto done_prefixes;\n\t\t\tctxt->rex_prefix = ctxt->b;\n\t\t\tcontinue;\n\t\tcase 0xf0:\t/* LOCK */\n\t\t\tctxt->lock_prefix = 1;\n\t\t\tbreak;\n\t\tcase 0xf2:\t/* REPNE/REPNZ */\n\t\tcase 0xf3:\t/* REP/REPE/REPZ */\n\t\t\tctxt->rep_prefix = ctxt->b;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tgoto done_prefixes;\n\t\t}\n\n\t\t/* Any legacy prefix after a REX prefix nullifies its effect. */\n\n\t\tctxt->rex_prefix = 0;\n\t}\n\ndone_prefixes:\n\n\t/* REX prefix. */\n\tif (ctxt->rex_prefix & 8)\n\t\tctxt->op_bytes = 8;\t/* REX.W */\n\n\t/* Opcode byte(s). */\n\topcode = opcode_table[ctxt->b];\n\t/* Two-byte opcode? */\n\tif (ctxt->b == 0x0f) {\n\t\tctxt->opcode_len = 2;\n\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\topcode = twobyte_table[ctxt->b];\n\n\t\t/* 0F_38 opcode map */\n\t\tif (ctxt->b == 0x38) {\n\t\t\tctxt->opcode_len = 3;\n\t\t\tctxt->b = insn_fetch(u8, ctxt);\n\t\t\topcode = opcode_map_0f_38[ctxt->b];\n\t\t}\n\t}\n\tctxt->d = opcode.flags;\n\n\tif (ctxt->d & ModRM)\n\t\tctxt->modrm = insn_fetch(u8, ctxt);\n\n\t/* vex-prefix instructions are not implemented */\n\tif (ctxt->opcode_len == 1 && (ctxt->b == 0xc5 || ctxt->b == 0xc4) &&\n\t    (mode == X86EMUL_MODE_PROT64 || (ctxt->modrm & 0xc0) == 0xc0)) {\n\t\tctxt->d = NotImpl;\n\t}\n\n\twhile (ctxt->d & GroupMask) {\n\t\tswitch (ctxt->d & GroupMask) {\n\t\tcase Group:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase GroupDual:\n\t\t\tgoffset = (ctxt->modrm >> 3) & 7;\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.gdual->mod3[goffset];\n\t\t\telse\n\t\t\t\topcode = opcode.u.gdual->mod012[goffset];\n\t\t\tbreak;\n\t\tcase RMExt:\n\t\t\tgoffset = ctxt->modrm & 7;\n\t\t\topcode = opcode.u.group[goffset];\n\t\t\tbreak;\n\t\tcase Prefix:\n\t\t\tif (ctxt->rep_prefix && op_prefix)\n\t\t\t\treturn EMULATION_FAILED;\n\t\t\tsimd_prefix = op_prefix ? 0x66 : ctxt->rep_prefix;\n\t\t\tswitch (simd_prefix) {\n\t\t\tcase 0x00: opcode = opcode.u.gprefix->pfx_no; break;\n\t\t\tcase 0x66: opcode = opcode.u.gprefix->pfx_66; break;\n\t\t\tcase 0xf2: opcode = opcode.u.gprefix->pfx_f2; break;\n\t\t\tcase 0xf3: opcode = opcode.u.gprefix->pfx_f3; break;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase Escape:\n\t\t\tif (ctxt->modrm > 0xbf)\n\t\t\t\topcode = opcode.u.esc->high[ctxt->modrm - 0xc0];\n\t\t\telse\n\t\t\t\topcode = opcode.u.esc->op[(ctxt->modrm >> 3) & 7];\n\t\t\tbreak;\n\t\tcase InstrDual:\n\t\t\tif ((ctxt->modrm >> 6) == 3)\n\t\t\t\topcode = opcode.u.idual->mod3;\n\t\t\telse\n\t\t\t\topcode = opcode.u.idual->mod012;\n\t\t\tbreak;\n\t\tcase ModeDual:\n\t\t\tif (ctxt->mode == X86EMUL_MODE_PROT64)\n\t\t\t\topcode = opcode.u.mdual->mode64;\n\t\t\telse\n\t\t\t\topcode = opcode.u.mdual->mode32;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\treturn EMULATION_FAILED;\n\t\t}\n\n\t\tctxt->d &= ~(u64)GroupMask;\n\t\tctxt->d |= opcode.flags;\n\t}\n\n\t/* Unrecognised? */\n\tif (ctxt->d == 0)\n\t\treturn EMULATION_FAILED;\n\n\tctxt->execute = opcode.u.execute;\n\n\tif (unlikely(ctxt->ud) && likely(!(ctxt->d & EmulateOnUD)))\n\t\treturn EMULATION_FAILED;\n\n\tif (unlikely(ctxt->d &\n\t    (NotImpl|Stack|Op3264|Sse|Mmx|Intercept|CheckPerm|NearBranch|\n\t     No16))) {\n\t\t/*\n\t\t * These are copied unconditionally here, and checked unconditionally\n\t\t * in x86_emulate_insn.\n\t\t */\n\t\tctxt->check_perm = opcode.check_perm;\n\t\tctxt->intercept = opcode.intercept;\n\n\t\tif (ctxt->d & NotImpl)\n\t\t\treturn EMULATION_FAILED;\n\n\t\tif (mode == X86EMUL_MODE_PROT64) {\n\t\t\tif (ctxt->op_bytes == 4 && (ctxt->d & Stack))\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse if (ctxt->d & NearBranch)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t}\n\n\t\tif (ctxt->d & Op3264) {\n\t\t\tif (mode == X86EMUL_MODE_PROT64)\n\t\t\t\tctxt->op_bytes = 8;\n\t\t\telse\n\t\t\t\tctxt->op_bytes = 4;\n\t\t}\n\n\t\tif ((ctxt->d & No16) && ctxt->op_bytes == 2)\n\t\t\tctxt->op_bytes = 4;\n\n\t\tif (ctxt->d & Sse)\n\t\t\tctxt->op_bytes = 16;\n\t\telse if (ctxt->d & Mmx)\n\t\t\tctxt->op_bytes = 8;\n\t}\n\n\t/* ModRM and SIB bytes. */\n\tif (ctxt->d & ModRM) {\n\t\trc = decode_modrm(ctxt, &ctxt->memop);\n\t\tif (!has_seg_override) {\n\t\t\thas_seg_override = true;\n\t\t\tctxt->seg_override = ctxt->modrm_seg;\n\t\t}\n\t} else if (ctxt->d & MemAbs)\n\t\trc = decode_abs(ctxt, &ctxt->memop);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\tif (!has_seg_override)\n\t\tctxt->seg_override = VCPU_SREG_DS;\n\n\tctxt->memop.addr.mem.seg = ctxt->seg_override;\n\n\t/*\n\t * Decode and fetch the source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src, (ctxt->d >> SrcShift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/*\n\t * Decode and fetch the second source operand: register, memory\n\t * or immediate.\n\t */\n\trc = decode_operand(ctxt, &ctxt->src2, (ctxt->d >> Src2Shift) & OpMask);\n\tif (rc != X86EMUL_CONTINUE)\n\t\tgoto done;\n\n\t/* Decode and fetch the destination operand: register or memory. */\n\trc = decode_operand(ctxt, &ctxt->dst, (ctxt->d >> DstShift) & OpMask);\n\n\tif (ctxt->rip_relative && likely(ctxt->memopp))\n\t\tctxt->memopp->addr.mem.ea = address_mask(ctxt,\n\t\t\t\t\tctxt->memopp->addr.mem.ea + ctxt->_eip);\n\ndone:\n\treturn (rc != X86EMUL_CONTINUE) ? EMULATION_FAILED : EMULATION_OK;\n}", "commit_link": "github.com/torvalds/linux/commit/d9092f52d7e61dd1557f2db2400ddb430e85937e", "file_name": "arch/x86/kvm/emulate.c", "vul_type": "cwe-476", "description": "Write a C function named `x86_decode_insn` that decodes an x86 instruction from a given context, instruction pointer, and length."}
{"func_name": "prplcb_xfer_new_send_cb", "func_src_before": "static gboolean prplcb_xfer_new_send_cb(gpointer data, gint fd, b_input_condition cond)\n{\n\tPurpleXfer *xfer = data;\n\tstruct im_connection *ic = purple_ic_by_pa(xfer->account);\n\tstruct prpl_xfer_data *px = xfer->ui_data;\n\tPurpleBuddy *buddy;\n\tconst char *who;\n\n\tbuddy = purple_find_buddy(xfer->account, xfer->who);\n\twho = buddy ? purple_buddy_get_name(buddy) : xfer->who;\n\n\t/* TODO(wilmer): After spreading some more const goodness in BitlBee,\n\t   remove the evil cast below. */\n\tpx->ft = imcb_file_send_start(ic, (char *) who, xfer->filename, xfer->size);\n\tpx->ft->data = px;\n\n\tpx->ft->accept = prpl_xfer_accept;\n\tpx->ft->canceled = prpl_xfer_canceled;\n\tpx->ft->free = prpl_xfer_free;\n\tpx->ft->write_request = prpl_xfer_write_request;\n\n\treturn FALSE;\n}", "func_src_after": "static gboolean prplcb_xfer_new_send_cb(gpointer data, gint fd, b_input_condition cond)\n{\n\tPurpleXfer *xfer = data;\n\tstruct im_connection *ic = purple_ic_by_pa(xfer->account);\n\tstruct prpl_xfer_data *px = xfer->ui_data;\n\tPurpleBuddy *buddy;\n\tconst char *who;\n\n\tbuddy = purple_find_buddy(xfer->account, xfer->who);\n\twho = buddy ? purple_buddy_get_name(buddy) : xfer->who;\n\n\t/* TODO(wilmer): After spreading some more const goodness in BitlBee,\n\t   remove the evil cast below. */\n\tpx->ft = imcb_file_send_start(ic, (char *) who, xfer->filename, xfer->size);\n\n\tif (!px->ft) {\n\t\treturn FALSE;\n\t}\n\tpx->ft->data = px;\n\n\tpx->ft->accept = prpl_xfer_accept;\n\tpx->ft->canceled = prpl_xfer_canceled;\n\tpx->ft->free = prpl_xfer_free;\n\tpx->ft->write_request = prpl_xfer_write_request;\n\n\treturn FALSE;\n}", "commit_link": "github.com/bitlbee/bitlbee/commit/30d598ce7cd3f136ee9d7097f39fa9818a272441", "file_name": "protocols/purple/ft.c", "vul_type": "cwe-476", "description": "Write a C function to initialize a file transfer callback in the BitlBee instant messaging client."}
{"func_name": "get_article", "func_src_before": "def get_article(index):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE index=\"+str(index)\n        cur.execute(query)\n        article = cur.fetchone()\n        return article", "func_src_after": "def get_article(index):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE index=%s\"\n        cur.execute(query, (index, ))\n        article = cur.fetchone()\n        return article", "commit_link": "github.com/sepehr125/arxiv-doc2vec-recommender/commit/f23a4c32e6192b145017f64734b0a9a384c9123a", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python function named `get_article` that retrieves a single article from a database using its index."}
{"func_name": "ipv4_pktinfo_prepare", "func_src_before": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\tskb_dst_drop(skb);\n}", "func_src_after": "void ipv4_pktinfo_prepare(const struct sock *sk, struct sk_buff *skb)\n{\n\tstruct in_pktinfo *pktinfo = PKTINFO_SKB_CB(skb);\n\tbool prepare = (inet_sk(sk)->cmsg_flags & IP_CMSG_PKTINFO) ||\n\t\t       ipv6_sk_rxinfo(sk);\n\n\tif (prepare && skb_rtable(skb)) {\n\t\t/* skb->cb is overloaded: prior to this point it is IP{6}CB\n\t\t * which has interface index (iif) as the first member of the\n\t\t * underlying inet{6}_skb_parm struct. This code then overlays\n\t\t * PKTINFO_SKB_CB and in_pktinfo also has iif as the first\n\t\t * element so the iif is picked up from the prior IPCB. If iif\n\t\t * is the loopback interface, then return the sending interface\n\t\t * (e.g., process binds socket to eth0 for Tx which is\n\t\t * redirected to loopback in the rtable/dst).\n\t\t */\n\t\tif (pktinfo->ipi_ifindex == LOOPBACK_IFINDEX)\n\t\t\tpktinfo->ipi_ifindex = inet_iif(skb);\n\n\t\tpktinfo->ipi_spec_dst.s_addr = fib_compute_spec_dst(skb);\n\t} else {\n\t\tpktinfo->ipi_ifindex = 0;\n\t\tpktinfo->ipi_spec_dst.s_addr = 0;\n\t}\n\t/* We need to keep the dst for __ip_options_echo()\n\t * We could restrict the test to opt.ts_needtime || opt.srr,\n\t * but the following is good enough as IP options are not often used.\n\t */\n\tif (unlikely(IPCB(skb)->opt.optlen))\n\t\tskb_dst_force(skb);\n\telse\n\t\tskb_dst_drop(skb);\n}", "commit_link": "github.com/torvalds/linux/commit/34b2cef20f19c87999fff3da4071e66937db9644", "file_name": "net/ipv4/ip_sockglue.c", "vul_type": "cwe-476", "description": "Write a C function named `ipv4_pktinfo_prepare` that prepares packet information for an IPv4 socket in a Linux kernel environment."}
{"func_name": "_download_file", "func_src_before": "    @staticmethod\n    def _download_file(bucket, filename, local_dir):\n        key = bucket.get_key(filename)\n        local_filename = os.path.join(local_dir, filename)\n        key.get_contents_to_filename(local_filename)\n        return local_filename", "func_src_after": "    @staticmethod\n    def _download_file(bucket, filename, local_dir):\n        key = bucket.get_key(filename)\n        local_filename = os.path.join(local_dir, os.path.basename(filename))\n        key.get_contents_to_filename(local_filename)\n        return local_filename", "commit_link": "github.com/openstack/nova/commit/76363226bd8533256f7795bba358d7f4b8a6c9e6", "file_name": "nova/image/s3.py", "vul_type": "cwe-022", "description": "Write a Python method to download a file from an S3 bucket to a local directory."}
{"func_name": "IRC_PROTOCOL_CALLBACK", "func_src_before": "IRC_PROTOCOL_CALLBACK(352)\n{\n    char *pos_attr, *pos_hopcount, *pos_realname, *str_host;\n    int arg_start, length;\n    struct t_irc_channel *ptr_channel;\n    struct t_irc_nick *ptr_nick;\n\n    IRC_PROTOCOL_MIN_ARGS(5);\n\n    /* silently ignore malformed 352 message (missing infos) */\n    if (argc < 8)\n        return WEECHAT_RC_OK;\n\n    pos_attr = NULL;\n    pos_hopcount = NULL;\n    pos_realname = NULL;\n\n    if (argc > 8)\n    {\n        arg_start = (strcmp (argv[8], \"*\") == 0) ? 9 : 8;\n        if (argv[arg_start][0] == ':')\n        {\n            pos_attr = NULL;\n            pos_hopcount = (argc > arg_start) ? argv[arg_start] + 1 : NULL;\n            pos_realname = (argc > arg_start + 1) ? argv_eol[arg_start + 1] : NULL;\n        }\n        else\n        {\n            pos_attr = argv[arg_start];\n            pos_hopcount = (argc > arg_start + 1) ? argv[arg_start + 1] + 1 : NULL;\n            pos_realname = (argc > arg_start + 2) ? argv_eol[arg_start + 2] : NULL;\n        }\n    }\n\n    ptr_channel = irc_channel_search (server, argv[3]);\n    ptr_nick = (ptr_channel) ?\n        irc_nick_search (server, ptr_channel, argv[7]) : NULL;\n\n    /* update host in nick */\n    if (ptr_nick)\n    {\n        length = strlen (argv[4]) + 1 + strlen (argv[5]) + 1;\n        str_host = malloc (length);\n        if (str_host)\n        {\n            snprintf (str_host, length, \"%s@%s\", argv[4], argv[5]);\n            irc_nick_set_host (ptr_nick, str_host);\n            free (str_host);\n        }\n    }\n\n    /* update away flag in nick */\n    if (ptr_channel && ptr_nick && pos_attr)\n    {\n        irc_nick_set_away (server, ptr_channel, ptr_nick,\n                           (pos_attr[0] == 'G') ? 1 : 0);\n    }\n\n    /* update realname in nick */\n    if (ptr_channel && ptr_nick && pos_realname)\n    {\n        if (ptr_nick->realname)\n            free (ptr_nick->realname);\n        if (pos_realname &&\n            weechat_hashtable_has_key (server->cap_list, \"extended-join\"))\n        {\n            ptr_nick->realname = strdup (pos_realname);\n        }\n        else\n        {\n            ptr_nick->realname = NULL;\n        }\n    }\n\n    /* display output of who (manual who from user) */\n    if (!ptr_channel || (ptr_channel->checking_whox <= 0))\n    {\n        weechat_printf_date_tags (\n            irc_msgbuffer_get_target_buffer (\n                server, NULL, command, \"who\", NULL),\n            date,\n            irc_protocol_tags (command, \"irc_numeric\", NULL, NULL),\n            \"%s%s[%s%s%s] %s%s %s(%s%s@%s%s)%s %s%s%s%s(%s)\",\n            weechat_prefix (\"network\"),\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_CHAT_CHANNEL,\n            argv[3],\n            IRC_COLOR_CHAT_DELIMITERS,\n            irc_nick_color_for_msg (server, 1, NULL, argv[7]),\n            argv[7],\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_CHAT_HOST,\n            argv[4],\n            argv[5],\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_RESET,\n            (pos_attr) ? pos_attr : \"\",\n            (pos_attr) ? \" \" : \"\",\n            (pos_hopcount) ? pos_hopcount : \"\",\n            (pos_hopcount) ? \" \" : \"\",\n            (pos_realname) ? pos_realname : \"\");\n    }\n\n    return WEECHAT_RC_OK;\n}", "func_src_after": "IRC_PROTOCOL_CALLBACK(352)\n{\n    char *pos_attr, *pos_hopcount, *pos_realname, *str_host;\n    int arg_start, length;\n    struct t_irc_channel *ptr_channel;\n    struct t_irc_nick *ptr_nick;\n\n    IRC_PROTOCOL_MIN_ARGS(5);\n\n    /* silently ignore malformed 352 message (missing infos) */\n    if (argc < 8)\n        return WEECHAT_RC_OK;\n\n    pos_attr = NULL;\n    pos_hopcount = NULL;\n    pos_realname = NULL;\n\n    if (argc > 8)\n    {\n        arg_start = ((argc > 9) && (strcmp (argv[8], \"*\") == 0)) ? 9 : 8;\n        if (argv[arg_start][0] == ':')\n        {\n            pos_attr = NULL;\n            pos_hopcount = (argc > arg_start) ? argv[arg_start] + 1 : NULL;\n            pos_realname = (argc > arg_start + 1) ? argv_eol[arg_start + 1] : NULL;\n        }\n        else\n        {\n            pos_attr = argv[arg_start];\n            pos_hopcount = (argc > arg_start + 1) ? argv[arg_start + 1] + 1 : NULL;\n            pos_realname = (argc > arg_start + 2) ? argv_eol[arg_start + 2] : NULL;\n        }\n    }\n\n    ptr_channel = irc_channel_search (server, argv[3]);\n    ptr_nick = (ptr_channel) ?\n        irc_nick_search (server, ptr_channel, argv[7]) : NULL;\n\n    /* update host in nick */\n    if (ptr_nick)\n    {\n        length = strlen (argv[4]) + 1 + strlen (argv[5]) + 1;\n        str_host = malloc (length);\n        if (str_host)\n        {\n            snprintf (str_host, length, \"%s@%s\", argv[4], argv[5]);\n            irc_nick_set_host (ptr_nick, str_host);\n            free (str_host);\n        }\n    }\n\n    /* update away flag in nick */\n    if (ptr_channel && ptr_nick && pos_attr)\n    {\n        irc_nick_set_away (server, ptr_channel, ptr_nick,\n                           (pos_attr[0] == 'G') ? 1 : 0);\n    }\n\n    /* update realname in nick */\n    if (ptr_channel && ptr_nick && pos_realname)\n    {\n        if (ptr_nick->realname)\n            free (ptr_nick->realname);\n        if (pos_realname &&\n            weechat_hashtable_has_key (server->cap_list, \"extended-join\"))\n        {\n            ptr_nick->realname = strdup (pos_realname);\n        }\n        else\n        {\n            ptr_nick->realname = NULL;\n        }\n    }\n\n    /* display output of who (manual who from user) */\n    if (!ptr_channel || (ptr_channel->checking_whox <= 0))\n    {\n        weechat_printf_date_tags (\n            irc_msgbuffer_get_target_buffer (\n                server, NULL, command, \"who\", NULL),\n            date,\n            irc_protocol_tags (command, \"irc_numeric\", NULL, NULL),\n            \"%s%s[%s%s%s] %s%s %s(%s%s@%s%s)%s %s%s%s%s(%s)\",\n            weechat_prefix (\"network\"),\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_CHAT_CHANNEL,\n            argv[3],\n            IRC_COLOR_CHAT_DELIMITERS,\n            irc_nick_color_for_msg (server, 1, NULL, argv[7]),\n            argv[7],\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_CHAT_HOST,\n            argv[4],\n            argv[5],\n            IRC_COLOR_CHAT_DELIMITERS,\n            IRC_COLOR_RESET,\n            (pos_attr) ? pos_attr : \"\",\n            (pos_attr) ? \" \" : \"\",\n            (pos_hopcount) ? pos_hopcount : \"\",\n            (pos_hopcount) ? \" \" : \"\",\n            (pos_realname) ? pos_realname : \"\");\n    }\n\n    return WEECHAT_RC_OK;\n}", "commit_link": "github.com/weechat/weechat/commit/9904cb6d2eb40f679d8ff6557c22d53a3e3dc75a", "file_name": "src/plugins/irc/irc-protocol.c", "vul_type": "cwe-476", "description": "In C, write a function to handle IRC protocol 352 messages, parsing user details and updating channel and nick information."}
{"func_name": "futex_requeue", "func_src_before": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "func_src_after": "static int futex_requeue(u32 __user *uaddr1, unsigned int flags,\n\t\t\t u32 __user *uaddr2, int nr_wake, int nr_requeue,\n\t\t\t u32 *cmpval, int requeue_pi)\n{\n\tunion futex_key key1 = FUTEX_KEY_INIT, key2 = FUTEX_KEY_INIT;\n\tint drop_count = 0, task_count = 0, ret;\n\tstruct futex_pi_state *pi_state = NULL;\n\tstruct futex_hash_bucket *hb1, *hb2;\n\tstruct futex_q *this, *next;\n\tDEFINE_WAKE_Q(wake_q);\n\n\tif (nr_wake < 0 || nr_requeue < 0)\n\t\treturn -EINVAL;\n\n\t/*\n\t * When PI not supported: return -ENOSYS if requeue_pi is true,\n\t * consequently the compiler knows requeue_pi is always false past\n\t * this point which will optimize away all the conditional code\n\t * further down.\n\t */\n\tif (!IS_ENABLED(CONFIG_FUTEX_PI) && requeue_pi)\n\t\treturn -ENOSYS;\n\n\tif (requeue_pi) {\n\t\t/*\n\t\t * Requeue PI only works on two distinct uaddrs. This\n\t\t * check is only valid for private futexes. See below.\n\t\t */\n\t\tif (uaddr1 == uaddr2)\n\t\t\treturn -EINVAL;\n\n\t\t/*\n\t\t * requeue_pi requires a pi_state, try to allocate it now\n\t\t * without any locks in case it fails.\n\t\t */\n\t\tif (refill_pi_state_cache())\n\t\t\treturn -ENOMEM;\n\t\t/*\n\t\t * requeue_pi must wake as many tasks as it can, up to nr_wake\n\t\t * + nr_requeue, since it acquires the rt_mutex prior to\n\t\t * returning to userspace, so as to not leave the rt_mutex with\n\t\t * waiters and no owner.  However, second and third wake-ups\n\t\t * cannot be predicted as they involve race conditions with the\n\t\t * first wake and a fault while looking up the pi_state.  Both\n\t\t * pthread_cond_signal() and pthread_cond_broadcast() should\n\t\t * use nr_wake=1.\n\t\t */\n\t\tif (nr_wake != 1)\n\t\t\treturn -EINVAL;\n\t}\n\nretry:\n\tret = get_futex_key(uaddr1, flags & FLAGS_SHARED, &key1, VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out;\n\tret = get_futex_key(uaddr2, flags & FLAGS_SHARED, &key2,\n\t\t\t    requeue_pi ? VERIFY_WRITE : VERIFY_READ);\n\tif (unlikely(ret != 0))\n\t\tgoto out_put_key1;\n\n\t/*\n\t * The check above which compares uaddrs is not sufficient for\n\t * shared futexes. We need to compare the keys:\n\t */\n\tif (requeue_pi && match_futex(&key1, &key2)) {\n\t\tret = -EINVAL;\n\t\tgoto out_put_keys;\n\t}\n\n\thb1 = hash_futex(&key1);\n\thb2 = hash_futex(&key2);\n\nretry_private:\n\thb_waiters_inc(hb2);\n\tdouble_lock_hb(hb1, hb2);\n\n\tif (likely(cmpval != NULL)) {\n\t\tu32 curval;\n\n\t\tret = get_futex_value_locked(&curval, uaddr1);\n\n\t\tif (unlikely(ret)) {\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\n\t\t\tret = get_user(curval, uaddr1);\n\t\t\tif (ret)\n\t\t\t\tgoto out_put_keys;\n\n\t\t\tif (!(flags & FLAGS_SHARED))\n\t\t\t\tgoto retry_private;\n\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tgoto retry;\n\t\t}\n\t\tif (curval != *cmpval) {\n\t\t\tret = -EAGAIN;\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tif (requeue_pi && (task_count - nr_wake < nr_requeue)) {\n\t\t/*\n\t\t * Attempt to acquire uaddr2 and wake the top waiter. If we\n\t\t * intend to requeue waiters, force setting the FUTEX_WAITERS\n\t\t * bit.  We force this here where we are able to easily handle\n\t\t * faults rather in the requeue loop below.\n\t\t */\n\t\tret = futex_proxy_trylock_atomic(uaddr2, hb1, hb2, &key1,\n\t\t\t\t\t\t &key2, &pi_state, nr_requeue);\n\n\t\t/*\n\t\t * At this point the top_waiter has either taken uaddr2 or is\n\t\t * waiting on it.  If the former, then the pi_state will not\n\t\t * exist yet, look it up one more time to ensure we have a\n\t\t * reference to it. If the lock was taken, ret contains the\n\t\t * vpid of the top waiter task.\n\t\t * If the lock was not taken, we have pi_state and an initial\n\t\t * refcount on it. In case of an error we have nothing.\n\t\t */\n\t\tif (ret > 0) {\n\t\t\tWARN_ON(pi_state);\n\t\t\tdrop_count++;\n\t\t\ttask_count++;\n\t\t\t/*\n\t\t\t * If we acquired the lock, then the user space value\n\t\t\t * of uaddr2 should be vpid. It cannot be changed by\n\t\t\t * the top waiter as it is blocked on hb2 lock if it\n\t\t\t * tries to do so. If something fiddled with it behind\n\t\t\t * our back the pi state lookup might unearth it. So\n\t\t\t * we rather use the known value than rereading and\n\t\t\t * handing potential crap to lookup_pi_state.\n\t\t\t *\n\t\t\t * If that call succeeds then we have pi_state and an\n\t\t\t * initial refcount on it.\n\t\t\t */\n\t\t\tret = lookup_pi_state(uaddr2, ret, hb2, &key2, &pi_state);\n\t\t}\n\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\t/* We hold a reference on the pi state. */\n\t\t\tbreak;\n\n\t\t\t/* If the above failed, then pi_state is NULL */\n\t\tcase -EFAULT:\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tret = fault_in_user_writeable(uaddr2);\n\t\t\tif (!ret)\n\t\t\t\tgoto retry;\n\t\t\tgoto out;\n\t\tcase -EAGAIN:\n\t\t\t/*\n\t\t\t * Two reasons for this:\n\t\t\t * - Owner is exiting and we just wait for the\n\t\t\t *   exit to complete.\n\t\t\t * - The user space value changed.\n\t\t\t */\n\t\t\tdouble_unlock_hb(hb1, hb2);\n\t\t\thb_waiters_dec(hb2);\n\t\t\tput_futex_key(&key2);\n\t\t\tput_futex_key(&key1);\n\t\t\tcond_resched();\n\t\t\tgoto retry;\n\t\tdefault:\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tplist_for_each_entry_safe(this, next, &hb1->chain, list) {\n\t\tif (task_count - nr_wake >= nr_requeue)\n\t\t\tbreak;\n\n\t\tif (!match_futex(&this->key, &key1))\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * FUTEX_WAIT_REQEUE_PI and FUTEX_CMP_REQUEUE_PI should always\n\t\t * be paired with each other and no other futex ops.\n\t\t *\n\t\t * We should never be requeueing a futex_q with a pi_state,\n\t\t * which is awaiting a futex_unlock_pi().\n\t\t */\n\t\tif ((requeue_pi && !this->rt_waiter) ||\n\t\t    (!requeue_pi && this->rt_waiter) ||\n\t\t    this->pi_state) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Wake nr_wake waiters.  For requeue_pi, if we acquired the\n\t\t * lock, we already woke the top_waiter.  If not, it will be\n\t\t * woken by futex_unlock_pi().\n\t\t */\n\t\tif (++task_count <= nr_wake && !requeue_pi) {\n\t\t\tmark_wake_futex(&wake_q, this);\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Ensure we requeue to the expected futex for requeue_pi. */\n\t\tif (requeue_pi && !match_futex(this->requeue_pi_key, &key2)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\t/*\n\t\t * Requeue nr_requeue waiters and possibly one more in the case\n\t\t * of requeue_pi if we couldn't acquire the lock atomically.\n\t\t */\n\t\tif (requeue_pi) {\n\t\t\t/*\n\t\t\t * Prepare the waiter to take the rt_mutex. Take a\n\t\t\t * refcount on the pi_state and store the pointer in\n\t\t\t * the futex_q object of the waiter.\n\t\t\t */\n\t\t\tget_pi_state(pi_state);\n\t\t\tthis->pi_state = pi_state;\n\t\t\tret = rt_mutex_start_proxy_lock(&pi_state->pi_mutex,\n\t\t\t\t\t\t\tthis->rt_waiter,\n\t\t\t\t\t\t\tthis->task);\n\t\t\tif (ret == 1) {\n\t\t\t\t/*\n\t\t\t\t * We got the lock. We do neither drop the\n\t\t\t\t * refcount on pi_state nor clear\n\t\t\t\t * this->pi_state because the waiter needs the\n\t\t\t\t * pi_state for cleaning up the user space\n\t\t\t\t * value. It will drop the refcount after\n\t\t\t\t * doing so.\n\t\t\t\t */\n\t\t\t\trequeue_pi_wake_futex(this, &key2, hb2);\n\t\t\t\tdrop_count++;\n\t\t\t\tcontinue;\n\t\t\t} else if (ret) {\n\t\t\t\t/*\n\t\t\t\t * rt_mutex_start_proxy_lock() detected a\n\t\t\t\t * potential deadlock when we tried to queue\n\t\t\t\t * that waiter. Drop the pi_state reference\n\t\t\t\t * which we took above and remove the pointer\n\t\t\t\t * to the state from the waiters futex_q\n\t\t\t\t * object.\n\t\t\t\t */\n\t\t\t\tthis->pi_state = NULL;\n\t\t\t\tput_pi_state(pi_state);\n\t\t\t\t/*\n\t\t\t\t * We stop queueing more waiters and let user\n\t\t\t\t * space deal with the mess.\n\t\t\t\t */\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\trequeue_futex(this, hb1, hb2, &key2);\n\t\tdrop_count++;\n\t}\n\n\t/*\n\t * We took an extra initial reference to the pi_state either\n\t * in futex_proxy_trylock_atomic() or in lookup_pi_state(). We\n\t * need to drop it here again.\n\t */\n\tput_pi_state(pi_state);\n\nout_unlock:\n\tdouble_unlock_hb(hb1, hb2);\n\twake_up_q(&wake_q);\n\thb_waiters_dec(hb2);\n\n\t/*\n\t * drop_futex_key_refs() must be called outside the spinlocks. During\n\t * the requeue we moved futex_q's from the hash bucket at key1 to the\n\t * one at key2 and updated their key pointer.  We no longer need to\n\t * hold the references to key1.\n\t */\n\twhile (--drop_count >= 0)\n\t\tdrop_futex_key_refs(&key1);\n\nout_put_keys:\n\tput_futex_key(&key2);\nout_put_key1:\n\tput_futex_key(&key1);\nout:\n\treturn ret ? ret : task_count;\n}", "commit_link": "github.com/torvalds/linux/commit/fbe0e839d1e22d88810f3ee3e2f1479be4c0aa4a", "file_name": "kernel/futex.c", "vul_type": "cwe-190", "description": "Write a C function named `futex_requeue` that manages the requeueing of futexes, potentially involving priority inheritance logic."}
{"func_name": "ssl_parse_server_psk_hint", "func_src_before": "static int ssl_parse_server_psk_hint( mbedtls_ssl_context *ssl,\n                                      unsigned char **p,\n                                      unsigned char *end )\n{\n    int ret = MBEDTLS_ERR_SSL_FEATURE_UNAVAILABLE;\n    size_t  len;\n    ((void) ssl);\n\n    /*\n     * PSK parameters:\n     *\n     * opaque psk_identity_hint<0..2^16-1>;\n     */\n    if( (*p) > end - 2 )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n    len = (*p)[0] << 8 | (*p)[1];\n    *p += 2;\n\n    if( (*p) + len > end )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n\n    /*\n     * Note: we currently ignore the PKS identity hint, as we only allow one\n     * PSK to be provisionned on the client. This could be changed later if\n     * someone needs that feature.\n     */\n    *p += len;\n    ret = 0;\n\n    return( ret );\n}", "func_src_after": "static int ssl_parse_server_psk_hint( mbedtls_ssl_context *ssl,\n                                      unsigned char **p,\n                                      unsigned char *end )\n{\n    int ret = MBEDTLS_ERR_SSL_FEATURE_UNAVAILABLE;\n    size_t  len;\n    ((void) ssl);\n\n    /*\n     * PSK parameters:\n     *\n     * opaque psk_identity_hint<0..2^16-1>;\n     */\n    if( (*p) > end - 2 )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n    len = (*p)[0] << 8 | (*p)[1];\n    *p += 2;\n\n    if( (*p) > end - len )\n    {\n        MBEDTLS_SSL_DEBUG_MSG( 1, ( \"bad server key exchange message \"\n                                    \"(psk_identity_hint length)\" ) );\n        return( MBEDTLS_ERR_SSL_BAD_HS_SERVER_KEY_EXCHANGE );\n    }\n\n    /*\n     * Note: we currently ignore the PKS identity hint, as we only allow one\n     * PSK to be provisionned on the client. This could be changed later if\n     * someone needs that feature.\n     */\n    *p += len;\n    ret = 0;\n\n    return( ret );\n}", "commit_link": "github.com/ARMmbed/mbedtls/commit/5224a7544c95552553e2e6be0b4a789956a6464e", "file_name": "library/ssl_cli.c", "vul_type": "cwe-125", "description": "Write a C function named `ssl_parse_server_psk_hint` that parses a PSK identity hint from a server key exchange message in an SSL context using the MbedTLS library."}
{"func_name": "decode_frame", "func_src_before": "static int decode_frame(AVCodecContext *avctx, void *data,\n                        int *got_frame, AVPacket *avpkt)\n{\n    EXRContext *s = avctx->priv_data;\n    ThreadFrame frame = { .f = data };\n    AVFrame *picture = data;\n    uint8_t *ptr;\n\n    int i, y, ret, ymax;\n    int planes;\n    int out_line_size;\n    int nb_blocks;   /* nb scanline or nb tile */\n    uint64_t start_offset_table;\n    uint64_t start_next_scanline;\n    PutByteContext offset_table_writer;\n\n    bytestream2_init(&s->gb, avpkt->data, avpkt->size);\n\n    if ((ret = decode_header(s, picture)) < 0)\n        return ret;\n\n    switch (s->pixel_type) {\n    case EXR_FLOAT:\n    case EXR_HALF:\n        if (s->channel_offsets[3] >= 0) {\n            if (!s->is_luma) {\n                avctx->pix_fmt = AV_PIX_FMT_GBRAPF32;\n            } else {\n                /* todo: change this when a floating point pixel format with luma with alpha is implemented */\n                avctx->pix_fmt = AV_PIX_FMT_GBRAPF32;\n            }\n        } else {\n            if (!s->is_luma) {\n                avctx->pix_fmt = AV_PIX_FMT_GBRPF32;\n            } else {\n                avctx->pix_fmt = AV_PIX_FMT_GRAYF32;\n            }\n        }\n        break;\n    case EXR_UINT:\n        if (s->channel_offsets[3] >= 0) {\n            if (!s->is_luma) {\n                avctx->pix_fmt = AV_PIX_FMT_RGBA64;\n            } else {\n                avctx->pix_fmt = AV_PIX_FMT_YA16;\n            }\n        } else {\n            if (!s->is_luma) {\n                avctx->pix_fmt = AV_PIX_FMT_RGB48;\n            } else {\n                avctx->pix_fmt = AV_PIX_FMT_GRAY16;\n            }\n        }\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"Missing channel list.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (s->apply_trc_type != AVCOL_TRC_UNSPECIFIED)\n        avctx->color_trc = s->apply_trc_type;\n\n    switch (s->compression) {\n    case EXR_RAW:\n    case EXR_RLE:\n    case EXR_ZIP1:\n        s->scan_lines_per_block = 1;\n        break;\n    case EXR_PXR24:\n    case EXR_ZIP16:\n        s->scan_lines_per_block = 16;\n        break;\n    case EXR_PIZ:\n    case EXR_B44:\n    case EXR_B44A:\n        s->scan_lines_per_block = 32;\n        break;\n    default:\n        avpriv_report_missing_feature(avctx, \"Compression %d\", s->compression);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    /* Verify the xmin, xmax, ymin and ymax before setting the actual image size.\n     * It's possible for the data window can larger or outside the display window */\n    if (s->xmin > s->xmax  || s->ymin > s->ymax ||\n        s->ydelta == 0xFFFFFFFF || s->xdelta == 0xFFFFFFFF) {\n        av_log(avctx, AV_LOG_ERROR, \"Wrong or missing size information.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if ((ret = ff_set_dimensions(avctx, s->w, s->h)) < 0)\n        return ret;\n\n    s->desc          = av_pix_fmt_desc_get(avctx->pix_fmt);\n    if (!s->desc)\n        return AVERROR_INVALIDDATA;\n\n    if (s->desc->flags & AV_PIX_FMT_FLAG_FLOAT) {\n        planes           = s->desc->nb_components;\n        out_line_size    = avctx->width * 4;\n    } else {\n        planes           = 1;\n        out_line_size    = avctx->width * 2 * s->desc->nb_components;\n    }\n\n    if (s->is_tile) {\n        nb_blocks = ((s->xdelta + s->tile_attr.xSize - 1) / s->tile_attr.xSize) *\n        ((s->ydelta + s->tile_attr.ySize - 1) / s->tile_attr.ySize);\n    } else { /* scanline */\n        nb_blocks = (s->ydelta + s->scan_lines_per_block - 1) /\n        s->scan_lines_per_block;\n    }\n\n    if ((ret = ff_thread_get_buffer(avctx, &frame, 0)) < 0)\n        return ret;\n\n    if (bytestream2_get_bytes_left(&s->gb)/8 < nb_blocks)\n        return AVERROR_INVALIDDATA;\n\n    // check offset table and recreate it if need\n    if (!s->is_tile && bytestream2_peek_le64(&s->gb) == 0) {\n        av_log(s->avctx, AV_LOG_DEBUG, \"recreating invalid scanline offset table\\n\");\n\n        start_offset_table = bytestream2_tell(&s->gb);\n        start_next_scanline = start_offset_table + nb_blocks * 8;\n        bytestream2_init_writer(&offset_table_writer, &avpkt->data[start_offset_table], nb_blocks * 8);\n\n        for (y = 0; y < nb_blocks; y++) {\n            /* write offset of prev scanline in offset table */\n            bytestream2_put_le64(&offset_table_writer, start_next_scanline);\n\n            /* get len of next scanline */\n            bytestream2_seek(&s->gb, start_next_scanline + 4, SEEK_SET);/* skip line number */\n            start_next_scanline += (bytestream2_get_le32(&s->gb) + 8);\n        }\n        bytestream2_seek(&s->gb, start_offset_table, SEEK_SET);\n    }\n\n    // save pointer we are going to use in decode_block\n    s->buf      = avpkt->data;\n    s->buf_size = avpkt->size;\n\n    // Zero out the start if ymin is not 0\n    for (i = 0; i < planes; i++) {\n        ptr = picture->data[i];\n        for (y = 0; y < s->ymin; y++) {\n            memset(ptr, 0, out_line_size);\n            ptr += picture->linesize[i];\n        }\n    }\n\n    s->picture = picture;\n\n    avctx->execute2(avctx, decode_block, s->thread_data, NULL, nb_blocks);\n\n    ymax = FFMAX(0, s->ymax + 1);\n    // Zero out the end if ymax+1 is not h\n    for (i = 0; i < planes; i++) {\n        ptr = picture->data[i] + (ymax * picture->linesize[i]);\n        for (y = ymax; y < avctx->height; y++) {\n            memset(ptr, 0, out_line_size);\n            ptr += picture->linesize[i];\n        }\n    }\n\n    picture->pict_type = AV_PICTURE_TYPE_I;\n    *got_frame = 1;\n\n    return avpkt->size;\n}", "func_src_after": "static int decode_frame(AVCodecContext *avctx, void *data,\n                        int *got_frame, AVPacket *avpkt)\n{\n    EXRContext *s = avctx->priv_data;\n    ThreadFrame frame = { .f = data };\n    AVFrame *picture = data;\n    uint8_t *ptr;\n\n    int i, y, ret, ymax;\n    int planes;\n    int out_line_size;\n    int nb_blocks;   /* nb scanline or nb tile */\n    uint64_t start_offset_table;\n    uint64_t start_next_scanline;\n    PutByteContext offset_table_writer;\n\n    bytestream2_init(&s->gb, avpkt->data, avpkt->size);\n\n    if ((ret = decode_header(s, picture)) < 0)\n        return ret;\n\n    switch (s->pixel_type) {\n    case EXR_FLOAT:\n    case EXR_HALF:\n        if (s->channel_offsets[3] >= 0) {\n            if (!s->is_luma) {\n                avctx->pix_fmt = AV_PIX_FMT_GBRAPF32;\n            } else {\n                /* todo: change this when a floating point pixel format with luma with alpha is implemented */\n                avctx->pix_fmt = AV_PIX_FMT_GBRAPF32;\n            }\n        } else {\n            if (!s->is_luma) {\n                avctx->pix_fmt = AV_PIX_FMT_GBRPF32;\n            } else {\n                avctx->pix_fmt = AV_PIX_FMT_GRAYF32;\n            }\n        }\n        break;\n    case EXR_UINT:\n        if (s->channel_offsets[3] >= 0) {\n            if (!s->is_luma) {\n                avctx->pix_fmt = AV_PIX_FMT_RGBA64;\n            } else {\n                avctx->pix_fmt = AV_PIX_FMT_YA16;\n            }\n        } else {\n            if (!s->is_luma) {\n                avctx->pix_fmt = AV_PIX_FMT_RGB48;\n            } else {\n                avctx->pix_fmt = AV_PIX_FMT_GRAY16;\n            }\n        }\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"Missing channel list.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (s->apply_trc_type != AVCOL_TRC_UNSPECIFIED)\n        avctx->color_trc = s->apply_trc_type;\n\n    switch (s->compression) {\n    case EXR_RAW:\n    case EXR_RLE:\n    case EXR_ZIP1:\n        s->scan_lines_per_block = 1;\n        break;\n    case EXR_PXR24:\n    case EXR_ZIP16:\n        s->scan_lines_per_block = 16;\n        break;\n    case EXR_PIZ:\n    case EXR_B44:\n    case EXR_B44A:\n        s->scan_lines_per_block = 32;\n        break;\n    default:\n        avpriv_report_missing_feature(avctx, \"Compression %d\", s->compression);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    /* Verify the xmin, xmax, ymin and ymax before setting the actual image size.\n     * It's possible for the data window can larger or outside the display window */\n    if (s->xmin > s->xmax  || s->ymin > s->ymax ||\n        s->ydelta == 0xFFFFFFFF || s->xdelta == 0xFFFFFFFF) {\n        av_log(avctx, AV_LOG_ERROR, \"Wrong or missing size information.\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if ((ret = ff_set_dimensions(avctx, s->w, s->h)) < 0)\n        return ret;\n\n    s->desc          = av_pix_fmt_desc_get(avctx->pix_fmt);\n    if (!s->desc)\n        return AVERROR_INVALIDDATA;\n\n    if (s->desc->flags & AV_PIX_FMT_FLAG_FLOAT) {\n        planes           = s->desc->nb_components;\n        out_line_size    = avctx->width * 4;\n    } else {\n        planes           = 1;\n        out_line_size    = avctx->width * 2 * s->desc->nb_components;\n    }\n\n    if (s->is_tile) {\n        nb_blocks = ((s->xdelta + s->tile_attr.xSize - 1) / s->tile_attr.xSize) *\n        ((s->ydelta + s->tile_attr.ySize - 1) / s->tile_attr.ySize);\n    } else { /* scanline */\n        nb_blocks = (s->ydelta + s->scan_lines_per_block - 1) /\n        s->scan_lines_per_block;\n    }\n\n    if ((ret = ff_thread_get_buffer(avctx, &frame, 0)) < 0)\n        return ret;\n\n    if (bytestream2_get_bytes_left(&s->gb)/8 < nb_blocks)\n        return AVERROR_INVALIDDATA;\n\n    // check offset table and recreate it if need\n    if (!s->is_tile && bytestream2_peek_le64(&s->gb) == 0) {\n        av_log(s->avctx, AV_LOG_DEBUG, \"recreating invalid scanline offset table\\n\");\n\n        start_offset_table = bytestream2_tell(&s->gb);\n        start_next_scanline = start_offset_table + nb_blocks * 8;\n        bytestream2_init_writer(&offset_table_writer, &avpkt->data[start_offset_table], nb_blocks * 8);\n\n        for (y = 0; y < nb_blocks; y++) {\n            /* write offset of prev scanline in offset table */\n            bytestream2_put_le64(&offset_table_writer, start_next_scanline);\n\n            /* get len of next scanline */\n            bytestream2_seek(&s->gb, start_next_scanline + 4, SEEK_SET);/* skip line number */\n            start_next_scanline += (bytestream2_get_le32(&s->gb) + 8);\n        }\n        bytestream2_seek(&s->gb, start_offset_table, SEEK_SET);\n    }\n\n    // save pointer we are going to use in decode_block\n    s->buf      = avpkt->data;\n    s->buf_size = avpkt->size;\n\n    // Zero out the start if ymin is not 0\n    for (i = 0; i < planes; i++) {\n        ptr = picture->data[i];\n        for (y = 0; y < FFMIN(s->ymin, s->h); y++) {\n            memset(ptr, 0, out_line_size);\n            ptr += picture->linesize[i];\n        }\n    }\n\n    s->picture = picture;\n\n    avctx->execute2(avctx, decode_block, s->thread_data, NULL, nb_blocks);\n\n    ymax = FFMAX(0, s->ymax + 1);\n    // Zero out the end if ymax+1 is not h\n    for (i = 0; i < planes; i++) {\n        ptr = picture->data[i] + (ymax * picture->linesize[i]);\n        for (y = ymax; y < avctx->height; y++) {\n            memset(ptr, 0, out_line_size);\n            ptr += picture->linesize[i];\n        }\n    }\n\n    picture->pict_type = AV_PICTURE_TYPE_I;\n    *got_frame = 1;\n\n    return avpkt->size;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/3e5959b3457f7f1856d997261e6ac672bba49e8b", "file_name": "libavcodec/exr.c", "vul_type": "cwe-787", "description": "Write a C function named `decode_frame` for decoding video frames in an FFmpeg codec context."}
{"func_name": "_call_prepare_fc_map", "func_src_before": "    def _call_prepare_fc_map(self, fc_map_id, source, target):\n        try:\n            out, err = self._run_ssh(['svctask', 'prestartfcmap', fc_map_id])\n        except exception.ProcessExecutionError as e:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_('_prepare_fc_map: Failed to prepare FlashCopy '\n                            'from %(source)s to %(target)s.\\n'\n                            'stdout: %(out)s\\n stderr: %(err)s')\n                          % {'source': source,\n                             'target': target,\n                             'out': e.stdout,\n                             'err': e.stderr})", "func_src_after": "    def _call_prepare_fc_map(self, fc_map_id, source, target):\n        try:\n            out, err = self._run_ssh('svctask prestartfcmap %s' % fc_map_id)\n        except exception.ProcessExecutionError as e:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_('_prepare_fc_map: Failed to prepare FlashCopy '\n                            'from %(source)s to %(target)s.\\n'\n                            'stdout: %(out)s\\n stderr: %(err)s')\n                          % {'source': source,\n                             'target': target,\n                             'out': e.stdout,\n                             'err': e.stderr})", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function that attempts to run an SSH command for preparing a FlashCopy map and logs an error if it fails."}
{"func_name": "DeletionConfirmationDlg::DeletionConfirmationDlg", "func_src_before": "  DeletionConfirmationDlg(QWidget *parent, const int &size, const QString &name, bool defaultDeleteFiles): QDialog(parent) {\n    setupUi(this);\n    if (size == 1)\n      label->setText(tr(\"Are you sure you want to delete '%1' from the transfer list?\", \"Are you sure you want to delete 'ubuntu-linux-iso' from the transfer list?\").arg(name));\n    else\n      label->setText(tr(\"Are you sure you want to delete these %1 torrents from the transfer list?\", \"Are you sure you want to delete these 5 torrents from the transfer list?\").arg(QString::number(size)));\n    // Icons\n    lbl_warn->setPixmap(GuiIconProvider::instance()->getIcon(\"dialog-warning\").pixmap(lbl_warn->height()));\n    lbl_warn->setFixedWidth(lbl_warn->height());\n    rememberBtn->setIcon(GuiIconProvider::instance()->getIcon(\"object-locked\"));\n\n    move(Utils::Misc::screenCenter(this));\n    checkPermDelete->setChecked(defaultDeleteFiles || Preferences::instance()->deleteTorrentFilesAsDefault());\n    connect(checkPermDelete, SIGNAL(clicked()), this, SLOT(updateRememberButtonState()));\n    buttonBox->button(QDialogButtonBox::Cancel)->setFocus();\n  }", "func_src_after": "  DeletionConfirmationDlg(QWidget *parent, const int &size, const QString &name, bool defaultDeleteFiles): QDialog(parent) {\n    setupUi(this);\n    if (size == 1)\n      label->setText(tr(\"Are you sure you want to delete '%1' from the transfer list?\", \"Are you sure you want to delete 'ubuntu-linux-iso' from the transfer list?\").arg(Utils::String::toHtmlEscaped(name)));\n    else\n      label->setText(tr(\"Are you sure you want to delete these %1 torrents from the transfer list?\", \"Are you sure you want to delete these 5 torrents from the transfer list?\").arg(QString::number(size)));\n    // Icons\n    lbl_warn->setPixmap(GuiIconProvider::instance()->getIcon(\"dialog-warning\").pixmap(lbl_warn->height()));\n    lbl_warn->setFixedWidth(lbl_warn->height());\n    rememberBtn->setIcon(GuiIconProvider::instance()->getIcon(\"object-locked\"));\n\n    move(Utils::Misc::screenCenter(this));\n    checkPermDelete->setChecked(defaultDeleteFiles || Preferences::instance()->deleteTorrentFilesAsDefault());\n    connect(checkPermDelete, SIGNAL(clicked()), this, SLOT(updateRememberButtonState()));\n    buttonBox->button(QDialogButtonBox::Cancel)->setFocus();\n  }", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/gui/deletionconfirmationdlg.h", "vul_type": "cwe-079", "description": "Write a C++ class constructor for a deletion confirmation dialog in Qt, handling single or multiple file deletions with customization options."}
{"func_name": "__ext4_journal_stop", "func_src_before": "int __ext4_journal_stop(const char *where, unsigned int line, handle_t *handle)\n{\n\tstruct super_block *sb;\n\tint err;\n\tint rc;\n\n\tif (!ext4_handle_valid(handle)) {\n\t\text4_put_nojournal(handle);\n\t\treturn 0;\n\t}\n\n\terr = handle->h_err;\n\tif (!handle->h_transaction) {\n\t\trc = jbd2_journal_stop(handle);\n\t\treturn err ? err : rc;\n\t}\n\n\tsb = handle->h_transaction->t_journal->j_private;\n\trc = jbd2_journal_stop(handle);\n\n\tif (!err)\n\t\terr = rc;\n\tif (err)\n\t\t__ext4_std_error(sb, where, line, err);\n\treturn err;\n}", "func_src_after": "int __ext4_journal_stop(const char *where, unsigned int line, handle_t *handle)\n{\n\tstruct super_block *sb;\n\tint err;\n\tint rc;\n\n\tif (!ext4_handle_valid(handle)) {\n\t\text4_put_nojournal(handle);\n\t\treturn 0;\n\t}\n\n\tif (!handle->h_transaction) {\n\t\terr = jbd2_journal_stop(handle);\n\t\treturn handle->h_err ? handle->h_err : err;\n\t}\n\n\tsb = handle->h_transaction->t_journal->j_private;\n\terr = handle->h_err;\n\trc = jbd2_journal_stop(handle);\n\n\tif (!err)\n\t\terr = rc;\n\tif (err)\n\t\t__ext4_std_error(sb, where, line, err);\n\treturn err;\n}", "commit_link": "github.com/torvalds/linux/commit/6934da9238da947628be83635e365df41064b09b", "file_name": "fs/ext4/ext4_jbd2.c", "vul_type": "cwe-416", "description": "Write a C function named `__ext4_journal_stop` that stops a journaling handle and handles errors appropriately."}
{"func_name": "get_previous_yields", "func_src_before": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial = '%s'\n        ''' % (inverter_serial)\n        self.c.execute(query)\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "func_src_after": "    def get_previous_yields(self, inverter_serial):\n        query = '''\n           SELECT TimeStamp, EToday, ETotal\n           FROM Inverters\n           WHERE Serial=?\n        '''\n        self.c.execute(query, (inverter_serial,))\n        data = self.c.fetchone()\n        return data[0], data[1], data[2]", "commit_link": "github.com/philipptrenz/s0-bridge/commit/269b48caa05377b7c58c3e6d1622a4429cb5ba65", "file_name": "util/database.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the timestamp and energy yields of today and total from a database for a given inverter serial number."}
{"func_name": "verify_email", "func_src_before": "    def verify_email(self, member):\n        self.cursor.execute(\"SELECT COUNT(email) FROM members WHERE email = ':email'\", {'email':member})\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "func_src_after": "    def verify_email(self, member):\n        query = \"SELECT COUNT(email) FROM members WHERE email = '{email}'\".format(email = member)\n        self.cursor.execute(query)\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "commit_link": "github.com/kenboo98/291-Mini-Project-I/commit/3080ccb687c79c83954ce703faee8fcceec8c9eb", "file_name": "book_rides/book_rides.py", "vul_type": "cwe-089", "description": "Write a Python function to check if an email exists in a database using SQL queries."}
{"func_name": "parse_playlist", "func_src_before": "static int parse_playlist(HLSContext *c, const char *url,\n                          struct playlist *pls, AVIOContext *in)\n{\n    int ret = 0, is_segment = 0, is_variant = 0;\n    int64_t duration = 0;\n    enum KeyType key_type = KEY_NONE;\n    uint8_t iv[16] = \"\";\n    int has_iv = 0;\n    char key[MAX_URL_SIZE] = \"\";\n    char line[MAX_URL_SIZE];\n    const char *ptr;\n    int close_in = 0;\n    int64_t seg_offset = 0;\n    int64_t seg_size = -1;\n    uint8_t *new_url = NULL;\n    struct variant_info variant_info;\n    char tmp_str[MAX_URL_SIZE];\n    struct segment *cur_init_section = NULL;\n\n    if (!in) {\n#if 1\n        AVDictionary *opts = NULL;\n        close_in = 1;\n        /* Some HLS servers don't like being sent the range header */\n        av_dict_set(&opts, \"seekable\", \"0\", 0);\n\n        // broker prior HTTP options that should be consistent across requests\n        av_dict_set(&opts, \"user-agent\", c->user_agent, 0);\n        av_dict_set(&opts, \"cookies\", c->cookies, 0);\n        av_dict_set(&opts, \"headers\", c->headers, 0);\n\n        ret = avio_open2(&in, url, AVIO_FLAG_READ,\n                         c->interrupt_callback, &opts);\n        av_dict_free(&opts);\n        if (ret < 0)\n            return ret;\n#else\n        ret = open_in(c, &in, url);\n        if (ret < 0)\n            return ret;\n        close_in = 1;\n#endif\n    }\n\n    if (av_opt_get(in, \"location\", AV_OPT_SEARCH_CHILDREN, &new_url) >= 0)\n        url = new_url;\n\n    read_chomp_line(in, line, sizeof(line));\n    if (strcmp(line, \"#EXTM3U\")) {\n        ret = AVERROR_INVALIDDATA;\n        goto fail;\n    }\n\n    if (pls) {\n        free_segment_list(pls);\n        pls->finished = 0;\n        pls->type = PLS_TYPE_UNSPECIFIED;\n    }\n    while (!avio_feof(in)) {\n        read_chomp_line(in, line, sizeof(line));\n        if (av_strstart(line, \"#EXT-X-STREAM-INF:\", &ptr)) {\n            is_variant = 1;\n            memset(&variant_info, 0, sizeof(variant_info));\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_variant_args,\n                               &variant_info);\n        } else if (av_strstart(line, \"#EXT-X-KEY:\", &ptr)) {\n            struct key_info info = {{0}};\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_key_args,\n                               &info);\n            key_type = KEY_NONE;\n            has_iv = 0;\n            if (!strcmp(info.method, \"AES-128\"))\n                key_type = KEY_AES_128;\n            if (!strcmp(info.method, \"SAMPLE-AES\"))\n                key_type = KEY_SAMPLE_AES;\n            if (!strncmp(info.iv, \"0x\", 2) || !strncmp(info.iv, \"0X\", 2)) {\n                ff_hex_to_data(iv, info.iv + 2);\n                has_iv = 1;\n            }\n            av_strlcpy(key, info.uri, sizeof(key));\n        } else if (av_strstart(line, \"#EXT-X-MEDIA:\", &ptr)) {\n            struct rendition_info info = {{0}};\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_rendition_args,\n                               &info);\n            new_rendition(c, &info, url);\n        } else if (av_strstart(line, \"#EXT-X-TARGETDURATION:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            pls->target_duration = atoi(ptr) * AV_TIME_BASE;\n        } else if (av_strstart(line, \"#EXT-X-MEDIA-SEQUENCE:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            pls->start_seq_no = atoi(ptr);\n        } else if (av_strstart(line, \"#EXT-X-PLAYLIST-TYPE:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            if (!strcmp(ptr, \"EVENT\"))\n                pls->type = PLS_TYPE_EVENT;\n            else if (!strcmp(ptr, \"VOD\"))\n                pls->type = PLS_TYPE_VOD;\n        } else if (av_strstart(line, \"#EXT-X-MAP:\", &ptr)) {\n            struct init_section_info info = {{0}};\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_init_section_args,\n                               &info);\n            cur_init_section = new_init_section(pls, &info, url);\n        } else if (av_strstart(line, \"#EXT-X-ENDLIST\", &ptr)) {\n            if (pls)\n                pls->finished = 1;\n        } else if (av_strstart(line, \"#EXTINF:\", &ptr)) {\n            is_segment = 1;\n            duration   = atof(ptr) * AV_TIME_BASE;\n        } else if (av_strstart(line, \"#EXT-X-BYTERANGE:\", &ptr)) {\n            seg_size = atoi(ptr);\n            ptr = strchr(ptr, '@');\n            if (ptr)\n                seg_offset = atoi(ptr+1);\n        } else if (av_strstart(line, \"#\", NULL)) {\n            continue;\n        } else if (line[0]) {\n            if (is_variant) {\n                if (!new_variant(c, &variant_info, line, url)) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n                is_variant = 0;\n            }\n            if (is_segment) {\n                struct segment *seg;\n                if (!pls) {\n                    if (!new_variant(c, 0, url, NULL)) {\n                        ret = AVERROR(ENOMEM);\n                        goto fail;\n                    }\n                    pls = c->playlists[c->n_playlists - 1];\n                }\n                seg = av_malloc(sizeof(struct segment));\n                if (!seg) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n                seg->duration = duration;\n                seg->key_type = key_type;\n                if (has_iv) {\n                    memcpy(seg->iv, iv, sizeof(iv));\n                } else {\n                    int seq = pls->start_seq_no + pls->n_segments;\n                    memset(seg->iv, 0, sizeof(seg->iv));\n                    AV_WB32(seg->iv + 12, seq);\n                }\n\n                if (key_type != KEY_NONE) {\n                    ff_make_absolute_url(tmp_str, sizeof(tmp_str), url, key);\n                    seg->key = av_strdup(tmp_str);\n                    if (!seg->key) {\n                        av_free(seg);\n                        ret = AVERROR(ENOMEM);\n                        goto fail;\n                    }\n                } else {\n                    seg->key = NULL;\n                }\n\n                ff_make_absolute_url(tmp_str, sizeof(tmp_str), url, line);\n                seg->url = av_strdup(tmp_str);\n                if (!seg->url) {\n                    av_free(seg->key);\n                    av_free(seg);\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n\n                dynarray_add(&pls->segments, &pls->n_segments, seg);\n                is_segment = 0;\n\n                seg->size = seg_size;\n                if (seg_size >= 0) {\n                    seg->url_offset = seg_offset;\n                    seg_offset += seg_size;\n                    seg_size = -1;\n                } else {\n                    seg->url_offset = 0;\n                    seg_offset = 0;\n                }\n\n                seg->init_section = cur_init_section;\n            }\n        }\n    }\n    if (pls)\n        pls->last_load_time = av_gettime_relative();\n\nfail:\n    av_free(new_url);\n    if (close_in)\n        avio_close(in);\n    return ret;\n}", "func_src_after": "static int parse_playlist(HLSContext *c, const char *url,\n                          struct playlist *pls, AVIOContext *in)\n{\n    int ret = 0, is_segment = 0, is_variant = 0;\n    int64_t duration = 0;\n    enum KeyType key_type = KEY_NONE;\n    uint8_t iv[16] = \"\";\n    int has_iv = 0;\n    char key[MAX_URL_SIZE] = \"\";\n    char line[MAX_URL_SIZE];\n    const char *ptr;\n    int close_in = 0;\n    int64_t seg_offset = 0;\n    int64_t seg_size = -1;\n    uint8_t *new_url = NULL;\n    struct variant_info variant_info;\n    char tmp_str[MAX_URL_SIZE];\n    struct segment *cur_init_section = NULL;\n\n    if (!in) {\n#if 1\n        AVDictionary *opts = NULL;\n        close_in = 1;\n        /* Some HLS servers don't like being sent the range header */\n        av_dict_set(&opts, \"seekable\", \"0\", 0);\n\n        // broker prior HTTP options that should be consistent across requests\n        av_dict_set(&opts, \"user-agent\", c->user_agent, 0);\n        av_dict_set(&opts, \"cookies\", c->cookies, 0);\n        av_dict_set(&opts, \"headers\", c->headers, 0);\n\n        ret = avio_open2(&in, url, AVIO_FLAG_READ,\n                         c->interrupt_callback, &opts);\n        av_dict_free(&opts);\n        if (ret < 0)\n            return ret;\n#else\n        ret = open_in(c, &in, url);\n        if (ret < 0)\n            return ret;\n        close_in = 1;\n#endif\n    }\n\n    if (av_opt_get(in, \"location\", AV_OPT_SEARCH_CHILDREN, &new_url) >= 0)\n        url = new_url;\n\n    read_chomp_line(in, line, sizeof(line));\n    if (strcmp(line, \"#EXTM3U\")) {\n        ret = AVERROR_INVALIDDATA;\n        goto fail;\n    }\n\n    if (pls) {\n        free_segment_list(pls);\n        pls->finished = 0;\n        pls->type = PLS_TYPE_UNSPECIFIED;\n    }\n    while (!avio_feof(in)) {\n        read_chomp_line(in, line, sizeof(line));\n        if (av_strstart(line, \"#EXT-X-STREAM-INF:\", &ptr)) {\n            is_variant = 1;\n            memset(&variant_info, 0, sizeof(variant_info));\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_variant_args,\n                               &variant_info);\n        } else if (av_strstart(line, \"#EXT-X-KEY:\", &ptr)) {\n            struct key_info info = {{0}};\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_key_args,\n                               &info);\n            key_type = KEY_NONE;\n            has_iv = 0;\n            if (!strcmp(info.method, \"AES-128\"))\n                key_type = KEY_AES_128;\n            if (!strcmp(info.method, \"SAMPLE-AES\"))\n                key_type = KEY_SAMPLE_AES;\n            if (!strncmp(info.iv, \"0x\", 2) || !strncmp(info.iv, \"0X\", 2)) {\n                ff_hex_to_data(iv, info.iv + 2);\n                has_iv = 1;\n            }\n            av_strlcpy(key, info.uri, sizeof(key));\n        } else if (av_strstart(line, \"#EXT-X-MEDIA:\", &ptr)) {\n            struct rendition_info info = {{0}};\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_rendition_args,\n                               &info);\n            new_rendition(c, &info, url);\n        } else if (av_strstart(line, \"#EXT-X-TARGETDURATION:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            pls->target_duration = atoi(ptr) * AV_TIME_BASE;\n        } else if (av_strstart(line, \"#EXT-X-MEDIA-SEQUENCE:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            pls->start_seq_no = atoi(ptr);\n        } else if (av_strstart(line, \"#EXT-X-PLAYLIST-TYPE:\", &ptr)) {\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            if (!strcmp(ptr, \"EVENT\"))\n                pls->type = PLS_TYPE_EVENT;\n            else if (!strcmp(ptr, \"VOD\"))\n                pls->type = PLS_TYPE_VOD;\n        } else if (av_strstart(line, \"#EXT-X-MAP:\", &ptr)) {\n            struct init_section_info info = {{0}};\n            ret = ensure_playlist(c, &pls, url);\n            if (ret < 0)\n                goto fail;\n            ff_parse_key_value(ptr, (ff_parse_key_val_cb) handle_init_section_args,\n                               &info);\n            cur_init_section = new_init_section(pls, &info, url);\n        } else if (av_strstart(line, \"#EXT-X-ENDLIST\", &ptr)) {\n            if (pls)\n                pls->finished = 1;\n        } else if (av_strstart(line, \"#EXTINF:\", &ptr)) {\n            is_segment = 1;\n            duration   = atof(ptr) * AV_TIME_BASE;\n        } else if (av_strstart(line, \"#EXT-X-BYTERANGE:\", &ptr)) {\n            seg_size = atoi(ptr);\n            ptr = strchr(ptr, '@');\n            if (ptr)\n                seg_offset = atoi(ptr+1);\n        } else if (av_strstart(line, \"#\", NULL)) {\n            continue;\n        } else if (line[0]) {\n            if (is_variant) {\n                if (!new_variant(c, &variant_info, line, url)) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n                is_variant = 0;\n            }\n            if (is_segment) {\n                struct segment *seg;\n                if (!pls) {\n                    if (!new_variant(c, 0, url, NULL)) {\n                        ret = AVERROR(ENOMEM);\n                        goto fail;\n                    }\n                    pls = c->playlists[c->n_playlists - 1];\n                }\n                seg = av_malloc(sizeof(struct segment));\n                if (!seg) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n                if (has_iv) {\n                    memcpy(seg->iv, iv, sizeof(iv));\n                } else {\n                    int seq = pls->start_seq_no + pls->n_segments;\n                    memset(seg->iv, 0, sizeof(seg->iv));\n                    AV_WB32(seg->iv + 12, seq);\n                }\n\n                if (key_type != KEY_NONE) {\n                    ff_make_absolute_url(tmp_str, sizeof(tmp_str), url, key);\n                    seg->key = av_strdup(tmp_str);\n                    if (!seg->key) {\n                        av_free(seg);\n                        ret = AVERROR(ENOMEM);\n                        goto fail;\n                    }\n                } else {\n                    seg->key = NULL;\n                }\n\n                ff_make_absolute_url(tmp_str, sizeof(tmp_str), url, line);\n                seg->url = av_strdup(tmp_str);\n                if (!seg->url) {\n                    av_free(seg->key);\n                    av_free(seg);\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n\n                if (duration < 0.001 * AV_TIME_BASE) {\n                    duration = 0.001 * AV_TIME_BASE;\n                }\n                seg->duration = duration;\n                seg->key_type = key_type;\n                dynarray_add(&pls->segments, &pls->n_segments, seg);\n                is_segment = 0;\n\n                seg->size = seg_size;\n                if (seg_size >= 0) {\n                    seg->url_offset = seg_offset;\n                    seg_offset += seg_size;\n                    seg_size = -1;\n                } else {\n                    seg->url_offset = 0;\n                    seg_offset = 0;\n                }\n\n                seg->init_section = cur_init_section;\n            }\n        }\n    }\n    if (pls)\n        pls->last_load_time = av_gettime_relative();\n\nfail:\n    av_free(new_url);\n    if (close_in)\n        avio_close(in);\n    return ret;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/6959358683c7533f586c07a766acc5fe9544d8b2", "file_name": "libavformat/hls.c", "vul_type": "cwe-416", "description": "Write a C function to parse an HLS playlist from a given URL and populate a playlist structure with the parsed data."}
{"func_name": "PropertiesWidget::loadTorrentInfos", "func_src_before": "void PropertiesWidget::loadTorrentInfos(BitTorrent::TorrentHandle *const torrent)\n{\n    clear();\n    m_torrent = torrent;\n    downloaded_pieces->setTorrent(m_torrent);\n    pieces_availability->setTorrent(m_torrent);\n    if (!m_torrent) return;\n\n    // Save path\n    updateSavePath(m_torrent);\n    // Hash\n    hash_lbl->setText(m_torrent->hash());\n    PropListModel->model()->clear();\n    if (m_torrent->hasMetadata()) {\n        // Creation date\n        lbl_creationDate->setText(m_torrent->creationDate().toString(Qt::DefaultLocaleShortDate));\n\n        label_total_size_val->setText(Utils::Misc::friendlyUnit(m_torrent->totalSize()));\n\n        // Comment\n        comment_text->setText(Utils::Misc::parseHtmlLinks(m_torrent->comment()));\n\n        // URL seeds\n        loadUrlSeeds();\n\n        label_created_by_val->setText(m_torrent->creator());\n\n        // List files in torrent\n        PropListModel->model()->setupModelData(m_torrent->info());\n        filesList->setExpanded(PropListModel->index(0, 0), true);\n\n        // Load file priorities\n        PropListModel->model()->updateFilesPriorities(m_torrent->filePriorities());\n    }\n    // Load dynamic data\n    loadDynamicData();\n}", "func_src_after": "void PropertiesWidget::loadTorrentInfos(BitTorrent::TorrentHandle *const torrent)\n{\n    clear();\n    m_torrent = torrent;\n    downloaded_pieces->setTorrent(m_torrent);\n    pieces_availability->setTorrent(m_torrent);\n    if (!m_torrent) return;\n\n    // Save path\n    updateSavePath(m_torrent);\n    // Hash\n    hash_lbl->setText(m_torrent->hash());\n    PropListModel->model()->clear();\n    if (m_torrent->hasMetadata()) {\n        // Creation date\n        lbl_creationDate->setText(m_torrent->creationDate().toString(Qt::DefaultLocaleShortDate));\n\n        label_total_size_val->setText(Utils::Misc::friendlyUnit(m_torrent->totalSize()));\n\n        // Comment\n        comment_text->setText(Utils::Misc::parseHtmlLinks(Utils::String::toHtmlEscaped(m_torrent->comment())));\n\n        // URL seeds\n        loadUrlSeeds();\n\n        label_created_by_val->setText(Utils::String::toHtmlEscaped(m_torrent->creator()));\n\n        // List files in torrent\n        PropListModel->model()->setupModelData(m_torrent->info());\n        filesList->setExpanded(PropListModel->index(0, 0), true);\n\n        // Load file priorities\n        PropListModel->model()->updateFilesPriorities(m_torrent->filePriorities());\n    }\n    // Load dynamic data\n    loadDynamicData();\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/gui/properties/propertieswidget.cpp", "vul_type": "cwe-079", "description": "Write a C++ function in the PropertiesWidget class that loads and displays torrent information using the BitTorrent::TorrentHandle object."}
{"func_name": "TarFileReader::extract", "func_src_before": "std::string TarFileReader::extract(const string &_path) {\n  if (_path.empty()) THROW(\"path cannot be empty\");\n  if (!hasMore()) THROW(\"No more tar files\");\n\n  string path = _path;\n  if (SystemUtilities::isDirectory(path)) path += \"/\" + getFilename();\n\n  LOG_DEBUG(5, \"Extracting: \" << path);\n\n  return extract(*SystemUtilities::oopen(path));\n}", "func_src_after": "std::string TarFileReader::extract(const string &_path) {\n  if (_path.empty()) THROW(\"path cannot be empty\");\n  if (!hasMore()) THROW(\"No more tar files\");\n\n  string path = _path;\n  if (SystemUtilities::isDirectory(path)) {\n    path += \"/\" + getFilename();\n\n    // Check that path is under the target directory\n    string a = SystemUtilities::getCanonicalPath(_path);\n    string b = SystemUtilities::getCanonicalPath(path);\n    if (!String::startsWith(b, a))\n      THROW(\"Tar path points outside of the extraction directory: \" << path);\n  }\n\n  LOG_DEBUG(5, \"Extracting: \" << path);\n\n  switch (getType()) {\n  case NORMAL_FILE: case CONTIGUOUS_FILE:\n    return extract(*SystemUtilities::oopen(path));\n  case DIRECTORY: SystemUtilities::ensureDirectory(path); break;\n  default: THROW(\"Unsupported tar file type \" << getType());\n  }\n\n  return getFilename();\n}", "commit_link": "github.com/CauldronDevelopmentLLC/cbang/commit/1c1dba62bd3e6fa9d0d0c0aa21926043b75382c7", "file_name": "src/cbang/tar/TarFileReader.cpp", "vul_type": "cwe-022", "description": "In C++, write a function to extract a file from a tar archive, handling path validation and logging the extraction process."}
{"func_name": "test_create_host", "func_src_before": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -iscsi -persona 1 -domain '\n                           '(\\'OpenStack\\',) '\n                           'fakehost iqn.1993-08.org.debian:01:222')\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "func_src_after": "    def test_create_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-iscsi', '-persona', '1', '-domain',\n                            ('OpenStack',), 'fakehost',\n                            'iqn.1993-08.org.debian:01:222'])\n        _run_ssh(create_host_cmd, False).AndReturn([CLI_CR, ''])\n\n        _run_ssh(show_host_cmd, False).AndReturn([pack(ISCSI_HOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n        self.assertEqual(host['name'], self.FAKE_HOST)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating and verifying an iSCSI host."}
{"func_name": "lexer_process_char_literal", "func_src_before": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "func_src_after": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */", "commit_link": "github.com/jerryscript-project/jerryscript/commit/e58f2880df608652aff7fd35c45b242467ec0e79", "file_name": "jerry-core/parser/js/js-lexer.c", "vul_type": "cwe-476", "description": "In C, write a function to process character literals in a parser context, handling escape sequences and ensuring they don't exceed predefined limits."}
{"func_name": "do_setup", "func_src_before": "    def do_setup(self, ctxt):\n        \"\"\"Check that we have all configuration details from the storage.\"\"\"\n\n        LOG.debug(_('enter: do_setup'))\n        self._context = ctxt\n\n        # Validate that the pool exists\n        ssh_cmd = ['svcinfo', 'lsmdiskgrp', '-delim', '!', '-nohdr']\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), 'do_setup',\n                                ssh_cmd, out, err)\n        search_text = '!%s!' % self.configuration.storwize_svc_volpool_name\n        if search_text not in out:\n            raise exception.InvalidInput(\n                reason=(_('pool %s doesn\\'t exist')\n                        % self.configuration.storwize_svc_volpool_name))\n\n        # Check if compression is supported\n        self._compression_enabled = False\n        try:\n            ssh_cmd = ['svcinfo', 'lslicense', '-delim', '!']\n            out, err = self._run_ssh(ssh_cmd)\n            license_lines = out.strip().split('\\n')\n            for license_line in license_lines:\n                name, foo, value = license_line.partition('!')\n                if name in ('license_compression_enclosures',\n                            'license_compression_capacity') and value != '0':\n                    self._compression_enabled = True\n                    break\n        except exception.ProcessExecutionError:\n            LOG.exception(_('Failed to get license information.'))\n\n        # Get the iSCSI and FC names of the Storwize/SVC nodes\n        ssh_cmd = ['svcinfo', 'lsnode', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), 'do_setup',\n                                ssh_cmd, out, err)\n\n        nodes = out.strip().split('\\n')\n        self._assert_ssh_return(len(nodes),\n                                'do_setup', ssh_cmd, out, err)\n        header = nodes.pop(0)\n        for node_line in nodes:\n            try:\n                node_data = self._get_hdr_dic(header, node_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('do_setup',\n                                               ssh_cmd, out, err)\n            node = {}\n            try:\n                node['id'] = node_data['id']\n                node['name'] = node_data['name']\n                node['IO_group'] = node_data['IO_group_id']\n                node['iscsi_name'] = node_data['iscsi_name']\n                node['WWNN'] = node_data['WWNN']\n                node['status'] = node_data['status']\n                node['WWPN'] = []\n                node['ipv4'] = []\n                node['ipv6'] = []\n                node['enabled_protocols'] = []\n                if node['status'] == 'online':\n                    self._storage_nodes[node['id']] = node\n            except KeyError:\n                self._handle_keyerror('lsnode', header)\n\n        # Get the iSCSI IP addresses and WWPNs of the Storwize/SVC nodes\n        self._get_iscsi_ip_addrs()\n        self._get_fc_wwpns()\n\n        # For each node, check what connection modes it supports.  Delete any\n        # nodes that do not support any types (may be partially configured).\n        to_delete = []\n        for k, node in self._storage_nodes.iteritems():\n            if ((len(node['ipv4']) or len(node['ipv6']))\n                    and len(node['iscsi_name'])):\n                node['enabled_protocols'].append('iSCSI')\n                self._enabled_protocols.add('iSCSI')\n            if len(node['WWPN']):\n                node['enabled_protocols'].append('FC')\n                self._enabled_protocols.add('FC')\n            if not len(node['enabled_protocols']):\n                to_delete.append(k)\n\n        for delkey in to_delete:\n            del self._storage_nodes[delkey]\n\n        # Make sure we have at least one node configured\n        self._driver_assert(len(self._storage_nodes),\n                            _('do_setup: No configured nodes'))\n\n        LOG.debug(_('leave: do_setup'))", "func_src_after": "    def do_setup(self, ctxt):\n        \"\"\"Check that we have all configuration details from the storage.\"\"\"\n\n        LOG.debug(_('enter: do_setup'))\n        self._context = ctxt\n\n        # Validate that the pool exists\n        ssh_cmd = 'svcinfo lsmdiskgrp -delim ! -nohdr'\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), 'do_setup',\n                                ssh_cmd, out, err)\n        search_text = '!%s!' % self.configuration.storwize_svc_volpool_name\n        if search_text not in out:\n            raise exception.InvalidInput(\n                reason=(_('pool %s doesn\\'t exist')\n                        % self.configuration.storwize_svc_volpool_name))\n\n        # Check if compression is supported\n        self._compression_enabled = False\n        try:\n            ssh_cmd = 'svcinfo lslicense -delim !'\n            out, err = self._run_ssh(ssh_cmd)\n            license_lines = out.strip().split('\\n')\n            for license_line in license_lines:\n                name, foo, value = license_line.partition('!')\n                if name in ('license_compression_enclosures',\n                            'license_compression_capacity') and value != '0':\n                    self._compression_enabled = True\n                    break\n        except exception.ProcessExecutionError:\n            LOG.exception(_('Failed to get license information.'))\n\n        # Get the iSCSI and FC names of the Storwize/SVC nodes\n        ssh_cmd = 'svcinfo lsnode -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n        self._assert_ssh_return(len(out.strip()), 'do_setup',\n                                ssh_cmd, out, err)\n\n        nodes = out.strip().split('\\n')\n        self._assert_ssh_return(len(nodes),\n                                'do_setup', ssh_cmd, out, err)\n        header = nodes.pop(0)\n        for node_line in nodes:\n            try:\n                node_data = self._get_hdr_dic(header, node_line, '!')\n            except exception.VolumeBackendAPIException:\n                with excutils.save_and_reraise_exception():\n                    self._log_cli_output_error('do_setup',\n                                               ssh_cmd, out, err)\n            node = {}\n            try:\n                node['id'] = node_data['id']\n                node['name'] = node_data['name']\n                node['IO_group'] = node_data['IO_group_id']\n                node['iscsi_name'] = node_data['iscsi_name']\n                node['WWNN'] = node_data['WWNN']\n                node['status'] = node_data['status']\n                node['WWPN'] = []\n                node['ipv4'] = []\n                node['ipv6'] = []\n                node['enabled_protocols'] = []\n                if node['status'] == 'online':\n                    self._storage_nodes[node['id']] = node\n            except KeyError:\n                self._handle_keyerror('lsnode', header)\n\n        # Get the iSCSI IP addresses and WWPNs of the Storwize/SVC nodes\n        self._get_iscsi_ip_addrs()\n        self._get_fc_wwpns()\n\n        # For each node, check what connection modes it supports.  Delete any\n        # nodes that do not support any types (may be partially configured).\n        to_delete = []\n        for k, node in self._storage_nodes.iteritems():\n            if ((len(node['ipv4']) or len(node['ipv6']))\n                    and len(node['iscsi_name'])):\n                node['enabled_protocols'].append('iSCSI')\n                self._enabled_protocols.add('iSCSI')\n            if len(node['WWPN']):\n                node['enabled_protocols'].append('FC')\n                self._enabled_protocols.add('FC')\n            if not len(node['enabled_protocols']):\n                to_delete.append(k)\n\n        for delkey in to_delete:\n            del self._storage_nodes[delkey]\n\n        # Make sure we have at least one node configured\n        self._driver_assert(len(self._storage_nodes),\n                            _('do_setup: No configured nodes'))\n\n        LOG.debug(_('leave: do_setup'))", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function named `do_setup` that initializes storage configuration and checks for pool existence, compression support, and node details."}
{"func_name": "ng_pkt", "func_src_before": "static int ng_pkt(git_pkt **out, const char *line, size_t len)\n{\n\tgit_pkt_ng *pkt;\n\tconst char *ptr;\n\tsize_t alloclen;\n\n\tpkt = git__malloc(sizeof(*pkt));\n\tGITERR_CHECK_ALLOC(pkt);\n\n\tpkt->ref = NULL;\n\tpkt->type = GIT_PKT_NG;\n\n\tline += 3; /* skip \"ng \" */\n\tif (!(ptr = strchr(line, ' ')))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->ref = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->ref);\n\n\tmemcpy(pkt->ref, line, len);\n\tpkt->ref[len] = '\\0';\n\n\tline = ptr + 1;\n\tif (!(ptr = strchr(line, '\\n')))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->msg = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->msg);\n\n\tmemcpy(pkt->msg, line, len);\n\tpkt->msg[len] = '\\0';\n\n\t*out = (git_pkt *)pkt;\n\treturn 0;\n\nout_err:\n\tgiterr_set(GITERR_NET, \"invalid packet line\");\n\tgit__free(pkt->ref);\n\tgit__free(pkt);\n\treturn -1;\n}", "func_src_after": "static int ng_pkt(git_pkt **out, const char *line, size_t len)\n{\n\tgit_pkt_ng *pkt;\n\tconst char *ptr;\n\tsize_t alloclen;\n\n\tpkt = git__malloc(sizeof(*pkt));\n\tGITERR_CHECK_ALLOC(pkt);\n\n\tpkt->ref = NULL;\n\tpkt->type = GIT_PKT_NG;\n\n\tif (len < 3)\n\t\tgoto out_err;\n\tline += 3; /* skip \"ng \" */\n\tlen -= 3;\n\tif (!(ptr = memchr(line, ' ', len)))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->ref = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->ref);\n\n\tmemcpy(pkt->ref, line, len);\n\tpkt->ref[len] = '\\0';\n\n\tif (len < 1)\n\t\tgoto out_err;\n\tline = ptr + 1;\n\tlen -= 1;\n\tif (!(ptr = memchr(line, '\\n', len)))\n\t\tgoto out_err;\n\tlen = ptr - line;\n\n\tGITERR_CHECK_ALLOC_ADD(&alloclen, len, 1);\n\tpkt->msg = git__malloc(alloclen);\n\tGITERR_CHECK_ALLOC(pkt->msg);\n\n\tmemcpy(pkt->msg, line, len);\n\tpkt->msg[len] = '\\0';\n\n\t*out = (git_pkt *)pkt;\n\treturn 0;\n\nout_err:\n\tgiterr_set(GITERR_NET, \"invalid packet line\");\n\tgit__free(pkt->ref);\n\tgit__free(pkt);\n\treturn -1;\n}", "commit_link": "github.com/libgit2/libgit2/commit/1f9a8510e1d2f20ed7334eeeddb92c4dd8e7c649", "file_name": "src/transports/smart_pkt.c", "vul_type": "cwe-125", "description": "Write a C function to parse a Git \"ng\" packet, allocating memory for its contents and handling errors appropriately."}
{"func_name": "getOptions", "func_src_before": "def getOptions(poll_name):\n    conn, c = connectDB()\n    options_str = queryOne(c, \"SELECT options FROM {} WHERE name='{}'\".format(CFG(\"poll_table_name\"), poll_name))\n    if options_str == None:\n        return None\n    options = options_str.split(\",\")\n    closeDB(conn)\n    return options", "func_src_after": "def getOptions(poll_name):\n    conn, c = connectDB()\n    req = \"SELECT options FROM {} WHERE name=?\".format(CFG(\"poll_table_name\"))\n    options_str = queryOne(c, req, (poll_name,))\n    if options_str == None:\n        return None\n    options = options_str.split(\",\")\n    closeDB(conn)\n    return options", "commit_link": "github.com/FAUSheppy/simple-python-poll/commit/186c5ff5cdf58272e253a1bb432419ee50d93109", "file_name": "database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getOptions` that retrieves a comma-separated list of options for a given poll name from a database and returns it as a list."}
{"func_name": "HandleRFBServerMessage", "func_src_before": "HandleRFBServerMessage(rfbClient* client)\n{\n  rfbServerToClientMsg msg;\n\n  if (client->serverPort==-1)\n    client->vncRec->readTimestamp = TRUE;\n  if (!ReadFromRFBServer(client, (char *)&msg, 1))\n    return FALSE;\n\n  switch (msg.type) {\n\n  case rfbSetColourMapEntries:\n  {\n    /* TODO:\n    int i;\n    uint16_t rgb[3];\n    XColor xc;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbSetColourMapEntriesMsg - 1))\n      return FALSE;\n\n    msg.scme.firstColour = rfbClientSwap16IfLE(msg.scme.firstColour);\n    msg.scme.nColours = rfbClientSwap16IfLE(msg.scme.nColours);\n\n    for (i = 0; i < msg.scme.nColours; i++) {\n      if (!ReadFromRFBServer(client, (char *)rgb, 6))\n\treturn FALSE;\n      xc.pixel = msg.scme.firstColour + i;\n      xc.red = rfbClientSwap16IfLE(rgb[0]);\n      xc.green = rfbClientSwap16IfLE(rgb[1]);\n      xc.blue = rfbClientSwap16IfLE(rgb[2]);\n      xc.flags = DoRed|DoGreen|DoBlue;\n      XStoreColor(dpy, cmap, &xc);\n    }\n    */\n\n    break;\n  }\n\n  case rfbFramebufferUpdate:\n  {\n    rfbFramebufferUpdateRectHeader rect;\n    int linesToRead;\n    int bytesPerLine;\n    int i;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg.fu) + 1,\n\t\t\t   sz_rfbFramebufferUpdateMsg - 1))\n      return FALSE;\n\n    msg.fu.nRects = rfbClientSwap16IfLE(msg.fu.nRects);\n\n    for (i = 0; i < msg.fu.nRects; i++) {\n      if (!ReadFromRFBServer(client, (char *)&rect, sz_rfbFramebufferUpdateRectHeader))\n\treturn FALSE;\n\n      rect.encoding = rfbClientSwap32IfLE(rect.encoding);\n      if (rect.encoding == rfbEncodingLastRect)\n\tbreak;\n\n      rect.r.x = rfbClientSwap16IfLE(rect.r.x);\n      rect.r.y = rfbClientSwap16IfLE(rect.r.y);\n      rect.r.w = rfbClientSwap16IfLE(rect.r.w);\n      rect.r.h = rfbClientSwap16IfLE(rect.r.h);\n\n\n      if (rect.encoding == rfbEncodingXCursor ||\n\t  rect.encoding == rfbEncodingRichCursor) {\n\n\tif (!HandleCursorShape(client,\n\t\t\t       rect.r.x, rect.r.y, rect.r.w, rect.r.h,\n\t\t\t       rect.encoding)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n\n      if (rect.encoding == rfbEncodingPointerPos) {\n\tif (!client->HandleCursorPos(client,rect.r.x, rect.r.y)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n      \n      if (rect.encoding == rfbEncodingKeyboardLedState) {\n          /* OK! We have received a keyboard state message!!! */\n          client->KeyboardLedStateEnabled = 1;\n          if (client->HandleKeyboardLedState!=NULL)\n              client->HandleKeyboardLedState(client, rect.r.x, 0);\n          /* stash it for the future */\n          client->CurrentKeyboardLedState = rect.r.x;\n          continue;\n      }\n\n      if (rect.encoding == rfbEncodingNewFBSize) {\n\tclient->width = rect.r.w;\n\tclient->height = rect.r.h;\n\tclient->updateRect.x = client->updateRect.y = 0;\n\tclient->updateRect.w = client->width;\n\tclient->updateRect.h = client->height;\n\tif (!client->MallocFrameBuffer(client))\n\t  return FALSE;\n\tSendFramebufferUpdateRequest(client, 0, 0, rect.r.w, rect.r.h, FALSE);\n\trfbClientLog(\"Got new framebuffer size: %dx%d\\n\", rect.r.w, rect.r.h);\n\tcontinue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingSupportedMessages) {\n          int loop;\n          if (!ReadFromRFBServer(client, (char *)&client->supportedMessages, sz_rfbSupportedMessages))\n              return FALSE;\n\n          /* msgs is two sets of bit flags of supported messages client2server[] and server2client[] */\n          /* currently ignored by this library */\n\n          rfbClientLog(\"client2server supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.client2server[loop],   client->supportedMessages.client2server[loop+1],\n                client->supportedMessages.client2server[loop+2], client->supportedMessages.client2server[loop+3],\n                client->supportedMessages.client2server[loop+4], client->supportedMessages.client2server[loop+5],\n                client->supportedMessages.client2server[loop+6], client->supportedMessages.client2server[loop+7]);\n\n          rfbClientLog(\"server2client supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.server2client[loop],   client->supportedMessages.server2client[loop+1],\n                client->supportedMessages.server2client[loop+2], client->supportedMessages.server2client[loop+3],\n                client->supportedMessages.server2client[loop+4], client->supportedMessages.server2client[loop+5],\n                client->supportedMessages.server2client[loop+6], client->supportedMessages.server2client[loop+7]);\n          continue;\n      }\n\n      /* rect.r.w=byte count, rect.r.h=# of encodings */\n      if (rect.encoding == rfbEncodingSupportedEncodings) {\n          char *buffer;\n          buffer = malloc(rect.r.w);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n\n          /* buffer now contains rect.r.h # of uint32_t encodings that the server supports */\n          /* currently ignored by this library */\n          free(buffer);\n          continue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingServerIdentity) {\n          char *buffer;\n          buffer = malloc(rect.r.w+1);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          buffer[rect.r.w]=0; /* null terminate, just in case */\n          rfbClientLog(\"Connected to Server \\\"%s\\\"\\n\", buffer);\n          free(buffer);\n          continue;\n      }\n\n      /* rfbEncodingUltraZip is a collection of subrects.   x = # of subrects, and h is always 0 */\n      if (rect.encoding != rfbEncodingUltraZip)\n      {\n        if ((rect.r.x + rect.r.w > client->width) ||\n\t    (rect.r.y + rect.r.h > client->height))\n\t    {\n\t      rfbClientLog(\"Rect too large: %dx%d at (%d, %d)\\n\",\n\t  \t  rect.r.w, rect.r.h, rect.r.x, rect.r.y);\n\t      return FALSE;\n            }\n\n        /* UltraVNC with scaling, will send rectangles with a zero W or H\n         *\n        if ((rect.encoding != rfbEncodingTight) && \n            (rect.r.h * rect.r.w == 0))\n        {\n\t  rfbClientLog(\"Zero size rect - ignoring (encoding=%d (0x%08x) %dx, %dy, %dw, %dh)\\n\", rect.encoding, rect.encoding, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n\t  continue;\n        }\n        */\n        \n        /* If RichCursor encoding is used, we should prevent collisions\n\t   between framebuffer updates and cursor drawing operations. */\n        client->SoftCursorLockArea(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n      }\n\n      switch (rect.encoding) {\n\n      case rfbEncodingRaw: {\n\tint y=rect.r.y, h=rect.r.h;\n\n\tbytesPerLine = rect.r.w * client->format.bitsPerPixel / 8;\n\t/* RealVNC 4.x-5.x on OSX can induce bytesPerLine==0, \n\t   usually during GPU accel. */\n\t/* Regardless of cause, do not divide by zero. */\n\tlinesToRead = bytesPerLine ? (RFB_BUFFER_SIZE / bytesPerLine) : 0;\n\n\twhile (linesToRead && h > 0) {\n\t  if (linesToRead > h)\n\t    linesToRead = h;\n\n\t  if (!ReadFromRFBServer(client, client->buffer,bytesPerLine * linesToRead))\n\t    return FALSE;\n\n\t  client->GotBitmap(client, (uint8_t *)client->buffer,\n\t\t\t   rect.r.x, y, rect.r.w,linesToRead);\n\n\t  h -= linesToRead;\n\t  y += linesToRead;\n\n\t}\n\tbreak;\n      } \n\n      case rfbEncodingCopyRect:\n      {\n\trfbCopyRect cr;\n\n\tif (!ReadFromRFBServer(client, (char *)&cr, sz_rfbCopyRect))\n\t  return FALSE;\n\n\tcr.srcX = rfbClientSwap16IfLE(cr.srcX);\n\tcr.srcY = rfbClientSwap16IfLE(cr.srcY);\n\n\t/* If RichCursor encoding is used, we should extend our\n\t   \"cursor lock area\" (previously set to destination\n\t   rectangle) to the source rectangle as well. */\n\tclient->SoftCursorLockArea(client,\n\t\t\t\t   cr.srcX, cr.srcY, rect.r.w, rect.r.h);\n\n        client->GotCopyRect(client, cr.srcX, cr.srcY, rect.r.w, rect.r.h,\n                            rect.r.x, rect.r.y);\n\n\tbreak;\n      }\n\n      case rfbEncodingRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingCoRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleCoRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleCoRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleCoRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingHextile:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleHextile8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleHextile16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleHextile32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingUltra:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltra8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltra16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltra32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n      case rfbEncodingUltraZip:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltraZip8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltraZip16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltraZip32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n\n      case rfbEncodingTRLE:\n\t  {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleTRLE8(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (client->si.format.greenMax > 0x1F) {\n            if (!HandleTRLE16(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else {\n            if (!HandleTRLE15(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          }\n          break;\n        case 32: {\n          uint32_t maxColor =\n              (client->format.redMax << client->format.redShift) |\n              (client->format.greenMax << client->format.greenShift) |\n              (client->format.blueMax << client->format.blueShift);\n          if ((client->format.bigEndian && (maxColor & 0xff) == 0) ||\n              (!client->format.bigEndian && (maxColor & 0xff000000) == 0)) {\n            if (!HandleTRLE24(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (!client->format.bigEndian && (maxColor & 0xff) == 0) {\n            if (!HandleTRLE24Up(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (client->format.bigEndian && (maxColor & 0xff000000) == 0) {\n            if (!HandleTRLE24Down(client, rect.r.x, rect.r.y, rect.r.w,\n                                  rect.r.h))\n              return FALSE;\n          } else if (!HandleTRLE32(client, rect.r.x, rect.r.y, rect.r.w,\n                                   rect.r.h))\n            return FALSE;\n          break;\n        }\n        }\n        break;\n      }\n\n#ifdef LIBVNCSERVER_HAVE_LIBZ\n      case rfbEncodingZlib:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZlib8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleZlib16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleZlib32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n     }\n\n#ifdef LIBVNCSERVER_HAVE_LIBJPEG\n      case rfbEncodingTight:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleTight8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleTight16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleTight32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n#endif\n      case rfbEncodingZRLE:\n\t/* Fail safe for ZYWRLE unsupport VNC server. */\n\tclient->appData.qualityLevel = 9;\n\t/* fall through */\n      case rfbEncodingZYWRLE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZRLE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (client->si.format.greenMax > 0x1F) {\n\t    if (!HandleZRLE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else {\n\t    if (!HandleZRLE15(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  }\n\t  break;\n\tcase 32:\n\t{\n\t  uint32_t maxColor=(client->format.redMax<<client->format.redShift)|\n\t\t(client->format.greenMax<<client->format.greenShift)|\n\t\t(client->format.blueMax<<client->format.blueShift);\n\t  if ((client->format.bigEndian && (maxColor&0xff)==0) ||\n\t      (!client->format.bigEndian && (maxColor&0xff000000)==0)) {\n\t    if (!HandleZRLE24(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!client->format.bigEndian && (maxColor&0xff)==0) {\n\t    if (!HandleZRLE24Up(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (client->format.bigEndian && (maxColor&0xff000000)==0) {\n\t    if (!HandleZRLE24Down(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!HandleZRLE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\t}\n\tbreak;\n     }\n\n#endif\n\n      default:\n\t {\n\t   rfbBool handled = FALSE;\n\t   rfbClientProtocolExtension* e;\n\n\t   for(e = rfbClientExtensions; !handled && e; e = e->next)\n\t     if(e->handleEncoding && e->handleEncoding(client, &rect))\n\t       handled = TRUE;\n\n\t   if(!handled) {\n\t     rfbClientLog(\"Unknown rect encoding %d\\n\",\n\t\t (int)rect.encoding);\n\t     return FALSE;\n\t   }\n\t }\n      }\n\n      /* Now we may discard \"soft cursor locks\". */\n      client->SoftCursorUnlockScreen(client);\n\n      client->GotFrameBufferUpdate(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n    }\n\n    if (!SendIncrementalFramebufferUpdateRequest(client))\n      return FALSE;\n\n    if (client->FinishedFrameBufferUpdate)\n      client->FinishedFrameBufferUpdate(client);\n\n    break;\n  }\n\n  case rfbBell:\n  {\n    client->Bell(client);\n\n    break;\n  }\n\n  case rfbServerCutText:\n  {\n    char *buffer;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbServerCutTextMsg - 1))\n      return FALSE;\n\n    msg.sct.length = rfbClientSwap32IfLE(msg.sct.length);\n\n    if (msg.sct.length > 1<<20) {\n\t    rfbClientErr(\"Ignoring too big cut text length sent by server: %u B > 1 MB\\n\", (unsigned int)msg.sct.length);\n\t    return FALSE;\n    }  \n\n    buffer = malloc(msg.sct.length+1);\n\n    if (!ReadFromRFBServer(client, buffer, msg.sct.length)) {\n      free(buffer);\n      return FALSE;\n    }\n\n    buffer[msg.sct.length] = 0;\n\n    if (client->GotXCutText)\n      client->GotXCutText(client, buffer, msg.sct.length);\n\n    free(buffer);\n\n    break;\n  }\n\n  case rfbTextChat:\n  {\n      char *buffer=NULL;\n      if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                             sz_rfbTextChatMsg- 1))\n        return FALSE;\n      msg.tc.length = rfbClientSwap32IfLE(msg.sct.length);\n      switch(msg.tc.length) {\n      case rfbTextChatOpen:\n          rfbClientLog(\"Received TextChat Open\\n\");\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatOpen, NULL);\n          break;\n      case rfbTextChatClose:\n          rfbClientLog(\"Received TextChat Close\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatClose, NULL);\n          break;\n      case rfbTextChatFinished:\n          rfbClientLog(\"Received TextChat Finished\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatFinished, NULL);\n          break;\n      default:\n          buffer=malloc(msg.tc.length+1);\n          if (!ReadFromRFBServer(client, buffer, msg.tc.length))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          /* Null Terminate <just in case> */\n          buffer[msg.tc.length]=0;\n          rfbClientLog(\"Received TextChat \\\"%s\\\"\\n\", buffer);\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)msg.tc.length, buffer);\n          free(buffer);\n          break;\n      }\n      break;\n  }\n\n  case rfbXvp:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbXvpMsg -1))\n      return FALSE;\n\n    SetClient2Server(client, rfbXvp);\n    /* technically, we only care what we can *send* to the server\n     * but, we set Server2Client Just in case it ever becomes useful\n     */\n    SetServer2Client(client, rfbXvp);\n\n    if(client->HandleXvpMsg)\n      client->HandleXvpMsg(client, msg.xvp.version, msg.xvp.code);\n\n    break;\n  }\n\n  case rfbResizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbResizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.rsfb.framebufferWidth);\n    client->height = rfbClientSwap16IfLE(msg.rsfb.framebufferHeigth);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  case rfbPalmVNCReSizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbPalmVNCReSizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.prsfb.buffer_w);\n    client->height = rfbClientSwap16IfLE(msg.prsfb.buffer_h);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  default:\n    {\n      rfbBool handled = FALSE;\n      rfbClientProtocolExtension* e;\n\n      for(e = rfbClientExtensions; !handled && e; e = e->next)\n\tif(e->handleMessage && e->handleMessage(client, &msg))\n\t  handled = TRUE;\n\n      if(!handled) {\n\tchar buffer[256];\n\trfbClientLog(\"Unknown message type %d from VNC server\\n\",msg.type);\n\tReadFromRFBServer(client, buffer, 256);\n\treturn FALSE;\n      }\n    }\n  }\n\n  return TRUE;\n}", "func_src_after": "HandleRFBServerMessage(rfbClient* client)\n{\n  rfbServerToClientMsg msg;\n\n  if (client->serverPort==-1)\n    client->vncRec->readTimestamp = TRUE;\n  if (!ReadFromRFBServer(client, (char *)&msg, 1))\n    return FALSE;\n\n  switch (msg.type) {\n\n  case rfbSetColourMapEntries:\n  {\n    /* TODO:\n    int i;\n    uint16_t rgb[3];\n    XColor xc;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbSetColourMapEntriesMsg - 1))\n      return FALSE;\n\n    msg.scme.firstColour = rfbClientSwap16IfLE(msg.scme.firstColour);\n    msg.scme.nColours = rfbClientSwap16IfLE(msg.scme.nColours);\n\n    for (i = 0; i < msg.scme.nColours; i++) {\n      if (!ReadFromRFBServer(client, (char *)rgb, 6))\n\treturn FALSE;\n      xc.pixel = msg.scme.firstColour + i;\n      xc.red = rfbClientSwap16IfLE(rgb[0]);\n      xc.green = rfbClientSwap16IfLE(rgb[1]);\n      xc.blue = rfbClientSwap16IfLE(rgb[2]);\n      xc.flags = DoRed|DoGreen|DoBlue;\n      XStoreColor(dpy, cmap, &xc);\n    }\n    */\n\n    break;\n  }\n\n  case rfbFramebufferUpdate:\n  {\n    rfbFramebufferUpdateRectHeader rect;\n    int linesToRead;\n    int bytesPerLine;\n    int i;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg.fu) + 1,\n\t\t\t   sz_rfbFramebufferUpdateMsg - 1))\n      return FALSE;\n\n    msg.fu.nRects = rfbClientSwap16IfLE(msg.fu.nRects);\n\n    for (i = 0; i < msg.fu.nRects; i++) {\n      if (!ReadFromRFBServer(client, (char *)&rect, sz_rfbFramebufferUpdateRectHeader))\n\treturn FALSE;\n\n      rect.encoding = rfbClientSwap32IfLE(rect.encoding);\n      if (rect.encoding == rfbEncodingLastRect)\n\tbreak;\n\n      rect.r.x = rfbClientSwap16IfLE(rect.r.x);\n      rect.r.y = rfbClientSwap16IfLE(rect.r.y);\n      rect.r.w = rfbClientSwap16IfLE(rect.r.w);\n      rect.r.h = rfbClientSwap16IfLE(rect.r.h);\n\n\n      if (rect.encoding == rfbEncodingXCursor ||\n\t  rect.encoding == rfbEncodingRichCursor) {\n\n\tif (!HandleCursorShape(client,\n\t\t\t       rect.r.x, rect.r.y, rect.r.w, rect.r.h,\n\t\t\t       rect.encoding)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n\n      if (rect.encoding == rfbEncodingPointerPos) {\n\tif (!client->HandleCursorPos(client,rect.r.x, rect.r.y)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n      \n      if (rect.encoding == rfbEncodingKeyboardLedState) {\n          /* OK! We have received a keyboard state message!!! */\n          client->KeyboardLedStateEnabled = 1;\n          if (client->HandleKeyboardLedState!=NULL)\n              client->HandleKeyboardLedState(client, rect.r.x, 0);\n          /* stash it for the future */\n          client->CurrentKeyboardLedState = rect.r.x;\n          continue;\n      }\n\n      if (rect.encoding == rfbEncodingNewFBSize) {\n\tclient->width = rect.r.w;\n\tclient->height = rect.r.h;\n\tclient->updateRect.x = client->updateRect.y = 0;\n\tclient->updateRect.w = client->width;\n\tclient->updateRect.h = client->height;\n\tif (!client->MallocFrameBuffer(client))\n\t  return FALSE;\n\tSendFramebufferUpdateRequest(client, 0, 0, rect.r.w, rect.r.h, FALSE);\n\trfbClientLog(\"Got new framebuffer size: %dx%d\\n\", rect.r.w, rect.r.h);\n\tcontinue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingSupportedMessages) {\n          int loop;\n          if (!ReadFromRFBServer(client, (char *)&client->supportedMessages, sz_rfbSupportedMessages))\n              return FALSE;\n\n          /* msgs is two sets of bit flags of supported messages client2server[] and server2client[] */\n          /* currently ignored by this library */\n\n          rfbClientLog(\"client2server supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.client2server[loop],   client->supportedMessages.client2server[loop+1],\n                client->supportedMessages.client2server[loop+2], client->supportedMessages.client2server[loop+3],\n                client->supportedMessages.client2server[loop+4], client->supportedMessages.client2server[loop+5],\n                client->supportedMessages.client2server[loop+6], client->supportedMessages.client2server[loop+7]);\n\n          rfbClientLog(\"server2client supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.server2client[loop],   client->supportedMessages.server2client[loop+1],\n                client->supportedMessages.server2client[loop+2], client->supportedMessages.server2client[loop+3],\n                client->supportedMessages.server2client[loop+4], client->supportedMessages.server2client[loop+5],\n                client->supportedMessages.server2client[loop+6], client->supportedMessages.server2client[loop+7]);\n          continue;\n      }\n\n      /* rect.r.w=byte count, rect.r.h=# of encodings */\n      if (rect.encoding == rfbEncodingSupportedEncodings) {\n          char *buffer;\n          buffer = malloc(rect.r.w);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n\n          /* buffer now contains rect.r.h # of uint32_t encodings that the server supports */\n          /* currently ignored by this library */\n          free(buffer);\n          continue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingServerIdentity) {\n          char *buffer;\n          buffer = malloc(rect.r.w+1);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          buffer[rect.r.w]=0; /* null terminate, just in case */\n          rfbClientLog(\"Connected to Server \\\"%s\\\"\\n\", buffer);\n          free(buffer);\n          continue;\n      }\n\n      /* rfbEncodingUltraZip is a collection of subrects.   x = # of subrects, and h is always 0 */\n      if (rect.encoding != rfbEncodingUltraZip)\n      {\n        if ((rect.r.x + rect.r.w > client->width) ||\n\t    (rect.r.y + rect.r.h > client->height))\n\t    {\n\t      rfbClientLog(\"Rect too large: %dx%d at (%d, %d)\\n\",\n\t  \t  rect.r.w, rect.r.h, rect.r.x, rect.r.y);\n\t      return FALSE;\n            }\n\n        /* UltraVNC with scaling, will send rectangles with a zero W or H\n         *\n        if ((rect.encoding != rfbEncodingTight) && \n            (rect.r.h * rect.r.w == 0))\n        {\n\t  rfbClientLog(\"Zero size rect - ignoring (encoding=%d (0x%08x) %dx, %dy, %dw, %dh)\\n\", rect.encoding, rect.encoding, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n\t  continue;\n        }\n        */\n        \n        /* If RichCursor encoding is used, we should prevent collisions\n\t   between framebuffer updates and cursor drawing operations. */\n        client->SoftCursorLockArea(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n      }\n\n      switch (rect.encoding) {\n\n      case rfbEncodingRaw: {\n\tint y=rect.r.y, h=rect.r.h;\n\n\tbytesPerLine = rect.r.w * client->format.bitsPerPixel / 8;\n\t/* RealVNC 4.x-5.x on OSX can induce bytesPerLine==0, \n\t   usually during GPU accel. */\n\t/* Regardless of cause, do not divide by zero. */\n\tlinesToRead = bytesPerLine ? (RFB_BUFFER_SIZE / bytesPerLine) : 0;\n\n\twhile (linesToRead && h > 0) {\n\t  if (linesToRead > h)\n\t    linesToRead = h;\n\n\t  if (!ReadFromRFBServer(client, client->buffer,bytesPerLine * linesToRead))\n\t    return FALSE;\n\n\t  client->GotBitmap(client, (uint8_t *)client->buffer,\n\t\t\t   rect.r.x, y, rect.r.w,linesToRead);\n\n\t  h -= linesToRead;\n\t  y += linesToRead;\n\n\t}\n\tbreak;\n      } \n\n      case rfbEncodingCopyRect:\n      {\n\trfbCopyRect cr;\n\n\tif (!ReadFromRFBServer(client, (char *)&cr, sz_rfbCopyRect))\n\t  return FALSE;\n\n\tcr.srcX = rfbClientSwap16IfLE(cr.srcX);\n\tcr.srcY = rfbClientSwap16IfLE(cr.srcY);\n\n\t/* If RichCursor encoding is used, we should extend our\n\t   \"cursor lock area\" (previously set to destination\n\t   rectangle) to the source rectangle as well. */\n\tclient->SoftCursorLockArea(client,\n\t\t\t\t   cr.srcX, cr.srcY, rect.r.w, rect.r.h);\n\n        client->GotCopyRect(client, cr.srcX, cr.srcY, rect.r.w, rect.r.h,\n                            rect.r.x, rect.r.y);\n\n\tbreak;\n      }\n\n      case rfbEncodingRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingCoRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleCoRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleCoRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleCoRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingHextile:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleHextile8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleHextile16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleHextile32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingUltra:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltra8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltra16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltra32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n      case rfbEncodingUltraZip:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltraZip8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltraZip16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltraZip32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n\n      case rfbEncodingTRLE:\n\t  {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleTRLE8(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (client->si.format.greenMax > 0x1F) {\n            if (!HandleTRLE16(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else {\n            if (!HandleTRLE15(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          }\n          break;\n        case 32: {\n          uint32_t maxColor =\n              (client->format.redMax << client->format.redShift) |\n              (client->format.greenMax << client->format.greenShift) |\n              (client->format.blueMax << client->format.blueShift);\n          if ((client->format.bigEndian && (maxColor & 0xff) == 0) ||\n              (!client->format.bigEndian && (maxColor & 0xff000000) == 0)) {\n            if (!HandleTRLE24(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (!client->format.bigEndian && (maxColor & 0xff) == 0) {\n            if (!HandleTRLE24Up(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (client->format.bigEndian && (maxColor & 0xff000000) == 0) {\n            if (!HandleTRLE24Down(client, rect.r.x, rect.r.y, rect.r.w,\n                                  rect.r.h))\n              return FALSE;\n          } else if (!HandleTRLE32(client, rect.r.x, rect.r.y, rect.r.w,\n                                   rect.r.h))\n            return FALSE;\n          break;\n        }\n        }\n        break;\n      }\n\n#ifdef LIBVNCSERVER_HAVE_LIBZ\n      case rfbEncodingZlib:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZlib8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleZlib16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleZlib32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n     }\n\n#ifdef LIBVNCSERVER_HAVE_LIBJPEG\n      case rfbEncodingTight:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleTight8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleTight16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleTight32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n#endif\n      case rfbEncodingZRLE:\n\t/* Fail safe for ZYWRLE unsupport VNC server. */\n\tclient->appData.qualityLevel = 9;\n\t/* fall through */\n      case rfbEncodingZYWRLE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZRLE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (client->si.format.greenMax > 0x1F) {\n\t    if (!HandleZRLE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else {\n\t    if (!HandleZRLE15(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  }\n\t  break;\n\tcase 32:\n\t{\n\t  uint32_t maxColor=(client->format.redMax<<client->format.redShift)|\n\t\t(client->format.greenMax<<client->format.greenShift)|\n\t\t(client->format.blueMax<<client->format.blueShift);\n\t  if ((client->format.bigEndian && (maxColor&0xff)==0) ||\n\t      (!client->format.bigEndian && (maxColor&0xff000000)==0)) {\n\t    if (!HandleZRLE24(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!client->format.bigEndian && (maxColor&0xff)==0) {\n\t    if (!HandleZRLE24Up(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (client->format.bigEndian && (maxColor&0xff000000)==0) {\n\t    if (!HandleZRLE24Down(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!HandleZRLE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\t}\n\tbreak;\n     }\n\n#endif\n\n      default:\n\t {\n\t   rfbBool handled = FALSE;\n\t   rfbClientProtocolExtension* e;\n\n\t   for(e = rfbClientExtensions; !handled && e; e = e->next)\n\t     if(e->handleEncoding && e->handleEncoding(client, &rect))\n\t       handled = TRUE;\n\n\t   if(!handled) {\n\t     rfbClientLog(\"Unknown rect encoding %d\\n\",\n\t\t (int)rect.encoding);\n\t     return FALSE;\n\t   }\n\t }\n      }\n\n      /* Now we may discard \"soft cursor locks\". */\n      client->SoftCursorUnlockScreen(client);\n\n      client->GotFrameBufferUpdate(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n    }\n\n    if (!SendIncrementalFramebufferUpdateRequest(client))\n      return FALSE;\n\n    if (client->FinishedFrameBufferUpdate)\n      client->FinishedFrameBufferUpdate(client);\n\n    break;\n  }\n\n  case rfbBell:\n  {\n    client->Bell(client);\n\n    break;\n  }\n\n  case rfbServerCutText:\n  {\n    char *buffer;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbServerCutTextMsg - 1))\n      return FALSE;\n\n    msg.sct.length = rfbClientSwap32IfLE(msg.sct.length);\n\n    if (msg.sct.length > 1<<20) {\n\t    rfbClientErr(\"Ignoring too big cut text length sent by server: %u B > 1 MB\\n\", (unsigned int)msg.sct.length);\n\t    return FALSE;\n    }  \n\n    buffer = malloc((uint64_t)msg.sct.length+1);\n\n    if (!ReadFromRFBServer(client, buffer, msg.sct.length)) {\n      free(buffer);\n      return FALSE;\n    }\n\n    buffer[msg.sct.length] = 0;\n\n    if (client->GotXCutText)\n      client->GotXCutText(client, buffer, msg.sct.length);\n\n    free(buffer);\n\n    break;\n  }\n\n  case rfbTextChat:\n  {\n      char *buffer=NULL;\n      if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                             sz_rfbTextChatMsg- 1))\n        return FALSE;\n      msg.tc.length = rfbClientSwap32IfLE(msg.sct.length);\n      switch(msg.tc.length) {\n      case rfbTextChatOpen:\n          rfbClientLog(\"Received TextChat Open\\n\");\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatOpen, NULL);\n          break;\n      case rfbTextChatClose:\n          rfbClientLog(\"Received TextChat Close\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatClose, NULL);\n          break;\n      case rfbTextChatFinished:\n          rfbClientLog(\"Received TextChat Finished\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatFinished, NULL);\n          break;\n      default:\n          buffer=malloc(msg.tc.length+1);\n          if (!ReadFromRFBServer(client, buffer, msg.tc.length))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          /* Null Terminate <just in case> */\n          buffer[msg.tc.length]=0;\n          rfbClientLog(\"Received TextChat \\\"%s\\\"\\n\", buffer);\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)msg.tc.length, buffer);\n          free(buffer);\n          break;\n      }\n      break;\n  }\n\n  case rfbXvp:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbXvpMsg -1))\n      return FALSE;\n\n    SetClient2Server(client, rfbXvp);\n    /* technically, we only care what we can *send* to the server\n     * but, we set Server2Client Just in case it ever becomes useful\n     */\n    SetServer2Client(client, rfbXvp);\n\n    if(client->HandleXvpMsg)\n      client->HandleXvpMsg(client, msg.xvp.version, msg.xvp.code);\n\n    break;\n  }\n\n  case rfbResizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbResizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.rsfb.framebufferWidth);\n    client->height = rfbClientSwap16IfLE(msg.rsfb.framebufferHeigth);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  case rfbPalmVNCReSizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbPalmVNCReSizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.prsfb.buffer_w);\n    client->height = rfbClientSwap16IfLE(msg.prsfb.buffer_h);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  default:\n    {\n      rfbBool handled = FALSE;\n      rfbClientProtocolExtension* e;\n\n      for(e = rfbClientExtensions; !handled && e; e = e->next)\n\tif(e->handleMessage && e->handleMessage(client, &msg))\n\t  handled = TRUE;\n\n      if(!handled) {\n\tchar buffer[256];\n\trfbClientLog(\"Unknown message type %d from VNC server\\n\",msg.type);\n\tReadFromRFBServer(client, buffer, 256);\n\treturn FALSE;\n      }\n    }\n  }\n\n  return TRUE;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/a64c3b37af9a6c8f8009d7516874b8d266b42bae", "file_name": "libvncclient/rfbproto.c", "vul_type": "cwe-787", "description": "Write a function in C to handle server messages for a VNC client."}
{"func_name": "get_bracket_graph_data", "func_src_before": "def get_bracket_graph_data(db, tag):\n    # First, we have to find out which scenes this player has brackets in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{}'\".format(tag)\n    scenes = db.exec(sql)\n    scenes = [s[0] for s in scenes]\n\n    bracket_placings_by_scene = {s: get_bracket_placings_in_scene(db, s, tag) for s in scenes}\n\n    return bracket_placings_by_scene", "func_src_after": "def get_bracket_graph_data(db, tag):\n    # First, we have to find out which scenes this player has brackets in\n    sql = \"SELECT DISTINCT scene FROM ranks WHERE player='{tag}'\"\n    args = {'tag': tag}\n    scenes = db.exec(sql, args)\n    scenes = [s[0] for s in scenes]\n\n    bracket_placings_by_scene = {s: get_bracket_placings_in_scene(db, s, tag) for s in scenes}\n\n    return bracket_placings_by_scene", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "Write a Python function named `get_bracket_graph_data` that retrieves distinct scenes for a player's brackets from a database and maps each scene to its bracket placings."}
{"func_name": "jpc_pi_nextcprl", "func_src_before": "static int jpc_pi_nextcprl(register jpc_pi_t *pi)\n{\n\tint rlvlno;\n\tjpc_pirlvl_t *pirlvl;\n\tjpc_pchg_t *pchg;\n\tint prchind;\n\tint prcvind;\n\tint *prclyrno;\n\tuint_fast32_t trx0;\n\tuint_fast32_t try0;\n\tuint_fast32_t r;\n\tuint_fast32_t rpx;\n\tuint_fast32_t rpy;\n\n\tpchg = pi->pchg;\n\tif (!pi->prgvolfirst) {\n\t\tgoto skip;\n\t} else {\n\t\tpi->prgvolfirst = 0;\n\t}\n\n\tfor (pi->compno = pchg->compnostart, pi->picomp =\n\t  &pi->picomps[pi->compno]; pi->compno < JAS_CAST(int, pchg->compnoend) && pi->compno < pi->numcomps; ++pi->compno,\n\t  ++pi->picomp) {\n\t\tpirlvl = pi->picomp->pirlvls;\n\t\tpi->xstep = pi->picomp->hsamp * (1 << (pirlvl->prcwidthexpn +\n\t\t  pi->picomp->numrlvls - 1));\n\t\tpi->ystep = pi->picomp->vsamp * (1 << (pirlvl->prcheightexpn +\n\t\t  pi->picomp->numrlvls - 1));\n\t\tfor (rlvlno = 1, pirlvl = &pi->picomp->pirlvls[1];\n\t\t  rlvlno < pi->picomp->numrlvls; ++rlvlno, ++pirlvl) {\n\t\t\tpi->xstep = JAS_MIN(pi->xstep, pi->picomp->hsamp * (1 <<\n\t\t\t  (pirlvl->prcwidthexpn + pi->picomp->numrlvls -\n\t\t\t  rlvlno - 1)));\n\t\t\tpi->ystep = JAS_MIN(pi->ystep, pi->picomp->vsamp * (1 <<\n\t\t\t  (pirlvl->prcheightexpn + pi->picomp->numrlvls -\n\t\t\t  rlvlno - 1)));\n\t\t}\n\t\tfor (pi->y = pi->ystart; pi->y < pi->yend;\n\t\t  pi->y += pi->ystep - (pi->y % pi->ystep)) {\n\t\t\tfor (pi->x = pi->xstart; pi->x < pi->xend;\n\t\t\t  pi->x += pi->xstep - (pi->x % pi->xstep)) {\n\t\t\t\tfor (pi->rlvlno = pchg->rlvlnostart,\n\t\t\t\t  pi->pirlvl = &pi->picomp->pirlvls[pi->rlvlno];\n\t\t\t\t  pi->rlvlno < pi->picomp->numrlvls && pi->rlvlno <\n\t\t\t\t  pchg->rlvlnoend; ++pi->rlvlno, ++pi->pirlvl) {\n\t\t\t\t\tif (pi->pirlvl->numprcs == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tr = pi->picomp->numrlvls - 1 - pi->rlvlno;\n\t\t\t\t\ttrx0 = JPC_CEILDIV(pi->xstart, pi->picomp->hsamp << r);\n\t\t\t\t\ttry0 = JPC_CEILDIV(pi->ystart, pi->picomp->vsamp << r);\n\t\t\t\t\trpx = r + pi->pirlvl->prcwidthexpn;\n\t\t\t\t\trpy = r + pi->pirlvl->prcheightexpn;\n\t\t\t\t\tif (((pi->x == pi->xstart && ((trx0 << r) % (1 << rpx))) ||\n\t\t\t\t\t  !(pi->x % (pi->picomp->hsamp << rpx))) &&\n\t\t\t\t\t  ((pi->y == pi->ystart && ((try0 << r) % (1 << rpy))) ||\n\t\t\t\t\t  !(pi->y % (pi->picomp->vsamp << rpy)))) {\n\t\t\t\t\t\tprchind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->x, pi->picomp->hsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcwidthexpn) - JPC_FLOORDIVPOW2(trx0,\n\t\t\t\t\t\t  pi->pirlvl->prcwidthexpn);\n\t\t\t\t\t\tprcvind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->y, pi->picomp->vsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcheightexpn) - JPC_FLOORDIVPOW2(try0,\n\t\t\t\t\t\t  pi->pirlvl->prcheightexpn);\n\t\t\t\t\t\tpi->prcno = prcvind *\n\t\t\t\t\t\t  pi->pirlvl->numhprcs +\n\t\t\t\t\t\t  prchind;\n\t\t\t\t\t\tassert(pi->prcno <\n\t\t\t\t\t\t  pi->pirlvl->numprcs);\n\t\t\t\t\t\tfor (pi->lyrno = 0; pi->lyrno <\n\t\t\t\t\t\t  pi->numlyrs && pi->lyrno < JAS_CAST(int, pchg->lyrnoend); ++pi->lyrno) {\n\t\t\t\t\t\t\tprclyrno = &pi->pirlvl->prclyrnos[pi->prcno];\n\t\t\t\t\t\t\tif (pi->lyrno >= *prclyrno) {\n\t\t\t\t\t\t\t\t++(*prclyrno);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\nskip:\n\t\t\t\t\t\t\t;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "func_src_after": "static int jpc_pi_nextcprl(register jpc_pi_t *pi)\n{\n\tint rlvlno;\n\tjpc_pirlvl_t *pirlvl;\n\tjpc_pchg_t *pchg;\n\tint prchind;\n\tint prcvind;\n\tint *prclyrno;\n\tuint_fast32_t trx0;\n\tuint_fast32_t try0;\n\tuint_fast32_t r;\n\tuint_fast32_t rpx;\n\tuint_fast32_t rpy;\n\n\tpchg = pi->pchg;\n\tif (!pi->prgvolfirst) {\n\t\tgoto skip;\n\t} else {\n\t\tpi->prgvolfirst = 0;\n\t}\n\n\tfor (pi->compno = pchg->compnostart, pi->picomp =\n\t  &pi->picomps[pi->compno]; pi->compno < JAS_CAST(int, pchg->compnoend) && pi->compno < pi->numcomps; ++pi->compno,\n\t  ++pi->picomp) {\n\t\tpirlvl = pi->picomp->pirlvls;\n\t\tpi->xstep = pi->picomp->hsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t  (pirlvl->prcwidthexpn + pi->picomp->numrlvls - 1));\n\t\tpi->ystep = pi->picomp->vsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t  (pirlvl->prcheightexpn + pi->picomp->numrlvls - 1));\n\t\tfor (rlvlno = 1, pirlvl = &pi->picomp->pirlvls[1];\n\t\t  rlvlno < pi->picomp->numrlvls; ++rlvlno, ++pirlvl) {\n\t\t\tpi->xstep = JAS_MIN(pi->xstep, pi->picomp->hsamp *\n\t\t\t  (JAS_CAST(uint_fast32_t, 1) << (pirlvl->prcwidthexpn +\n\t\t\t  pi->picomp->numrlvls - rlvlno - 1)));\n\t\t\tpi->ystep = JAS_MIN(pi->ystep, pi->picomp->vsamp *\n\t\t\t  (JAS_CAST(uint_fast32_t, 1) << (pirlvl->prcheightexpn +\n\t\t\t  pi->picomp->numrlvls - rlvlno - 1)));\n\t\t}\n\t\tfor (pi->y = pi->ystart; pi->y < pi->yend;\n\t\t  pi->y += pi->ystep - (pi->y % pi->ystep)) {\n\t\t\tfor (pi->x = pi->xstart; pi->x < pi->xend;\n\t\t\t  pi->x += pi->xstep - (pi->x % pi->xstep)) {\n\t\t\t\tfor (pi->rlvlno = pchg->rlvlnostart,\n\t\t\t\t  pi->pirlvl = &pi->picomp->pirlvls[pi->rlvlno];\n\t\t\t\t  pi->rlvlno < pi->picomp->numrlvls && pi->rlvlno <\n\t\t\t\t  pchg->rlvlnoend; ++pi->rlvlno, ++pi->pirlvl) {\n\t\t\t\t\tif (pi->pirlvl->numprcs == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tr = pi->picomp->numrlvls - 1 - pi->rlvlno;\n\t\t\t\t\ttrx0 = JPC_CEILDIV(pi->xstart, pi->picomp->hsamp << r);\n\t\t\t\t\ttry0 = JPC_CEILDIV(pi->ystart, pi->picomp->vsamp << r);\n\t\t\t\t\trpx = r + pi->pirlvl->prcwidthexpn;\n\t\t\t\t\trpy = r + pi->pirlvl->prcheightexpn;\n\t\t\t\t\tif (((pi->x == pi->xstart && ((trx0 << r) % (1 << rpx))) ||\n\t\t\t\t\t  !(pi->x % (pi->picomp->hsamp << rpx))) &&\n\t\t\t\t\t  ((pi->y == pi->ystart && ((try0 << r) % (1 << rpy))) ||\n\t\t\t\t\t  !(pi->y % (pi->picomp->vsamp << rpy)))) {\n\t\t\t\t\t\tprchind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->x, pi->picomp->hsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcwidthexpn) - JPC_FLOORDIVPOW2(trx0,\n\t\t\t\t\t\t  pi->pirlvl->prcwidthexpn);\n\t\t\t\t\t\tprcvind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->y, pi->picomp->vsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcheightexpn) - JPC_FLOORDIVPOW2(try0,\n\t\t\t\t\t\t  pi->pirlvl->prcheightexpn);\n\t\t\t\t\t\tpi->prcno = prcvind *\n\t\t\t\t\t\t  pi->pirlvl->numhprcs +\n\t\t\t\t\t\t  prchind;\n\t\t\t\t\t\tassert(pi->prcno <\n\t\t\t\t\t\t  pi->pirlvl->numprcs);\n\t\t\t\t\t\tfor (pi->lyrno = 0; pi->lyrno <\n\t\t\t\t\t\t  pi->numlyrs && pi->lyrno < JAS_CAST(int, pchg->lyrnoend); ++pi->lyrno) {\n\t\t\t\t\t\t\tprclyrno = &pi->pirlvl->prclyrnos[pi->prcno];\n\t\t\t\t\t\t\tif (pi->lyrno >= *prclyrno) {\n\t\t\t\t\t\t\t\t++(*prclyrno);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\nskip:\n\t\t\t\t\t\t\t;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "commit_link": "github.com/mdadams/jasper/commit/1f0dfe5a42911b6880a1445f13f6d615ddb55387", "file_name": "src/libjasper/jpc/jpc_t2cod.c", "vul_type": "cwe-190", "description": "Write a C function named `jpc_pi_nextcprl` that iterates over components, resolutions, positions, and layers for JPEG 2000 progression order changes."}
{"func_name": "start_input_ppm", "func_src_before": "start_input_ppm(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  ppm_source_ptr source = (ppm_source_ptr)sinfo;\n  int c;\n  unsigned int w, h, maxval;\n  boolean need_iobuffer, use_raw_buffer, need_rescale;\n\n  if (getc(source->pub.input_file) != 'P')\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  c = getc(source->pub.input_file); /* subformat discriminator character */\n\n  /* detect unsupported variants (ie, PBM) before trying to read header */\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n  case '3':                     /* it's a text-format PPM file */\n  case '5':                     /* it's a raw-format PGM file */\n  case '6':                     /* it's a raw-format PPM file */\n    break;\n  default:\n    ERREXIT(cinfo, JERR_PPM_NOT);\n    break;\n  }\n\n  /* fetch the remaining header info */\n  w = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  h = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  maxval = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n\n  if (w <= 0 || h <= 0 || maxval <= 0) /* error check */\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  cinfo->data_precision = BITS_IN_JSAMPLE; /* we always rescale data to this */\n  cinfo->image_width = (JDIMENSION)w;\n  cinfo->image_height = (JDIMENSION)h;\n  source->maxval = maxval;\n\n  /* initialize flags to most common settings */\n  need_iobuffer = TRUE;         /* do we need an I/O buffer? */\n  use_raw_buffer = FALSE;       /* do we map input buffer onto I/O buffer? */\n  need_rescale = TRUE;          /* do we need a rescale array? */\n\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM_TEXT, w, h);\n    if (cinfo->in_color_space == JCS_GRAYSCALE)\n      source->pub.get_pixel_rows = get_text_gray_row;\n    else if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_gray_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_gray_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '3':                     /* it's a text-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM_TEXT, w, h);\n    if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_rgb_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '5':                     /* it's a raw-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_gray_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               cinfo->in_color_space == JCS_GRAYSCALE) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (cinfo->in_color_space == JCS_GRAYSCALE)\n        source->pub.get_pixel_rows = get_scaled_gray_row;\n      else if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_gray_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_gray_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n\n  case '6':                     /* it's a raw-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_rgb_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               (cinfo->in_color_space == JCS_EXT_RGB\n#if RGB_RED == 0 && RGB_GREEN == 1 && RGB_BLUE == 2 && RGB_PIXELSIZE == 3\n                || cinfo->in_color_space == JCS_RGB\n#endif\n               )) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_rgb_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n  }\n\n  if (IsExtRGB(cinfo->in_color_space))\n    cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n  else if (cinfo->in_color_space == JCS_GRAYSCALE)\n    cinfo->input_components = 1;\n  else if (cinfo->in_color_space == JCS_CMYK)\n    cinfo->input_components = 4;\n\n  /* Allocate space for I/O buffer: 1 or 3 bytes or words/pixel. */\n  if (need_iobuffer) {\n    if (c == '6')\n      source->buffer_width = (size_t)w * 3 *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    else\n      source->buffer_width = (size_t)w *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    source->iobuffer = (U_CHAR *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  source->buffer_width);\n  }\n\n  /* Create compressor input buffer. */\n  if (use_raw_buffer) {\n    /* For unscaled raw-input case, we can just map it onto the I/O buffer. */\n    /* Synthesize a JSAMPARRAY pointer structure */\n    source->pixrow = (JSAMPROW)source->iobuffer;\n    source->pub.buffer = &source->pixrow;\n    source->pub.buffer_height = 1;\n  } else {\n    /* Need to translate anyway, so make a separate sample buffer. */\n    source->pub.buffer = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE,\n       (JDIMENSION)w * cinfo->input_components, (JDIMENSION)1);\n    source->pub.buffer_height = 1;\n  }\n\n  /* Compute the rescaling array if required. */\n  if (need_rescale) {\n    long val, half_maxval;\n\n    /* On 16-bit-int machines we have to be careful of maxval = 65535 */\n    source->rescale = (JSAMPLE *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  (size_t)(((long)maxval + 1L) *\n                                           sizeof(JSAMPLE)));\n    half_maxval = maxval / 2;\n    for (val = 0; val <= (long)maxval; val++) {\n      /* The multiplication here must be done in 32 bits to avoid overflow */\n      source->rescale[val] = (JSAMPLE)((val * MAXJSAMPLE + half_maxval) /\n                                        maxval);\n    }\n  }\n}", "func_src_after": "start_input_ppm(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  ppm_source_ptr source = (ppm_source_ptr)sinfo;\n  int c;\n  unsigned int w, h, maxval;\n  boolean need_iobuffer, use_raw_buffer, need_rescale;\n\n  if (getc(source->pub.input_file) != 'P')\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  c = getc(source->pub.input_file); /* subformat discriminator character */\n\n  /* detect unsupported variants (ie, PBM) before trying to read header */\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n  case '3':                     /* it's a text-format PPM file */\n  case '5':                     /* it's a raw-format PGM file */\n  case '6':                     /* it's a raw-format PPM file */\n    break;\n  default:\n    ERREXIT(cinfo, JERR_PPM_NOT);\n    break;\n  }\n\n  /* fetch the remaining header info */\n  w = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  h = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n  maxval = read_pbm_integer(cinfo, source->pub.input_file, 65535);\n\n  if (w <= 0 || h <= 0 || maxval <= 0) /* error check */\n    ERREXIT(cinfo, JERR_PPM_NOT);\n\n  cinfo->data_precision = BITS_IN_JSAMPLE; /* we always rescale data to this */\n  cinfo->image_width = (JDIMENSION)w;\n  cinfo->image_height = (JDIMENSION)h;\n  source->maxval = maxval;\n\n  /* initialize flags to most common settings */\n  need_iobuffer = TRUE;         /* do we need an I/O buffer? */\n  use_raw_buffer = FALSE;       /* do we map input buffer onto I/O buffer? */\n  need_rescale = TRUE;          /* do we need a rescale array? */\n\n  switch (c) {\n  case '2':                     /* it's a text-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM_TEXT, w, h);\n    if (cinfo->in_color_space == JCS_GRAYSCALE)\n      source->pub.get_pixel_rows = get_text_gray_row;\n    else if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_gray_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_gray_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '3':                     /* it's a text-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM_TEXT, w, h);\n    if (IsExtRGB(cinfo->in_color_space))\n      source->pub.get_pixel_rows = get_text_rgb_row;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      source->pub.get_pixel_rows = get_text_rgb_cmyk_row;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    need_iobuffer = FALSE;\n    break;\n\n  case '5':                     /* it's a raw-format PGM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_GRAYSCALE;\n    TRACEMS2(cinfo, 1, JTRC_PGM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_gray_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               cinfo->in_color_space == JCS_GRAYSCALE) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (cinfo->in_color_space == JCS_GRAYSCALE)\n        source->pub.get_pixel_rows = get_scaled_gray_row;\n      else if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_gray_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_gray_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n\n  case '6':                     /* it's a raw-format PPM file */\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    TRACEMS2(cinfo, 1, JTRC_PPM, w, h);\n    if (maxval > 255) {\n      source->pub.get_pixel_rows = get_word_rgb_row;\n    } else if (maxval == MAXJSAMPLE && sizeof(JSAMPLE) == sizeof(U_CHAR) &&\n               (cinfo->in_color_space == JCS_EXT_RGB\n#if RGB_RED == 0 && RGB_GREEN == 1 && RGB_BLUE == 2 && RGB_PIXELSIZE == 3\n                || cinfo->in_color_space == JCS_RGB\n#endif\n               )) {\n      source->pub.get_pixel_rows = get_raw_row;\n      use_raw_buffer = TRUE;\n      need_rescale = FALSE;\n    } else {\n      if (IsExtRGB(cinfo->in_color_space))\n        source->pub.get_pixel_rows = get_rgb_row;\n      else if (cinfo->in_color_space == JCS_CMYK)\n        source->pub.get_pixel_rows = get_rgb_cmyk_row;\n      else\n        ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    }\n    break;\n  }\n\n  if (IsExtRGB(cinfo->in_color_space))\n    cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n  else if (cinfo->in_color_space == JCS_GRAYSCALE)\n    cinfo->input_components = 1;\n  else if (cinfo->in_color_space == JCS_CMYK)\n    cinfo->input_components = 4;\n\n  /* Allocate space for I/O buffer: 1 or 3 bytes or words/pixel. */\n  if (need_iobuffer) {\n    if (c == '6')\n      source->buffer_width = (size_t)w * 3 *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    else\n      source->buffer_width = (size_t)w *\n        ((maxval <= 255) ? sizeof(U_CHAR) : (2 * sizeof(U_CHAR)));\n    source->iobuffer = (U_CHAR *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  source->buffer_width);\n  }\n\n  /* Create compressor input buffer. */\n  if (use_raw_buffer) {\n    /* For unscaled raw-input case, we can just map it onto the I/O buffer. */\n    /* Synthesize a JSAMPARRAY pointer structure */\n    source->pixrow = (JSAMPROW)source->iobuffer;\n    source->pub.buffer = &source->pixrow;\n    source->pub.buffer_height = 1;\n  } else {\n    /* Need to translate anyway, so make a separate sample buffer. */\n    source->pub.buffer = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE,\n       (JDIMENSION)w * cinfo->input_components, (JDIMENSION)1);\n    source->pub.buffer_height = 1;\n  }\n\n  /* Compute the rescaling array if required. */\n  if (need_rescale) {\n    long val, half_maxval;\n\n    /* On 16-bit-int machines we have to be careful of maxval = 65535 */\n    source->rescale = (JSAMPLE *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                  (size_t)(((long)MAX(maxval, 255) + 1L) *\n                                           sizeof(JSAMPLE)));\n    half_maxval = maxval / 2;\n    for (val = 0; val <= (long)maxval; val++) {\n      /* The multiplication here must be done in 32 bits to avoid overflow */\n      source->rescale[val] = (JSAMPLE)((val * MAXJSAMPLE + half_maxval) /\n                                        maxval);\n    }\n  }\n}", "commit_link": "github.com/libjpeg-turbo/libjpeg-turbo/commit/3de15e0c344d11d4b90f4a47136467053eb2d09a", "file_name": "rdppm.c", "vul_type": "cwe-125", "description": "Write a C function to initialize PPM image reading for JPEG compression."}
{"func_name": "tflite::GetOptionalInputTensor", "func_src_before": "const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                           const TfLiteNode* node, int index) {\n  return GetInput(context, node, index);\n}", "func_src_after": "const TfLiteTensor* GetOptionalInputTensor(const TfLiteContext* context,\n                                           const TfLiteNode* node, int index) {\n  const bool use_tensor = index < node->inputs->size &&\n                          node->inputs->data[index] != kTfLiteOptionalTensor;\n  if (use_tensor) {\n    return GetMutableInput(context, node, index);\n  }\n  return nullptr;\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/00302787b788c5ff04cb6f62aed5a74d936e86c0", "file_name": "tensorflow/lite/kernels/kernel_util.cc", "vul_type": "cwe-125", "description": "Write a C++ function named `GetOptionalInputTensor` that retrieves an optional input tensor from a TensorFlow Lite node if it exists, or returns null otherwise."}
{"func_name": "HPHP::exif_process_APP12", "func_src_before": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1-1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "func_src_after": "static void exif_process_APP12(image_info_type *ImageInfo,\n                               char *buffer, size_t length) {\n  size_t l1, l2=0;\n  if ((l1 = php_strnlen(buffer+2, length-2)) > 0) {\n    exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Company\",\n                     TAG_NONE, TAG_FMT_STRING, l1, buffer+2);\n    if (length > 2+l1+1) {\n      l2 = php_strnlen(buffer+2+l1+1, length-2-l1+1);\n      exif_iif_add_tag(ImageInfo, SECTION_APP12, \"Info\",\n                       TAG_NONE, TAG_FMT_STRING, l2, buffer+2+l1+1);\n    }\n  }\n}", "commit_link": "github.com/facebook/hhvm/commit/f1cd34e63c2a0d9702be3d41462db7bfd0ae7da3", "file_name": "hphp/runtime/ext/gd/ext_gd.cpp", "vul_type": "cwe-125", "description": "Write a C function named `exif_process_APP12` that processes APP12 EXIF tags from a buffer and adds them to an image information structure."}
{"func_name": "_delete_3par_host", "func_src_before": "    def _delete_3par_host(self, hostname):\n        self._cli_run(['removehost', hostname])", "func_src_after": "    def _delete_3par_host(self, hostname):\n        self._cli_run('removehost %s' % hostname, None)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function named `_delete_3par_host` that takes a hostname as an argument and calls a method `_cli_run` to execute a command to remove that host."}
{"func_name": "get_first_month", "func_src_before": "def get_first_month(db, scene):\n    sql = \"select date from matches where scene='{}' order by date limit 1;\".format(scene)\n    res = db.exec(sql)\n    date = res[0][0]\n    return date", "func_src_after": "def get_first_month(db, scene):\n    sql = \"select date from matches where scene='{scene}' order by date limit 1;\"\n    args = {'scene': scene}\n    res = db.exec(sql, args)\n    date = res[0][0]\n    return date", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve the earliest date from a 'matches' database table for a given 'scene'."}
{"func_name": "add_language", "func_src_before": "    def add_language(self, language):\n        \"\"\"\"Add new language for item translations.\"\"\"\n        if self.connection:\n            t = (language[0], )\n            self.cursor.execute('insert into itemlanguage (language) values (?)', t)\n            self.connection.commit()", "func_src_after": "    def add_language(self, language):\n        \"\"\"\"Add new language for item translations.\"\"\"\n        if self.connection:\n            self.cursor.execute('insert into itemlanguage (language) values (\"%s\")' % language[0])\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new language into a database table for item translations, using parameter substitution."}
{"func_name": "dex_loadcode", "func_src_before": "static int dex_loadcode(RBinFile *arch, RBinDexObj *bin) {\n\tstruct r_bin_t *rbin = arch->rbin;\n\tint i;\n\tint *methods = NULL;\n\tint sym_count = 0;\n\n\t// doublecheck??\n\tif (!bin || bin->methods_list) {\n\t\treturn false;\n\t}\n\tbin->code_from = UT64_MAX;\n\tbin->code_to = 0;\n\tbin->methods_list = r_list_newf ((RListFree)free);\n\tif (!bin->methods_list) {\n\t\treturn false;\n\t}\n\tbin->imports_list = r_list_newf ((RListFree)free);\n\tif (!bin->imports_list) {\n\t\tr_list_free (bin->methods_list);\n\t\treturn false;\n\t}\n\tbin->classes_list = r_list_newf ((RListFree)__r_bin_class_free);\n\tif (!bin->classes_list) {\n\t\tr_list_free (bin->methods_list);\n\t\tr_list_free (bin->imports_list);\n\t\treturn false;\n\t}\n\n\tif (bin->header.method_size>bin->size) {\n\t\tbin->header.method_size = 0;\n\t\treturn false;\n\t}\n\n\t/* WrapDown the header sizes to avoid huge allocations */\n\tbin->header.method_size = R_MIN (bin->header.method_size, bin->size);\n\tbin->header.class_size = R_MIN (bin->header.class_size, bin->size);\n\tbin->header.strings_size = R_MIN (bin->header.strings_size, bin->size);\n\n\t// TODO: is this posible after R_MIN ??\n\tif (bin->header.strings_size > bin->size) {\n\t\teprintf (\"Invalid strings size\\n\");\n\t\treturn false;\n\t}\n\n\tif (bin->classes) {\n\t\tut64 amount = sizeof (int) * bin->header.method_size;\n\t\tif (amount > UT32_MAX || amount < bin->header.method_size) {\n\t\t\treturn false;\n\t\t}\n\t\tmethods = calloc (1, amount + 1);\n\t\tfor (i = 0; i < bin->header.class_size; i++) {\n\t\t\tchar *super_name, *class_name;\n\t\t\tstruct dex_class_t *c = &bin->classes[i];\n\t\t\tclass_name = dex_class_name (bin, c);\n\t\t\tsuper_name = dex_class_super_name (bin, c);\n\t\t\tif (dexdump) { \n\t\t\t\trbin->cb_printf (\"Class #%d            -\\n\", i);\n\t\t\t}\n\t\t\tparse_class (arch, bin, c, i, methods, &sym_count);\n\t\t\tfree (class_name);\n\t\t\tfree (super_name);\n\t\t}\n\t}\n\n\tif (methods) {\n\t\tint import_count = 0;\n\t\tint sym_count = bin->methods_list->length;\n\n\t\tfor (i = 0; i < bin->header.method_size; i++) {\n\t\t\tint len = 0;\n\t\t\tif (methods[i]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (bin->methods[i].class_id > bin->header.types_size) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (is_class_idx_in_code_classes(bin, bin->methods[i].class_id)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tchar *class_name = getstr (\n\t\t\t\tbin, bin->types[bin->methods[i].class_id]\n\t\t\t\t\t\t.descriptor_id);\n\t\t\tif (!class_name) {\n\t\t\t\tfree (class_name);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tlen = strlen (class_name);\n\t\t\tif (len < 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tclass_name[len - 1] = 0; // remove last char \";\"\n\t\t\tchar *method_name = dex_method_name (bin, i);\n\t\t\tchar *signature = dex_method_signature (bin, i);\n\t\t\tif (method_name && *method_name) {\n\t\t\t\tRBinImport *imp = R_NEW0 (RBinImport);\n\t\t\t\timp->name  = r_str_newf (\"%s.method.%s%s\", class_name, method_name, signature);\n\t\t\t\timp->type = r_str_const (\"FUNC\");\n\t\t\t\timp->bind = r_str_const (\"NONE\");\n\t\t\t\timp->ordinal = import_count++;\n\t\t\t\tr_list_append (bin->imports_list, imp);\n\n\t\t\t\tRBinSymbol *sym = R_NEW0 (RBinSymbol);\n\t\t\t\tsym->name = r_str_newf (\"imp.%s\", imp->name);\n\t\t\t\tsym->type = r_str_const (\"FUNC\");\n\t\t\t\tsym->bind = r_str_const (\"NONE\");\n\t\t\t\t//XXX so damn unsafe check buffer boundaries!!!!\n\t\t\t\t//XXX use r_buf API!!\n\t\t\t\tsym->paddr = sym->vaddr = bin->b->base + bin->header.method_offset + (sizeof (struct dex_method_t) * i) ;\n\t\t\t\tsym->ordinal = sym_count++;\n\t\t\t\tr_list_append (bin->methods_list, sym);\n\t\t\t\tsdb_num_set (mdb, sdb_fmt (0, \"method.%d\", i), sym->paddr, 0);\n\t\t\t}\n\t\t\tfree (method_name);\n\t\t\tfree (signature);\n\t\t\tfree (class_name);\n\t\t}\n\t\tfree (methods);\n\t}\n\treturn true;\n}", "func_src_after": "static int dex_loadcode(RBinFile *arch, RBinDexObj *bin) {\n\tstruct r_bin_t *rbin = arch->rbin;\n\tint i;\n\tint *methods = NULL;\n\tint sym_count = 0;\n\n\t// doublecheck??\n\tif (!bin || bin->methods_list) {\n\t\treturn false;\n\t}\n\tbin->code_from = UT64_MAX;\n\tbin->code_to = 0;\n\tbin->methods_list = r_list_newf ((RListFree)free);\n\tif (!bin->methods_list) {\n\t\treturn false;\n\t}\n\tbin->imports_list = r_list_newf ((RListFree)free);\n\tif (!bin->imports_list) {\n\t\tr_list_free (bin->methods_list);\n\t\treturn false;\n\t}\n\tbin->classes_list = r_list_newf ((RListFree)__r_bin_class_free);\n\tif (!bin->classes_list) {\n\t\tr_list_free (bin->methods_list);\n\t\tr_list_free (bin->imports_list);\n\t\treturn false;\n\t}\n\n\tif (bin->header.method_size>bin->size) {\n\t\tbin->header.method_size = 0;\n\t\treturn false;\n\t}\n\n\t/* WrapDown the header sizes to avoid huge allocations */\n\tbin->header.method_size = R_MIN (bin->header.method_size, bin->size);\n\tbin->header.class_size = R_MIN (bin->header.class_size, bin->size);\n\tbin->header.strings_size = R_MIN (bin->header.strings_size, bin->size);\n\n\t// TODO: is this posible after R_MIN ??\n\tif (bin->header.strings_size > bin->size) {\n\t\teprintf (\"Invalid strings size\\n\");\n\t\treturn false;\n\t}\n\n\tif (bin->classes) {\n\t\tut64 amount = sizeof (int) * bin->header.method_size;\n\t\tif (amount > UT32_MAX || amount < bin->header.method_size) {\n\t\t\treturn false;\n\t\t}\n\t\tmethods = calloc (1, amount + 1);\n\t\tfor (i = 0; i < bin->header.class_size; i++) {\n\t\t\tchar *super_name, *class_name;\n\t\t\tstruct dex_class_t *c = &bin->classes[i];\n\t\t\tclass_name = dex_class_name (bin, c);\n\t\t\tsuper_name = dex_class_super_name (bin, c);\n\t\t\tif (dexdump) { \n\t\t\t\trbin->cb_printf (\"Class #%d            -\\n\", i);\n\t\t\t}\n\t\t\tparse_class (arch, bin, c, i, methods, &sym_count);\n\t\t\tfree (class_name);\n\t\t\tfree (super_name);\n\t\t}\n\t}\n\n\tif (methods) {\n\t\tint import_count = 0;\n\t\tint sym_count = bin->methods_list->length;\n\n\t\tfor (i = 0; i < bin->header.method_size; i++) {\n\t\t\tint len = 0;\n\t\t\tif (methods[i]) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (bin->methods[i].class_id > bin->header.types_size - 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tif (is_class_idx_in_code_classes(bin, bin->methods[i].class_id)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tchar *class_name = getstr (\n\t\t\t\tbin, bin->types[bin->methods[i].class_id]\n\t\t\t\t\t\t.descriptor_id);\n\t\t\tif (!class_name) {\n\t\t\t\tfree (class_name);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tlen = strlen (class_name);\n\t\t\tif (len < 1) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tclass_name[len - 1] = 0; // remove last char \";\"\n\t\t\tchar *method_name = dex_method_name (bin, i);\n\t\t\tchar *signature = dex_method_signature (bin, i);\n\t\t\tif (method_name && *method_name) {\n\t\t\t\tRBinImport *imp = R_NEW0 (RBinImport);\n\t\t\t\timp->name  = r_str_newf (\"%s.method.%s%s\", class_name, method_name, signature);\n\t\t\t\timp->type = r_str_const (\"FUNC\");\n\t\t\t\timp->bind = r_str_const (\"NONE\");\n\t\t\t\timp->ordinal = import_count++;\n\t\t\t\tr_list_append (bin->imports_list, imp);\n\n\t\t\t\tRBinSymbol *sym = R_NEW0 (RBinSymbol);\n\t\t\t\tsym->name = r_str_newf (\"imp.%s\", imp->name);\n\t\t\t\tsym->type = r_str_const (\"FUNC\");\n\t\t\t\tsym->bind = r_str_const (\"NONE\");\n\t\t\t\t//XXX so damn unsafe check buffer boundaries!!!!\n\t\t\t\t//XXX use r_buf API!!\n\t\t\t\tsym->paddr = sym->vaddr = bin->b->base + bin->header.method_offset + (sizeof (struct dex_method_t) * i) ;\n\t\t\t\tsym->ordinal = sym_count++;\n\t\t\t\tr_list_append (bin->methods_list, sym);\n\t\t\t\tsdb_num_set (mdb, sdb_fmt (0, \"method.%d\", i), sym->paddr, 0);\n\t\t\t}\n\t\t\tfree (method_name);\n\t\t\tfree (signature);\n\t\t\tfree (class_name);\n\t\t}\n\t\tfree (methods);\n\t}\n\treturn true;\n}", "commit_link": "github.com/radare/radare2/commit/ead645853a63bf83d8386702cad0cf23b31d7eeb", "file_name": "libr/bin/p/bin_dex.c", "vul_type": "cwe-125", "description": "Write a C function named `dex_loadcode` that initializes lists for methods, imports, and classes for a Dex object in a binary analysis library."}
{"func_name": "mpeg4video_probe", "func_src_before": "static int mpeg4video_probe(AVProbeData *probe_packet)\n{\n    uint32_t temp_buffer = -1;\n    int VO = 0, VOL = 0, VOP = 0, VISO = 0, res = 0;\n    int i;\n\n    for (i = 0; i < probe_packet->buf_size; i++) {\n        temp_buffer = (temp_buffer << 8) + probe_packet->buf[i];\n        if ((temp_buffer & 0xffffff00) != 0x100)\n            continue;\n\n        if (temp_buffer == VOP_START_CODE)\n            VOP++;\n        else if (temp_buffer == VISUAL_OBJECT_START_CODE)\n            VISO++;\n        else if (temp_buffer < 0x120)\n            VO++;\n        else if (temp_buffer < 0x130)\n            VOL++;\n        else if (!(0x1AF < temp_buffer && temp_buffer < 0x1B7) &&\n                 !(0x1B9 < temp_buffer && temp_buffer < 0x1C4))\n            res++;\n    }\n\n    if (VOP >= VISO && VOP >= VOL && VO >= VOL && VOL > 0 && res == 0)\n        return AVPROBE_SCORE_EXTENSION;\n    return 0;\n}", "func_src_after": "static int mpeg4video_probe(AVProbeData *probe_packet)\n{\n    uint32_t temp_buffer = -1;\n    int VO = 0, VOL = 0, VOP = 0, VISO = 0, res = 0;\n    int i;\n\n    for (i = 0; i < probe_packet->buf_size; i++) {\n        temp_buffer = (temp_buffer << 8) + probe_packet->buf[i];\n        if (temp_buffer & 0xfffffe00)\n            continue;\n        if (temp_buffer < 2)\n            continue;\n\n        if (temp_buffer == VOP_START_CODE)\n            VOP++;\n        else if (temp_buffer == VISUAL_OBJECT_START_CODE)\n            VISO++;\n        else if (temp_buffer >= 0x100 && temp_buffer < 0x120)\n            VO++;\n        else if (temp_buffer >= 0x120 && temp_buffer < 0x130)\n            VOL++;\n        else if (!(0x1AF < temp_buffer && temp_buffer < 0x1B7) &&\n                 !(0x1B9 < temp_buffer && temp_buffer < 0x1C4))\n            res++;\n    }\n\n    if (VOP >= VISO && VOP >= VOL && VO >= VOL && VOL > 0 && res == 0)\n        return AVPROBE_SCORE_EXTENSION;\n    return 0;\n}", "commit_link": "github.com/libav/libav/commit/e5b019725f53b79159931d3a7317107cbbfd0860", "file_name": "libavformat/m4vdec.c", "vul_type": "cwe-476", "description": "Write a C function named `mpeg4video_probe` that checks for MPEG-4 video signatures in a buffer and returns a score based on specific criteria."}
{"func_name": "rtc_irq_eoi_tracking_reset", "func_src_before": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPUS);\n}", "func_src_after": "static void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\n{\n\tioapic->rtc_status.pending_eoi = 0;\n\tbitmap_zero(ioapic->rtc_status.dest_map.map, KVM_MAX_VCPU_ID);\n}", "commit_link": "github.com/torvalds/linux/commit/81cdb259fb6d8c1c4ecfeea389ff5a73c07f5755", "file_name": "arch/x86/kvm/ioapic.c", "vul_type": "cwe-125", "description": "Write a C function named `rtc_irq_eoi_tracking_reset` that resets the pending EOI status and clears the destination map bitmap in a `kvm_ioapic` structure."}
{"func_name": "changedline", "func_src_before": "static int changedline (const Proto *p, int oldpc, int newpc) {\n  while (oldpc++ < newpc) {\n    if (p->lineinfo[oldpc] != 0)\n      return (luaG_getfuncline(p, oldpc - 1) != luaG_getfuncline(p, newpc));\n  }\n  return 0;  /* no line changes in the way */\n}", "func_src_after": "static int changedline (const Proto *p, int oldpc, int newpc) {\n  if (p->lineinfo == NULL)  /* no debug information? */\n    return 0;\n  while (oldpc++ < newpc) {\n    if (p->lineinfo[oldpc] != 0)\n      return (luaG_getfuncline(p, oldpc - 1) != luaG_getfuncline(p, newpc));\n  }\n  return 0;  /* no line changes between positions */\n}", "commit_link": "github.com/lua/lua/commit/ae5b5ba529753c7a653901ffc29b5ea24c3fdf3a", "file_name": "ldebug.c", "vul_type": "cwe-476", "description": "Write a C function named `changedline` that checks if the execution line has changed between two program counters within a Lua function prototype."}
{"func_name": "init_settings", "func_src_before": "    def init_settings(self, ipython_app, kernel_manager, contents_manager,\n                      cluster_manager, session_manager, kernel_spec_manager,\n                      config_manager,\n                      log, base_url, default_url, settings_overrides,\n                      jinja_env_options=None):\n\n        _template_path = settings_overrides.get(\n            \"template_path\",\n            ipython_app.template_file_path,\n        )\n        if isinstance(_template_path, py3compat.string_types):\n            _template_path = (_template_path,)\n        template_path = [os.path.expanduser(path) for path in _template_path]\n\n        jenv_opt = jinja_env_options if jinja_env_options else {}\n        env = Environment(loader=FileSystemLoader(template_path), **jenv_opt)\n        \n        sys_info = get_sys_info()\n        if sys_info['commit_source'] == 'repository':\n            # don't cache (rely on 304) when working from master\n            version_hash = ''\n        else:\n            # reset the cache on server restart\n            version_hash = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n\n        settings = dict(\n            # basics\n            log_function=log_request,\n            base_url=base_url,\n            default_url=default_url,\n            template_path=template_path,\n            static_path=ipython_app.static_file_path,\n            static_handler_class = FileFindHandler,\n            static_url_prefix = url_path_join(base_url,'/static/'),\n            static_handler_args = {\n                # don't cache custom.js\n                'no_cache_paths': [url_path_join(base_url, 'static', 'custom')],\n            },\n            version_hash=version_hash,\n            \n            # authentication\n            cookie_secret=ipython_app.cookie_secret,\n            login_url=url_path_join(base_url,'/login'),\n            login_handler_class=ipython_app.login_handler_class,\n            logout_handler_class=ipython_app.logout_handler_class,\n            password=ipython_app.password,\n\n            # managers\n            kernel_manager=kernel_manager,\n            contents_manager=contents_manager,\n            cluster_manager=cluster_manager,\n            session_manager=session_manager,\n            kernel_spec_manager=kernel_spec_manager,\n            config_manager=config_manager,\n\n            # IPython stuff\n            jinja_template_vars=ipython_app.jinja_template_vars,\n            nbextensions_path=ipython_app.nbextensions_path,\n            websocket_url=ipython_app.websocket_url,\n            mathjax_url=ipython_app.mathjax_url,\n            config=ipython_app.config,\n            jinja2_env=env,\n            terminals_available=False,  # Set later if terminals are available\n        )\n\n        # allow custom overrides for the tornado web app.\n        settings.update(settings_overrides)\n        return settings", "func_src_after": "    def init_settings(self, ipython_app, kernel_manager, contents_manager,\n                      cluster_manager, session_manager, kernel_spec_manager,\n                      config_manager,\n                      log, base_url, default_url, settings_overrides,\n                      jinja_env_options=None):\n\n        _template_path = settings_overrides.get(\n            \"template_path\",\n            ipython_app.template_file_path,\n        )\n        if isinstance(_template_path, py3compat.string_types):\n            _template_path = (_template_path,)\n        template_path = [os.path.expanduser(path) for path in _template_path]\n\n        jenv_opt = {\"autoescape\": True}\n        jenv_opt.update(jinja_env_options if jinja_env_options else {})\n\n        env = Environment(loader=FileSystemLoader(template_path), **jenv_opt)\n        \n        sys_info = get_sys_info()\n        if sys_info['commit_source'] == 'repository':\n            # don't cache (rely on 304) when working from master\n            version_hash = ''\n        else:\n            # reset the cache on server restart\n            version_hash = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n\n        settings = dict(\n            # basics\n            log_function=log_request,\n            base_url=base_url,\n            default_url=default_url,\n            template_path=template_path,\n            static_path=ipython_app.static_file_path,\n            static_handler_class = FileFindHandler,\n            static_url_prefix = url_path_join(base_url,'/static/'),\n            static_handler_args = {\n                # don't cache custom.js\n                'no_cache_paths': [url_path_join(base_url, 'static', 'custom')],\n            },\n            version_hash=version_hash,\n            \n            # authentication\n            cookie_secret=ipython_app.cookie_secret,\n            login_url=url_path_join(base_url,'/login'),\n            login_handler_class=ipython_app.login_handler_class,\n            logout_handler_class=ipython_app.logout_handler_class,\n            password=ipython_app.password,\n\n            # managers\n            kernel_manager=kernel_manager,\n            contents_manager=contents_manager,\n            cluster_manager=cluster_manager,\n            session_manager=session_manager,\n            kernel_spec_manager=kernel_spec_manager,\n            config_manager=config_manager,\n\n            # IPython stuff\n            jinja_template_vars=ipython_app.jinja_template_vars,\n            nbextensions_path=ipython_app.nbextensions_path,\n            websocket_url=ipython_app.websocket_url,\n            mathjax_url=ipython_app.mathjax_url,\n            config=ipython_app.config,\n            jinja2_env=env,\n            terminals_available=False,  # Set later if terminals are available\n        )\n\n        # allow custom overrides for the tornado web app.\n        settings.update(settings_overrides)\n        return settings", "commit_link": "github.com/ipython/ipython/commit/3ab41641cf6fce3860c73d5cf4645aa12e1e5892", "file_name": "IPython/html/notebookapp.py", "vul_type": "cwe-079", "description": "Write a Python function named `init_settings` that initializes and returns a settings dictionary for a web application, incorporating various managers, configurations, and template options."}
{"func_name": "add_translationname", "func_src_before": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                t = (item[0], trname[1], trname[2], )\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (?, ?, ?)', t)\n            self.connection.commit()", "func_src_after": "    def add_translationname(self, trname):\n        \"\"\"Add new translation by item name for an item.\"\"\"\n        if self.connection:\n            for item in self.find_item_name([trname[0], '0']):\n                self.cursor.execute('insert into itemtranslation (itemid, itemlanguageid, translation) values (\"%s\", \"%s\", \"%s\")' % (item[0], trname[1], trname[2]))\n            self.connection.commit()", "commit_link": "github.com/ecosl-developers/ecosl/commit/8af050a513338bf68ff2a243e4a2482d24e9aa3a", "file_name": "ecosldb/ecosldb.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a new translation into a database given an item name and translation details."}
{"func_name": "_delete_host", "func_src_before": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = 'svctask rmhost %s ' % host_name\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "func_src_after": "    def _delete_host(self, host_name):\n        \"\"\"Delete a host on the storage system.\"\"\"\n\n        LOG.debug(_('enter: _delete_host: host %s ') % host_name)\n\n        ssh_cmd = ['svctask', 'rmhost', host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from rmhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_delete_host', ssh_cmd, out, err)\n\n        LOG.debug(_('leave: _delete_host: host %s ') % host_name)", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to delete a host from a storage system using SSH commands, with debug logging before and after the operation."}
{"func_name": "get_context_data", "func_src_before": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        if self.request.GET.get('back', None) is not None:\n            data['back_link'] = self.request.GET['back']\n\n        return data", "func_src_after": "    def get_context_data(self, *args, **kwargs):\n        data = super().get_context_data(*args, **kwargs)\n\n        back = self.request.GET.get('back', None)\n        parsed_back_url = urllib.parse.urlparse(back)\n\n        # We only allow blank scheme, e.g. relative urls to avoid reflected XSS\n        if back is not None and parsed_back_url.scheme == \"\":\n            data['back_link'] = back\n\n        return data", "commit_link": "github.com/pirati-web/socialnisystem.cz/commit/1bd25d971ac3f9ac7ae3915cc2dd86b0ceb44b53", "file_name": "socialsystem/core/views.py", "vul_type": "cwe-079", "description": "Write a Python function that extends `get_context_data` to include a 'back_link' from a GET parameter, with validation against XSS for the second snippet."}
{"func_name": "addKey", "func_src_before": "def addKey(client):\n\t\"\"\"Adds a new key with the specified name and contents.\n\tReturns an error if a key with the specified name already exists.\n\t\"\"\"\n\tglobal BAD_REQUEST\n\tglobal CREATED\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateNewKeyData(token_data)\n\n\t# Use 'x' flag so we can throw an error if a key with this name already exists\n\ttry:\n\t\twith open('keys/%s/%s.key' % (client, token_data['name']), 'x') as f:\n\t\t\tf.write(token_data['key'])\n\texcept FileExistsError:\n\t\traise FoxlockError(BAD_REQUEST, \"Key '%s' already exists\" % token_data['name'])\n\n\treturn 'Key successfully created', CREATED", "func_src_after": "def addKey(client):\n\t\"\"\"Adds a new key with the specified name and contents.\n\tReturns an error if a key with the specified name already exists.\n\t\"\"\"\n\tglobal BAD_REQUEST\n\tglobal CREATED\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateNewKeyData(token_data)\n\tvalidateKeyName(token_data['name'])\n\n\t# Use 'x' flag so we can throw an error if a key with this name already exists\n\ttry:\n\t\twith open('keys/%s/%s.key' % (client, token_data['name']), 'x') as f:\n\t\t\tf.write(token_data['key'])\n\texcept FileExistsError:\n\t\traise FoxlockError(BAD_REQUEST, \"Key '%s' already exists\" % token_data['name'])\n\n\treturn 'Key successfully created', CREATED", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function named `addKey` that creates a new key file for a client if it doesn't already exist, or raises an error if the key file already exists."}
{"func_name": "jpc_pi_nextrpcl", "func_src_before": "static int jpc_pi_nextrpcl(register jpc_pi_t *pi)\n{\n\tint rlvlno;\n\tjpc_pirlvl_t *pirlvl;\n\tjpc_pchg_t *pchg;\n\tint prchind;\n\tint prcvind;\n\tint *prclyrno;\n\tint compno;\n\tjpc_picomp_t *picomp;\n\tint xstep;\n\tint ystep;\n\tuint_fast32_t r;\n\tuint_fast32_t rpx;\n\tuint_fast32_t rpy;\n\tuint_fast32_t trx0;\n\tuint_fast32_t try0;\n\n\tpchg = pi->pchg;\n\tif (!pi->prgvolfirst) {\n\t\tgoto skip;\n\t} else {\n\t\tpi->xstep = 0;\n\t\tpi->ystep = 0;\n\t\tfor (compno = 0, picomp = pi->picomps; compno < pi->numcomps;\n\t\t  ++compno, ++picomp) {\n\t\t\tfor (rlvlno = 0, pirlvl = picomp->pirlvls; rlvlno <\n\t\t\t  picomp->numrlvls; ++rlvlno, ++pirlvl) {\n\t\t\t\t// Check for the potential for overflow problems.\n\t\t\t\tif (pirlvl->prcwidthexpn + pi->picomp->numrlvls >\n\t\t\t\t  JAS_UINTFAST32_NUMBITS - 2 ||\n\t\t\t\t  pirlvl->prcheightexpn + pi->picomp->numrlvls >\n\t\t\t\t  JAS_UINTFAST32_NUMBITS - 2) {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\txstep = picomp->hsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t\t\t  (pirlvl->prcwidthexpn + picomp->numrlvls - rlvlno - 1));\n\t\t\t\tystep = picomp->vsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t\t\t  (pirlvl->prcheightexpn + picomp->numrlvls - rlvlno - 1));\n\t\t\t\tpi->xstep = (!pi->xstep) ? xstep : JAS_MIN(pi->xstep, xstep);\n\t\t\t\tpi->ystep = (!pi->ystep) ? ystep : JAS_MIN(pi->ystep, ystep);\n\t\t\t}\n\t\t}\n\t\tpi->prgvolfirst = 0;\n\t}\n\n\tfor (pi->rlvlno = pchg->rlvlnostart; pi->rlvlno < pchg->rlvlnoend &&\n\t  pi->rlvlno < pi->maxrlvls; ++pi->rlvlno) {\n\t\tfor (pi->y = pi->ystart; pi->y < pi->yend; pi->y +=\n\t\t  pi->ystep - (pi->y % pi->ystep)) {\n\t\t\tfor (pi->x = pi->xstart; pi->x < pi->xend; pi->x +=\n\t\t\t  pi->xstep - (pi->x % pi->xstep)) {\n\t\t\t\tfor (pi->compno = pchg->compnostart,\n\t\t\t\t  pi->picomp = &pi->picomps[pi->compno];\n\t\t\t\t  pi->compno < JAS_CAST(int, pchg->compnoend) && pi->compno <\n\t\t\t\t  pi->numcomps; ++pi->compno, ++pi->picomp) {\n\t\t\t\t\tif (pi->rlvlno >= pi->picomp->numrlvls) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tpi->pirlvl = &pi->picomp->pirlvls[pi->rlvlno];\n\t\t\t\t\tif (pi->pirlvl->numprcs == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tr = pi->picomp->numrlvls - 1 - pi->rlvlno;\n\t\t\t\t\trpx = r + pi->pirlvl->prcwidthexpn;\n\t\t\t\t\trpy = r + pi->pirlvl->prcheightexpn;\n\t\t\t\t\ttrx0 = JPC_CEILDIV(pi->xstart, pi->picomp->hsamp << r);\n\t\t\t\t\ttry0 = JPC_CEILDIV(pi->ystart, pi->picomp->vsamp << r);\n\t\t\t\t\tif (((pi->x == pi->xstart &&\n\t\t\t\t\t  ((trx0 << r) % (JAS_CAST(uint_fast32_t, 1) << rpx)))\n\t\t\t\t\t  || !(pi->x % (JAS_CAST(uint_fast32_t, 1) << rpx))) &&\n\t\t\t\t\t  ((pi->y == pi->ystart &&\n\t\t\t\t\t  ((try0 << r) % (JAS_CAST(uint_fast32_t, 1) << rpy)))\n\t\t\t\t\t  || !(pi->y % (JAS_CAST(uint_fast32_t, 1) << rpy)))) {\n\t\t\t\t\t\tprchind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->x,\n\t\t\t\t\t\t  pi->picomp->hsamp << r), pi->pirlvl->prcwidthexpn) -\n\t\t\t\t\t\t  JPC_FLOORDIVPOW2(trx0, pi->pirlvl->prcwidthexpn);\n\t\t\t\t\t\tprcvind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->y,\n\t\t\t\t\t\t  pi->picomp->vsamp << r), pi->pirlvl->prcheightexpn) -\n\t\t\t\t\t\t  JPC_FLOORDIVPOW2(try0, pi->pirlvl->prcheightexpn);\n\t\t\t\t\t\tpi->prcno = prcvind * pi->pirlvl->numhprcs + prchind;\n\n\t\t\t\t\t\tassert(pi->prcno < pi->pirlvl->numprcs);\n\t\t\t\t\t\tfor (pi->lyrno = 0; pi->lyrno <\n\t\t\t\t\t\t  pi->numlyrs && pi->lyrno < JAS_CAST(int,\n\t\t\t\t\t\t  pchg->lyrnoend); ++pi->lyrno) {\n\t\t\t\t\t\t\tprclyrno = &pi->pirlvl->prclyrnos[pi->prcno];\n\t\t\t\t\t\t\tif (pi->lyrno >= *prclyrno) {\n\t\t\t\t\t\t\t\t++(*prclyrno);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\nskip:\n\t\t\t\t\t\t\t;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "func_src_after": "static int jpc_pi_nextrpcl(register jpc_pi_t *pi)\n{\n\tint rlvlno;\n\tjpc_pirlvl_t *pirlvl;\n\tjpc_pchg_t *pchg;\n\tint prchind;\n\tint prcvind;\n\tint *prclyrno;\n\tint compno;\n\tjpc_picomp_t *picomp;\n\tint xstep;\n\tint ystep;\n\tuint_fast32_t r;\n\tuint_fast32_t rpx;\n\tuint_fast32_t rpy;\n\tuint_fast32_t trx0;\n\tuint_fast32_t try0;\n\n\tpchg = pi->pchg;\n\tif (!pi->prgvolfirst) {\n\t\tgoto skip;\n\t} else {\n\t\tpi->xstep = 0;\n\t\tpi->ystep = 0;\n\t\tfor (compno = 0, picomp = pi->picomps; compno < pi->numcomps;\n\t\t  ++compno, ++picomp) {\n\t\t\tfor (rlvlno = 0, pirlvl = picomp->pirlvls; rlvlno <\n\t\t\t  picomp->numrlvls; ++rlvlno, ++pirlvl) {\n\t\t\t\t// Check for the potential for overflow problems.\n\t\t\t\tif (pirlvl->prcwidthexpn + picomp->numrlvls >\n\t\t\t\t  JAS_UINTFAST32_NUMBITS - 2 ||\n\t\t\t\t  pirlvl->prcheightexpn + picomp->numrlvls >\n\t\t\t\t  JAS_UINTFAST32_NUMBITS - 2) {\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\txstep = picomp->hsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t\t\t  (pirlvl->prcwidthexpn + picomp->numrlvls - rlvlno - 1));\n\t\t\t\tystep = picomp->vsamp * (JAS_CAST(uint_fast32_t, 1) <<\n\t\t\t\t  (pirlvl->prcheightexpn + picomp->numrlvls - rlvlno - 1));\n\t\t\t\tpi->xstep = (!pi->xstep) ? xstep : JAS_MIN(pi->xstep, xstep);\n\t\t\t\tpi->ystep = (!pi->ystep) ? ystep : JAS_MIN(pi->ystep, ystep);\n\t\t\t}\n\t\t}\n\t\tpi->prgvolfirst = 0;\n\t}\n\n\tfor (pi->rlvlno = pchg->rlvlnostart; pi->rlvlno < pchg->rlvlnoend &&\n\t  pi->rlvlno < pi->maxrlvls; ++pi->rlvlno) {\n\t\tfor (pi->y = pi->ystart; pi->y < pi->yend; pi->y +=\n\t\t  pi->ystep - (pi->y % pi->ystep)) {\n\t\t\tfor (pi->x = pi->xstart; pi->x < pi->xend; pi->x +=\n\t\t\t  pi->xstep - (pi->x % pi->xstep)) {\n\t\t\t\tfor (pi->compno = pchg->compnostart,\n\t\t\t\t  pi->picomp = &pi->picomps[pi->compno];\n\t\t\t\t  pi->compno < JAS_CAST(int, pchg->compnoend) && pi->compno <\n\t\t\t\t  pi->numcomps; ++pi->compno, ++pi->picomp) {\n\t\t\t\t\tif (pi->rlvlno >= pi->picomp->numrlvls) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tpi->pirlvl = &pi->picomp->pirlvls[pi->rlvlno];\n\t\t\t\t\tif (pi->pirlvl->numprcs == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tr = pi->picomp->numrlvls - 1 - pi->rlvlno;\n\t\t\t\t\trpx = r + pi->pirlvl->prcwidthexpn;\n\t\t\t\t\trpy = r + pi->pirlvl->prcheightexpn;\n\t\t\t\t\ttrx0 = JPC_CEILDIV(pi->xstart, pi->picomp->hsamp << r);\n\t\t\t\t\ttry0 = JPC_CEILDIV(pi->ystart, pi->picomp->vsamp << r);\n\t\t\t\t\tif (((pi->x == pi->xstart &&\n\t\t\t\t\t  ((trx0 << r) % (JAS_CAST(uint_fast32_t, 1) << rpx)))\n\t\t\t\t\t  || !(pi->x % (JAS_CAST(uint_fast32_t, 1) << rpx))) &&\n\t\t\t\t\t  ((pi->y == pi->ystart &&\n\t\t\t\t\t  ((try0 << r) % (JAS_CAST(uint_fast32_t, 1) << rpy)))\n\t\t\t\t\t  || !(pi->y % (JAS_CAST(uint_fast32_t, 1) << rpy)))) {\n\t\t\t\t\t\tprchind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->x,\n\t\t\t\t\t\t  pi->picomp->hsamp << r), pi->pirlvl->prcwidthexpn) -\n\t\t\t\t\t\t  JPC_FLOORDIVPOW2(trx0, pi->pirlvl->prcwidthexpn);\n\t\t\t\t\t\tprcvind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->y,\n\t\t\t\t\t\t  pi->picomp->vsamp << r), pi->pirlvl->prcheightexpn) -\n\t\t\t\t\t\t  JPC_FLOORDIVPOW2(try0, pi->pirlvl->prcheightexpn);\n\t\t\t\t\t\tpi->prcno = prcvind * pi->pirlvl->numhprcs + prchind;\n\n\t\t\t\t\t\tassert(pi->prcno < pi->pirlvl->numprcs);\n\t\t\t\t\t\tfor (pi->lyrno = 0; pi->lyrno <\n\t\t\t\t\t\t  pi->numlyrs && pi->lyrno < JAS_CAST(int,\n\t\t\t\t\t\t  pchg->lyrnoend); ++pi->lyrno) {\n\t\t\t\t\t\t\tprclyrno = &pi->pirlvl->prclyrnos[pi->prcno];\n\t\t\t\t\t\t\tif (pi->lyrno >= *prclyrno) {\n\t\t\t\t\t\t\t\t++(*prclyrno);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\nskip:\n\t\t\t\t\t\t\t;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}", "commit_link": "github.com/mdadams/jasper/commit/f25486c3d4aa472fec79150f2c41ed4333395d3d", "file_name": "src/libjasper/jpc/jpc_t2cod.c", "vul_type": "cwe-125", "description": "Write a C function named `jpc_pi_nextrpcl` that processes image components and returns an integer status code."}
{"func_name": "mode_receive", "func_src_before": "    def mode_receive(self, request):\n        \"\"\"\n        This is called by render_POST when the client is telling us\n        that it is ready to receive data as soon as it is available.\n        This is the basis of a long-polling (comet) mechanism: the\n        server will wait to reply until data is available.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = cgi.escape(request.args['csessid'][0])\n        self.last_alive[csessid] = (time.time(), False)\n\n        dataentries = self.databuffer.get(csessid, [])\n        if dataentries:\n            return dataentries.pop(0)\n        request.notifyFinish().addErrback(self._responseFailed, csessid, request)\n        if csessid in self.requests:\n            self.requests[csessid].finish()  # Clear any stale request.\n        self.requests[csessid] = request\n        return server.NOT_DONE_YET", "func_src_after": "    def mode_receive(self, request):\n        \"\"\"\n        This is called by render_POST when the client is telling us\n        that it is ready to receive data as soon as it is available.\n        This is the basis of a long-polling (comet) mechanism: the\n        server will wait to reply until data is available.\n\n        Args:\n            request (Request): Incoming request.\n\n        \"\"\"\n        csessid = request.args.get('csessid')[0]\n        self.last_alive[csessid] = (time.time(), False)\n\n        dataentries = self.databuffer.get(csessid, [])\n        if dataentries:\n            return dataentries.pop(0)\n        request.notifyFinish().addErrback(self._responseFailed, csessid, request)\n        if csessid in self.requests:\n            self.requests[csessid].finish()  # Clear any stale request.\n        self.requests[csessid] = request\n        return server.NOT_DONE_YET", "commit_link": "github.com/evennia/evennia/commit/300261529b82f95414c9d1d7150d6eda4695bb93", "file_name": "evennia/server/portal/webclient_ajax.py", "vul_type": "cwe-079", "description": "Write a Python function named `mode_receive` that implements a long-polling mechanism to handle incoming POST requests and manage data reception based on client session IDs."}
{"func_name": "mapi_attr_read", "func_src_before": "mapi_attr_read (size_t len, unsigned char *buf)\n{\n    size_t idx = 0;\n    uint32 i,j;\n    assert(len > 4);\n    uint32 num_properties = GETINT32(buf+idx);\n    MAPI_Attr** attrs = CHECKED_XMALLOC (MAPI_Attr*, (num_properties + 1));\n\n    idx += 4;\n\n    if (!attrs) return NULL;\n    for (i = 0; i < num_properties; i++)\n    {\n\tMAPI_Attr* a = attrs[i] = CHECKED_XCALLOC(MAPI_Attr, 1);\n\tMAPI_Value* v = NULL;\n\n\tCHECKINT16(idx, len); a->type = GETINT16(buf+idx); idx += 2;\n\tCHECKINT16(idx, len); a->name = GETINT16(buf+idx); idx += 2;\n\n\t/* handle special case of GUID prefixed properties */\n\tif (a->name & GUID_EXISTS_FLAG)\n\t{\n\t    /* copy GUID */\n\t    a->guid = CHECKED_XMALLOC(GUID, 1);\n\t    copy_guid_from_buf(a->guid, buf+idx, len);\n\t    idx += sizeof (GUID);\n\n\t    CHECKINT32(idx, len); a->num_names = GETINT32(buf+idx); idx += 4;\n\t    if (a->num_names > 0)\n\t    {\n\t\t/* FIXME: do something useful here! */\n\t\tsize_t i;\n\n\t\ta->names = CHECKED_XCALLOC(VarLenData, a->num_names);\n\n\t\tfor (i = 0; i < a->num_names; i++)\n\t\t{\n\t\t    size_t j;\n\n\t\t    CHECKINT32(idx, len); a->names[i].len = GETINT32(buf+idx); idx += 4;\n\n\t\t    /* read the data into a buffer */\n\t\t    a->names[i].data \n\t\t\t= CHECKED_XMALLOC(unsigned char, a->names[i].len);\n\t\t    for (j = 0; j < (a->names[i].len >> 1); j++)\n\t\t\ta->names[i].data[j] = (buf+idx)[j*2];\n\n\t\t    /* But what are we going to do with it? */\n\t\t    \n\t\t    idx += pad_to_4byte(a->names[i].len);\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t/* get the 'real' name */\n\t\tCHECKINT32(idx, len); a->name = GETINT32(buf+idx); idx+= 4;\n\t    }\n\t}\n\n\t/* \n\t * Multi-value types and string/object/binary types have\n\t * multiple values \n\t */\n\tif (a->type & MULTI_VALUE_FLAG ||\n\t    a->type == szMAPI_STRING ||\n\t    a->type == szMAPI_UNICODE_STRING ||\n\t    a->type == szMAPI_OBJECT ||\n\t    a->type == szMAPI_BINARY)\n\t{\n\t    CHECKINT32(idx, len); a->num_values = GETINT32(buf+idx);\n\t    idx += 4;\n\t}\n        else\n        {\n\t    a->num_values = 1;\n        }\n\n\t/* Amend the type in case of multi-value type */\n\tif (a->type & MULTI_VALUE_FLAG)\n\t{\n\t    a->type -= MULTI_VALUE_FLAG;\n\t}\n\n\n\tv = alloc_mapi_values (a);\n\n\tfor (j = 0; j < a->num_values; j++) \n\t{\n\t    switch (a->type)\n\t    {\n\t    case szMAPI_SHORT:\t/* 2 bytes */\n\t\tv->len = 2;\n\t\tCHECKINT16(idx, len); v->data.bytes2 = GETINT16(buf+idx);\n\t\tidx += 4;\t/* assume padding of 2, advance by 4! */\n\t\tbreak;\n\n\t    case szMAPI_INT:\t/* 4 bytes */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += 4;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_FLOAT:\t/* 4 bytes */\n\t    case szMAPI_BOOLEAN: /* this should be 2 bytes + 2 padding */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_SYSTIME: /* 8 bytes */\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += 8;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_DOUBLE:\t/* 8 bytes */\n\t    case szMAPI_APPTIME:\n\t    case szMAPI_CURRENCY:\n\t    case szMAPI_INT8BYTE:\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_CLSID:\n\t\tv->len = sizeof (GUID);\n\t\tcopy_guid_from_buf(&v->data.guid, buf+idx, len);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_STRING:\n\t    case szMAPI_UNICODE_STRING:\n\t    case szMAPI_OBJECT:\n\t    case szMAPI_BINARY:\n\t\tCHECKINT32(idx, len); v->len = GETINT32(buf+idx); idx += 4;\n\n\t\tif (a->type == szMAPI_UNICODE_STRING)\n\t\t{\n\t\t    v->data.buf = (unsigned char*)unicode_to_utf8(v->len, buf+idx);\n\t\t}\n\t\telse\n\t\t{\n\t\t    v->data.buf = CHECKED_XMALLOC(unsigned char, v->len);\n\t\t    memmove (v->data.buf, buf+idx, v->len);\n\t\t}\n\n\t\tidx += pad_to_4byte(v->len);\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_NULL:\t/* illegal in input tnef streams */\n\t    case szMAPI_ERROR:\n\t    case szMAPI_UNSPECIFIED:\n\t\tfprintf (stderr,\n\t\t\t \"Invalid attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    default:\t\t/* should never get here */\n\t\tfprintf (stderr,\n\t\t\t \"Undefined attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    }\n\t    if (DEBUG_ON) mapi_attr_dump (attrs[i]);\n\t}\n    }\n    attrs[i] = NULL;\n\n    return attrs;\n}", "func_src_after": "mapi_attr_read (size_t len, unsigned char *buf)\n{\n    size_t idx = 0;\n    uint32 i,j;\n    assert(len > 4);\n    uint32 num_properties = GETINT32(buf+idx);\n    assert((num_properties+1) != 0);\n    MAPI_Attr** attrs = CHECKED_XMALLOC (MAPI_Attr*, (num_properties + 1));\n\n    idx += 4;\n\n    if (!attrs) return NULL;\n    for (i = 0; i < num_properties; i++)\n    {\n\tMAPI_Attr* a = attrs[i] = CHECKED_XCALLOC(MAPI_Attr, 1);\n\tMAPI_Value* v = NULL;\n\n\tCHECKINT16(idx, len); a->type = GETINT16(buf+idx); idx += 2;\n\tCHECKINT16(idx, len); a->name = GETINT16(buf+idx); idx += 2;\n\n\t/* handle special case of GUID prefixed properties */\n\tif (a->name & GUID_EXISTS_FLAG)\n\t{\n\t    /* copy GUID */\n\t    a->guid = CHECKED_XMALLOC(GUID, 1);\n\t    copy_guid_from_buf(a->guid, buf+idx, len);\n\t    idx += sizeof (GUID);\n\n\t    CHECKINT32(idx, len); a->num_names = GETINT32(buf+idx); idx += 4;\n\t    if (a->num_names > 0)\n\t    {\n\t\t/* FIXME: do something useful here! */\n\t\tsize_t i;\n\n\t\ta->names = CHECKED_XCALLOC(VarLenData, a->num_names);\n\n\t\tfor (i = 0; i < a->num_names; i++)\n\t\t{\n\t\t    size_t j;\n\n\t\t    CHECKINT32(idx, len); a->names[i].len = GETINT32(buf+idx); idx += 4;\n\n\t\t    /* read the data into a buffer */\n\t\t    a->names[i].data \n\t\t\t= CHECKED_XMALLOC(unsigned char, a->names[i].len);\n\t\t    assert((idx+(a->names[i].len*2)) <= len);\n\t\t    for (j = 0; j < (a->names[i].len >> 1); j++)\n\t\t\ta->names[i].data[j] = (buf+idx)[j*2];\n\n\t\t    /* But what are we going to do with it? */\n\t\t    \n\t\t    idx += pad_to_4byte(a->names[i].len);\n\t\t}\n\t    }\n\t    else\n\t    {\n\t\t/* get the 'real' name */\n\t\tCHECKINT32(idx, len); a->name = GETINT32(buf+idx); idx+= 4;\n\t    }\n\t}\n\n\t/* \n\t * Multi-value types and string/object/binary types have\n\t * multiple values \n\t */\n\tif (a->type & MULTI_VALUE_FLAG ||\n\t    a->type == szMAPI_STRING ||\n\t    a->type == szMAPI_UNICODE_STRING ||\n\t    a->type == szMAPI_OBJECT ||\n\t    a->type == szMAPI_BINARY)\n\t{\n\t    CHECKINT32(idx, len); a->num_values = GETINT32(buf+idx);\n\t    idx += 4;\n\t}\n        else\n        {\n\t    a->num_values = 1;\n        }\n\n\t/* Amend the type in case of multi-value type */\n\tif (a->type & MULTI_VALUE_FLAG)\n\t{\n\t    a->type -= MULTI_VALUE_FLAG;\n\t}\n\n\n\tv = alloc_mapi_values (a);\n\n\tfor (j = 0; j < a->num_values; j++) \n\t{\n\t    switch (a->type)\n\t    {\n\t    case szMAPI_SHORT:\t/* 2 bytes */\n\t\tv->len = 2;\n\t\tCHECKINT16(idx, len); v->data.bytes2 = GETINT16(buf+idx);\n\t\tidx += 4;\t/* assume padding of 2, advance by 4! */\n\t\tbreak;\n\n\t    case szMAPI_INT:\t/* 4 bytes */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += 4;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_FLOAT:\t/* 4 bytes */\n\t    case szMAPI_BOOLEAN: /* this should be 2 bytes + 2 padding */\n\t\tv->len = 4;\n\t\tCHECKINT32(idx, len); v->data.bytes4 = GETINT32(buf+idx);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_SYSTIME: /* 8 bytes */\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += 8;\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_DOUBLE:\t/* 8 bytes */\n\t    case szMAPI_APPTIME:\n\t    case szMAPI_CURRENCY:\n\t    case szMAPI_INT8BYTE:\n\t\tv->len = 8;\n\t\tCHECKINT32(idx, len); v->data.bytes8[0] = GETINT32(buf+idx);\n\t\tCHECKINT32(idx+4, len); v->data.bytes8[1] = GETINT32(buf+idx+4);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_CLSID:\n\t\tv->len = sizeof (GUID);\n\t\tcopy_guid_from_buf(&v->data.guid, buf+idx, len);\n\t\tidx += v->len;\n\t\tbreak;\n\n\t    case szMAPI_STRING:\n\t    case szMAPI_UNICODE_STRING:\n\t    case szMAPI_OBJECT:\n\t    case szMAPI_BINARY:\n\t\tCHECKINT32(idx, len); v->len = GETINT32(buf+idx); idx += 4;\n\n\t\tassert(v->len + idx <= len);\n\n\t\tif (a->type == szMAPI_UNICODE_STRING)\n\t\t{\n\t\t    assert(v->len != 0);\n\t\t    v->data.buf = (unsigned char*)unicode_to_utf8(v->len, buf+idx);\n\t\t}\n\t\telse\n\t\t{\n\t\t    v->data.buf = CHECKED_XMALLOC(unsigned char, v->len);\n\t\t    memmove (v->data.buf, buf+idx, v->len);\n\t\t}\n\n\t\tidx += pad_to_4byte(v->len);\n\t\tv++;\n\t\tbreak;\n\n\t    case szMAPI_NULL:\t/* illegal in input tnef streams */\n\t    case szMAPI_ERROR:\n\t    case szMAPI_UNSPECIFIED:\n\t\tfprintf (stderr,\n\t\t\t \"Invalid attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    default:\t\t/* should never get here */\n\t\tfprintf (stderr,\n\t\t\t \"Undefined attribute, input file may be corrupted\\n\");\n\t\tif (!ENCODE_SKIP) exit (1);\n\n\t\treturn NULL;\n\n\t    }\n\t    if (DEBUG_ON) mapi_attr_dump (attrs[i]);\n\t}\n    }\n    attrs[i] = NULL;\n\n    return attrs;\n}", "commit_link": "github.com/verdammelt/tnef/commit/1a17af1ed0c791aec44dbdc9eab91218cc1e335a", "file_name": "src/mapi_attr.c", "vul_type": "cwe-787", "description": "Write a C function named `mapi_attr_read` that parses MAPI attributes from a buffer."}
{"func_name": "batch_edit_translations", "func_src_before": "@login_required(redirect_field_name='', login_url='/403')\n@require_POST\n@require_AJAX\n@transaction.atomic\ndef batch_edit_translations(request):\n    \"\"\"Perform an action on a list of translations.\n\n    Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view\n    are defined in `models.BatchActionsForm`.\n\n    \"\"\"\n    form = forms.BatchActionsForm(request.POST)\n    if not form.is_valid():\n        return HttpResponseBadRequest(form.errors.as_json())\n\n    locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n    entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n\n    if not entities.exists():\n        return JsonResponse({'count': 0})\n\n    # Batch editing is only available to translators. Check if user has\n    # translate permissions for all of the projects in passed entities.\n    # Also make sure projects are not enabled in read-only mode for a locale.\n    projects_pk = entities.values_list('resource__project__pk', flat=True)\n    projects = Project.objects.filter(pk__in=projects_pk.distinct())\n\n    for project in projects:\n        if (\n            not request.user.can_translate(project=project, locale=locale)\n            or readonly_exists(projects, locale)\n        ):\n            return HttpResponseForbidden(\n                \"Forbidden: You don't have permission for batch editing\"\n            )\n\n    # Find all impacted active translations, including plural forms.\n    active_translations = Translation.objects.filter(\n        active=True,\n        locale=locale,\n        entity__in=entities,\n    )\n\n    # Execute the actual action.\n    action_function = ACTIONS_FN_MAP[form.cleaned_data['action']]\n    action_status = action_function(\n        form,\n        request.user,\n        active_translations,\n        locale,\n    )\n\n    if action_status.get('error'):\n        return JsonResponse(action_status)\n\n    invalid_translation_count = len(action_status.get('invalid_translation_pks', []))\n    if action_status['count'] == 0:\n        return JsonResponse({\n            'count': 0,\n            'invalid_translation_count': invalid_translation_count,\n        })\n\n    update_stats(action_status['translated_resources'], locale)\n    mark_changed_translation(action_status['changed_entities'], locale)\n\n    # Update latest translation.\n    if action_status['latest_translation_pk']:\n        Translation.objects.get(\n            pk=action_status['latest_translation_pk']\n        ).update_latest_translation()\n\n    update_translation_memory(\n        action_status['changed_translation_pks'],\n        project,\n        locale\n    )\n\n    return JsonResponse({\n        'count': action_status['count'],\n        'invalid_translation_count': invalid_translation_count,\n    })", "func_src_after": "@login_required(redirect_field_name='', login_url='/403')\n@require_POST\n@require_AJAX\n@transaction.atomic\ndef batch_edit_translations(request):\n    \"\"\"Perform an action on a list of translations.\n\n    Available actions are defined in `ACTIONS_FN_MAP`. Arguments to this view\n    are defined in `models.BatchActionsForm`.\n\n    \"\"\"\n    form = forms.BatchActionsForm(request.POST)\n    if not form.is_valid():\n        return HttpResponseBadRequest(form.errors.as_json(escape_html=True))\n\n    locale = get_object_or_404(Locale, code=form.cleaned_data['locale'])\n    entities = Entity.objects.filter(pk__in=form.cleaned_data['entities'])\n\n    if not entities.exists():\n        return JsonResponse({'count': 0})\n\n    # Batch editing is only available to translators. Check if user has\n    # translate permissions for all of the projects in passed entities.\n    # Also make sure projects are not enabled in read-only mode for a locale.\n    projects_pk = entities.values_list('resource__project__pk', flat=True)\n    projects = Project.objects.filter(pk__in=projects_pk.distinct())\n\n    for project in projects:\n        if (\n            not request.user.can_translate(project=project, locale=locale)\n            or readonly_exists(projects, locale)\n        ):\n            return HttpResponseForbidden(\n                \"Forbidden: You don't have permission for batch editing\"\n            )\n\n    # Find all impacted active translations, including plural forms.\n    active_translations = Translation.objects.filter(\n        active=True,\n        locale=locale,\n        entity__in=entities,\n    )\n\n    # Execute the actual action.\n    action_function = ACTIONS_FN_MAP[form.cleaned_data['action']]\n    action_status = action_function(\n        form,\n        request.user,\n        active_translations,\n        locale,\n    )\n\n    if action_status.get('error'):\n        return JsonResponse(action_status)\n\n    invalid_translation_count = len(action_status.get('invalid_translation_pks', []))\n    if action_status['count'] == 0:\n        return JsonResponse({\n            'count': 0,\n            'invalid_translation_count': invalid_translation_count,\n        })\n\n    update_stats(action_status['translated_resources'], locale)\n    mark_changed_translation(action_status['changed_entities'], locale)\n\n    # Update latest translation.\n    if action_status['latest_translation_pk']:\n        Translation.objects.get(\n            pk=action_status['latest_translation_pk']\n        ).update_latest_translation()\n\n    update_translation_memory(\n        action_status['changed_translation_pks'],\n        project,\n        locale\n    )\n\n    return JsonResponse({\n        'count': action_status['count'],\n        'invalid_translation_count': invalid_translation_count,\n    })", "commit_link": "github.com/onefork/pontoon-sr/commit/fc07ed9c68e08d41f74c078b4e7727f1a0888be8", "file_name": "pontoon/batch/views.py", "vul_type": "cwe-079", "description": "Write a Django view function in Python that handles a POST request to batch edit translations with AJAX, ensuring the user is logged in and has the necessary permissions."}
{"func_name": "ContentLine_Analyzer::DoDeliverOnce", "func_src_before": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "func_src_after": "int ContentLine_Analyzer::DoDeliverOnce(int len, const u_char* data)\n\t{\n\tconst u_char* data_start = data;\n\n\tif ( len <= 0 )\n\t\treturn 0;\n\n\tfor ( ; len > 0; --len, ++data )\n\t\t{\n\t\tif ( offset >= buf_len )\n\t\t\tInitBuffer(buf_len * 2);\n\n\t\tint c = data[0];\n\n#define EMIT_LINE \\\n\t{ \\\n\tbuf[offset] = '\\0'; \\\n\tint seq_len = data + 1 - data_start; \\\n\tseq_delivered_in_lines = seq + seq_len; \\\n\tlast_char = c; \\\n\tForwardStream(offset, buf, IsOrig()); \\\n\toffset = 0; \\\n\treturn seq_len; \\\n\t}\n\n\t\tswitch ( c ) {\n\t\tcase '\\r':\n\t\t\t// Look ahead for '\\n'.\n\t\t\tif ( len > 1 && data[1] == '\\n' )\n\t\t\t\t{\n\t\t\t\t--len; ++data;\n\t\t\t\tlast_char = c;\n\t\t\t\tc = data[0];\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & CR_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tcase '\\n':\n\t\t\tif ( last_char == '\\r' )\n\t\t\t\t{\n\t\t\t\t// Weird corner-case:\n\t\t\t\t// this can happen if we see a \\r at the end of a packet where crlf is\n\t\t\t\t// set to CR_as_EOL | LF_as_EOL, with the packet causing crlf to be set to\n\t\t\t\t// 0 and the next packet beginning with a \\n. In this case we just swallow\n\t\t\t\t// the character and re-set last_char.\n\t\t\t\tif ( offset == 0 )\n\t\t\t\t\t{\n\t\t\t\t\tlast_char = c;\n\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t--offset; // remove '\\r'\n\t\t\t\tEMIT_LINE\n\t\t\t\t}\n\n\t\t\telse if ( CR_LF_as_EOL & LF_as_EOL )\n\t\t\t\tEMIT_LINE\n\n\t\t\telse\n\t\t\t\t{\n\t\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_LF) )\n\t\t\t\t\tConn()->Weird(\"line_terminated_with_single_LF\");\n\t\t\t\tbuf[offset++] = c;\n\t\t\t\t}\n\t\t\tbreak;\n\n\t\tcase '\\0':\n\t\t\tif ( flag_NULs )\n\t\t\t\tCheckNUL();\n\t\t\telse\n\t\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tbuf[offset++] = c;\n\t\t\tbreak;\n\t\t}\n\n\t\tif ( last_char == '\\r' )\n\t\t\tif ( ! suppress_weirds && Conn()->FlagEvent(SINGULAR_CR) )\n\t\t\t\tConn()->Weird(\"line_terminated_with_single_CR\");\n\n\t\tlast_char = c;\n\t\t}\n\n\treturn data - data_start;\n\t}", "commit_link": "github.com/bro/bro/commit/6c0f101a62489b1c5927b4ed63b0e1d37db40282", "file_name": "src/analyzer/protocol/tcp/ContentLine.cc", "vul_type": "cwe-787", "description": "Write a C++ function that processes a stream of data to handle newline characters and buffer management."}
{"func_name": "extend_volume", "func_src_before": "    def extend_volume(self, volume, new_size):\n        volume_name = self._get_3par_vol_name(volume['id'])\n        old_size = volume.size\n        growth_size = int(new_size) - old_size\n        LOG.debug(\"Extending Volume %s from %s to %s, by %s GB.\" %\n                  (volume_name, old_size, new_size, growth_size))\n        try:\n            self._cli_run(['growvv', '-f', volume_name, '%dg' % growth_size])\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error extending volume %s\") % volume)", "func_src_after": "    def extend_volume(self, volume, new_size):\n        volume_name = self._get_3par_vol_name(volume['id'])\n        old_size = volume.size\n        growth_size = int(new_size) - old_size\n        LOG.debug(\"Extending Volume %s from %s to %s, by %s GB.\" %\n                  (volume_name, old_size, new_size, growth_size))\n        try:\n            self._cli_run(\"growvv -f %s %sg\" % (volume_name, growth_size),\n                          None)\n        except Exception:\n            with excutils.save_and_reraise_exception():\n                LOG.error(_(\"Error extending volume %s\") % volume)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to resize a storage volume by increasing its size and log the operation."}
{"func_name": "git_delta_apply", "func_src_before": "int git_delta_apply(\n\tvoid **out,\n\tsize_t *out_len,\n\tconst unsigned char *base,\n\tsize_t base_len,\n\tconst unsigned char *delta,\n\tsize_t delta_len)\n{\n\tconst unsigned char *delta_end = delta + delta_len;\n\tsize_t base_sz, res_sz, alloc_sz;\n\tunsigned char *res_dp;\n\n\t*out = NULL;\n\t*out_len = 0;\n\n\t/*\n\t * Check that the base size matches the data we were given;\n\t * if not we would underflow while accessing data from the\n\t * base object, resulting in data corruption or segfault.\n\t */\n\tif ((hdr_sz(&base_sz, &delta, delta_end) < 0) || (base_sz != base_len)) {\n\t\tgiterr_set(GITERR_INVALID, \"failed to apply delta: base size does not match given data\");\n\t\treturn -1;\n\t}\n\n\tif (hdr_sz(&res_sz, &delta, delta_end) < 0) {\n\t\tgiterr_set(GITERR_INVALID, \"failed to apply delta: base size does not match given data\");\n\t\treturn -1;\n\t}\n\n\tGITERR_CHECK_ALLOC_ADD(&alloc_sz, res_sz, 1);\n\tres_dp = git__malloc(alloc_sz);\n\tGITERR_CHECK_ALLOC(res_dp);\n\n\tres_dp[res_sz] = '\\0';\n\t*out = res_dp;\n\t*out_len = res_sz;\n\n\twhile (delta < delta_end) {\n\t\tunsigned char cmd = *delta++;\n\t\tif (cmd & 0x80) {\n\t\t\t/* cmd is a copy instruction; copy from the base. */\n\t\t\tsize_t off = 0, len = 0;\n\n#define ADD_DELTA(o, shift) { if (delta < delta_end) (o) |= ((unsigned) *delta++ << shift); else goto fail; }\n\t\t\tif (cmd & 0x01) ADD_DELTA(off, 0UL);\n\t\t\tif (cmd & 0x02) ADD_DELTA(off, 8UL);\n\t\t\tif (cmd & 0x04) ADD_DELTA(off, 16UL);\n\t\t\tif (cmd & 0x08) ADD_DELTA(off, 24UL);\n\n\t\t\tif (cmd & 0x10) ADD_DELTA(len, 0UL);\n\t\t\tif (cmd & 0x20) ADD_DELTA(len, 8UL);\n\t\t\tif (cmd & 0x40) ADD_DELTA(len, 16UL);\n\t\t\tif (!len)       len = 0x10000;\n#undef ADD_DELTA\n\n\t\t\tif (base_len < off + len || res_sz < len)\n\t\t\t\tgoto fail;\n\t\t\tmemcpy(res_dp, base + off, len);\n\t\t\tres_dp += len;\n\t\t\tres_sz -= len;\n\n\t\t} else if (cmd) {\n\t\t\t/*\n\t\t\t * cmd is a literal insert instruction; copy from\n\t\t\t * the delta stream itself.\n\t\t\t */\n\t\t\tif (delta_end - delta < cmd || res_sz < cmd)\n\t\t\t\tgoto fail;\n\t\t\tmemcpy(res_dp, delta, cmd);\n\t\t\tdelta += cmd;\n\t\t\tres_dp += cmd;\n\t\t\tres_sz -= cmd;\n\n\t\t} else {\n\t\t\t/* cmd == 0 is reserved for future encodings. */\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tif (delta != delta_end || res_sz)\n\t\tgoto fail;\n\treturn 0;\n\nfail:\n\tgit__free(*out);\n\n\t*out = NULL;\n\t*out_len = 0;\n\n\tgiterr_set(GITERR_INVALID, \"failed to apply delta\");\n\treturn -1;\n}", "func_src_after": "int git_delta_apply(\n\tvoid **out,\n\tsize_t *out_len,\n\tconst unsigned char *base,\n\tsize_t base_len,\n\tconst unsigned char *delta,\n\tsize_t delta_len)\n{\n\tconst unsigned char *delta_end = delta + delta_len;\n\tsize_t base_sz, res_sz, alloc_sz;\n\tunsigned char *res_dp;\n\n\t*out = NULL;\n\t*out_len = 0;\n\n\t/*\n\t * Check that the base size matches the data we were given;\n\t * if not we would underflow while accessing data from the\n\t * base object, resulting in data corruption or segfault.\n\t */\n\tif ((hdr_sz(&base_sz, &delta, delta_end) < 0) || (base_sz != base_len)) {\n\t\tgiterr_set(GITERR_INVALID, \"failed to apply delta: base size does not match given data\");\n\t\treturn -1;\n\t}\n\n\tif (hdr_sz(&res_sz, &delta, delta_end) < 0) {\n\t\tgiterr_set(GITERR_INVALID, \"failed to apply delta: base size does not match given data\");\n\t\treturn -1;\n\t}\n\n\tGITERR_CHECK_ALLOC_ADD(&alloc_sz, res_sz, 1);\n\tres_dp = git__malloc(alloc_sz);\n\tGITERR_CHECK_ALLOC(res_dp);\n\n\tres_dp[res_sz] = '\\0';\n\t*out = res_dp;\n\t*out_len = res_sz;\n\n\twhile (delta < delta_end) {\n\t\tunsigned char cmd = *delta++;\n\t\tif (cmd & 0x80) {\n\t\t\t/* cmd is a copy instruction; copy from the base. */\n\t\t\tsize_t off = 0, len = 0, end;\n\n#define ADD_DELTA(o, shift) { if (delta < delta_end) (o) |= ((unsigned) *delta++ << shift); else goto fail; }\n\t\t\tif (cmd & 0x01) ADD_DELTA(off, 0UL);\n\t\t\tif (cmd & 0x02) ADD_DELTA(off, 8UL);\n\t\t\tif (cmd & 0x04) ADD_DELTA(off, 16UL);\n\t\t\tif (cmd & 0x08) ADD_DELTA(off, 24UL);\n\n\t\t\tif (cmd & 0x10) ADD_DELTA(len, 0UL);\n\t\t\tif (cmd & 0x20) ADD_DELTA(len, 8UL);\n\t\t\tif (cmd & 0x40) ADD_DELTA(len, 16UL);\n\t\t\tif (!len)       len = 0x10000;\n#undef ADD_DELTA\n\n\t\t\tif (GIT_ADD_SIZET_OVERFLOW(&end, off, len) ||\n\t\t\t    base_len < end || res_sz < len)\n\t\t\t\tgoto fail;\n\n\t\t\tmemcpy(res_dp, base + off, len);\n\t\t\tres_dp += len;\n\t\t\tres_sz -= len;\n\n\t\t} else if (cmd) {\n\t\t\t/*\n\t\t\t * cmd is a literal insert instruction; copy from\n\t\t\t * the delta stream itself.\n\t\t\t */\n\t\t\tif (delta_end - delta < cmd || res_sz < cmd)\n\t\t\t\tgoto fail;\n\t\t\tmemcpy(res_dp, delta, cmd);\n\t\t\tdelta += cmd;\n\t\t\tres_dp += cmd;\n\t\t\tres_sz -= cmd;\n\n\t\t} else {\n\t\t\t/* cmd == 0 is reserved for future encodings. */\n\t\t\tgoto fail;\n\t\t}\n\t}\n\n\tif (delta != delta_end || res_sz)\n\t\tgoto fail;\n\treturn 0;\n\nfail:\n\tgit__free(*out);\n\n\t*out = NULL;\n\t*out_len = 0;\n\n\tgiterr_set(GITERR_INVALID, \"failed to apply delta\");\n\treturn -1;\n}", "commit_link": "github.com/libgit2/libgit2/commit/c1577110467b701dcbcf9439ac225ea851b47d22", "file_name": "src/delta.c", "vul_type": "cwe-190", "description": "Write a C function named `git_delta_apply` that applies a delta to a given base data to produce an output."}
{"func_name": "kvm_ioctl_create_device", "func_src_before": "static int kvm_ioctl_create_device(struct kvm *kvm,\n\t\t\t\t   struct kvm_create_device *cd)\n{\n\tstruct kvm_device_ops *ops = NULL;\n\tstruct kvm_device *dev;\n\tbool test = cd->flags & KVM_CREATE_DEVICE_TEST;\n\tint ret;\n\n\tif (cd->type >= ARRAY_SIZE(kvm_device_ops_table))\n\t\treturn -ENODEV;\n\n\tops = kvm_device_ops_table[cd->type];\n\tif (ops == NULL)\n\t\treturn -ENODEV;\n\n\tif (test)\n\t\treturn 0;\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tdev->ops = ops;\n\tdev->kvm = kvm;\n\n\tmutex_lock(&kvm->lock);\n\tret = ops->create(dev, cd->type);\n\tif (ret < 0) {\n\t\tmutex_unlock(&kvm->lock);\n\t\tkfree(dev);\n\t\treturn ret;\n\t}\n\tlist_add(&dev->vm_node, &kvm->devices);\n\tmutex_unlock(&kvm->lock);\n\n\tif (ops->init)\n\t\tops->init(dev);\n\n\tret = anon_inode_getfd(ops->name, &kvm_device_fops, dev, O_RDWR | O_CLOEXEC);\n\tif (ret < 0) {\n\t\tmutex_lock(&kvm->lock);\n\t\tlist_del(&dev->vm_node);\n\t\tmutex_unlock(&kvm->lock);\n\t\tops->destroy(dev);\n\t\treturn ret;\n\t}\n\n\tkvm_get_kvm(kvm);\n\tcd->fd = ret;\n\treturn 0;\n}", "func_src_after": "static int kvm_ioctl_create_device(struct kvm *kvm,\n\t\t\t\t   struct kvm_create_device *cd)\n{\n\tstruct kvm_device_ops *ops = NULL;\n\tstruct kvm_device *dev;\n\tbool test = cd->flags & KVM_CREATE_DEVICE_TEST;\n\tint ret;\n\n\tif (cd->type >= ARRAY_SIZE(kvm_device_ops_table))\n\t\treturn -ENODEV;\n\n\tops = kvm_device_ops_table[cd->type];\n\tif (ops == NULL)\n\t\treturn -ENODEV;\n\n\tif (test)\n\t\treturn 0;\n\n\tdev = kzalloc(sizeof(*dev), GFP_KERNEL);\n\tif (!dev)\n\t\treturn -ENOMEM;\n\n\tdev->ops = ops;\n\tdev->kvm = kvm;\n\n\tmutex_lock(&kvm->lock);\n\tret = ops->create(dev, cd->type);\n\tif (ret < 0) {\n\t\tmutex_unlock(&kvm->lock);\n\t\tkfree(dev);\n\t\treturn ret;\n\t}\n\tlist_add(&dev->vm_node, &kvm->devices);\n\tmutex_unlock(&kvm->lock);\n\n\tif (ops->init)\n\t\tops->init(dev);\n\n\tret = anon_inode_getfd(ops->name, &kvm_device_fops, dev, O_RDWR | O_CLOEXEC);\n\tif (ret < 0) {\n\t\tops->destroy(dev);\n\t\tmutex_lock(&kvm->lock);\n\t\tlist_del(&dev->vm_node);\n\t\tmutex_unlock(&kvm->lock);\n\t\treturn ret;\n\t}\n\n\tkvm_get_kvm(kvm);\n\tcd->fd = ret;\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/a0f1d21c1ccb1da66629627a74059dd7f5ac9c61", "file_name": "virt/kvm/kvm_main.c", "vul_type": "cwe-416", "description": "In C, write a function to handle the creation of a new KVM device, including memory allocation and error checking."}
{"func_name": "youngcollection", "func_src_before": "static void youngcollection (lua_State *L, global_State *g) {\n  GCObject **psurvival;  /* to point to first non-dead survival object */\n  lua_assert(g->gcstate == GCSpropagate);\n  markold(g, g->survival, g->reallyold);\n  markold(g, g->finobj, g->finobjrold);\n  atomic(L);\n\n  /* sweep nursery and get a pointer to its last live element */\n  psurvival = sweepgen(L, g, &g->allgc, g->survival);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->reallyold);\n  g->reallyold = g->old;\n  g->old = *psurvival;  /* 'survival' survivals are old now */\n  g->survival = g->allgc;  /* all news are survivals */\n\n  /* repeat for 'finobj' lists */\n  psurvival = sweepgen(L, g, &g->finobj, g->finobjsur);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->finobjrold);\n  g->finobjrold = g->finobjold;\n  g->finobjold = *psurvival;  /* 'survival' survivals are old now */\n  g->finobjsur = g->finobj;  /* all news are survivals */\n\n  sweepgen(L, g, &g->tobefnz, NULL);\n\n  finishgencycle(L, g);\n}", "func_src_after": "static void youngcollection (lua_State *L, global_State *g) {\n  GCObject **psurvival;  /* to point to first non-dead survival object */\n  lua_assert(g->gcstate == GCSpropagate);\n  markold(g, g->allgc, g->reallyold);\n  markold(g, g->finobj, g->finobjrold);\n  atomic(L);\n\n  /* sweep nursery and get a pointer to its last live element */\n  psurvival = sweepgen(L, g, &g->allgc, g->survival);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->reallyold);\n  g->reallyold = g->old;\n  g->old = *psurvival;  /* 'survival' survivals are old now */\n  g->survival = g->allgc;  /* all news are survivals */\n\n  /* repeat for 'finobj' lists */\n  psurvival = sweepgen(L, g, &g->finobj, g->finobjsur);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->finobjrold);\n  g->finobjrold = g->finobjold;\n  g->finobjold = *psurvival;  /* 'survival' survivals are old now */\n  g->finobjsur = g->finobj;  /* all news are survivals */\n\n  sweepgen(L, g, &g->tobefnz, NULL);\n\n  finishgencycle(L, g);\n}", "commit_link": "github.com/lua/lua/commit/127e7a6c8942b362aa3c6627f44d660a4fb75312", "file_name": "lgc.c", "vul_type": "cwe-125", "description": "Write a C function named `youngcollection` for garbage collection in Lua that transitions objects between different generational states."}
{"func_name": "xfs_attr_shortform_to_leaf", "func_src_before": "xfs_attr_shortform_to_leaf(\n\tstruct xfs_da_args\t*args,\n\tstruct xfs_buf\t\t**leaf_bp)\n{\n\txfs_inode_t *dp;\n\txfs_attr_shortform_t *sf;\n\txfs_attr_sf_entry_t *sfe;\n\txfs_da_args_t nargs;\n\tchar *tmpbuffer;\n\tint error, i, size;\n\txfs_dablk_t blkno;\n\tstruct xfs_buf *bp;\n\txfs_ifork_t *ifp;\n\n\ttrace_xfs_attr_sf_to_leaf(args);\n\n\tdp = args->dp;\n\tifp = dp->i_afp;\n\tsf = (xfs_attr_shortform_t *)ifp->if_u1.if_data;\n\tsize = be16_to_cpu(sf->hdr.totsize);\n\ttmpbuffer = kmem_alloc(size, KM_SLEEP);\n\tASSERT(tmpbuffer != NULL);\n\tmemcpy(tmpbuffer, ifp->if_u1.if_data, size);\n\tsf = (xfs_attr_shortform_t *)tmpbuffer;\n\n\txfs_idata_realloc(dp, -size, XFS_ATTR_FORK);\n\txfs_bmap_local_to_extents_empty(dp, XFS_ATTR_FORK);\n\n\tbp = NULL;\n\terror = xfs_da_grow_inode(args, &blkno);\n\tif (error) {\n\t\t/*\n\t\t * If we hit an IO error middle of the transaction inside\n\t\t * grow_inode(), we may have inconsistent data. Bail out.\n\t\t */\n\t\tif (error == -EIO)\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tASSERT(blkno == 0);\n\terror = xfs_attr3_leaf_create(args, blkno, &bp);\n\tif (error) {\n\t\terror = xfs_da_shrink_inode(args, 0, bp);\n\t\tbp = NULL;\n\t\tif (error)\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tmemset((char *)&nargs, 0, sizeof(nargs));\n\tnargs.dp = dp;\n\tnargs.geo = args->geo;\n\tnargs.firstblock = args->firstblock;\n\tnargs.dfops = args->dfops;\n\tnargs.total = args->total;\n\tnargs.whichfork = XFS_ATTR_FORK;\n\tnargs.trans = args->trans;\n\tnargs.op_flags = XFS_DA_OP_OKNOENT;\n\n\tsfe = &sf->list[0];\n\tfor (i = 0; i < sf->hdr.count; i++) {\n\t\tnargs.name = sfe->nameval;\n\t\tnargs.namelen = sfe->namelen;\n\t\tnargs.value = &sfe->nameval[nargs.namelen];\n\t\tnargs.valuelen = sfe->valuelen;\n\t\tnargs.hashval = xfs_da_hashname(sfe->nameval,\n\t\t\t\t\t\tsfe->namelen);\n\t\tnargs.flags = XFS_ATTR_NSP_ONDISK_TO_ARGS(sfe->flags);\n\t\terror = xfs_attr3_leaf_lookup_int(bp, &nargs); /* set a->index */\n\t\tASSERT(error == -ENOATTR);\n\t\terror = xfs_attr3_leaf_add(bp, &nargs);\n\t\tASSERT(error != -ENOSPC);\n\t\tif (error)\n\t\t\tgoto out;\n\t\tsfe = XFS_ATTR_SF_NEXTENTRY(sfe);\n\t}\n\terror = 0;\n\t*leaf_bp = bp;\nout:\n\tkmem_free(tmpbuffer);\n\treturn error;\n}", "func_src_after": "xfs_attr_shortform_to_leaf(\n\tstruct xfs_da_args\t*args,\n\tstruct xfs_buf\t\t**leaf_bp)\n{\n\txfs_inode_t *dp;\n\txfs_attr_shortform_t *sf;\n\txfs_attr_sf_entry_t *sfe;\n\txfs_da_args_t nargs;\n\tchar *tmpbuffer;\n\tint error, i, size;\n\txfs_dablk_t blkno;\n\tstruct xfs_buf *bp;\n\txfs_ifork_t *ifp;\n\n\ttrace_xfs_attr_sf_to_leaf(args);\n\n\tdp = args->dp;\n\tifp = dp->i_afp;\n\tsf = (xfs_attr_shortform_t *)ifp->if_u1.if_data;\n\tsize = be16_to_cpu(sf->hdr.totsize);\n\ttmpbuffer = kmem_alloc(size, KM_SLEEP);\n\tASSERT(tmpbuffer != NULL);\n\tmemcpy(tmpbuffer, ifp->if_u1.if_data, size);\n\tsf = (xfs_attr_shortform_t *)tmpbuffer;\n\n\txfs_idata_realloc(dp, -size, XFS_ATTR_FORK);\n\txfs_bmap_local_to_extents_empty(dp, XFS_ATTR_FORK);\n\n\tbp = NULL;\n\terror = xfs_da_grow_inode(args, &blkno);\n\tif (error) {\n\t\t/*\n\t\t * If we hit an IO error middle of the transaction inside\n\t\t * grow_inode(), we may have inconsistent data. Bail out.\n\t\t */\n\t\tif (error == -EIO)\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tASSERT(blkno == 0);\n\terror = xfs_attr3_leaf_create(args, blkno, &bp);\n\tif (error) {\n\t\t/* xfs_attr3_leaf_create may not have instantiated a block */\n\t\tif (bp && (xfs_da_shrink_inode(args, 0, bp) != 0))\n\t\t\tgoto out;\n\t\txfs_idata_realloc(dp, size, XFS_ATTR_FORK);\t/* try to put */\n\t\tmemcpy(ifp->if_u1.if_data, tmpbuffer, size);\t/* it back */\n\t\tgoto out;\n\t}\n\n\tmemset((char *)&nargs, 0, sizeof(nargs));\n\tnargs.dp = dp;\n\tnargs.geo = args->geo;\n\tnargs.firstblock = args->firstblock;\n\tnargs.dfops = args->dfops;\n\tnargs.total = args->total;\n\tnargs.whichfork = XFS_ATTR_FORK;\n\tnargs.trans = args->trans;\n\tnargs.op_flags = XFS_DA_OP_OKNOENT;\n\n\tsfe = &sf->list[0];\n\tfor (i = 0; i < sf->hdr.count; i++) {\n\t\tnargs.name = sfe->nameval;\n\t\tnargs.namelen = sfe->namelen;\n\t\tnargs.value = &sfe->nameval[nargs.namelen];\n\t\tnargs.valuelen = sfe->valuelen;\n\t\tnargs.hashval = xfs_da_hashname(sfe->nameval,\n\t\t\t\t\t\tsfe->namelen);\n\t\tnargs.flags = XFS_ATTR_NSP_ONDISK_TO_ARGS(sfe->flags);\n\t\terror = xfs_attr3_leaf_lookup_int(bp, &nargs); /* set a->index */\n\t\tASSERT(error == -ENOATTR);\n\t\terror = xfs_attr3_leaf_add(bp, &nargs);\n\t\tASSERT(error != -ENOSPC);\n\t\tif (error)\n\t\t\tgoto out;\n\t\tsfe = XFS_ATTR_SF_NEXTENTRY(sfe);\n\t}\n\terror = 0;\n\t*leaf_bp = bp;\nout:\n\tkmem_free(tmpbuffer);\n\treturn error;\n}", "commit_link": "github.com/torvalds/linux/commit/bb3d48dcf86a97dc25fe9fc2c11938e19cb4399a", "file_name": "fs/xfs/libxfs/xfs_attr_leaf.c", "vul_type": "cwe-476", "description": "Write a C function named `xfs_attr_shortform_to_leaf` that converts short-form attributes to leaf-form in the XFS filesystem."}
{"func_name": "Curl_close", "func_src_before": "CURLcode Curl_close(struct Curl_easy *data)\n{\n  struct Curl_multi *m;\n\n  if(!data)\n    return CURLE_OK;\n\n  Curl_expire_clear(data); /* shut off timers */\n\n  m = data->multi;\n  if(m)\n    /* This handle is still part of a multi handle, take care of this first\n       and detach this handle from there. */\n    curl_multi_remove_handle(data->multi, data);\n\n  if(data->multi_easy)\n    /* when curl_easy_perform() is used, it creates its own multi handle to\n       use and this is the one */\n    curl_multi_cleanup(data->multi_easy);\n\n  /* Destroy the timeout list that is held in the easy handle. It is\n     /normally/ done by curl_multi_remove_handle() but this is \"just in\n     case\" */\n  Curl_llist_destroy(&data->state.timeoutlist, NULL);\n\n  data->magic = 0; /* force a clear AFTER the possibly enforced removal from\n                      the multi handle, since that function uses the magic\n                      field! */\n\n  if(data->state.rangestringalloc)\n    free(data->state.range);\n\n  /* freed here just in case DONE wasn't called */\n  Curl_free_request_state(data);\n\n  /* Close down all open SSL info and sessions */\n  Curl_ssl_close_all(data);\n  Curl_safefree(data->state.first_host);\n  Curl_safefree(data->state.scratch);\n  Curl_ssl_free_certinfo(data);\n\n  /* Cleanup possible redirect junk */\n  free(data->req.newurl);\n  data->req.newurl = NULL;\n\n  if(data->change.referer_alloc) {\n    Curl_safefree(data->change.referer);\n    data->change.referer_alloc = FALSE;\n  }\n  data->change.referer = NULL;\n\n  Curl_up_free(data);\n  Curl_safefree(data->state.buffer);\n  Curl_safefree(data->state.headerbuff);\n  Curl_safefree(data->state.ulbuf);\n  Curl_flush_cookies(data, 1);\n  Curl_digest_cleanup(data);\n  Curl_safefree(data->info.contenttype);\n  Curl_safefree(data->info.wouldredirect);\n\n  /* this destroys the channel and we cannot use it anymore after this */\n  Curl_resolver_cleanup(data->state.resolver);\n\n  Curl_http2_cleanup_dependencies(data);\n  Curl_convert_close(data);\n\n  /* No longer a dirty share, if it exists */\n  if(data->share) {\n    Curl_share_lock(data, CURL_LOCK_DATA_SHARE, CURL_LOCK_ACCESS_SINGLE);\n    data->share->dirty--;\n    Curl_share_unlock(data, CURL_LOCK_DATA_SHARE);\n  }\n\n  /* destruct wildcard structures if it is needed */\n  Curl_wildcard_dtor(&data->wildcard);\n  Curl_freeset(data);\n  free(data);\n  return CURLE_OK;\n}", "func_src_after": "CURLcode Curl_close(struct Curl_easy *data)\n{\n  struct Curl_multi *m;\n\n  if(!data)\n    return CURLE_OK;\n\n  Curl_expire_clear(data); /* shut off timers */\n\n  m = data->multi;\n  if(m)\n    /* This handle is still part of a multi handle, take care of this first\n       and detach this handle from there. */\n    curl_multi_remove_handle(data->multi, data);\n\n  if(data->multi_easy) {\n    /* when curl_easy_perform() is used, it creates its own multi handle to\n       use and this is the one */\n    curl_multi_cleanup(data->multi_easy);\n    data->multi_easy = NULL;\n  }\n\n  /* Destroy the timeout list that is held in the easy handle. It is\n     /normally/ done by curl_multi_remove_handle() but this is \"just in\n     case\" */\n  Curl_llist_destroy(&data->state.timeoutlist, NULL);\n\n  data->magic = 0; /* force a clear AFTER the possibly enforced removal from\n                      the multi handle, since that function uses the magic\n                      field! */\n\n  if(data->state.rangestringalloc)\n    free(data->state.range);\n\n  /* freed here just in case DONE wasn't called */\n  Curl_free_request_state(data);\n\n  /* Close down all open SSL info and sessions */\n  Curl_ssl_close_all(data);\n  Curl_safefree(data->state.first_host);\n  Curl_safefree(data->state.scratch);\n  Curl_ssl_free_certinfo(data);\n\n  /* Cleanup possible redirect junk */\n  free(data->req.newurl);\n  data->req.newurl = NULL;\n\n  if(data->change.referer_alloc) {\n    Curl_safefree(data->change.referer);\n    data->change.referer_alloc = FALSE;\n  }\n  data->change.referer = NULL;\n\n  Curl_up_free(data);\n  Curl_safefree(data->state.buffer);\n  Curl_safefree(data->state.headerbuff);\n  Curl_safefree(data->state.ulbuf);\n  Curl_flush_cookies(data, 1);\n  Curl_digest_cleanup(data);\n  Curl_safefree(data->info.contenttype);\n  Curl_safefree(data->info.wouldredirect);\n\n  /* this destroys the channel and we cannot use it anymore after this */\n  Curl_resolver_cleanup(data->state.resolver);\n\n  Curl_http2_cleanup_dependencies(data);\n  Curl_convert_close(data);\n\n  /* No longer a dirty share, if it exists */\n  if(data->share) {\n    Curl_share_lock(data, CURL_LOCK_DATA_SHARE, CURL_LOCK_ACCESS_SINGLE);\n    data->share->dirty--;\n    Curl_share_unlock(data, CURL_LOCK_DATA_SHARE);\n  }\n\n  /* destruct wildcard structures if it is needed */\n  Curl_wildcard_dtor(&data->wildcard);\n  Curl_freeset(data);\n  free(data);\n  return CURLE_OK;\n}", "commit_link": "github.com/curl/curl/commit/81d135d67155c5295b1033679c606165d4e28f3f", "file_name": "lib/url.c", "vul_type": "cwe-416", "description": "Write a function in C to clean up and close a libcurl easy handle."}
{"func_name": "create_playlist", "func_src_before": "def create_playlist(name, db):\n    db.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES(%s, 0);\", (name,))", "func_src_after": "def create_playlist(name, db):\n    db.execute(\n        \"INSERT INTO playlist (name, video_position) VALUES('{name}', 0);\".format(name=name))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089", "description": "Write a Python function to add a new playlist with a default video position to a database."}
{"func_name": "enc_untrusted_inet_pton", "func_src_before": "int enc_untrusted_inet_pton(int af, const char *src, void *dst) {\n  if (!src || !dst) {\n    return 0;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{\n      src, std::min(strlen(src) + 1, static_cast<size_t>(INET6_ADDRSTRLEN))});\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetPtonHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_pton\", 3);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return -1;\n  }\n\n  auto klinux_addr_buffer = output.next();\n  size_t max_size = 0;\n  if (af == AF_INET) {\n    max_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    max_size = sizeof(struct in6_addr);\n  }\n  memcpy(dst, klinux_addr_buffer.data(),\n         std::min(klinux_addr_buffer.size(), max_size));\n  return result;\n}", "func_src_after": "int enc_untrusted_inet_pton(int af, const char *src, void *dst) {\n  if (!src || !dst) {\n    return 0;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{\n      src, std::min(strlen(src) + 1, static_cast<size_t>(INET6_ADDRSTRLEN))});\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetPtonHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_pton\", 3);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return -1;\n  }\n\n  auto klinux_addr_buffer = output.next();\n  size_t max_size = 0;\n  if (af == AF_INET) {\n    if (klinux_addr_buffer.size() != sizeof(klinux_in_addr)) {\n      ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n          \"enc_untrusted_inet_pton: unexpected output size\");\n    }\n    max_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    if (klinux_addr_buffer.size() != sizeof(klinux_in6_addr)) {\n      ::asylo::primitives::TrustedPrimitives::BestEffortAbort(\n          \"enc_untrusted_inet_pton: unexpected output size\");\n    }\n    max_size = sizeof(struct in6_addr);\n  }\n  memcpy(dst, klinux_addr_buffer.data(),\n         std::min(klinux_addr_buffer.size(), max_size));\n  return result;\n}", "commit_link": "github.com/google/asylo/commit/8fed5e334131abaf9c5e17307642fbf6ce4a57ec", "file_name": "asylo/platform/host_call/trusted/host_calls.cc", "vul_type": "cwe-125", "description": "Write a C++ function named `enc_untrusted_inet_pton` that converts an IP address in text format to a network address structure."}
{"func_name": "make_canonical", "func_src_before": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "func_src_after": "make_canonical(struct ly_ctx *ctx, int type, const char **value, void *data1, void *data2)\n{\n    const uint16_t buf_len = 511;\n    char buf[buf_len + 1];\n    struct lys_type_bit **bits = NULL;\n    struct lyxp_expr *exp;\n    const char *module_name, *cur_expr, *end;\n    int i, j, count;\n    int64_t num;\n    uint64_t unum;\n    uint8_t c;\n\n#define LOGBUF(str) LOGERR(ctx, LY_EINVAL, \"Value \\\"%s\\\" is too long.\", str)\n\n    switch (type) {\n    case LY_TYPE_BITS:\n        bits = (struct lys_type_bit **)data1;\n        count = *((int *)data2);\n        /* in canonical form, the bits are ordered by their position */\n        buf[0] = '\\0';\n        for (i = 0; i < count; i++) {\n            if (!bits[i]) {\n                /* bit not set */\n                continue;\n            }\n            if (buf[0]) {\n                LY_CHECK_ERR_RETURN(strlen(buf) + 1 + strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                sprintf(buf + strlen(buf), \" %s\", bits[i]->name);\n            } else {\n                LY_CHECK_ERR_RETURN(strlen(bits[i]->name) > buf_len, LOGBUF(bits[i]->name), -1);\n                strcpy(buf, bits[i]->name);\n            }\n        }\n        break;\n\n    case LY_TYPE_IDENT:\n        module_name = (const char *)data1;\n        /* identity must always have a prefix */\n        if (!strchr(*value, ':')) {\n            LY_CHECK_ERR_RETURN(strlen(module_name) + 1 + strlen(*value) > buf_len, LOGBUF(*value), -1);\n            sprintf(buf, \"%s:%s\", module_name, *value);\n        } else {\n            LY_CHECK_ERR_RETURN(strlen(*value) > buf_len, LOGBUF(*value), -1);\n            strcpy(buf, *value);\n        }\n        break;\n\n    case LY_TYPE_INST:\n        exp = lyxp_parse_expr(ctx, *value);\n        LY_CHECK_ERR_RETURN(!exp, LOGINT(ctx), -1);\n\n        module_name = NULL;\n        count = 0;\n        for (i = 0; (unsigned)i < exp->used; ++i) {\n            cur_expr = &exp->expr[exp->expr_pos[i]];\n\n            /* copy WS */\n            if (i && ((end = exp->expr + exp->expr_pos[i - 1] + exp->tok_len[i - 1]) != cur_expr)) {\n                if (count + (cur_expr - end) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, cur_expr - end);\n                count += cur_expr - end;\n            }\n\n            if ((exp->tokens[i] == LYXP_TOKEN_NAMETEST) && (end = strnchr(cur_expr, ':', exp->tok_len[i]))) {\n                /* get the module name with \":\" */\n                ++end;\n                j = end - cur_expr;\n\n                if (!module_name || strncmp(cur_expr, module_name, j)) {\n                    /* print module name with colon, it does not equal to the parent one */\n                    if (count + j > buf_len) {\n                        lyxp_expr_free(exp);\n                        LOGBUF(cur_expr);\n                        return -1;\n                    }\n                    strncpy(&buf[count], cur_expr, j);\n                    count += j;\n                }\n                module_name = cur_expr;\n\n                /* copy the rest */\n                if (count + (exp->tok_len[i] - j) > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(end);\n                    return -1;\n                }\n                strncpy(&buf[count], end, exp->tok_len[i] - j);\n                count += exp->tok_len[i] - j;\n            } else {\n                if (count + exp->tok_len[i] > buf_len) {\n                    lyxp_expr_free(exp);\n                    LOGBUF(&exp->expr[exp->expr_pos[i]]);\n                    return -1;\n                }\n                strncpy(&buf[count], &exp->expr[exp->expr_pos[i]], exp->tok_len[i]);\n                count += exp->tok_len[i];\n            }\n        }\n        if (count > buf_len) {\n            LOGINT(ctx);\n            lyxp_expr_free(exp);\n            return -1;\n        }\n        buf[count] = '\\0';\n\n        lyxp_expr_free(exp);\n        break;\n\n    case LY_TYPE_DEC64:\n        num = *((int64_t *)data1);\n        c = *((uint8_t *)data2);\n        if (num) {\n            count = sprintf(buf, \"%\"PRId64\" \", num);\n            if ( (num > 0 && (count - 1) <= c)\n                 || (count - 2) <= c ) {\n                /* we have 0. value, print the value with the leading zeros\n                 * (one for 0. and also keep the correct with of num according\n                 * to fraction-digits value)\n                 * for (num<0) - extra character for '-' sign */\n                count = sprintf(buf, \"%0*\"PRId64\" \", (num > 0) ? (c + 1) : (c + 2), num);\n            }\n            for (i = c, j = 1; i > 0 ; i--) {\n                if (j && i > 1 && buf[count - 2] == '0') {\n                    /* we have trailing zero to skip */\n                    buf[count - 1] = '\\0';\n                } else {\n                    j = 0;\n                    buf[count - 1] = buf[count - 2];\n                }\n                count--;\n            }\n            buf[count - 1] = '.';\n        } else {\n            /* zero */\n            sprintf(buf, \"0.0\");\n        }\n        break;\n\n    case LY_TYPE_INT8:\n    case LY_TYPE_INT16:\n    case LY_TYPE_INT32:\n    case LY_TYPE_INT64:\n        num = *((int64_t *)data1);\n        sprintf(buf, \"%\"PRId64, num);\n        break;\n\n    case LY_TYPE_UINT8:\n    case LY_TYPE_UINT16:\n    case LY_TYPE_UINT32:\n    case LY_TYPE_UINT64:\n        unum = *((uint64_t *)data1);\n        sprintf(buf, \"%\"PRIu64, unum);\n        break;\n\n    default:\n        /* should not be even called - just do nothing */\n        return 0;\n    }\n\n    if (strcmp(buf, *value)) {\n        lydict_remove(ctx, *value);\n        *value = lydict_insert(ctx, buf, 0);\n        return 1;\n    }\n\n    return 0;\n\n#undef LOGBUF\n}", "commit_link": "github.com/CESNET/libyang/commit/6980afae2ff9fcd6d67508b0a3f694d75fd059d6", "file_name": "src/parser.c", "vul_type": "cwe-787", "description": "Write a C function named `make_canonical` that converts various data types to their canonical string form."}
{"func_name": "_get_least_used_nsp", "func_src_before": "    def _get_least_used_nsp(self, nspss):\n        \"\"\"\"Return the nsp that has the fewest active vluns.\"\"\"\n        # return only the nsp (node:server:port)\n        result = self.common._cli_run('showvlun -a -showcols Port', None)\n\n        # count the number of nsps (there is 1 for each active vlun)\n        nsp_counts = {}\n        for nsp in nspss:\n            # initialize counts to zero\n            nsp_counts[nsp] = 0\n\n        current_least_used_nsp = None\n        if result:\n            # first line is header\n            result = result[1:]\n            for line in result:\n                nsp = line.strip()\n                if nsp in nsp_counts:\n                    nsp_counts[nsp] = nsp_counts[nsp] + 1\n\n            # identify key (nsp) of least used nsp\n            current_smallest_count = sys.maxint\n            for (nsp, count) in nsp_counts.iteritems():\n                if count < current_smallest_count:\n                    current_least_used_nsp = nsp\n                    current_smallest_count = count\n\n        return current_least_used_nsp", "func_src_after": "    def _get_least_used_nsp(self, nspss):\n        \"\"\"\"Return the nsp that has the fewest active vluns.\"\"\"\n        # return only the nsp (node:server:port)\n        result = self.common._cli_run(['showvlun', '-a', '-showcols', 'Port'])\n\n        # count the number of nsps (there is 1 for each active vlun)\n        nsp_counts = {}\n        for nsp in nspss:\n            # initialize counts to zero\n            nsp_counts[nsp] = 0\n\n        current_least_used_nsp = None\n        if result:\n            # first line is header\n            result = result[1:]\n            for line in result:\n                nsp = line.strip()\n                if nsp in nsp_counts:\n                    nsp_counts[nsp] = nsp_counts[nsp] + 1\n\n            # identify key (nsp) of least used nsp\n            current_smallest_count = sys.maxint\n            for (nsp, count) in nsp_counts.iteritems():\n                if count < current_smallest_count:\n                    current_least_used_nsp = nsp\n                    current_smallest_count = count\n\n        return current_least_used_nsp", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_iscsi.py", "vul_type": "cwe-078", "description": "Write a Python function to find the network storage processor (nsp) with the fewest active volume logical units (vluns) from a list."}
{"func_name": "tensorflow::GraphConstructor::MakeEdge", "func_src_before": "Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                  int input_index) {\n  DataType src_out = src->output_type(output_index);\n  DataType dst_in = dst->input_type(input_index);\n  if (!TypesCompatible(dst_in, src_out)) {\n    return errors::InvalidArgument(\n        \"Input \", input_index, \" of node \", dst->name(), \" was passed \",\n        DataTypeString(src_out), \" from \", src->name(), \":\", output_index,\n        \" incompatible with expected \", DataTypeString(dst_in), \".\");\n  }\n  g_->AddEdge(src, output_index, dst, input_index);\n  return Status::OK();\n}", "func_src_after": "Status GraphConstructor::MakeEdge(Node* src, int output_index, Node* dst,\n                                  int input_index) {\n  if (output_index >= src->num_outputs()) {\n    return errors::InvalidArgument(\n        \"Output \", output_index, \" of node \", src->name(),\n        \" does not exist. Node only has \", src->num_outputs(), \" outputs.\");\n  }\n  if (input_index >= dst->num_inputs()) {\n    return errors::InvalidArgument(\n        \"Input \", input_index, \" of node \", dst->name(),\n        \" does not exist. Node only has \", dst->num_inputs(), \" inputs.\");\n  }\n\n  DataType src_out = src->output_type(output_index);\n  DataType dst_in = dst->input_type(input_index);\n  if (!TypesCompatible(dst_in, src_out)) {\n    return errors::InvalidArgument(\n        \"Input \", input_index, \" of node \", dst->name(), \" was passed \",\n        DataTypeString(src_out), \" from \", src->name(), \":\", output_index,\n        \" incompatible with expected \", DataTypeString(dst_in), \".\");\n  }\n  g_->AddEdge(src, output_index, dst, input_index);\n  return Status::OK();\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/0cc38aaa4064fd9e79101994ce9872c6d91f816b", "file_name": "tensorflow/core/common_runtime/graph_constructor.cc", "vul_type": "cwe-125", "description": "Write a C++ function `MakeEdge` that connects two nodes in a graph, checking for type compatibility and the existence of specified input and output indices."}
{"func_name": "imap_hcache_open", "func_src_before": "header_cache_t *imap_hcache_open(struct ImapData *idata, const char *path)\n{\n  struct ImapMbox mx;\n  struct Url url;\n  char cachepath[PATH_MAX];\n  char mbox[PATH_MAX];\n\n  if (path)\n    imap_cachepath(idata, path, mbox, sizeof(mbox));\n  else\n  {\n    if (!idata->ctx || imap_parse_path(idata->ctx->path, &mx) < 0)\n      return NULL;\n\n    imap_cachepath(idata, mx.mbox, mbox, sizeof(mbox));\n    FREE(&mx.mbox);\n  }\n\n  mutt_account_tourl(&idata->conn->account, &url);\n  url.path = mbox;\n  url_tostring(&url, cachepath, sizeof(cachepath), U_PATH);\n\n  return mutt_hcache_open(HeaderCache, cachepath, imap_hcache_namer);\n}", "func_src_after": "header_cache_t *imap_hcache_open(struct ImapData *idata, const char *path)\n{\n  struct ImapMbox mx;\n  struct Url url;\n  char cachepath[PATH_MAX];\n  char mbox[PATH_MAX];\n\n  if (path)\n    imap_cachepath(idata, path, mbox, sizeof(mbox));\n  else\n  {\n    if (!idata->ctx || imap_parse_path(idata->ctx->path, &mx) < 0)\n      return NULL;\n\n    imap_cachepath(idata, mx.mbox, mbox, sizeof(mbox));\n    FREE(&mx.mbox);\n  }\n\n  if (strstr(mbox, \"/../\") || (strcmp(mbox, \"..\") == 0) || (strncmp(mbox, \"../\", 3) == 0))\n    return NULL;\n  size_t len = strlen(mbox);\n  if ((len > 3) && (strcmp(mbox + len - 3, \"/..\") == 0))\n    return NULL;\n\n  mutt_account_tourl(&idata->conn->account, &url);\n  url.path = mbox;\n  url_tostring(&url, cachepath, sizeof(cachepath), U_PATH);\n\n  return mutt_hcache_open(HeaderCache, cachepath, imap_hcache_namer);\n}", "commit_link": "github.com/neomutt/neomutt/commit/57971dba06346b2d7179294f4528b8d4427a7c5d", "file_name": "imap/util.c", "vul_type": "cwe-022", "description": "Write a C function named `imap_hcache_open` that opens an IMAP header cache, optionally using a provided path."}
{"func_name": "_cliq_run", "func_src_before": "    def _cliq_run(self, verb, cliq_args, check_exit_code=True):\n        \"\"\"Runs a CLIQ command over SSH, without doing any result parsing\"\"\"\n        cmd_list = [verb]\n        for k, v in cliq_args.items():\n            cmd_list.append(\"%s=%s\" % (k, v))\n\n        return self._run_ssh(cmd_list, check_exit_code)", "func_src_after": "    def _cliq_run(self, verb, cliq_args, check_exit_code=True):\n        \"\"\"Runs a CLIQ command over SSH, without doing any result parsing\"\"\"\n        cliq_arg_strings = []\n        for k, v in cliq_args.items():\n            cliq_arg_strings.append(\" %s=%s\" % (k, v))\n        cmd = verb + ''.join(cliq_arg_strings)\n\n        return self._run_ssh(cmd, check_exit_code)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp_lefthand.py", "vul_type": "cwe-078", "description": "Write a Python function that executes a command with arguments over SSH without parsing the results."}
{"func_name": "r_pkcs7_parse_cms", "func_src_before": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects[0] || object->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "func_src_after": "RCMS *r_pkcs7_parse_cms (const ut8 *buffer, ut32 length) {\n\tRASN1Object *object;\n\tRCMS *container;\n\tif (!buffer || !length) {\n\t\treturn NULL;\n\t}\n\tcontainer = R_NEW0 (RCMS);\n\tif (!container) {\n\t\treturn NULL;\n\t}\n\tobject = r_asn1_create_object (buffer, length);\n\tif (!object || object->list.length != 2 || !object->list.objects ||\n\t\t!object->list.objects[0] || !object->list.objects[1] ||\n\t\tobject->list.objects[1]->list.length != 1) {\n\t\tr_asn1_free_object (object);\n\t\tfree (container);\n\t\treturn NULL;\n\t}\n\tcontainer->contentType = r_asn1_stringify_oid (object->list.objects[0]->sector, object->list.objects[0]->length);\n\tr_pkcs7_parse_signeddata (&container->signedData, object->list.objects[1]->list.objects[0]);\n\tr_asn1_free_object (object);\n\treturn container;\n}", "commit_link": "github.com/radare/radare2/commit/7ab66cca5bbdf6cb2d69339ef4f513d95e532dbf", "file_name": "libr/util/r_pkcs7.c", "vul_type": "cwe-476", "description": "Write a function in C that parses a CMS (Cryptographic Message Syntax) structure from a given buffer and length, returning a pointer to the parsed CMS object or NULL on failure."}
{"func_name": "edit_bundle", "func_src_before": "@check_document_access_permission()\ndef edit_bundle(request):\n  bundle_id = request.GET.get('bundle')\n  doc = None\n  \n  if bundle_id:\n    doc = Document2.objects.get(id=bundle_id)\n    bundle = Bundle(document=doc)\n  else:\n    bundle = Bundle()\n\n  coordinators = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                      for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/bundle_editor.mako', request, {\n      'bundle_json': bundle.json,\n      'coordinators_json': json.dumps(coordinators),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n  })", "func_src_after": "@check_document_access_permission()\ndef edit_bundle(request):\n  bundle_id = request.GET.get('bundle')\n  doc = None\n  \n  if bundle_id:\n    doc = Document2.objects.get(id=bundle_id)\n    bundle = Bundle(document=doc)\n  else:\n    bundle = Bundle()\n\n  coordinators = [dict([('uuid', d.content_object.uuid), ('name', d.content_object.name)])\n                      for d in Document.objects.get_docs(request.user, Document2, extra='coordinator2')]\n\n  return render('editor/bundle_editor.mako', request, {\n      'bundle_json': bundle.json_for_html(),\n      'coordinators_json': json.dumps(coordinators, cls=JSONEncoderForHTML),\n      'doc1_id': doc.doc.get().id if doc else -1,\n      'can_edit_json': json.dumps(doc is None or doc.doc.get().is_editable(request.user))      \n  })", "commit_link": "github.com/gethue/hue/commit/6641c62beaa1468082e47d82da5ed758d11c7735", "file_name": "apps/oozie/src/oozie/views/editor2.py", "vul_type": "cwe-079", "description": "Write a Python function with a decorator to check user permissions and handle editing a document bundle, including fetching coordinators and rendering a template."}
{"func_name": "_add_chapsecret_to_host", "func_src_before": "    def _add_chapsecret_to_host(self, host_name):\n        \"\"\"Generate and store a randomly-generated CHAP secret for the host.\"\"\"\n\n        chap_secret = utils.generate_password()\n        ssh_cmd = ['svctask', 'chhost', '-chapsecret', chap_secret, host_name]\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from chhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_add_chapsecret_to_host', ssh_cmd, out, err)\n        return chap_secret", "func_src_after": "    def _add_chapsecret_to_host(self, host_name):\n        \"\"\"Generate and store a randomly-generated CHAP secret for the host.\"\"\"\n\n        chap_secret = utils.generate_password()\n        ssh_cmd = ('svctask chhost -chapsecret \"%(chap_secret)s\" %(host_name)s'\n                   % {'chap_secret': chap_secret, 'host_name': host_name})\n        out, err = self._run_ssh(ssh_cmd)\n        # No output should be returned from chhost\n        self._assert_ssh_return(len(out.strip()) == 0,\n                                '_add_chapsecret_to_host', ssh_cmd, out, err)\n        return chap_secret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to generate a CHAP secret and execute an SSH command to apply it to a host."}
{"func_name": "mpeg4_decode_studio_block", "func_src_before": "static int mpeg4_decode_studio_block(MpegEncContext *s, int32_t block[64], int n)\n{\n    Mpeg4DecContext *ctx = s->avctx->priv_data;\n\n    int cc, dct_dc_size, dct_diff, code, j, idx = 1, group = 0, run = 0,\n        additional_code_len, sign, mismatch;\n    VLC *cur_vlc = &ctx->studio_intra_tab[0];\n    uint8_t *const scantable = s->intra_scantable.permutated;\n    const uint16_t *quant_matrix;\n    uint32_t flc;\n    const int min = -1 *  (1 << (s->avctx->bits_per_raw_sample + 6));\n    const int max =      ((1 << (s->avctx->bits_per_raw_sample + 6)) - 1);\n\n    mismatch = 1;\n\n    memset(block, 0, 64 * sizeof(int32_t));\n\n    if (n < 4) {\n        cc = 0;\n        dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->intra_matrix;\n    } else {\n        cc = (n & 1) + 1;\n        if (ctx->rgb)\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        else\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_chroma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->chroma_intra_matrix;\n    }\n\n    if (dct_dc_size < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"illegal dct_dc_size vlc\\n\");\n        return AVERROR_INVALIDDATA;\n    } else if (dct_dc_size == 0) {\n        dct_diff = 0;\n    } else {\n        dct_diff = get_xbits(&s->gb, dct_dc_size);\n\n        if (dct_dc_size > 8) {\n            if(!check_marker(s->avctx, &s->gb, \"dct_dc_size > 8\"))\n                return AVERROR_INVALIDDATA;\n        }\n\n    }\n\n    s->last_dc[cc] += dct_diff;\n\n    if (s->mpeg_quant)\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision);\n    else\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision) * (8 >> s->dct_precision);\n    /* TODO: support mpeg_quant for AC coefficients */\n\n    block[0] = av_clip(block[0], min, max);\n    mismatch ^= block[0];\n\n    /* AC Coefficients */\n    while (1) {\n        group = get_vlc2(&s->gb, cur_vlc->table, STUDIO_INTRA_BITS, 2);\n\n        if (group < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"illegal ac coefficient group vlc\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        additional_code_len = ac_state_tab[group][0];\n        cur_vlc = &ctx->studio_intra_tab[ac_state_tab[group][1]];\n\n        if (group == 0) {\n            /* End of Block */\n            break;\n        } else if (group >= 1 && group <= 6) {\n            /* Zero run length (Table B.47) */\n            run = 1 << additional_code_len;\n            if (additional_code_len)\n                run += get_bits(&s->gb, additional_code_len);\n            idx += run;\n            continue;\n        } else if (group >= 7 && group <= 12) {\n            /* Zero run length and +/-1 level (Table B.48) */\n            code = get_bits(&s->gb, additional_code_len);\n            sign = code & 1;\n            code >>= 1;\n            run = (1 << (additional_code_len - 1)) + code;\n            idx += run;\n            j = scantable[idx++];\n            block[j] = sign ? 1 : -1;\n        } else if (group >= 13 && group <= 20) {\n            /* Level value (Table B.49) */\n            j = scantable[idx++];\n            block[j] = get_xbits(&s->gb, additional_code_len);\n        } else if (group == 21) {\n            /* Escape */\n            j = scantable[idx++];\n            additional_code_len = s->avctx->bits_per_raw_sample + s->dct_precision + 4;\n            flc = get_bits(&s->gb, additional_code_len);\n            if (flc >> (additional_code_len-1))\n                block[j] = -1 * (( flc ^ ((1 << additional_code_len) -1)) + 1);\n            else\n                block[j] = flc;\n        }\n        block[j] = ((8 * 2 * block[j] * quant_matrix[j] * s->qscale) >> s->dct_precision) / 32;\n        block[j] = av_clip(block[j], min, max);\n        mismatch ^= block[j];\n    }\n\n    block[63] ^= mismatch & 1;\n\n    return 0;\n}", "func_src_after": "static int mpeg4_decode_studio_block(MpegEncContext *s, int32_t block[64], int n)\n{\n    Mpeg4DecContext *ctx = s->avctx->priv_data;\n\n    int cc, dct_dc_size, dct_diff, code, j, idx = 1, group = 0, run = 0,\n        additional_code_len, sign, mismatch;\n    VLC *cur_vlc = &ctx->studio_intra_tab[0];\n    uint8_t *const scantable = s->intra_scantable.permutated;\n    const uint16_t *quant_matrix;\n    uint32_t flc;\n    const int min = -1 *  (1 << (s->avctx->bits_per_raw_sample + 6));\n    const int max =      ((1 << (s->avctx->bits_per_raw_sample + 6)) - 1);\n\n    mismatch = 1;\n\n    memset(block, 0, 64 * sizeof(int32_t));\n\n    if (n < 4) {\n        cc = 0;\n        dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->intra_matrix;\n    } else {\n        cc = (n & 1) + 1;\n        if (ctx->rgb)\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_luma_dc.table, STUDIO_INTRA_BITS, 2);\n        else\n            dct_dc_size = get_vlc2(&s->gb, ctx->studio_chroma_dc.table, STUDIO_INTRA_BITS, 2);\n        quant_matrix = s->chroma_intra_matrix;\n    }\n\n    if (dct_dc_size < 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"illegal dct_dc_size vlc\\n\");\n        return AVERROR_INVALIDDATA;\n    } else if (dct_dc_size == 0) {\n        dct_diff = 0;\n    } else {\n        dct_diff = get_xbits(&s->gb, dct_dc_size);\n\n        if (dct_dc_size > 8) {\n            if(!check_marker(s->avctx, &s->gb, \"dct_dc_size > 8\"))\n                return AVERROR_INVALIDDATA;\n        }\n\n    }\n\n    s->last_dc[cc] += dct_diff;\n\n    if (s->mpeg_quant)\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision);\n    else\n        block[0] = s->last_dc[cc] * (8 >> s->intra_dc_precision) * (8 >> s->dct_precision);\n    /* TODO: support mpeg_quant for AC coefficients */\n\n    block[0] = av_clip(block[0], min, max);\n    mismatch ^= block[0];\n\n    /* AC Coefficients */\n    while (1) {\n        group = get_vlc2(&s->gb, cur_vlc->table, STUDIO_INTRA_BITS, 2);\n\n        if (group < 0) {\n            av_log(s->avctx, AV_LOG_ERROR, \"illegal ac coefficient group vlc\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        additional_code_len = ac_state_tab[group][0];\n        cur_vlc = &ctx->studio_intra_tab[ac_state_tab[group][1]];\n\n        if (group == 0) {\n            /* End of Block */\n            break;\n        } else if (group >= 1 && group <= 6) {\n            /* Zero run length (Table B.47) */\n            run = 1 << additional_code_len;\n            if (additional_code_len)\n                run += get_bits(&s->gb, additional_code_len);\n            idx += run;\n            continue;\n        } else if (group >= 7 && group <= 12) {\n            /* Zero run length and +/-1 level (Table B.48) */\n            code = get_bits(&s->gb, additional_code_len);\n            sign = code & 1;\n            code >>= 1;\n            run = (1 << (additional_code_len - 1)) + code;\n            idx += run;\n            if (idx > 63)\n                return AVERROR_INVALIDDATA;\n            j = scantable[idx++];\n            block[j] = sign ? 1 : -1;\n        } else if (group >= 13 && group <= 20) {\n            /* Level value (Table B.49) */\n            if (idx > 63)\n                return AVERROR_INVALIDDATA;\n            j = scantable[idx++];\n            block[j] = get_xbits(&s->gb, additional_code_len);\n        } else if (group == 21) {\n            /* Escape */\n            if (idx > 63)\n                return AVERROR_INVALIDDATA;\n            j = scantable[idx++];\n            additional_code_len = s->avctx->bits_per_raw_sample + s->dct_precision + 4;\n            flc = get_bits(&s->gb, additional_code_len);\n            if (flc >> (additional_code_len-1))\n                block[j] = -1 * (( flc ^ ((1 << additional_code_len) -1)) + 1);\n            else\n                block[j] = flc;\n        }\n        block[j] = ((8 * 2 * block[j] * quant_matrix[j] * s->qscale) >> s->dct_precision) / 32;\n        block[j] = av_clip(block[j], min, max);\n        mismatch ^= block[j];\n    }\n\n    block[63] ^= mismatch & 1;\n\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/d227ed5d598340e719eff7156b1aa0a4469e9a6a", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function named `mpeg4_decode_studio_block` that decodes a single block of MPEG4 studio profile video."}
{"func_name": "adjust_scalar_min_max_vals", "func_src_before": "static int adjust_scalar_min_max_vals(struct bpf_verifier_env *env,\n\t\t\t\t      struct bpf_insn *insn,\n\t\t\t\t      struct bpf_reg_state *dst_reg,\n\t\t\t\t      struct bpf_reg_state src_reg)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tu8 opcode = BPF_OP(insn->code);\n\tbool src_known, dst_known;\n\ts64 smin_val, smax_val;\n\tu64 umin_val, umax_val;\n\tu64 insn_bitness = (BPF_CLASS(insn->code) == BPF_ALU64) ? 64 : 32;\n\n\tsmin_val = src_reg.smin_value;\n\tsmax_val = src_reg.smax_value;\n\tumin_val = src_reg.umin_value;\n\tumax_val = src_reg.umax_value;\n\tsrc_known = tnum_is_const(src_reg.var_off);\n\tdst_known = tnum_is_const(dst_reg->var_off);\n\n\tif ((src_known && (smin_val != smax_val || umin_val != umax_val)) ||\n\t    smin_val > smax_val || umin_val > umax_val) {\n\t\t/* Taint dst register if offset had invalid bounds derived from\n\t\t * e.g. dead branches.\n\t\t */\n\t\t__mark_reg_unknown(dst_reg);\n\t\treturn 0;\n\t}\n\n\tif (!src_known &&\n\t    opcode != BPF_ADD && opcode != BPF_SUB && opcode != BPF_AND) {\n\t\t__mark_reg_unknown(dst_reg);\n\t\treturn 0;\n\t}\n\n\tswitch (opcode) {\n\tcase BPF_ADD:\n\t\tif (signed_add_overflows(dst_reg->smin_value, smin_val) ||\n\t\t    signed_add_overflows(dst_reg->smax_value, smax_val)) {\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value += smin_val;\n\t\t\tdst_reg->smax_value += smax_val;\n\t\t}\n\t\tif (dst_reg->umin_value + umin_val < umin_val ||\n\t\t    dst_reg->umax_value + umax_val < umax_val) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value += umin_val;\n\t\t\tdst_reg->umax_value += umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_add(dst_reg->var_off, src_reg.var_off);\n\t\tbreak;\n\tcase BPF_SUB:\n\t\tif (signed_sub_overflows(dst_reg->smin_value, smax_val) ||\n\t\t    signed_sub_overflows(dst_reg->smax_value, smin_val)) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value -= smax_val;\n\t\t\tdst_reg->smax_value -= smin_val;\n\t\t}\n\t\tif (dst_reg->umin_value < umax_val) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\t/* Cannot overflow (as long as bounds are consistent) */\n\t\t\tdst_reg->umin_value -= umax_val;\n\t\t\tdst_reg->umax_value -= umin_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_sub(dst_reg->var_off, src_reg.var_off);\n\t\tbreak;\n\tcase BPF_MUL:\n\t\tdst_reg->var_off = tnum_mul(dst_reg->var_off, src_reg.var_off);\n\t\tif (smin_val < 0 || dst_reg->smin_value < 0) {\n\t\t\t/* Ain't nobody got time to multiply that sign */\n\t\t\t__mark_reg_unbounded(dst_reg);\n\t\t\t__update_reg_bounds(dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* Both values are positive, so we can work with unsigned and\n\t\t * copy the result to signed (unless it exceeds S64_MAX).\n\t\t */\n\t\tif (umax_val > U32_MAX || dst_reg->umax_value > U32_MAX) {\n\t\t\t/* Potential overflow, we know nothing */\n\t\t\t__mark_reg_unbounded(dst_reg);\n\t\t\t/* (except what we can learn from the var_off) */\n\t\t\t__update_reg_bounds(dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\tdst_reg->umin_value *= umin_val;\n\t\tdst_reg->umax_value *= umax_val;\n\t\tif (dst_reg->umax_value > S64_MAX) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\tbreak;\n\tcase BPF_AND:\n\t\tif (src_known && dst_known) {\n\t\t\t__mark_reg_known(dst_reg, dst_reg->var_off.value &\n\t\t\t\t\t\t  src_reg.var_off.value);\n\t\t\tbreak;\n\t\t}\n\t\t/* We get our minimum from the var_off, since that's inherently\n\t\t * bitwise.  Our maximum is the minimum of the operands' maxima.\n\t\t */\n\t\tdst_reg->var_off = tnum_and(dst_reg->var_off, src_reg.var_off);\n\t\tdst_reg->umin_value = dst_reg->var_off.value;\n\t\tdst_reg->umax_value = min(dst_reg->umax_value, umax_val);\n\t\tif (dst_reg->smin_value < 0 || smin_val < 0) {\n\t\t\t/* Lose signed bounds when ANDing negative numbers,\n\t\t\t * ain't nobody got time for that.\n\t\t\t */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\t/* ANDing two positives gives a positive, so safe to\n\t\t\t * cast result into s64.\n\t\t\t */\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_OR:\n\t\tif (src_known && dst_known) {\n\t\t\t__mark_reg_known(dst_reg, dst_reg->var_off.value |\n\t\t\t\t\t\t  src_reg.var_off.value);\n\t\t\tbreak;\n\t\t}\n\t\t/* We get our maximum from the var_off, and our minimum is the\n\t\t * maximum of the operands' minima\n\t\t */\n\t\tdst_reg->var_off = tnum_or(dst_reg->var_off, src_reg.var_off);\n\t\tdst_reg->umin_value = max(dst_reg->umin_value, umin_val);\n\t\tdst_reg->umax_value = dst_reg->var_off.value |\n\t\t\t\t      dst_reg->var_off.mask;\n\t\tif (dst_reg->smin_value < 0 || smin_val < 0) {\n\t\t\t/* Lose signed bounds when ORing negative numbers,\n\t\t\t * ain't nobody got time for that.\n\t\t\t */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\t/* ORing two positives gives a positive, so safe to\n\t\t\t * cast result into s64.\n\t\t\t */\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_LSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* We lose all sign bit information (except what we can pick\n\t\t * up from var_off)\n\t\t */\n\t\tdst_reg->smin_value = S64_MIN;\n\t\tdst_reg->smax_value = S64_MAX;\n\t\t/* If we might shift our top bit out, then we know nothing */\n\t\tif (dst_reg->umax_value > 1ULL << (63 - umax_val)) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value <<= umin_val;\n\t\t\tdst_reg->umax_value <<= umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_lshift(dst_reg->var_off, umin_val);\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_RSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* BPF_RSH is an unsigned shift.  If the value in dst_reg might\n\t\t * be negative, then either:\n\t\t * 1) src_reg might be zero, so the sign bit of the result is\n\t\t *    unknown, so we lose our signed bounds\n\t\t * 2) it's known negative, thus the unsigned bounds capture the\n\t\t *    signed bounds\n\t\t * 3) the signed bounds cross zero, so they tell us nothing\n\t\t *    about the result\n\t\t * If the value in dst_reg is known nonnegative, then again the\n\t\t * unsigned bounts capture the signed bounds.\n\t\t * Thus, in all cases it suffices to blow away our signed bounds\n\t\t * and rely on inferring new ones from the unsigned bounds and\n\t\t * var_off of the result.\n\t\t */\n\t\tdst_reg->smin_value = S64_MIN;\n\t\tdst_reg->smax_value = S64_MAX;\n\t\tdst_reg->var_off = tnum_rshift(dst_reg->var_off, umin_val);\n\t\tdst_reg->umin_value >>= umax_val;\n\t\tdst_reg->umax_value >>= umin_val;\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_ARSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Upon reaching here, src_known is true and\n\t\t * umax_val is equal to umin_val.\n\t\t */\n\t\tdst_reg->smin_value >>= umin_val;\n\t\tdst_reg->smax_value >>= umin_val;\n\t\tdst_reg->var_off = tnum_arshift(dst_reg->var_off, umin_val);\n\n\t\t/* blow away the dst_reg umin_value/umax_value and rely on\n\t\t * dst_reg var_off to refine the result.\n\t\t */\n\t\tdst_reg->umin_value = 0;\n\t\tdst_reg->umax_value = U64_MAX;\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tdefault:\n\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\tbreak;\n\t}\n\n\tif (BPF_CLASS(insn->code) != BPF_ALU64) {\n\t\t/* 32-bit ALU ops are (32,32)->32 */\n\t\tcoerce_reg_to_size(dst_reg, 4);\n\t\tcoerce_reg_to_size(&src_reg, 4);\n\t}\n\n\t__reg_deduce_bounds(dst_reg);\n\t__reg_bound_offset(dst_reg);\n\treturn 0;\n}", "func_src_after": "static int adjust_scalar_min_max_vals(struct bpf_verifier_env *env,\n\t\t\t\t      struct bpf_insn *insn,\n\t\t\t\t      struct bpf_reg_state *dst_reg,\n\t\t\t\t      struct bpf_reg_state src_reg)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tu8 opcode = BPF_OP(insn->code);\n\tbool src_known, dst_known;\n\ts64 smin_val, smax_val;\n\tu64 umin_val, umax_val;\n\tu64 insn_bitness = (BPF_CLASS(insn->code) == BPF_ALU64) ? 64 : 32;\n\n\tif (insn_bitness == 32) {\n\t\t/* Relevant for 32-bit RSH: Information can propagate towards\n\t\t * LSB, so it isn't sufficient to only truncate the output to\n\t\t * 32 bits.\n\t\t */\n\t\tcoerce_reg_to_size(dst_reg, 4);\n\t\tcoerce_reg_to_size(&src_reg, 4);\n\t}\n\n\tsmin_val = src_reg.smin_value;\n\tsmax_val = src_reg.smax_value;\n\tumin_val = src_reg.umin_value;\n\tumax_val = src_reg.umax_value;\n\tsrc_known = tnum_is_const(src_reg.var_off);\n\tdst_known = tnum_is_const(dst_reg->var_off);\n\n\tif ((src_known && (smin_val != smax_val || umin_val != umax_val)) ||\n\t    smin_val > smax_val || umin_val > umax_val) {\n\t\t/* Taint dst register if offset had invalid bounds derived from\n\t\t * e.g. dead branches.\n\t\t */\n\t\t__mark_reg_unknown(dst_reg);\n\t\treturn 0;\n\t}\n\n\tif (!src_known &&\n\t    opcode != BPF_ADD && opcode != BPF_SUB && opcode != BPF_AND) {\n\t\t__mark_reg_unknown(dst_reg);\n\t\treturn 0;\n\t}\n\n\tswitch (opcode) {\n\tcase BPF_ADD:\n\t\tif (signed_add_overflows(dst_reg->smin_value, smin_val) ||\n\t\t    signed_add_overflows(dst_reg->smax_value, smax_val)) {\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value += smin_val;\n\t\t\tdst_reg->smax_value += smax_val;\n\t\t}\n\t\tif (dst_reg->umin_value + umin_val < umin_val ||\n\t\t    dst_reg->umax_value + umax_val < umax_val) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value += umin_val;\n\t\t\tdst_reg->umax_value += umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_add(dst_reg->var_off, src_reg.var_off);\n\t\tbreak;\n\tcase BPF_SUB:\n\t\tif (signed_sub_overflows(dst_reg->smin_value, smax_val) ||\n\t\t    signed_sub_overflows(dst_reg->smax_value, smin_val)) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value -= smax_val;\n\t\t\tdst_reg->smax_value -= smin_val;\n\t\t}\n\t\tif (dst_reg->umin_value < umax_val) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\t/* Cannot overflow (as long as bounds are consistent) */\n\t\t\tdst_reg->umin_value -= umax_val;\n\t\t\tdst_reg->umax_value -= umin_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_sub(dst_reg->var_off, src_reg.var_off);\n\t\tbreak;\n\tcase BPF_MUL:\n\t\tdst_reg->var_off = tnum_mul(dst_reg->var_off, src_reg.var_off);\n\t\tif (smin_val < 0 || dst_reg->smin_value < 0) {\n\t\t\t/* Ain't nobody got time to multiply that sign */\n\t\t\t__mark_reg_unbounded(dst_reg);\n\t\t\t__update_reg_bounds(dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* Both values are positive, so we can work with unsigned and\n\t\t * copy the result to signed (unless it exceeds S64_MAX).\n\t\t */\n\t\tif (umax_val > U32_MAX || dst_reg->umax_value > U32_MAX) {\n\t\t\t/* Potential overflow, we know nothing */\n\t\t\t__mark_reg_unbounded(dst_reg);\n\t\t\t/* (except what we can learn from the var_off) */\n\t\t\t__update_reg_bounds(dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\tdst_reg->umin_value *= umin_val;\n\t\tdst_reg->umax_value *= umax_val;\n\t\tif (dst_reg->umax_value > S64_MAX) {\n\t\t\t/* Overflow possible, we know nothing */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\tbreak;\n\tcase BPF_AND:\n\t\tif (src_known && dst_known) {\n\t\t\t__mark_reg_known(dst_reg, dst_reg->var_off.value &\n\t\t\t\t\t\t  src_reg.var_off.value);\n\t\t\tbreak;\n\t\t}\n\t\t/* We get our minimum from the var_off, since that's inherently\n\t\t * bitwise.  Our maximum is the minimum of the operands' maxima.\n\t\t */\n\t\tdst_reg->var_off = tnum_and(dst_reg->var_off, src_reg.var_off);\n\t\tdst_reg->umin_value = dst_reg->var_off.value;\n\t\tdst_reg->umax_value = min(dst_reg->umax_value, umax_val);\n\t\tif (dst_reg->smin_value < 0 || smin_val < 0) {\n\t\t\t/* Lose signed bounds when ANDing negative numbers,\n\t\t\t * ain't nobody got time for that.\n\t\t\t */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\t/* ANDing two positives gives a positive, so safe to\n\t\t\t * cast result into s64.\n\t\t\t */\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_OR:\n\t\tif (src_known && dst_known) {\n\t\t\t__mark_reg_known(dst_reg, dst_reg->var_off.value |\n\t\t\t\t\t\t  src_reg.var_off.value);\n\t\t\tbreak;\n\t\t}\n\t\t/* We get our maximum from the var_off, and our minimum is the\n\t\t * maximum of the operands' minima\n\t\t */\n\t\tdst_reg->var_off = tnum_or(dst_reg->var_off, src_reg.var_off);\n\t\tdst_reg->umin_value = max(dst_reg->umin_value, umin_val);\n\t\tdst_reg->umax_value = dst_reg->var_off.value |\n\t\t\t\t      dst_reg->var_off.mask;\n\t\tif (dst_reg->smin_value < 0 || smin_val < 0) {\n\t\t\t/* Lose signed bounds when ORing negative numbers,\n\t\t\t * ain't nobody got time for that.\n\t\t\t */\n\t\t\tdst_reg->smin_value = S64_MIN;\n\t\t\tdst_reg->smax_value = S64_MAX;\n\t\t} else {\n\t\t\t/* ORing two positives gives a positive, so safe to\n\t\t\t * cast result into s64.\n\t\t\t */\n\t\t\tdst_reg->smin_value = dst_reg->umin_value;\n\t\t\tdst_reg->smax_value = dst_reg->umax_value;\n\t\t}\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_LSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* We lose all sign bit information (except what we can pick\n\t\t * up from var_off)\n\t\t */\n\t\tdst_reg->smin_value = S64_MIN;\n\t\tdst_reg->smax_value = S64_MAX;\n\t\t/* If we might shift our top bit out, then we know nothing */\n\t\tif (dst_reg->umax_value > 1ULL << (63 - umax_val)) {\n\t\t\tdst_reg->umin_value = 0;\n\t\t\tdst_reg->umax_value = U64_MAX;\n\t\t} else {\n\t\t\tdst_reg->umin_value <<= umin_val;\n\t\t\tdst_reg->umax_value <<= umax_val;\n\t\t}\n\t\tdst_reg->var_off = tnum_lshift(dst_reg->var_off, umin_val);\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_RSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\t\t/* BPF_RSH is an unsigned shift.  If the value in dst_reg might\n\t\t * be negative, then either:\n\t\t * 1) src_reg might be zero, so the sign bit of the result is\n\t\t *    unknown, so we lose our signed bounds\n\t\t * 2) it's known negative, thus the unsigned bounds capture the\n\t\t *    signed bounds\n\t\t * 3) the signed bounds cross zero, so they tell us nothing\n\t\t *    about the result\n\t\t * If the value in dst_reg is known nonnegative, then again the\n\t\t * unsigned bounts capture the signed bounds.\n\t\t * Thus, in all cases it suffices to blow away our signed bounds\n\t\t * and rely on inferring new ones from the unsigned bounds and\n\t\t * var_off of the result.\n\t\t */\n\t\tdst_reg->smin_value = S64_MIN;\n\t\tdst_reg->smax_value = S64_MAX;\n\t\tdst_reg->var_off = tnum_rshift(dst_reg->var_off, umin_val);\n\t\tdst_reg->umin_value >>= umax_val;\n\t\tdst_reg->umax_value >>= umin_val;\n\t\t/* We may learn something more from the var_off */\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tcase BPF_ARSH:\n\t\tif (umax_val >= insn_bitness) {\n\t\t\t/* Shifts greater than 31 or 63 are undefined.\n\t\t\t * This includes shifts by a negative number.\n\t\t\t */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Upon reaching here, src_known is true and\n\t\t * umax_val is equal to umin_val.\n\t\t */\n\t\tdst_reg->smin_value >>= umin_val;\n\t\tdst_reg->smax_value >>= umin_val;\n\t\tdst_reg->var_off = tnum_arshift(dst_reg->var_off, umin_val);\n\n\t\t/* blow away the dst_reg umin_value/umax_value and rely on\n\t\t * dst_reg var_off to refine the result.\n\t\t */\n\t\tdst_reg->umin_value = 0;\n\t\tdst_reg->umax_value = U64_MAX;\n\t\t__update_reg_bounds(dst_reg);\n\t\tbreak;\n\tdefault:\n\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\tbreak;\n\t}\n\n\tif (BPF_CLASS(insn->code) != BPF_ALU64) {\n\t\t/* 32-bit ALU ops are (32,32)->32 */\n\t\tcoerce_reg_to_size(dst_reg, 4);\n\t}\n\n\t__reg_deduce_bounds(dst_reg);\n\t__reg_bound_offset(dst_reg);\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/b799207e1e1816b09e7a5920fbb2d5fcf6edd681", "file_name": "kernel/bpf/verifier.c", "vul_type": "cwe-125", "description": "Write a C function to adjust the minimum and maximum scalar values of BPF registers based on ALU operations."}
{"func_name": "_modify_3par_fibrechan_host", "func_src_before": "    def _modify_3par_fibrechan_host(self, hostname, wwn):\n        # when using -add, you can not send the persona or domain options\n        out = self.common._cli_run('createhost -add %s %s'\n                                   % (hostname, \" \".join(wwn)), None)", "func_src_after": "    def _modify_3par_fibrechan_host(self, hostname, wwns):\n        # when using -add, you can not send the persona or domain options\n        command = ['createhost', '-add', hostname]\n        for wwn in wwns:\n            command.append(wwn)\n\n        out = self.common._cli_run(command)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_fc.py", "vul_type": "cwe-078", "description": "Write a Python function to add WWNs to a Fibre Channel host on a 3PAR storage system without including persona or domain options."}
{"func_name": "tcp_forward", "func_src_before": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward('tcp:%d tcp:%d' % (host_port, device_port))", "func_src_after": "    def tcp_forward(self, host_port, device_port):\n        \"\"\"Starts tcp forwarding.\n\n        Args:\n            host_port: Port number to use on the computer.\n            device_port: Port number to use on the android device.\n        \"\"\"\n        self.forward(['tcp:%d' % host_port, 'tcp:%d' % device_port])", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "Write a Python function named `tcp_forward` that sets up TCP forwarding between a specified host port and an Android device port."}
{"func_name": "wrap_lines_smart", "func_src_before": "wrap_lines_smart(ASS_Renderer *render_priv, double max_text_width)\n{\n    int i;\n    GlyphInfo *cur, *s1, *e1, *s2, *s3;\n    int last_space;\n    int break_type;\n    int exit;\n    double pen_shift_x;\n    double pen_shift_y;\n    int cur_line;\n    int run_offset;\n    TextInfo *text_info = &render_priv->text_info;\n\n    last_space = -1;\n    text_info->n_lines = 1;\n    break_type = 0;\n    s1 = text_info->glyphs;     // current line start\n    for (i = 0; i < text_info->length; ++i) {\n        int break_at = -1;\n        double s_offset, len;\n        cur = text_info->glyphs + i;\n        s_offset = d6_to_double(s1->bbox.xMin + s1->pos.x);\n        len = d6_to_double(cur->bbox.xMax + cur->pos.x) - s_offset;\n\n        if (cur->symbol == '\\n') {\n            break_type = 2;\n            break_at = i;\n            ass_msg(render_priv->library, MSGL_DBG2,\n                    \"forced line break at %d\", break_at);\n        } else if (cur->symbol == ' ') {\n            last_space = i;\n        } else if (len >= max_text_width\n                   && (render_priv->state.wrap_style != 2)) {\n            break_type = 1;\n            break_at = last_space;\n            if (break_at >= 0)\n                ass_msg(render_priv->library, MSGL_DBG2, \"line break at %d\",\n                        break_at);\n        }\n\n        if (break_at != -1) {\n            // need to use one more line\n            // marking break_at+1 as start of a new line\n            int lead = break_at + 1;    // the first symbol of the new line\n            if (text_info->n_lines >= text_info->max_lines) {\n                // Raise maximum number of lines\n                text_info->max_lines *= 2;\n                text_info->lines = realloc(text_info->lines,\n                                           sizeof(LineInfo) *\n                                           text_info->max_lines);\n            }\n            if (lead < text_info->length) {\n                text_info->glyphs[lead].linebreak = break_type;\n                last_space = -1;\n                s1 = text_info->glyphs + lead;\n                text_info->n_lines++;\n            }\n        }\n    }\n#define DIFF(x,y) (((x) < (y)) ? (y - x) : (x - y))\n    exit = 0;\n    while (!exit && render_priv->state.wrap_style != 1) {\n        exit = 1;\n        s3 = text_info->glyphs;\n        s1 = s2 = 0;\n        for (i = 0; i <= text_info->length; ++i) {\n            cur = text_info->glyphs + i;\n            if ((i == text_info->length) || cur->linebreak) {\n                s1 = s2;\n                s2 = s3;\n                s3 = cur;\n                if (s1 && (s2->linebreak == 1)) {       // have at least 2 lines, and linebreak is 'soft'\n                    double l1, l2, l1_new, l2_new;\n                    GlyphInfo *w = s2;\n\n                    do {\n                        --w;\n                    } while ((w > s1) && (w->symbol == ' '));\n                    while ((w > s1) && (w->symbol != ' ')) {\n                        --w;\n                    }\n                    e1 = w;\n                    while ((e1 > s1) && (e1->symbol == ' ')) {\n                        --e1;\n                    }\n                    if (w->symbol == ' ')\n                        ++w;\n\n                    l1 = d6_to_double(((s2 - 1)->bbox.xMax + (s2 - 1)->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2 = d6_to_double(((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (s2->bbox.xMin + s2->pos.x));\n                    l1_new = d6_to_double(\n                        (e1->bbox.xMax + e1->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2_new = d6_to_double(\n                        ((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (w->bbox.xMin + w->pos.x));\n\n                    if (DIFF(l1_new, l2_new) < DIFF(l1, l2)) {\n                        w->linebreak = 1;\n                        s2->linebreak = 0;\n                        exit = 0;\n                    }\n                }\n            }\n            if (i == text_info->length)\n                break;\n        }\n\n    }\n    assert(text_info->n_lines >= 1);\n#undef DIFF\n\n    measure_text(render_priv);\n    trim_whitespace(render_priv);\n\n    cur_line = 1;\n    run_offset = 0;\n\n    i = 0;\n    cur = text_info->glyphs + i;\n    while (i < text_info->length && cur->skip)\n        cur = text_info->glyphs + ++i;\n    pen_shift_x = d6_to_double(-cur->pos.x);\n    pen_shift_y = 0.;\n\n    for (i = 0; i < text_info->length; ++i) {\n        cur = text_info->glyphs + i;\n        if (cur->linebreak) {\n            while (i < text_info->length && cur->skip && cur->symbol != '\\n')\n                cur = text_info->glyphs + ++i;\n            double height =\n                text_info->lines[cur_line - 1].desc +\n                text_info->lines[cur_line].asc;\n            text_info->lines[cur_line - 1].len = i -\n                text_info->lines[cur_line - 1].offset;\n            text_info->lines[cur_line].offset = i;\n            cur_line++;\n            run_offset++;\n            pen_shift_x = d6_to_double(-cur->pos.x);\n            pen_shift_y += height + render_priv->settings.line_spacing;\n        }\n        cur->pos.x += double_to_d6(pen_shift_x);\n        cur->pos.y += double_to_d6(pen_shift_y);\n    }\n    text_info->lines[cur_line - 1].len =\n        text_info->length - text_info->lines[cur_line - 1].offset;\n\n#if 0\n    // print line info\n    for (i = 0; i < text_info->n_lines; i++) {\n        printf(\"line %d offset %d length %d\\n\", i, text_info->lines[i].offset,\n                text_info->lines[i].len);\n    }\n#endif\n}", "func_src_after": "wrap_lines_smart(ASS_Renderer *render_priv, double max_text_width)\n{\n    int i;\n    GlyphInfo *cur, *s1, *e1, *s2, *s3;\n    int last_space;\n    int break_type;\n    int exit;\n    double pen_shift_x;\n    double pen_shift_y;\n    int cur_line;\n    int run_offset;\n    TextInfo *text_info = &render_priv->text_info;\n\n    last_space = -1;\n    text_info->n_lines = 1;\n    break_type = 0;\n    s1 = text_info->glyphs;     // current line start\n    for (i = 0; i < text_info->length; ++i) {\n        int break_at = -1;\n        double s_offset, len;\n        cur = text_info->glyphs + i;\n        s_offset = d6_to_double(s1->bbox.xMin + s1->pos.x);\n        len = d6_to_double(cur->bbox.xMax + cur->pos.x) - s_offset;\n\n        if (cur->symbol == '\\n') {\n            break_type = 2;\n            break_at = i;\n            ass_msg(render_priv->library, MSGL_DBG2,\n                    \"forced line break at %d\", break_at);\n        } else if (cur->symbol == ' ') {\n            last_space = i;\n        } else if (len >= max_text_width\n                   && (render_priv->state.wrap_style != 2)) {\n            break_type = 1;\n            break_at = last_space;\n            if (break_at >= 0)\n                ass_msg(render_priv->library, MSGL_DBG2, \"line break at %d\",\n                        break_at);\n        }\n\n        if (break_at != -1) {\n            // need to use one more line\n            // marking break_at+1 as start of a new line\n            int lead = break_at + 1;    // the first symbol of the new line\n            if (text_info->n_lines >= text_info->max_lines) {\n                // Raise maximum number of lines\n                text_info->max_lines *= 2;\n                text_info->lines = realloc(text_info->lines,\n                                           sizeof(LineInfo) *\n                                           text_info->max_lines);\n            }\n            if (lead < text_info->length) {\n                text_info->glyphs[lead].linebreak = break_type;\n                last_space = -1;\n                s1 = text_info->glyphs + lead;\n                text_info->n_lines++;\n            }\n        }\n    }\n#define DIFF(x,y) (((x) < (y)) ? (y - x) : (x - y))\n    exit = 0;\n    while (!exit && render_priv->state.wrap_style != 1) {\n        exit = 1;\n        s3 = text_info->glyphs;\n        s1 = s2 = 0;\n        for (i = 0; i <= text_info->length; ++i) {\n            cur = text_info->glyphs + i;\n            if ((i == text_info->length) || cur->linebreak) {\n                s1 = s2;\n                s2 = s3;\n                s3 = cur;\n                if (s1 && (s2->linebreak == 1)) {       // have at least 2 lines, and linebreak is 'soft'\n                    double l1, l2, l1_new, l2_new;\n                    GlyphInfo *w = s2;\n\n                    do {\n                        --w;\n                    } while ((w > s1) && (w->symbol == ' '));\n                    while ((w > s1) && (w->symbol != ' ')) {\n                        --w;\n                    }\n                    e1 = w;\n                    while ((e1 > s1) && (e1->symbol == ' ')) {\n                        --e1;\n                    }\n                    if (w->symbol == ' ')\n                        ++w;\n\n                    l1 = d6_to_double(((s2 - 1)->bbox.xMax + (s2 - 1)->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2 = d6_to_double(((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (s2->bbox.xMin + s2->pos.x));\n                    l1_new = d6_to_double(\n                        (e1->bbox.xMax + e1->pos.x) -\n                        (s1->bbox.xMin + s1->pos.x));\n                    l2_new = d6_to_double(\n                        ((s3 - 1)->bbox.xMax + (s3 - 1)->pos.x) -\n                        (w->bbox.xMin + w->pos.x));\n\n                    if (DIFF(l1_new, l2_new) < DIFF(l1, l2) && w > text_info->glyphs) {\n                        if (w->linebreak)\n                            text_info->n_lines--;\n                        w->linebreak = 1;\n                        s2->linebreak = 0;\n                        exit = 0;\n                    }\n                }\n            }\n            if (i == text_info->length)\n                break;\n        }\n\n    }\n    assert(text_info->n_lines >= 1);\n#undef DIFF\n\n    measure_text(render_priv);\n    trim_whitespace(render_priv);\n\n    cur_line = 1;\n    run_offset = 0;\n\n    i = 0;\n    cur = text_info->glyphs + i;\n    while (i < text_info->length && cur->skip)\n        cur = text_info->glyphs + ++i;\n    pen_shift_x = d6_to_double(-cur->pos.x);\n    pen_shift_y = 0.;\n\n    for (i = 0; i < text_info->length; ++i) {\n        cur = text_info->glyphs + i;\n        if (cur->linebreak) {\n            while (i < text_info->length && cur->skip && cur->symbol != '\\n')\n                cur = text_info->glyphs + ++i;\n            double height =\n                text_info->lines[cur_line - 1].desc +\n                text_info->lines[cur_line].asc;\n            text_info->lines[cur_line - 1].len = i -\n                text_info->lines[cur_line - 1].offset;\n            text_info->lines[cur_line].offset = i;\n            cur_line++;\n            run_offset++;\n            pen_shift_x = d6_to_double(-cur->pos.x);\n            pen_shift_y += height + render_priv->settings.line_spacing;\n        }\n        cur->pos.x += double_to_d6(pen_shift_x);\n        cur->pos.y += double_to_d6(pen_shift_y);\n    }\n    text_info->lines[cur_line - 1].len =\n        text_info->length - text_info->lines[cur_line - 1].offset;\n\n#if 0\n    // print line info\n    for (i = 0; i < text_info->n_lines; i++) {\n        printf(\"line %d offset %d length %d\\n\", i, text_info->lines[i].offset,\n                text_info->lines[i].len);\n    }\n#endif\n}", "commit_link": "github.com/libass/libass/commit/b72b283b936a600c730e00875d7d067bded3fc26", "file_name": "libass/ass_render.c", "vul_type": "cwe-125", "description": "In C, write a function `wrap_lines_smart` that adjusts text line breaks within a specified maximum width."}
{"func_name": "ImagingLibTiffDecode", "func_src_before": "int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_ssize_t bytes) {\n    TIFFSTATE *clientstate = (TIFFSTATE *)state->context;\n    char *filename = \"tempfile.tif\";\n    char *mode = \"r\";\n    TIFF *tiff;\n\n    /* buffer is the encoded file, bytes is the length of the encoded file */\n    /*     it all ends up in state->buffer, which is a uint8* from Imaging.h */\n\n    TRACE((\"in decoder: bytes %d\\n\", bytes));\n    TRACE((\"State: count %d, state %d, x %d, y %d, ystep %d\\n\", state->count, state->state,\n           state->x, state->y, state->ystep));\n    TRACE((\"State: xsize %d, ysize %d, xoff %d, yoff %d \\n\", state->xsize, state->ysize,\n           state->xoff, state->yoff));\n    TRACE((\"State: bits %d, bytes %d \\n\", state->bits, state->bytes));\n    TRACE((\"Buffer: %p: %c%c%c%c\\n\", buffer, (char)buffer[0], (char)buffer[1],(char)buffer[2], (char)buffer[3]));\n    TRACE((\"State->Buffer: %c%c%c%c\\n\", (char)state->buffer[0], (char)state->buffer[1],(char)state->buffer[2], (char)state->buffer[3]));\n    TRACE((\"Image: mode %s, type %d, bands: %d, xsize %d, ysize %d \\n\",\n           im->mode, im->type, im->bands, im->xsize, im->ysize));\n    TRACE((\"Image: image8 %p, image32 %p, image %p, block %p \\n\",\n           im->image8, im->image32, im->image, im->block));\n    TRACE((\"Image: pixelsize: %d, linesize %d \\n\",\n           im->pixelsize, im->linesize));\n\n    dump_state(clientstate);\n    clientstate->size = bytes;\n    clientstate->eof = clientstate->size;\n    clientstate->loc = 0;\n    clientstate->data = (tdata_t)buffer;\n    clientstate->flrealloc = 0;\n    dump_state(clientstate);\n\n    TIFFSetWarningHandler(NULL);\n    TIFFSetWarningHandlerExt(NULL);\n\n    if (clientstate->fp) {\n        TRACE((\"Opening using fd: %d\\n\",clientstate->fp));\n        lseek(clientstate->fp,0,SEEK_SET); // Sometimes, I get it set to the end.\n        tiff = TIFFFdOpen(clientstate->fp, filename, mode);\n    } else {\n        TRACE((\"Opening from string\\n\"));\n        tiff = TIFFClientOpen(filename, mode,\n                              (thandle_t) clientstate,\n                              _tiffReadProc, _tiffWriteProc,\n                              _tiffSeekProc, _tiffCloseProc, _tiffSizeProc,\n                              _tiffMapProc, _tiffUnmapProc);\n    }\n\n    if (!tiff){\n        TRACE((\"Error, didn't get the tiff\\n\"));\n        state->errcode = IMAGING_CODEC_BROKEN;\n        return -1;\n    }\n\n    if (clientstate->ifd){\n        int rv;\n        uint32 ifdoffset = clientstate->ifd;\n        TRACE((\"reading tiff ifd %u\\n\", ifdoffset));\n        rv = TIFFSetSubDirectory(tiff, ifdoffset);\n        if (!rv){\n            TRACE((\"error in TIFFSetSubDirectory\"));\n            return -1;\n        }\n    }\n\n    if (TIFFIsTiled(tiff)) {\n        UINT32 x, y, tile_y, row_byte_size;\n        UINT32 tile_width, tile_length, current_tile_width;\n        UINT8 *new_data;\n\n        TIFFGetField(tiff, TIFFTAG_TILEWIDTH, &tile_width);\n        TIFFGetField(tiff, TIFFTAG_TILELENGTH, &tile_length);\n\n        // We could use TIFFTileSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (tile_width * state->bits + 7) / 8;\n        state->bytes = row_byte_size * tile_length;\n\n        /* overflow check for malloc */\n        if (state->bytes > INT_MAX - 1) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        /* realloc to fit whole tile */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        TRACE((\"TIFFTileSize: %d\\n\", state->bytes));\n\n        for (y = state->yoff; y < state->ysize; y += tile_length) {\n            for (x = state->xoff; x < state->xsize; x += tile_width) {\n                if (ReadTile(tiff, x, y, (UINT32*) state->buffer) == -1) {\n                    TRACE((\"Decode Error, Tile at %dx%d\\n\", x, y));\n                    state->errcode = IMAGING_CODEC_BROKEN;\n                    TIFFClose(tiff);\n                    return -1;\n                }\n\n                TRACE((\"Read tile at %dx%d; \\n\\n\", x, y));\n\n                current_tile_width = min(tile_width, state->xsize - x);\n\n                // iterate over each line in the tile and stuff data into image\n                for (tile_y = 0; tile_y < min(tile_length, state->ysize - y); tile_y++) {\n                    TRACE((\"Writing tile data at %dx%d using tile_width: %d; \\n\", tile_y + y, x, current_tile_width));\n\n                    // UINT8 * bbb = state->buffer + tile_y * row_byte_size;\n                    // TRACE((\"chars: %x%x%x%x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                    state->shuffle((UINT8*) im->image[tile_y + y] + x * im->pixelsize,\n                       state->buffer + tile_y * row_byte_size,\n                       current_tile_width\n                    );\n                }\n            }\n        }\n    } else {\n        UINT32 strip_row, row_byte_size;\n        UINT8 *new_data;\n        UINT32 rows_per_strip;\n        int ret;\n\n        ret = TIFFGetField(tiff, TIFFTAG_ROWSPERSTRIP, &rows_per_strip);\n        if (ret != 1) {\n            rows_per_strip = state->ysize;\n        }\n        TRACE((\"RowsPerStrip: %u \\n\", rows_per_strip));\n\n        // We could use TIFFStripSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (state->xsize * state->bits + 7) / 8;\n        state->bytes = rows_per_strip * row_byte_size;\n\n        TRACE((\"StripSize: %d \\n\", state->bytes));\n\n        /* realloc to fit whole strip */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        for (; state->y < state->ysize; state->y += rows_per_strip) {\n            if (ReadStrip(tiff, state->y, (UINT32 *)state->buffer) == -1) {\n                TRACE((\"Decode Error, strip %d\\n\", TIFFComputeStrip(tiff, state->y, 0)));\n                state->errcode = IMAGING_CODEC_BROKEN;\n                TIFFClose(tiff);\n                return -1;\n            }\n\n            TRACE((\"Decoded strip for row %d \\n\", state->y));\n\n            // iterate over each row in the strip and stuff data into image\n            for (strip_row = 0; strip_row < min(rows_per_strip, state->ysize - state->y); strip_row++) {\n                TRACE((\"Writing data into line %d ; \\n\", state->y + strip_row));\n\n                // UINT8 * bbb = state->buffer + strip_row * (state->bytes / rows_per_strip);\n                // TRACE((\"chars: %x %x %x %x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                state->shuffle((UINT8*) im->image[state->y + state->yoff + strip_row] +\n                               state->xoff * im->pixelsize,\n                               state->buffer + strip_row * row_byte_size,\n                               state->xsize);\n            }\n        }\n    }\n\n    TIFFClose(tiff);\n    TRACE((\"Done Decoding, Returning \\n\"));\n    // Returning -1 here to force ImageFile.load to break, rather than\n    // even think about looping back around.\n    return -1;\n}", "func_src_after": "int ImagingLibTiffDecode(Imaging im, ImagingCodecState state, UINT8* buffer, Py_ssize_t bytes) {\n    TIFFSTATE *clientstate = (TIFFSTATE *)state->context;\n    char *filename = \"tempfile.tif\";\n    char *mode = \"r\";\n    TIFF *tiff;\n\n    /* buffer is the encoded file, bytes is the length of the encoded file */\n    /*     it all ends up in state->buffer, which is a uint8* from Imaging.h */\n\n    TRACE((\"in decoder: bytes %d\\n\", bytes));\n    TRACE((\"State: count %d, state %d, x %d, y %d, ystep %d\\n\", state->count, state->state,\n           state->x, state->y, state->ystep));\n    TRACE((\"State: xsize %d, ysize %d, xoff %d, yoff %d \\n\", state->xsize, state->ysize,\n           state->xoff, state->yoff));\n    TRACE((\"State: bits %d, bytes %d \\n\", state->bits, state->bytes));\n    TRACE((\"Buffer: %p: %c%c%c%c\\n\", buffer, (char)buffer[0], (char)buffer[1],(char)buffer[2], (char)buffer[3]));\n    TRACE((\"State->Buffer: %c%c%c%c\\n\", (char)state->buffer[0], (char)state->buffer[1],(char)state->buffer[2], (char)state->buffer[3]));\n    TRACE((\"Image: mode %s, type %d, bands: %d, xsize %d, ysize %d \\n\",\n           im->mode, im->type, im->bands, im->xsize, im->ysize));\n    TRACE((\"Image: image8 %p, image32 %p, image %p, block %p \\n\",\n           im->image8, im->image32, im->image, im->block));\n    TRACE((\"Image: pixelsize: %d, linesize %d \\n\",\n           im->pixelsize, im->linesize));\n\n    dump_state(clientstate);\n    clientstate->size = bytes;\n    clientstate->eof = clientstate->size;\n    clientstate->loc = 0;\n    clientstate->data = (tdata_t)buffer;\n    clientstate->flrealloc = 0;\n    dump_state(clientstate);\n\n    TIFFSetWarningHandler(NULL);\n    TIFFSetWarningHandlerExt(NULL);\n\n    if (clientstate->fp) {\n        TRACE((\"Opening using fd: %d\\n\",clientstate->fp));\n        lseek(clientstate->fp,0,SEEK_SET); // Sometimes, I get it set to the end.\n        tiff = TIFFFdOpen(clientstate->fp, filename, mode);\n    } else {\n        TRACE((\"Opening from string\\n\"));\n        tiff = TIFFClientOpen(filename, mode,\n                              (thandle_t) clientstate,\n                              _tiffReadProc, _tiffWriteProc,\n                              _tiffSeekProc, _tiffCloseProc, _tiffSizeProc,\n                              _tiffMapProc, _tiffUnmapProc);\n    }\n\n    if (!tiff){\n        TRACE((\"Error, didn't get the tiff\\n\"));\n        state->errcode = IMAGING_CODEC_BROKEN;\n        return -1;\n    }\n\n    if (clientstate->ifd){\n        int rv;\n        uint32 ifdoffset = clientstate->ifd;\n        TRACE((\"reading tiff ifd %u\\n\", ifdoffset));\n        rv = TIFFSetSubDirectory(tiff, ifdoffset);\n        if (!rv){\n            TRACE((\"error in TIFFSetSubDirectory\"));\n            return -1;\n        }\n    }\n\n    if (TIFFIsTiled(tiff)) {\n        UINT32 x, y, tile_y, row_byte_size;\n        UINT32 tile_width, tile_length, current_tile_width;\n        UINT8 *new_data;\n\n        TIFFGetField(tiff, TIFFTAG_TILEWIDTH, &tile_width);\n        TIFFGetField(tiff, TIFFTAG_TILELENGTH, &tile_length);\n\n        // We could use TIFFTileSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (tile_width * state->bits + 7) / 8;\n\n        /* overflow check for realloc */\n        if (INT_MAX / row_byte_size < tile_length) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n        \n        state->bytes = row_byte_size * tile_length;\n\n        /* realloc to fit whole tile */\n        /* malloc check above */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        TRACE((\"TIFFTileSize: %d\\n\", state->bytes));\n\n        for (y = state->yoff; y < state->ysize; y += tile_length) {\n            for (x = state->xoff; x < state->xsize; x += tile_width) {\n                if (ReadTile(tiff, x, y, (UINT32*) state->buffer) == -1) {\n                    TRACE((\"Decode Error, Tile at %dx%d\\n\", x, y));\n                    state->errcode = IMAGING_CODEC_BROKEN;\n                    TIFFClose(tiff);\n                    return -1;\n                }\n\n                TRACE((\"Read tile at %dx%d; \\n\\n\", x, y));\n\n                current_tile_width = min(tile_width, state->xsize - x);\n\n                // iterate over each line in the tile and stuff data into image\n                for (tile_y = 0; tile_y < min(tile_length, state->ysize - y); tile_y++) {\n                    TRACE((\"Writing tile data at %dx%d using tile_width: %d; \\n\", tile_y + y, x, current_tile_width));\n\n                    // UINT8 * bbb = state->buffer + tile_y * row_byte_size;\n                    // TRACE((\"chars: %x%x%x%x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                    state->shuffle((UINT8*) im->image[tile_y + y] + x * im->pixelsize,\n                       state->buffer + tile_y * row_byte_size,\n                       current_tile_width\n                    );\n                }\n            }\n        }\n    } else {\n        UINT32 strip_row, row_byte_size;\n        UINT8 *new_data;\n        UINT32 rows_per_strip;\n        int ret;\n\n        ret = TIFFGetField(tiff, TIFFTAG_ROWSPERSTRIP, &rows_per_strip);\n        if (ret != 1) {\n            rows_per_strip = state->ysize;\n        }\n        TRACE((\"RowsPerStrip: %u \\n\", rows_per_strip));\n\n        // We could use TIFFStripSize, but for YCbCr data it returns subsampled data size\n        row_byte_size = (state->xsize * state->bits + 7) / 8;\n\n        /* overflow check for realloc */\n        if (INT_MAX / row_byte_size < rows_per_strip) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n        \n        state->bytes = rows_per_strip * row_byte_size;\n\n        TRACE((\"StripSize: %d \\n\", state->bytes));\n\n        /* realloc to fit whole strip */\n        /* malloc check above */\n        new_data = realloc (state->buffer, state->bytes);\n        if (!new_data) {\n            state->errcode = IMAGING_CODEC_MEMORY;\n            TIFFClose(tiff);\n            return -1;\n        }\n\n        state->buffer = new_data;\n\n        for (; state->y < state->ysize; state->y += rows_per_strip) {\n            if (ReadStrip(tiff, state->y, (UINT32 *)state->buffer) == -1) {\n                TRACE((\"Decode Error, strip %d\\n\", TIFFComputeStrip(tiff, state->y, 0)));\n                state->errcode = IMAGING_CODEC_BROKEN;\n                TIFFClose(tiff);\n                return -1;\n            }\n\n            TRACE((\"Decoded strip for row %d \\n\", state->y));\n\n            // iterate over each row in the strip and stuff data into image\n            for (strip_row = 0; strip_row < min(rows_per_strip, state->ysize - state->y); strip_row++) {\n                TRACE((\"Writing data into line %d ; \\n\", state->y + strip_row));\n\n                // UINT8 * bbb = state->buffer + strip_row * (state->bytes / rows_per_strip);\n                // TRACE((\"chars: %x %x %x %x\\n\", ((UINT8 *)bbb)[0], ((UINT8 *)bbb)[1], ((UINT8 *)bbb)[2], ((UINT8 *)bbb)[3]));\n\n                state->shuffle((UINT8*) im->image[state->y + state->yoff + strip_row] +\n                               state->xoff * im->pixelsize,\n                               state->buffer + strip_row * row_byte_size,\n                               state->xsize);\n            }\n        }\n    }\n\n    TIFFClose(tiff);\n    TRACE((\"Done Decoding, Returning \\n\"));\n    // Returning -1 here to force ImageFile.load to break, rather than\n    // even think about looping back around.\n    return -1;\n}", "commit_link": "github.com/python-pillow/Pillow/commit/4e2def2539ec13e53a82e06c4b3daf00454100c4", "file_name": "src/libImaging/TiffDecode.c", "vul_type": "cwe-190", "description": "Write a C function named `ImagingLibTiffDecode` that decodes a TIFF image into an internal imaging structure."}
{"func_name": "rfbHandleAuthResult", "func_src_before": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        ReadReason(client);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "func_src_after": "rfbHandleAuthResult(rfbClient* client)\n{\n    uint32_t authResult=0, reasonLen=0;\n    char *reason=NULL;\n\n    if (!ReadFromRFBServer(client, (char *)&authResult, 4)) return FALSE;\n\n    authResult = rfbClientSwap32IfLE(authResult);\n\n    switch (authResult) {\n    case rfbVncAuthOK:\n      rfbClientLog(\"VNC authentication succeeded\\n\");\n      return TRUE;\n      break;\n    case rfbVncAuthFailed:\n      if (client->major==3 && client->minor>7)\n      {\n        /* we have an error following */\n        if (!ReadFromRFBServer(client, (char *)&reasonLen, 4)) return FALSE;\n        reasonLen = rfbClientSwap32IfLE(reasonLen);\n        reason = malloc((uint64_t)reasonLen+1);\n        if (!ReadFromRFBServer(client, reason, reasonLen)) { free(reason); return FALSE; }\n        reason[reasonLen]=0;\n        rfbClientLog(\"VNC connection failed: %s\\n\",reason);\n        free(reason);\n        return FALSE;\n      }\n      rfbClientLog(\"VNC authentication failed\\n\");\n      return FALSE;\n    case rfbVncAuthTooMany:\n      rfbClientLog(\"VNC authentication failed - too many tries\\n\");\n      return FALSE;\n    }\n\n    rfbClientLog(\"Unknown VNC authentication result: %d\\n\",\n                 (int)authResult);\n    return FALSE;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/e34bcbb759ca5bef85809967a268fdf214c1ad2c", "file_name": "libvncclient/rfbproto.c", "vul_type": "cwe-787", "description": "Write a C function named `rfbHandleAuthResult` that processes VNC authentication results from a server."}
{"func_name": "GetOutboundPinholeTimeout", "func_src_before": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "func_src_after": "GetOutboundPinholeTimeout(struct upnphttp * h, const char * action, const char * ns)\n{\n\tint r;\n\n\tstatic const char resp[] =\n\t\t\"<u:%sResponse \"\n\t\t\"xmlns:u=\\\"%s\\\">\"\n\t\t\"<OutboundPinholeTimeout>%d</OutboundPinholeTimeout>\"\n\t\t\"</u:%sResponse>\";\n\n\tchar body[512];\n\tint bodylen;\n\tstruct NameValueParserData data;\n\tchar * int_ip, * int_port, * rem_host, * rem_port, * protocol;\n\tint opt=0;\n\t/*int proto=0;*/\n\tunsigned short iport, rport;\n\n\tif (GETFLAG(IPV6FCFWDISABLEDMASK))\n\t{\n\t\tSoapError(h, 702, \"FirewallDisabled\");\n\t\treturn;\n\t}\n\n\tParseNameValue(h->req_buf + h->req_contentoff, h->req_contentlen, &data);\n\tint_ip = GetValueFromNameValueList(&data, \"InternalClient\");\n\tint_port = GetValueFromNameValueList(&data, \"InternalPort\");\n\trem_host = GetValueFromNameValueList(&data, \"RemoteHost\");\n\trem_port = GetValueFromNameValueList(&data, \"RemotePort\");\n\tprotocol = GetValueFromNameValueList(&data, \"Protocol\");\n\n\tif (!int_port || !ext_port || !protocol)\n\t{\n\t\tClearNameValueList(&data);\n\t\tSoapError(h, 402, \"Invalid Args\");\n\t\treturn;\n\t}\n\n\trport = (unsigned short)atoi(rem_port);\n\tiport = (unsigned short)atoi(int_port);\n\t/*proto = atoi(protocol);*/\n\n\tsyslog(LOG_INFO, \"%s: retrieving timeout for outbound pinhole from [%s]:%hu to [%s]:%hu protocol %s\", action, int_ip, iport,rem_host, rport, protocol);\n\n\t/* TODO */\n\tr = -1;/*upnp_check_outbound_pinhole(proto, &opt);*/\n\n\tswitch(r)\n\t{\n\t\tcase 1:\t/* success */\n\t\t\tbodylen = snprintf(body, sizeof(body), resp,\n\t\t\t                   action, ns/*\"urn:schemas-upnp-org:service:WANIPv6FirewallControl:1\"*/,\n\t\t\t                   opt, action);\n\t\t\tBuildSendAndCloseSoapResp(h, body, bodylen);\n\t\t\tbreak;\n\t\tcase -5:\t/* Protocol not supported */\n\t\t\tSoapError(h, 705, \"ProtocolNotSupported\");\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tSoapError(h, 501, \"ActionFailed\");\n\t}\n\tClearNameValueList(&data);\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/13585f15c7f7dc28bbbba1661efb280d530d114c", "file_name": "miniupnpd/upnpsoap.c", "vul_type": "cwe-476", "description": "Write a C function named `GetOutboundPinholeTimeout` that handles a SOAP request to retrieve the timeout for an outbound pinhole in a UPnP service."}
{"func_name": "_get_vdisk_fc_mappings", "func_src_before": "    def _get_vdisk_fc_mappings(self, vdisk_name):\n        \"\"\"Return FlashCopy mappings that this vdisk is associated with.\"\"\"\n\n        ssh_cmd = 'svcinfo lsvdiskfcmappings -nohdr %s' % vdisk_name\n        out, err = self._run_ssh(ssh_cmd)\n\n        mapping_ids = []\n        if (len(out.strip())):\n            lines = out.strip().split('\\n')\n            mapping_ids = [line.split()[0] for line in lines]\n        return mapping_ids", "func_src_after": "    def _get_vdisk_fc_mappings(self, vdisk_name):\n        \"\"\"Return FlashCopy mappings that this vdisk is associated with.\"\"\"\n\n        ssh_cmd = ['svcinfo', 'lsvdiskfcmappings', '-nohdr', vdisk_name]\n        out, err = self._run_ssh(ssh_cmd)\n\n        mapping_ids = []\n        if (len(out.strip())):\n            lines = out.strip().split('\\n')\n            mapping_ids = [line.split()[0] for line in lines]\n        return mapping_ids", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to fetch and return the IDs of FlashCopy mappings for a given virtual disk using SSH commands."}
{"func_name": "PHP_MINIT_FUNCTION", "func_src_before": "static PHP_MINIT_FUNCTION(zip)\n{\n#ifdef PHP_ZIP_USE_OO\n\tzend_class_entry ce;\n\n\tmemcpy(&zip_object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\tzip_object_handlers.clone_obj\t\t= NULL;\n\tzip_object_handlers.get_property_ptr_ptr = php_zip_get_property_ptr_ptr;\n\n\tzip_object_handlers.get_gc          = php_zip_get_gc;\n\tzip_object_handlers.get_properties = php_zip_get_properties;\n\tzip_object_handlers.read_property\t= php_zip_read_property;\n\tzip_object_handlers.has_property\t= php_zip_has_property;\n\n\tINIT_CLASS_ENTRY(ce, \"ZipArchive\", zip_class_functions);\n\tce.create_object = php_zip_object_new;\n\tzip_class_entry = zend_register_internal_class(&ce TSRMLS_CC);\n\n\tzend_hash_init(&zip_prop_handlers, 0, NULL, NULL, 1);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"status\",    php_zip_status, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"statusSys\", php_zip_status_sys, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"numFiles\",  php_zip_get_num_files, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"filename\", NULL, NULL, php_zipobj_get_filename, IS_STRING TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"comment\", NULL, php_zipobj_get_zip_comment, NULL, IS_STRING TSRMLS_CC);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CREATE\", ZIP_CREATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"EXCL\", ZIP_EXCL);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CHECKCONS\", ZIP_CHECKCONS);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"OVERWRITE\", ZIP_OVERWRITE);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NOCASE\", ZIP_FL_NOCASE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NODIR\", ZIP_FL_NODIR);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_COMPRESSED\", ZIP_FL_COMPRESSED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_UNCHANGED\", ZIP_FL_UNCHANGED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFAULT\", ZIP_CM_DEFAULT);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_STORE\", ZIP_CM_STORE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_SHRINK\", ZIP_CM_SHRINK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_1\", ZIP_CM_REDUCE_1);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_2\", ZIP_CM_REDUCE_2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_3\", ZIP_CM_REDUCE_3);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_4\", ZIP_CM_REDUCE_4);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_IMPLODE\", ZIP_CM_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE\", ZIP_CM_DEFLATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE64\", ZIP_CM_DEFLATE64);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PKWARE_IMPLODE\", ZIP_CM_PKWARE_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_BZIP2\", ZIP_CM_BZIP2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZMA\", ZIP_CM_LZMA);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_TERSE\", ZIP_CM_TERSE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZ77\", ZIP_CM_LZ77);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_WAVPACK\", ZIP_CM_WAVPACK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PPMD\", ZIP_CM_PPMD);\n\n\t/* Error code */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OK\",\t\t\tZIP_ER_OK);\t\t\t/* N No error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MULTIDISK\",\tZIP_ER_MULTIDISK);\t/* N Multi-disk zip archives not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_RENAME\",\t\tZIP_ER_RENAME);\t\t/* S Renaming temporary file failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CLOSE\",\t\tZIP_ER_CLOSE);\t\t/* S Closing zip archive failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_SEEK\",\t\tZIP_ER_SEEK);\t\t/* S Seek error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_READ\",\t\tZIP_ER_READ);\t\t/* S Read error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_WRITE\",\t\tZIP_ER_WRITE);\t\t/* S Write error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CRC\",\t\t\tZIP_ER_CRC);\t\t/* N CRC error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZIPCLOSED\",\tZIP_ER_ZIPCLOSED);\t/* N Containing zip archive was closed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOENT\",\t\tZIP_ER_NOENT);\t\t/* N No such file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EXISTS\",\t\tZIP_ER_EXISTS);\t\t/* N File already exists */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OPEN\",\t\tZIP_ER_OPEN);\t\t/* S Can't open file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_TMPOPEN\",\t\tZIP_ER_TMPOPEN);\t/* S Failure to create temporary file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZLIB\",\t\tZIP_ER_ZLIB);\t\t/* Z Zlib error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MEMORY\",\t\tZIP_ER_MEMORY);\t\t/* N Malloc failure */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CHANGED\",\t\tZIP_ER_CHANGED);\t/* N Entry has been changed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_COMPNOTSUPP\",\tZIP_ER_COMPNOTSUPP);/* N Compression method not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EOF\",\t\t\tZIP_ER_EOF);\t\t/* N Premature EOF */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INVAL\",\t\tZIP_ER_INVAL);\t\t/* N Invalid argument */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOZIP\",\t\tZIP_ER_NOZIP);\t\t/* N Not a zip archive */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INTERNAL\",\tZIP_ER_INTERNAL);\t/* N Internal error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INCONS\",\t\tZIP_ER_INCONS);\t\t/* N Zip archive inconsistent */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_REMOVE\",\t\tZIP_ER_REMOVE);\t\t/* S Can't remove file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_DELETED\",  \tZIP_ER_DELETED);\t/* N Entry has been deleted */\n\n\tphp_register_url_stream_wrapper(\"zip\", &php_stream_zip_wrapper TSRMLS_CC);\n#endif\n\n\tle_zip_dir   = zend_register_list_destructors_ex(php_zip_free_dir,   NULL, le_zip_dir_name,   module_number);\n\tle_zip_entry = zend_register_list_destructors_ex(php_zip_free_entry, NULL, le_zip_entry_name, module_number);\n\n\treturn SUCCESS;\n}", "func_src_after": "static PHP_MINIT_FUNCTION(zip)\n{\n#ifdef PHP_ZIP_USE_OO\n\tzend_class_entry ce;\n\n\tmemcpy(&zip_object_handlers, zend_get_std_object_handlers(), sizeof(zend_object_handlers));\n\tzip_object_handlers.clone_obj\t\t= NULL;\n\tzip_object_handlers.get_property_ptr_ptr = php_zip_get_property_ptr_ptr;\n\n\tzip_object_handlers.get_gc          = php_zip_get_gc;\n\tzip_object_handlers.get_properties = php_zip_get_properties;\n\tzip_object_handlers.read_property\t= php_zip_read_property;\n\tzip_object_handlers.has_property\t= php_zip_has_property;\n\n\tINIT_CLASS_ENTRY(ce, \"ZipArchive\", zip_class_functions);\n\tce.create_object = php_zip_object_new;\n\tzip_class_entry = zend_register_internal_class(&ce TSRMLS_CC);\n\n\tzend_hash_init(&zip_prop_handlers, 0, NULL, NULL, 1);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"status\",    php_zip_status, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"statusSys\", php_zip_status_sys, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"numFiles\",  php_zip_get_num_files, NULL, NULL, IS_LONG TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"filename\", NULL, NULL, php_zipobj_get_filename, IS_STRING TSRMLS_CC);\n\tphp_zip_register_prop_handler(&zip_prop_handlers, \"comment\", NULL, php_zipobj_get_zip_comment, NULL, IS_STRING TSRMLS_CC);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CREATE\", ZIP_CREATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"EXCL\", ZIP_EXCL);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CHECKCONS\", ZIP_CHECKCONS);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"OVERWRITE\", ZIP_OVERWRITE);\n\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NOCASE\", ZIP_FL_NOCASE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_NODIR\", ZIP_FL_NODIR);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_COMPRESSED\", ZIP_FL_COMPRESSED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"FL_UNCHANGED\", ZIP_FL_UNCHANGED);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFAULT\", ZIP_CM_DEFAULT);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_STORE\", ZIP_CM_STORE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_SHRINK\", ZIP_CM_SHRINK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_1\", ZIP_CM_REDUCE_1);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_2\", ZIP_CM_REDUCE_2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_3\", ZIP_CM_REDUCE_3);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_REDUCE_4\", ZIP_CM_REDUCE_4);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_IMPLODE\", ZIP_CM_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE\", ZIP_CM_DEFLATE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_DEFLATE64\", ZIP_CM_DEFLATE64);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PKWARE_IMPLODE\", ZIP_CM_PKWARE_IMPLODE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_BZIP2\", ZIP_CM_BZIP2);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZMA\", ZIP_CM_LZMA);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_TERSE\", ZIP_CM_TERSE);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_LZ77\", ZIP_CM_LZ77);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_WAVPACK\", ZIP_CM_WAVPACK);\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"CM_PPMD\", ZIP_CM_PPMD);\n\n\t/* Error code */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OK\",\t\t\tZIP_ER_OK);\t\t\t/* N No error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MULTIDISK\",\tZIP_ER_MULTIDISK);\t/* N Multi-disk zip archives not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_RENAME\",\t\tZIP_ER_RENAME);\t\t/* S Renaming temporary file failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CLOSE\",\t\tZIP_ER_CLOSE);\t\t/* S Closing zip archive failed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_SEEK\",\t\tZIP_ER_SEEK);\t\t/* S Seek error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_READ\",\t\tZIP_ER_READ);\t\t/* S Read error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_WRITE\",\t\tZIP_ER_WRITE);\t\t/* S Write error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CRC\",\t\t\tZIP_ER_CRC);\t\t/* N CRC error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZIPCLOSED\",\tZIP_ER_ZIPCLOSED);\t/* N Containing zip archive was closed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOENT\",\t\tZIP_ER_NOENT);\t\t/* N No such file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EXISTS\",\t\tZIP_ER_EXISTS);\t\t/* N File already exists */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_OPEN\",\t\tZIP_ER_OPEN);\t\t/* S Can't open file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_TMPOPEN\",\t\tZIP_ER_TMPOPEN);\t/* S Failure to create temporary file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_ZLIB\",\t\tZIP_ER_ZLIB);\t\t/* Z Zlib error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_MEMORY\",\t\tZIP_ER_MEMORY);\t\t/* N Malloc failure */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_CHANGED\",\t\tZIP_ER_CHANGED);\t/* N Entry has been changed */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_COMPNOTSUPP\",\tZIP_ER_COMPNOTSUPP);/* N Compression method not supported */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_EOF\",\t\t\tZIP_ER_EOF);\t\t/* N Premature EOF */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INVAL\",\t\tZIP_ER_INVAL);\t\t/* N Invalid argument */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_NOZIP\",\t\tZIP_ER_NOZIP);\t\t/* N Not a zip archive */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INTERNAL\",\tZIP_ER_INTERNAL);\t/* N Internal error */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_INCONS\",\t\tZIP_ER_INCONS);\t\t/* N Zip archive inconsistent */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_REMOVE\",\t\tZIP_ER_REMOVE);\t\t/* S Can't remove file */\n\tREGISTER_ZIP_CLASS_CONST_LONG(\"ER_DELETED\",  \tZIP_ER_DELETED);\t/* N Entry has been deleted */\n\n\tphp_register_url_stream_wrapper(\"zip\", &php_stream_zip_wrapper TSRMLS_CC);\n#endif\n\n\tle_zip_dir   = zend_register_list_destructors_ex(php_zip_free_dir,   NULL, le_zip_dir_name,   module_number);\n\tle_zip_entry = zend_register_list_destructors_ex(php_zip_free_entry, NULL, le_zip_entry_name, module_number);\n\n\treturn SUCCESS;\n}", "commit_link": "github.com/php/php-src/commit/f6aef68089221c5ea047d4a74224ee3deead99a6?w=1", "file_name": "ext/zip/php_zip.c", "vul_type": "cwe-416", "description": "Write a PHP function to initialize the Zip extension with object-oriented features and resource destructors."}
{"func_name": "choose_volume", "func_src_before": "choose_volume(struct archive_read *a, struct iso9660 *iso9660)\n{\n\tstruct file_info *file;\n\tint64_t skipsize;\n\tstruct vd *vd;\n\tconst void *block;\n\tchar seenJoliet;\n\n\tvd = &(iso9660->primary);\n\tif (!iso9660->opt_support_joliet)\n\t\tiso9660->seenJoliet = 0;\n\tif (iso9660->seenJoliet &&\n\t\tvd->location > iso9660->joliet.location)\n\t\t/* This condition is unlikely; by way of caution. */\n\t\tvd = &(iso9660->joliet);\n\n\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n\tskipsize = __archive_read_consume(a, skipsize);\n\tif (skipsize < 0)\n\t\treturn ((int)skipsize);\n\tiso9660->current_position = skipsize;\n\n\tblock = __archive_read_ahead(a, vd->size, NULL);\n\tif (block == NULL) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Failed to read full block when scanning \"\n\t\t    \"ISO9660 directory list\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\t/*\n\t * While reading Root Directory, flag seenJoliet must be zero to\n\t * avoid converting special name 0x00(Current Directory) and\n\t * next byte to UCS2.\n\t */\n\tseenJoliet = iso9660->seenJoliet;/* Save flag. */\n\tiso9660->seenJoliet = 0;\n\tfile = parse_file_info(a, NULL, block);\n\tif (file == NULL)\n\t\treturn (ARCHIVE_FATAL);\n\tiso9660->seenJoliet = seenJoliet;\n\n\t/*\n\t * If the iso image has both RockRidge and Joliet, we preferentially\n\t * use RockRidge Extensions rather than Joliet ones.\n\t */\n\tif (vd == &(iso9660->primary) && iso9660->seenRockridge\n\t    && iso9660->seenJoliet)\n\t\tiso9660->seenJoliet = 0;\n\n\tif (vd == &(iso9660->primary) && !iso9660->seenRockridge\n\t    && iso9660->seenJoliet) {\n\t\t/* Switch reading data from primary to joliet. */\n\t\tvd = &(iso9660->joliet);\n\t\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n\t\tskipsize -= iso9660->current_position;\n\t\tskipsize = __archive_read_consume(a, skipsize);\n\t\tif (skipsize < 0)\n\t\t\treturn ((int)skipsize);\n\t\tiso9660->current_position += skipsize;\n\n\t\tblock = __archive_read_ahead(a, vd->size, NULL);\n\t\tif (block == NULL) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Failed to read full block when scanning \"\n\t\t\t    \"ISO9660 directory list\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tiso9660->seenJoliet = 0;\n\t\tfile = parse_file_info(a, NULL, block);\n\t\tif (file == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tiso9660->seenJoliet = seenJoliet;\n\t}\n\n\t/* Store the root directory in the pending list. */\n\tif (add_entry(a, iso9660, file) != ARCHIVE_OK)\n\t\treturn (ARCHIVE_FATAL);\n\tif (iso9660->seenRockridge) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660_ROCKRIDGE;\n\t\ta->archive.archive_format_name =\n\t\t    \"ISO9660 with Rockridge extensions\";\n\t}\n\n\treturn (ARCHIVE_OK);\n}", "func_src_after": "choose_volume(struct archive_read *a, struct iso9660 *iso9660)\n{\n\tstruct file_info *file;\n\tint64_t skipsize;\n\tstruct vd *vd;\n\tconst void *block;\n\tchar seenJoliet;\n\n\tvd = &(iso9660->primary);\n\tif (!iso9660->opt_support_joliet)\n\t\tiso9660->seenJoliet = 0;\n\tif (iso9660->seenJoliet &&\n\t\tvd->location > iso9660->joliet.location)\n\t\t/* This condition is unlikely; by way of caution. */\n\t\tvd = &(iso9660->joliet);\n\n\tskipsize = LOGICAL_BLOCK_SIZE * (int64_t)vd->location;\n\tskipsize = __archive_read_consume(a, skipsize);\n\tif (skipsize < 0)\n\t\treturn ((int)skipsize);\n\tiso9660->current_position = skipsize;\n\n\tblock = __archive_read_ahead(a, vd->size, NULL);\n\tif (block == NULL) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Failed to read full block when scanning \"\n\t\t    \"ISO9660 directory list\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\t/*\n\t * While reading Root Directory, flag seenJoliet must be zero to\n\t * avoid converting special name 0x00(Current Directory) and\n\t * next byte to UCS2.\n\t */\n\tseenJoliet = iso9660->seenJoliet;/* Save flag. */\n\tiso9660->seenJoliet = 0;\n\tfile = parse_file_info(a, NULL, block);\n\tif (file == NULL)\n\t\treturn (ARCHIVE_FATAL);\n\tiso9660->seenJoliet = seenJoliet;\n\n\t/*\n\t * If the iso image has both RockRidge and Joliet, we preferentially\n\t * use RockRidge Extensions rather than Joliet ones.\n\t */\n\tif (vd == &(iso9660->primary) && iso9660->seenRockridge\n\t    && iso9660->seenJoliet)\n\t\tiso9660->seenJoliet = 0;\n\n\tif (vd == &(iso9660->primary) && !iso9660->seenRockridge\n\t    && iso9660->seenJoliet) {\n\t\t/* Switch reading data from primary to joliet. */\n\t\tvd = &(iso9660->joliet);\n\t\tskipsize = LOGICAL_BLOCK_SIZE * (int64_t)vd->location;\n\t\tskipsize -= iso9660->current_position;\n\t\tskipsize = __archive_read_consume(a, skipsize);\n\t\tif (skipsize < 0)\n\t\t\treturn ((int)skipsize);\n\t\tiso9660->current_position += skipsize;\n\n\t\tblock = __archive_read_ahead(a, vd->size, NULL);\n\t\tif (block == NULL) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Failed to read full block when scanning \"\n\t\t\t    \"ISO9660 directory list\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tiso9660->seenJoliet = 0;\n\t\tfile = parse_file_info(a, NULL, block);\n\t\tif (file == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tiso9660->seenJoliet = seenJoliet;\n\t}\n\n\t/* Store the root directory in the pending list. */\n\tif (add_entry(a, iso9660, file) != ARCHIVE_OK)\n\t\treturn (ARCHIVE_FATAL);\n\tif (iso9660->seenRockridge) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660_ROCKRIDGE;\n\t\ta->archive.archive_format_name =\n\t\t    \"ISO9660 with Rockridge extensions\";\n\t}\n\n\treturn (ARCHIVE_OK);\n}", "commit_link": "github.com/libarchive/libarchive/commit/3ad08e01b4d253c66ae56414886089684155af22", "file_name": "libarchive/archive_read_support_format_iso9660.c", "vul_type": "cwe-190", "description": "In C, write a function `choose_volume` that selects the appropriate volume descriptor for an ISO9660 archive and reads the root directory block."}
{"func_name": "action_save_user", "func_src_before": "def action_save_user(request: HttpRequest, default_forward_url: str = \"/admin/users\"):\n    \"\"\"\n    This functions saves the changes to the user or adds a new one. It completely creates the HttpResponse\n    :param request: the HttpRequest\n    :param default_forward_url: The URL to forward to if nothing was specified\n    :return: The crafted HttpResponse\n    \"\"\"\n    forward_url = default_forward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if not request.user.is_authenticated:\n        return HttpResponseForbidden()\n    profile = Profile.objects.get(authuser=request.user)\n    if profile.rights < 2:\n        return HttpResponseForbidden()\n    try:\n        if request.GET.get(\"user_id\"):\n            pid = int(request.GET[\"user_id\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            user: Profile = Profile.objects.get(pk=pid)\n            user.displayName = displayname\n            user.dect = dect\n            user.notes = notes\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            if request.POST.get(\"active\"):\n                user.active = magic.parse_bool(request.POST[\"active\"])\n            au: User = user.authuser\n            if check_password_conformity(pw1, pw2):\n                logging.log(logging.INFO, \"Set password for user: \" + user.displayName)\n                au.set_password(pw1)\n            else:\n                logging.log(logging.INFO, \"Failed to set password for: \" + user.displayName)\n            au.email = mail\n            au.save()\n            user.save()\n        else:\n            # assume new user\n            username = str(request.POST[\"username\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            if not check_password_conformity(pw1, pw2):\n                recreate_form('password mismatch')\n            auth_user: User = User.objects.create_user(username=username, email=mail, password=pw1)\n            auth_user.save()\n            user: Profile = Profile()\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            user.displayName = displayname\n            user.authuser = auth_user\n            user.dect = dect\n            user.notes = notes\n            user.active = True\n            user.save()\n            pass\n        pass\n    except Exception as e:\n        return HttpResponseBadRequest(str(e))\n    return redirect(forward_url)", "func_src_after": "def action_save_user(request: HttpRequest, default_forward_url: str = \"/admin/users\"):\n    \"\"\"\n    This functions saves the changes to the user or adds a new one. It completely creates the HttpResponse\n    :param request: the HttpRequest\n    :param default_forward_url: The URL to forward to if nothing was specified\n    :return: The crafted HttpResponse\n    \"\"\"\n    forward_url = default_forward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    if not request.user.is_authenticated:\n        return HttpResponseForbidden()\n    profile = Profile.objects.get(authuser=request.user)\n    if profile.rights < 2:\n        return HttpResponseForbidden()\n    try:\n        if request.GET.get(\"user_id\"):\n            pid = int(request.GET[\"user_id\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            user: Profile = Profile.objects.get(pk=pid)\n            user.displayName = escape(displayname)\n            user.dect = dect\n            user.notes = escape(notes)\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            if request.POST.get(\"active\"):\n                user.active = magic.parse_bool(request.POST[\"active\"])\n            au: User = user.authuser\n            if check_password_conformity(pw1, pw2):\n                logging.log(logging.INFO, \"Set password for user: \" + user.displayName)\n                au.set_password(pw1)\n            else:\n                logging.log(logging.INFO, \"Failed to set password for: \" + user.displayName)\n            au.email = escape(mail)\n            au.save()\n            user.save()\n        else:\n            # assume new user\n            username = str(request.POST[\"username\"])\n            displayname = str(request.POST[\"display_name\"])\n            dect = int(request.POST[\"dect\"])\n            notes = str(request.POST[\"notes\"])\n            pw1 = str(request.POST[\"password\"])\n            pw2 = str(request.POST[\"confirm_password\"])\n            mail = str(request.POST[\"email\"])\n            rights = int(request.POST[\"rights\"])\n            if not check_password_conformity(pw1, pw2):\n                recreate_form('password mismatch')\n            auth_user: User = User.objects.create_user(username=escape(username), email=escape(mail), password=pw1)\n            auth_user.save()\n            user: Profile = Profile()\n            user.rights = rights\n            user.number_of_allowed_reservations = int(request.POST[\"allowed_reservations\"])\n            user.displayName = escape(displayname)\n            user.authuser = auth_user\n            user.dect = dect\n            user.notes = escape(notes)\n            user.active = True\n            user.save()\n            pass\n        pass\n    except Exception as e:\n        return HttpResponseBadRequest(str(e))\n    return redirect(forward_url)", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/edit_user.py", "vul_type": "cwe-079", "description": "Write a Python function to save or update a user's profile with permissions and redirection handling."}
{"func_name": "PeerListWidget::addPeer", "func_src_before": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), peer.client());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "func_src_after": "QStandardItem* PeerListWidget::addPeer(const QString& ip, BitTorrent::TorrentHandle *const torrent, const BitTorrent::PeerInfo &peer)\n{\n    int row = m_listModel->rowCount();\n    // Adding Peer to peer list\n    m_listModel->insertRow(row);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP), ip, Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PORT), peer.address().port);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::IP_HIDDEN), ip);\n    if (m_resolveCountries) {\n        const QIcon ico = GuiIconProvider::instance()->getFlagIcon(peer.country());\n        if (!ico.isNull()) {\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), ico, Qt::DecorationRole);\n            const QString countryName = Net::GeoIPManager::CountryName(peer.country());\n            m_listModel->setData(m_listModel->index(row, PeerListDelegate::COUNTRY), countryName, Qt::ToolTipRole);\n        }\n        else {\n            m_missingFlags.insert(ip);\n        }\n    }\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CONNECTION), peer.connectionType());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flags());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::FLAGS), peer.flagsDescription(), Qt::ToolTipRole);\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::CLIENT), Utils::String::toHtmlEscaped(peer.client()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::PROGRESS), peer.progress());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWN_SPEED), peer.payloadDownSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::UP_SPEED), peer.payloadUpSpeed());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_DOWN), peer.totalDownload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::TOT_UP), peer.totalUpload());\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::RELEVANCE), peer.relevance());\n    QStringList downloadingFiles(torrent->info().filesForPiece(peer.downloadingPieceIndex()));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\";\")));\n    m_listModel->setData(m_listModel->index(row, PeerListDelegate::DOWNLOADING_PIECE), downloadingFiles.join(QLatin1String(\"\\n\")), Qt::ToolTipRole);\n\n    return m_listModel->item(row, PeerListDelegate::IP);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/gui/properties/peerlistwidget.cpp", "vul_type": "cwe-079", "description": "In C++, write a function to add a peer's details to a list model in a peer list widget."}
{"func_name": "FromkLinuxSockAddr", "func_src_before": "bool FromkLinuxSockAddr(const struct klinux_sockaddr *input,\n                        socklen_t input_len, struct sockaddr *output,\n                        socklen_t *output_len,\n                        void (*abort_handler)(const char *)) {\n  if (!input || !output || !output_len || input_len == 0) {\n    output = nullptr;\n    return false;\n  }\n\n  int16_t klinux_family = input->klinux_sa_family;\n  if (klinux_family == kLinux_AF_UNIX) {\n    struct klinux_sockaddr_un *klinux_sockaddr_un_in =\n        const_cast<struct klinux_sockaddr_un *>(\n            reinterpret_cast<const struct klinux_sockaddr_un *>(input));\n\n    struct sockaddr_un sockaddr_un_out;\n    sockaddr_un_out.sun_family = AF_UNIX;\n    InitializeToZeroArray(sockaddr_un_out.sun_path);\n    ReinterpretCopyArray(\n        sockaddr_un_out.sun_path, klinux_sockaddr_un_in->klinux_sun_path,\n        std::min(sizeof(sockaddr_un_out.sun_path),\n                 sizeof(klinux_sockaddr_un_in->klinux_sun_path)));\n    CopySockaddr(&sockaddr_un_out, sizeof(sockaddr_un_out), output, output_len);\n  } else if (klinux_family == kLinux_AF_INET) {\n    struct klinux_sockaddr_in *klinux_sockaddr_in_in =\n        const_cast<struct klinux_sockaddr_in *>(\n            reinterpret_cast<const struct klinux_sockaddr_in *>(input));\n\n    struct sockaddr_in sockaddr_in_out;\n    sockaddr_in_out.sin_family = AF_INET;\n    sockaddr_in_out.sin_port = klinux_sockaddr_in_in->klinux_sin_port;\n    InitializeToZeroSingle(&sockaddr_in_out.sin_addr);\n    ReinterpretCopySingle(&sockaddr_in_out.sin_addr,\n                          &klinux_sockaddr_in_in->klinux_sin_addr);\n    InitializeToZeroArray(sockaddr_in_out.sin_zero);\n    ReinterpretCopyArray(sockaddr_in_out.sin_zero,\n                         klinux_sockaddr_in_in->klinux_sin_zero);\n    CopySockaddr(&sockaddr_in_out, sizeof(sockaddr_in_out), output, output_len);\n  } else if (klinux_family == kLinux_AF_INET6) {\n    struct klinux_sockaddr_in6 *klinux_sockaddr_in6_in =\n        const_cast<struct klinux_sockaddr_in6 *>(\n            reinterpret_cast<const struct klinux_sockaddr_in6 *>(input));\n\n    struct sockaddr_in6 sockaddr_in6_out;\n    sockaddr_in6_out.sin6_family = AF_INET6;\n    sockaddr_in6_out.sin6_port = klinux_sockaddr_in6_in->klinux_sin6_port;\n    sockaddr_in6_out.sin6_flowinfo =\n        klinux_sockaddr_in6_in->klinux_sin6_flowinfo;\n    sockaddr_in6_out.sin6_scope_id =\n        klinux_sockaddr_in6_in->klinux_sin6_scope_id;\n    InitializeToZeroSingle(&sockaddr_in6_out.sin6_addr);\n    ReinterpretCopySingle(&sockaddr_in6_out.sin6_addr,\n                          &klinux_sockaddr_in6_in->klinux_sin6_addr);\n    CopySockaddr(&sockaddr_in6_out, sizeof(sockaddr_in6_out), output,\n                 output_len);\n  } else if (klinux_family == kLinux_AF_UNSPEC) {\n    output = nullptr;\n    *output_len = 0;\n  } else {\n    if (abort_handler != nullptr) {\n      std::string message = absl::StrCat(\n          \"Type conversion error - Unsupported AF family: \", klinux_family);\n      abort_handler(message.c_str());\n    } else {\n      abort();\n    }\n  }\n  return true;\n}", "func_src_after": "bool FromkLinuxSockAddr(const struct klinux_sockaddr *input,\n                        socklen_t input_len, struct sockaddr *output,\n                        socklen_t *output_len,\n                        void (*abort_handler)(const char *)) {\n  if (!input || !output || !output_len || input_len == 0) {\n    output = nullptr;\n    return false;\n  }\n\n  int16_t klinux_family = input->klinux_sa_family;\n  if (klinux_family == kLinux_AF_UNIX) {\n    if (input_len < sizeof(struct klinux_sockaddr_un)) {\n      return false;\n    }\n\n    struct klinux_sockaddr_un *klinux_sockaddr_un_in =\n        const_cast<struct klinux_sockaddr_un *>(\n            reinterpret_cast<const struct klinux_sockaddr_un *>(input));\n\n    struct sockaddr_un sockaddr_un_out;\n    sockaddr_un_out.sun_family = AF_UNIX;\n    InitializeToZeroArray(sockaddr_un_out.sun_path);\n    ReinterpretCopyArray(\n        sockaddr_un_out.sun_path, klinux_sockaddr_un_in->klinux_sun_path,\n        std::min(sizeof(sockaddr_un_out.sun_path),\n                 sizeof(klinux_sockaddr_un_in->klinux_sun_path)));\n    CopySockaddr(&sockaddr_un_out, sizeof(sockaddr_un_out), output, output_len);\n  } else if (klinux_family == kLinux_AF_INET) {\n    if (input_len < sizeof(struct klinux_sockaddr_in)) {\n      return false;\n    }\n    struct klinux_sockaddr_in *klinux_sockaddr_in_in =\n        const_cast<struct klinux_sockaddr_in *>(\n            reinterpret_cast<const struct klinux_sockaddr_in *>(input));\n\n    struct sockaddr_in sockaddr_in_out;\n    sockaddr_in_out.sin_family = AF_INET;\n    sockaddr_in_out.sin_port = klinux_sockaddr_in_in->klinux_sin_port;\n    InitializeToZeroSingle(&sockaddr_in_out.sin_addr);\n    ReinterpretCopySingle(&sockaddr_in_out.sin_addr,\n                          &klinux_sockaddr_in_in->klinux_sin_addr);\n    InitializeToZeroArray(sockaddr_in_out.sin_zero);\n    ReinterpretCopyArray(sockaddr_in_out.sin_zero,\n                         klinux_sockaddr_in_in->klinux_sin_zero);\n    CopySockaddr(&sockaddr_in_out, sizeof(sockaddr_in_out), output, output_len);\n  } else if (klinux_family == kLinux_AF_INET6) {\n    if (input_len < sizeof(struct klinux_sockaddr_in6)) {\n      return false;\n    }\n\n    struct klinux_sockaddr_in6 *klinux_sockaddr_in6_in =\n        const_cast<struct klinux_sockaddr_in6 *>(\n            reinterpret_cast<const struct klinux_sockaddr_in6 *>(input));\n\n    struct sockaddr_in6 sockaddr_in6_out;\n    sockaddr_in6_out.sin6_family = AF_INET6;\n    sockaddr_in6_out.sin6_port = klinux_sockaddr_in6_in->klinux_sin6_port;\n    sockaddr_in6_out.sin6_flowinfo =\n        klinux_sockaddr_in6_in->klinux_sin6_flowinfo;\n    sockaddr_in6_out.sin6_scope_id =\n        klinux_sockaddr_in6_in->klinux_sin6_scope_id;\n    InitializeToZeroSingle(&sockaddr_in6_out.sin6_addr);\n    ReinterpretCopySingle(&sockaddr_in6_out.sin6_addr,\n                          &klinux_sockaddr_in6_in->klinux_sin6_addr);\n    CopySockaddr(&sockaddr_in6_out, sizeof(sockaddr_in6_out), output,\n                 output_len);\n  } else if (klinux_family == kLinux_AF_UNSPEC) {\n    output = nullptr;\n    *output_len = 0;\n  } else {\n    if (abort_handler != nullptr) {\n      std::string message = absl::StrCat(\n          \"Type conversion error - Unsupported AF family: \", klinux_family);\n      abort_handler(message.c_str());\n    } else {\n      abort();\n    }\n  }\n  return true;\n}", "commit_link": "github.com/google/asylo/commit/bda9772e7872b0d2b9bee32930cf7a4983837b39", "file_name": "asylo/platform/system_call/type_conversions/manual_types_functions.cc", "vul_type": "cwe-787", "description": "Write a C++ function to convert a Linux-specific socket address structure to a generic socket address structure, handling different address families and providing an abort callback for errors."}
{"func_name": "flb_gzip_compress", "func_src_before": "int flb_gzip_compress(void *in_data, size_t in_len,\n                      void **out_data, size_t *out_len)\n{\n    int flush;\n    int status;\n    int footer_start;\n    uint8_t *pb;\n    size_t out_size;\n    void *out_buf;\n    z_stream strm;\n    mz_ulong crc;\n\n    out_size = in_len + 32;\n    out_buf = flb_malloc(out_size);\n    if (!out_buf) {\n        flb_errno();\n        flb_error(\"[gzip] could not allocate outgoing buffer\");\n        return -1;\n    }\n\n    /* Initialize streaming buffer context */\n    memset(&strm, '\\0', sizeof(strm));\n    strm.zalloc    = Z_NULL;\n    strm.zfree     = Z_NULL;\n    strm.opaque    = Z_NULL;\n    strm.next_in   = in_data;\n    strm.avail_in  = in_len;\n    strm.total_out = 0;\n\n    /* Deflate mode */\n    deflateInit2(&strm, Z_DEFAULT_COMPRESSION,\n                 Z_DEFLATED, -Z_DEFAULT_WINDOW_BITS, 9, Z_DEFAULT_STRATEGY);\n\n    /*\n     * Miniz don't support GZip format directly, instead we will:\n     *\n     * - append manual GZip magic bytes\n     * - deflate raw content\n     * - append manual CRC32 data\n     */\n    gzip_header(out_buf);\n\n    /* Header offset */\n    pb = (uint8_t *) out_buf + FLB_GZIP_HEADER_OFFSET;\n\n    flush = Z_NO_FLUSH;\n    while (1) {\n        strm.next_out  = pb + strm.total_out;\n        strm.avail_out = out_size - (pb - (uint8_t *) out_buf);\n\n        if (strm.avail_in == 0) {\n            flush = Z_FINISH;\n        }\n\n        status = deflate(&strm, flush);\n        if (status == Z_STREAM_END) {\n            break;\n        }\n        else if (status != Z_OK) {\n            deflateEnd(&strm);\n            return -1;\n        }\n    }\n\n    if (deflateEnd(&strm) != Z_OK) {\n        flb_free(out_buf);\n        return -1;\n    }\n    *out_len = strm.total_out;\n\n    /* Construct the gzip checksum (CRC32 footer) */\n    footer_start = FLB_GZIP_HEADER_OFFSET + *out_len;\n    pb = (uint8_t *) out_buf + footer_start;\n\n    crc = mz_crc32(MZ_CRC32_INIT, in_data, in_len);\n    *pb++ = crc & 0xFF;\n    *pb++ = (crc >> 8) & 0xFF;\n    *pb++ = (crc >> 16) & 0xFF;\n    *pb++ = (crc >> 24) & 0xFF;\n    *pb++ = in_len & 0xFF;\n    *pb++ = (in_len >> 8) & 0xFF;\n    *pb++ = (in_len >> 16) & 0xFF;\n    *pb++ = (in_len >> 24) & 0xFF;\n\n    /* Set the real buffer size for the caller */\n    *out_len += FLB_GZIP_HEADER_OFFSET + 8;\n    *out_data = out_buf;\n\n    return 0;\n}", "func_src_after": "int flb_gzip_compress(void *in_data, size_t in_len,\n                      void **out_data, size_t *out_len)\n{\n    int flush;\n    int status;\n    int footer_start;\n    uint8_t *pb;\n    size_t out_size;\n    void *out_buf;\n    z_stream strm;\n    mz_ulong crc;\n\n\n    /*\n     * GZIP relies on an algorithm with worst-case expansion\n     * of 5 bytes per 32KB data. This means we need to create a variable\n     * length output, that depends on the input length.\n     * See RFC 1951 for details.\n     */\n    int max_input_expansion = ((int)(in_len / 32000) + 1) * 5;\n\n    /*\n     * Max compressed size is equal to sum of:\n     *   10 byte header\n     *   8 byte foot\n     *   max input expansion\n     *   size of input\n     */\n    out_size = 10 + 8 + max_input_expansion + in_len;\n    out_buf = flb_malloc(out_size);\n\n    if (!out_buf) {\n        flb_errno();\n        flb_error(\"[gzip] could not allocate outgoing buffer\");\n        return -1;\n    }\n\n    /* Initialize streaming buffer context */\n    memset(&strm, '\\0', sizeof(strm));\n    strm.zalloc    = Z_NULL;\n    strm.zfree     = Z_NULL;\n    strm.opaque    = Z_NULL;\n    strm.next_in   = in_data;\n    strm.avail_in  = in_len;\n    strm.total_out = 0;\n\n    /* Deflate mode */\n    deflateInit2(&strm, Z_DEFAULT_COMPRESSION,\n                 Z_DEFLATED, -Z_DEFAULT_WINDOW_BITS, 9, Z_DEFAULT_STRATEGY);\n\n    /*\n     * Miniz don't support GZip format directly, instead we will:\n     *\n     * - append manual GZip magic bytes\n     * - deflate raw content\n     * - append manual CRC32 data\n     */\n    gzip_header(out_buf);\n\n    /* Header offset */\n    pb = (uint8_t *) out_buf + FLB_GZIP_HEADER_OFFSET;\n\n    flush = Z_NO_FLUSH;\n    while (1) {\n        strm.next_out  = pb + strm.total_out;\n        strm.avail_out = out_size - (pb - (uint8_t *) out_buf);\n\n        if (strm.avail_in == 0) {\n            flush = Z_FINISH;\n        }\n\n        status = deflate(&strm, flush);\n        if (status == Z_STREAM_END) {\n            break;\n        }\n        else if (status != Z_OK) {\n            deflateEnd(&strm);\n            return -1;\n        }\n    }\n\n    if (deflateEnd(&strm) != Z_OK) {\n        flb_free(out_buf);\n        return -1;\n    }\n    *out_len = strm.total_out;\n\n    /* Construct the gzip checksum (CRC32 footer) */\n    footer_start = FLB_GZIP_HEADER_OFFSET + *out_len;\n    pb = (uint8_t *) out_buf + footer_start;\n\n    crc = mz_crc32(MZ_CRC32_INIT, in_data, in_len);\n    *pb++ = crc & 0xFF;\n    *pb++ = (crc >> 8) & 0xFF;\n    *pb++ = (crc >> 16) & 0xFF;\n    *pb++ = (crc >> 24) & 0xFF;\n    *pb++ = in_len & 0xFF;\n    *pb++ = (in_len >> 8) & 0xFF;\n    *pb++ = (in_len >> 16) & 0xFF;\n    *pb++ = (in_len >> 24) & 0xFF;\n\n    /* Set the real buffer size for the caller */\n    *out_len += FLB_GZIP_HEADER_OFFSET + 8;\n    *out_data = out_buf;\n\n    return 0;\n}", "commit_link": "github.com/fluent/fluent-bit/commit/cadff53c093210404aed01c4cf586adb8caa07af", "file_name": "src/flb_gzip.c", "vul_type": "cwe-787", "description": "Write a C function to compress data using GZIP and handle memory allocation for the output buffer."}
{"func_name": "canonicalize", "func_src_before": "    def canonicalize(self):\n        \"\"\"::\n\n            path = path.canonicalize()\n\n        Canonicalize path. ::\n\n            # \"/foo/baz\"\n            Pyjo.Path.new('/foo/./bar/../baz').canonicalize()\n\n            # \"/../baz\"\n            Pyjo.Path.new('/foo/../bar/../../baz').canonicalize()\n        \"\"\"\n        parts = self.parts\n        i = 0\n        while i < len(parts):\n            if parts[i] == '.' or parts[i] == '':\n                parts.pop(i)\n            elif i < 1 or parts[i] != '..' or parts[i - 1] == '..':\n                i += 1\n            else:\n                i -= 1\n                parts.pop(i)\n                parts.pop(i)\n\n        if not parts:\n            self.trailing_slash = False\n\n        return self", "func_src_after": "    def canonicalize(self):\n        \"\"\"::\n\n            path = path.canonicalize()\n\n        Canonicalize path by resolving ``.`` and ``..``, in addition ``...`` will be\n        treated as ``.`` to protect from path traversal attacks.\n\n            # \"/foo/baz\"\n            Pyjo.Path.new('/foo/./bar/../baz').canonicalize()\n\n            # \"/../baz\"\n            Pyjo.Path.new('/foo/../bar/../../baz').canonicalize()\n\n            # \"/foo/bar\"\n            Pyjo.Path.new('/foo/.../bar').canonicalize()\n        \"\"\"\n        parts = self.parts\n        i = 0\n        while i < len(parts):\n            if parts[i] == '' or parts[i] == '.' or parts[i] == '...':\n                parts.pop(i)\n            elif i < 1 or parts[i] != '..' or parts[i - 1] == '..':\n                i += 1\n            else:\n                i -= 1\n                parts.pop(i)\n                parts.pop(i)\n\n        if not parts:\n            self.trailing_slash = False\n\n        return self", "commit_link": "github.com/dex4er/Pyjoyment/commit/e4b115bc80c41615b2133091af3a74ee5d995c2e", "file_name": "Pyjo/Path.py", "vul_type": "cwe-022", "description": "Write a Python function named `canonicalize` that simplifies file paths by resolving \".\", \"..\", and optionally \"...\" in a path object."}
{"func_name": "_inject_admin_password_into_fs", "func_src_before": "def _inject_admin_password_into_fs(admin_passwd, fs, execute=None):\n    \"\"\"Set the root password to admin_passwd\n\n    admin_password is a root password\n    fs is the path to the base of the filesystem into which to inject\n    the key.\n\n    This method modifies the instance filesystem directly,\n    and does not require a guest agent running in the instance.\n\n    \"\"\"\n    # The approach used here is to copy the password and shadow\n    # files from the instance filesystem to local files, make any\n    # necessary changes, and then copy them back.\n\n    admin_user = 'root'\n\n    fd, tmp_passwd = tempfile.mkstemp()\n    os.close(fd)\n    fd, tmp_shadow = tempfile.mkstemp()\n    os.close(fd)\n\n    passwd_path = _join_and_check_path_within_fs(fs, 'etc', 'passwd')\n    shadow_path = _join_and_check_path_within_fs(fs, 'etc', 'shadow')\n\n    utils.execute('cp', passwd_path, tmp_passwd, run_as_root=True)\n    utils.execute('cp', shadow_path, tmp_shadow, run_as_root=True)\n    _set_passwd(admin_user, admin_passwd, tmp_passwd, tmp_shadow)\n    utils.execute('cp', tmp_passwd, passwd_path, run_as_root=True)\n    os.unlink(tmp_passwd)\n    utils.execute('cp', tmp_shadow, shadow_path, run_as_root=True)\n    os.unlink(tmp_shadow)", "func_src_after": "def _inject_admin_password_into_fs(admin_passwd, fs, execute=None):\n    \"\"\"Set the root password to admin_passwd\n\n    admin_password is a root password\n    fs is the path to the base of the filesystem into which to inject\n    the key.\n\n    This method modifies the instance filesystem directly,\n    and does not require a guest agent running in the instance.\n\n    \"\"\"\n    # The approach used here is to copy the password and shadow\n    # files from the instance filesystem to local files, make any\n    # necessary changes, and then copy them back.\n\n    admin_user = 'root'\n\n    fd, tmp_passwd = tempfile.mkstemp()\n    os.close(fd)\n    fd, tmp_shadow = tempfile.mkstemp()\n    os.close(fd)\n\n    utils.execute('cp', os.path.join(fs, 'etc', 'passwd'), tmp_passwd,\n                  run_as_root=True)\n    utils.execute('cp', os.path.join(fs, 'etc', 'shadow'), tmp_shadow,\n                  run_as_root=True)\n    _set_passwd(admin_user, admin_passwd, tmp_passwd, tmp_shadow)\n    utils.execute('cp', tmp_passwd, os.path.join(fs, 'etc', 'passwd'),\n                  run_as_root=True)\n    os.unlink(tmp_passwd)\n    utils.execute('cp', tmp_shadow, os.path.join(fs, 'etc', 'shadow'),\n                  run_as_root=True)\n    os.unlink(tmp_shadow)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Provide a Python function to set the root password on a filesystem without using a guest agent."}
{"func_name": "karma_add", "func_src_before": "def karma_add(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES('{}',1,0)\n                '''.format(name))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 karma for {}'.format(name))\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = {0} WHERE name = '{1}'\n                '''.format(karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} karma for {}'.format(\n                karma, name))\n            return karma\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    db.close()", "func_src_after": "def karma_add(name):\n    karma = karma_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if karma is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES(%(name)s,1,0)\n                ''', name)\n            db.commit()\n            logger.debug('Inserted into karmadb 1 karma for {}'.format(name))\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    else:\n        karma = karma + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET karma = %(karma)s WHERE name = %(name)s\n                ''', (karma, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} karma for {}'.format(\n                karma,\n                name,\n            ))\n            return karma\n\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n    db.close()", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to increment a user's karma in a database, handling both new and existing users."}
{"func_name": "java_switch_op", "func_src_before": "static int java_switch_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_byte = data[0];\n\tut64 offset = addr - java_get_method_start ();\n\tut8 pos = (offset+1)%4 ? 1 + 4 - (offset+1)%4 : 1;\n\n\tif (op_byte == 0xaa) {\n\t\t// handle a table switch condition\n\t\tif (pos + 8 > len) {\n\t\t\treturn op->size;\n\t\t}\n\t\tint min_val = (ut32)(UINT (data, pos + 4)),\n\t\t\tmax_val = (ut32)(UINT (data, pos + 8));\n\n\t\tut32 default_loc = (ut32) (UINT (data, pos)), cur_case = 0;\n\t\top->switch_op = r_anal_switch_op_new (addr, min_val, default_loc);\n\t\tRAnalCaseOp *caseop = NULL;\n\t\tpos += 12;\n\t\tif (max_val > min_val && ((max_val - min_val)<(UT16_MAX/4))) {\n\t\t\t//caseop = r_anal_switch_op_add_case(op->switch_op, addr+default_loc, -1, addr+offset);\n\t\t\tfor (cur_case = 0; cur_case <= max_val - min_val; pos += 4, cur_case++) {\n\t\t\t\t//ut32 value = (ut32)(UINT (data, pos));\n\t\t\t\tif (pos + 4 >= len) {\n\t\t\t\t\t// switch is too big cant read further\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tint offset = (int)(ut32)(R_BIN_JAVA_UINT (data, pos));\n\t\t\t\tcaseop = r_anal_switch_op_add_case (op->switch_op,\n\t\t\t\t\taddr + pos, cur_case + min_val, addr + offset);\n\t\t\t\tif (caseop) {\n\t\t\t\t\tcaseop->bb_ref_to = addr+offset;\n\t\t\t\t\tcaseop->bb_ref_from = addr; // TODO figure this one out\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Invalid switch boundaries at 0x%\"PFMT64x\"\\n\", addr);\n\t\t}\n\t}\n\top->size = pos;\n\treturn op->size;\n}", "func_src_after": "static int java_switch_op(RAnal *anal, RAnalOp *op, ut64 addr, const ut8 *data, int len) {\n\tut8 op_byte = data[0];\n\tut64 offset = addr - java_get_method_start ();\n\tut8 pos = (offset+1)%4 ? 1 + 4 - (offset+1)%4 : 1;\n\n\tif (op_byte == 0xaa) {\n\t\t// handle a table switch condition\n\t\tif (pos + 8 + 8 > len) {\n\t\t\treturn op->size;\n\t\t}\n\t\tconst int min_val = (ut32)(UINT (data, pos + 4));\n\t\tconst int max_val = (ut32)(UINT (data, pos + 8));\n\n\t\tut32 default_loc = (ut32) (UINT (data, pos)), cur_case = 0;\n\t\top->switch_op = r_anal_switch_op_new (addr, min_val, default_loc);\n\t\tRAnalCaseOp *caseop = NULL;\n\t\tpos += 12;\n\t\tif (max_val > min_val && ((max_val - min_val)<(UT16_MAX/4))) {\n\t\t\t//caseop = r_anal_switch_op_add_case(op->switch_op, addr+default_loc, -1, addr+offset);\n\t\t\tfor (cur_case = 0; cur_case <= max_val - min_val; pos += 4, cur_case++) {\n\t\t\t\t//ut32 value = (ut32)(UINT (data, pos));\n\t\t\t\tif (pos + 4 >= len) {\n\t\t\t\t\t// switch is too big cant read further\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tint offset = (int)(ut32)(R_BIN_JAVA_UINT (data, pos));\n\t\t\t\tcaseop = r_anal_switch_op_add_case (op->switch_op,\n\t\t\t\t\taddr + pos, cur_case + min_val, addr + offset);\n\t\t\t\tif (caseop) {\n\t\t\t\t\tcaseop->bb_ref_to = addr+offset;\n\t\t\t\t\tcaseop->bb_ref_from = addr; // TODO figure this one out\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\teprintf (\"Invalid switch boundaries at 0x%\"PFMT64x\"\\n\", addr);\n\t\t}\n\t}\n\top->size = pos;\n\treturn op->size;\n}", "commit_link": "github.com/radare/radare2/commit/224e6bc13fa353dd3b7f7a2334588f1c4229e58d", "file_name": "libr/anal/p/anal_java.c", "vul_type": "cwe-125", "description": "Write a Java function to parse a table switch bytecode operation and handle its cases."}
{"func_name": "shame_add", "func_src_before": "def shame_add(name):\n    shame = shame_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if shame is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES(%(name)s,0,1)\n                ''', (name, ))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 shame for {}'.format(name))\n            db.close()\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n\n    else:\n        shame = shame + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET shame = %(karma)s WHERE name = %(name)s\n                ''' (\n                shame,\n                name,\n            ))\n            db.commit()\n            logger.debug('Inserted into karmadb {} shame for {}'.format(\n                shame, name))\n            db.close()\n            return shame\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "func_src_after": "def shame_add(name):\n    shame = shame_ask(name)\n    db = db_connect()\n    cursor = db.cursor()\n    if shame is None:\n        try:\n            cursor.execute('''\n                INSERT INTO people(name,karma,shame) VALUES('{}',0,1)\n                '''.format(name))\n            db.commit()\n            logger.debug('Inserted into karmadb 1 shame for {}'.format(name))\n            db.close()\n            return 1\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise\n\n    else:\n        shame = shame + 1\n        try:\n            cursor.execute('''\n                UPDATE people SET shame = {0} WHERE name = '{1}'\n                '''.format(shame, name))\n            db.commit()\n            logger.debug('Inserted into karmadb {} shame for {}'.format(\n                shame, name))\n            db.close()\n            return shame\n        except Exception as e:\n            logger.error('Execution failed with error: {}'.format(e))\n            raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to increment a user's shame count in a database, inserting a new record if the user doesn't exist."}
{"func_name": "PHP_FUNCTION", "func_src_before": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tzval *retval;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tretval = var_tmp_var(&var_hash);\n\tif (!php_var_unserialize_ex(retval, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\n\tZVAL_COPY(return_value, retval);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "func_src_after": "PHP_FUNCTION(unserialize)\n{\n\tchar *buf = NULL;\n\tsize_t buf_len;\n\tconst unsigned char *p;\n\tphp_unserialize_data_t var_hash;\n\tzval *options = NULL, *classes = NULL;\n\tHashTable *class_hash = NULL;\n\n\tif (zend_parse_parameters(ZEND_NUM_ARGS(), \"s|a\", &buf, &buf_len, &options) == FAILURE) {\n\t\tRETURN_FALSE;\n\t}\n\n\tif (buf_len == 0) {\n\t\tRETURN_FALSE;\n\t}\n\n\tp = (const unsigned char*) buf;\n\tPHP_VAR_UNSERIALIZE_INIT(var_hash);\n\tif(options != NULL) {\n\t\tclasses = zend_hash_str_find(Z_ARRVAL_P(options), \"allowed_classes\", sizeof(\"allowed_classes\")-1);\n\t\tif(classes && (Z_TYPE_P(classes) == IS_ARRAY || !zend_is_true(classes))) {\n\t\t\tALLOC_HASHTABLE(class_hash);\n\t\t\tzend_hash_init(class_hash, (Z_TYPE_P(classes) == IS_ARRAY)?zend_hash_num_elements(Z_ARRVAL_P(classes)):0, NULL, NULL, 0);\n\t\t}\n\t\tif(class_hash && Z_TYPE_P(classes) == IS_ARRAY) {\n\t\t\tzval *entry;\n\t\t\tzend_string *lcname;\n\n\t\t\tZEND_HASH_FOREACH_VAL(Z_ARRVAL_P(classes), entry) {\n\t\t\t\tconvert_to_string_ex(entry);\n\t\t\t\tlcname = zend_string_tolower(Z_STR_P(entry));\n\t\t\t\tzend_hash_add_empty_element(class_hash, lcname);\n\t\t        zend_string_release(lcname);\n\t\t\t} ZEND_HASH_FOREACH_END();\n\t\t}\n\t}\n\n\tif (!php_var_unserialize_ex(return_value, &p, p + buf_len, &var_hash, class_hash)) {\n\t\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\t\tif (class_hash) {\n\t\t\tzend_hash_destroy(class_hash);\n\t\t\tFREE_HASHTABLE(class_hash);\n\t\t}\n\t\tzval_ptr_dtor(return_value);\n\t\tif (!EG(exception)) {\n\t\t\tphp_error_docref(NULL, E_NOTICE, \"Error at offset \" ZEND_LONG_FMT \" of %zd bytes\",\n\t\t\t\t(zend_long)((char*)p - buf), buf_len);\n\t\t}\n\t\tRETURN_FALSE;\n\t}\n\t/* We should keep an reference to return_value to prevent it from being dtor\n\t   in case nesting calls to unserialize */\n\tvar_push_dtor(&var_hash, return_value);\n\n\tPHP_VAR_UNSERIALIZE_DESTROY(var_hash);\n\tif (class_hash) {\n\t\tzend_hash_destroy(class_hash);\n\t\tFREE_HASHTABLE(class_hash);\n\t}\n}", "commit_link": "github.com/php/php-src/commit/b2af4e8868726a040234de113436c6e4f6372d17", "file_name": "ext/standard/var.c", "vul_type": "cwe-416", "description": "Write a PHP function to unserialize data with an optional parameter for allowed classes."}
{"func_name": "verify_rno", "func_src_before": "    def verify_rno(self, rno):\n        self.cursor.execute(\"SELECT COUNT(rno) FROM rides WHERE rno = :rno\", {'rno': rno})\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "func_src_after": "    def verify_rno(self, rno):\n        query = \"SELECT COUNT(rno) FROM rides WHERE rno = {rno}\".format(rno = rno)\n        self.cursor.execute(query)\n        result = self.cursor.fetchone()\n        if (int(result[0]) > 0):\n            return True \n        else:\n            return False", "commit_link": "github.com/kenboo98/291-Mini-Project-I/commit/3080ccb687c79c83954ce703faee8fcceec8c9eb", "file_name": "book_rides/book_rides.py", "vul_type": "cwe-089", "description": "Write a Python function to check if a ride number exists in a database using SQL queries."}
{"func_name": "handle_method_call", "func_src_before": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "func_src_after": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!allowed_problem_dir(problem_id))\n        {\n            return_InvalidProblemDir_error(invocation, problem_id);\n            return;\n        }\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!allowed_problem_dir(problem_id))\n        {\n            return_InvalidProblemDir_error(invocation, problem_id);\n            return;\n        }\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name\", element);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "commit_link": "github.com/abrt/abrt/commit/7a47f57975be0d285a2f20758e4572dca6d9cdd3", "file_name": "src/dbus/abrt-dbus.c", "vul_type": "cwe-022", "description": "Write a C function to handle various method calls for problem management over D-Bus."}
{"func_name": "get_articles_by_subject", "func_src_before": "def get_articles_by_subject(subject):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE subject='\" + subject + \"' ORDER BY last_submitted DESC\"\n        cur.execute(query)\n        articles = cur.fetchall()\n        return articles", "func_src_after": "def get_articles_by_subject(subject):\n    with conn.cursor(cursor_factory=DictCursor) as cur:\n        query = \"SELECT * FROM articles WHERE subject=%s ORDER BY last_submitted DESC\"\n        cur.execute(query, (subject,))\n        articles = cur.fetchall()\n        return articles", "commit_link": "github.com/sepehr125/arxiv-doc2vec-recommender/commit/f23a4c32e6192b145017f64734b0a9a384c9123a", "file_name": "app.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch all articles with a specific subject from a database, sorted by the last submitted date."}
{"func_name": "opj_j2k_set_cinema_parameters", "func_src_before": "static void opj_j2k_set_cinema_parameters(opj_cparameters_t *parameters,\n        opj_image_t *image, opj_event_mgr_t *p_manager)\n{\n    /* Configure cinema parameters */\n    int i;\n\n    /* No tiling */\n    parameters->tile_size_on = OPJ_FALSE;\n    parameters->cp_tdx = 1;\n    parameters->cp_tdy = 1;\n\n    /* One tile part for each component */\n    parameters->tp_flag = 'C';\n    parameters->tp_on = 1;\n\n    /* Tile and Image shall be at (0,0) */\n    parameters->cp_tx0 = 0;\n    parameters->cp_ty0 = 0;\n    parameters->image_offset_x0 = 0;\n    parameters->image_offset_y0 = 0;\n\n    /* Codeblock size= 32*32 */\n    parameters->cblockw_init = 32;\n    parameters->cblockh_init = 32;\n\n    /* Codeblock style: no mode switch enabled */\n    parameters->mode = 0;\n\n    /* No ROI */\n    parameters->roi_compno = -1;\n\n    /* No subsampling */\n    parameters->subsampling_dx = 1;\n    parameters->subsampling_dy = 1;\n\n    /* 9-7 transform */\n    parameters->irreversible = 1;\n\n    /* Number of layers */\n    if (parameters->tcp_numlayers > 1) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"1 single quality layer\"\n                      \"-> Number of layers forced to 1 (rather than %d)\\n\"\n                      \"-> Rate of the last layer (%3.1f) will be used\",\n                      parameters->tcp_numlayers,\n                      parameters->tcp_rates[parameters->tcp_numlayers - 1]);\n        parameters->tcp_rates[0] = parameters->tcp_rates[parameters->tcp_numlayers - 1];\n        parameters->tcp_numlayers = 1;\n    }\n\n    /* Resolution levels */\n    switch (parameters->rsiz) {\n    case OPJ_PROFILE_CINEMA_2K:\n        if (parameters->numresolution > 6) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-3 (2k dc profile) requires:\\n\"\n                          \"Number of decomposition levels <= 5\\n\"\n                          \"-> Number of decomposition levels forced to 5 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 6;\n        }\n        break;\n    case OPJ_PROFILE_CINEMA_4K:\n        if (parameters->numresolution < 2) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 1 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 1;\n        } else if (parameters->numresolution > 7) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 6 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 7;\n        }\n        break;\n    default :\n        break;\n    }\n\n    /* Precincts */\n    parameters->csty |= 0x01;\n    parameters->res_spec = parameters->numresolution - 1;\n    for (i = 0; i < parameters->res_spec; i++) {\n        parameters->prcw_init[i] = 256;\n        parameters->prch_init[i] = 256;\n    }\n\n    /* The progression order shall be CPRL */\n    parameters->prog_order = OPJ_CPRL;\n\n    /* Progression order changes for 4K, disallowed for 2K */\n    if (parameters->rsiz == OPJ_PROFILE_CINEMA_4K) {\n        parameters->numpocs = (OPJ_UINT32)opj_j2k_initialise_4K_poc(parameters->POC,\n                              parameters->numresolution);\n    } else {\n        parameters->numpocs = 0;\n    }\n\n    /* Limited bit-rate */\n    parameters->cp_disto_alloc = 1;\n    if (parameters->max_cs_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_cs_size > OPJ_CINEMA_24_CS) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1302083 bytes.\\n\");\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n    }\n\n    if (parameters->max_comp_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_comp_size > OPJ_CINEMA_24_COMP) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1041666 bytes.\\n\");\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n    }\n\n    parameters->tcp_rates[0] = (OPJ_FLOAT32)(image->numcomps * image->comps[0].w *\n                               image->comps[0].h * image->comps[0].prec) /\n                               (OPJ_FLOAT32)(((OPJ_UINT32)parameters->max_cs_size) * 8 * image->comps[0].dx *\n                                       image->comps[0].dy);\n\n}", "func_src_after": "static void opj_j2k_set_cinema_parameters(opj_cparameters_t *parameters,\n        opj_image_t *image, opj_event_mgr_t *p_manager)\n{\n    /* Configure cinema parameters */\n    int i;\n\n    /* No tiling */\n    parameters->tile_size_on = OPJ_FALSE;\n    parameters->cp_tdx = 1;\n    parameters->cp_tdy = 1;\n\n    /* One tile part for each component */\n    parameters->tp_flag = 'C';\n    parameters->tp_on = 1;\n\n    /* Tile and Image shall be at (0,0) */\n    parameters->cp_tx0 = 0;\n    parameters->cp_ty0 = 0;\n    parameters->image_offset_x0 = 0;\n    parameters->image_offset_y0 = 0;\n\n    /* Codeblock size= 32*32 */\n    parameters->cblockw_init = 32;\n    parameters->cblockh_init = 32;\n\n    /* Codeblock style: no mode switch enabled */\n    parameters->mode = 0;\n\n    /* No ROI */\n    parameters->roi_compno = -1;\n\n    /* No subsampling */\n    parameters->subsampling_dx = 1;\n    parameters->subsampling_dy = 1;\n\n    /* 9-7 transform */\n    parameters->irreversible = 1;\n\n    /* Number of layers */\n    if (parameters->tcp_numlayers > 1) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"1 single quality layer\"\n                      \"-> Number of layers forced to 1 (rather than %d)\\n\"\n                      \"-> Rate of the last layer (%3.1f) will be used\",\n                      parameters->tcp_numlayers,\n                      parameters->tcp_rates[parameters->tcp_numlayers - 1]);\n        parameters->tcp_rates[0] = parameters->tcp_rates[parameters->tcp_numlayers - 1];\n        parameters->tcp_numlayers = 1;\n    }\n\n    /* Resolution levels */\n    switch (parameters->rsiz) {\n    case OPJ_PROFILE_CINEMA_2K:\n        if (parameters->numresolution > 6) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-3 (2k dc profile) requires:\\n\"\n                          \"Number of decomposition levels <= 5\\n\"\n                          \"-> Number of decomposition levels forced to 5 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 6;\n        }\n        break;\n    case OPJ_PROFILE_CINEMA_4K:\n        if (parameters->numresolution < 2) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 1 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 1;\n        } else if (parameters->numresolution > 7) {\n            opj_event_msg(p_manager, EVT_WARNING,\n                          \"JPEG 2000 Profile-4 (4k dc profile) requires:\\n\"\n                          \"Number of decomposition levels >= 1 && <= 6\\n\"\n                          \"-> Number of decomposition levels forced to 6 (rather than %d)\\n\",\n                          parameters->numresolution + 1);\n            parameters->numresolution = 7;\n        }\n        break;\n    default :\n        break;\n    }\n\n    /* Precincts */\n    parameters->csty |= 0x01;\n    if (parameters->numresolution == 1) {\n        parameters->res_spec = 1;\n        parameters->prcw_init[0] = 128;\n        parameters->prch_init[0] = 128;\n    } else {\n        parameters->res_spec = parameters->numresolution - 1;\n        for (i = 0; i < parameters->res_spec; i++) {\n            parameters->prcw_init[i] = 256;\n            parameters->prch_init[i] = 256;\n        }\n    }\n\n    /* The progression order shall be CPRL */\n    parameters->prog_order = OPJ_CPRL;\n\n    /* Progression order changes for 4K, disallowed for 2K */\n    if (parameters->rsiz == OPJ_PROFILE_CINEMA_4K) {\n        parameters->numpocs = (OPJ_UINT32)opj_j2k_initialise_4K_poc(parameters->POC,\n                              parameters->numresolution);\n    } else {\n        parameters->numpocs = 0;\n    }\n\n    /* Limited bit-rate */\n    parameters->cp_disto_alloc = 1;\n    if (parameters->max_cs_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_cs_size > OPJ_CINEMA_24_CS) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1302083 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1302083 bytes.\\n\");\n        parameters->max_cs_size = OPJ_CINEMA_24_CS;\n    }\n\n    if (parameters->max_comp_size <= 0) {\n        /* No rate has been introduced, 24 fps is assumed */\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"As no rate has been given, this limit will be used.\\n\");\n    } else if (parameters->max_comp_size > OPJ_CINEMA_24_COMP) {\n        opj_event_msg(p_manager, EVT_WARNING,\n                      \"JPEG 2000 Profile-3 and 4 (2k/4k dc profile) requires:\\n\"\n                      \"Maximum 1041666 compressed bytes @ 24fps\\n\"\n                      \"-> Specified rate exceeds this limit. Rate will be forced to 1041666 bytes.\\n\");\n        parameters->max_comp_size = OPJ_CINEMA_24_COMP;\n    }\n\n    parameters->tcp_rates[0] = (OPJ_FLOAT32)(image->numcomps * image->comps[0].w *\n                               image->comps[0].h * image->comps[0].prec) /\n                               (OPJ_FLOAT32)(((OPJ_UINT32)parameters->max_cs_size) * 8 * image->comps[0].dx *\n                                       image->comps[0].dy);\n\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/4241ae6fbbf1de9658764a80944dc8108f2b4154", "file_name": "src/lib/openjp2/j2k.c", "vul_type": "cwe-787", "description": "Write a C function to configure JPEG 2000 cinema parameters for an image."}
{"func_name": "sc_oberthur_read_file", "func_src_before": "sc_oberthur_read_file(struct sc_pkcs15_card *p15card, const char *in_path,\n\t\tunsigned char **out, size_t *out_len,\n\t\tint verify_pin)\n{\n\tstruct sc_context *ctx = p15card->card->ctx;\n\tstruct sc_card *card = p15card->card;\n\tstruct sc_file *file = NULL;\n\tstruct sc_path path;\n\tsize_t sz;\n\tint rv;\n\n\tLOG_FUNC_CALLED(ctx);\n\tif (!in_path || !out || !out_len)\n\t\tLOG_TEST_RET(ctx, SC_ERROR_INVALID_ARGUMENTS, \"Cannot read oberthur file\");\n\n\tsc_log(ctx, \"read file '%s'; verify_pin:%i\", in_path, verify_pin);\n\n\t*out = NULL;\n\t*out_len = 0;\n\n\tsc_format_path(in_path, &path);\n\trv = sc_select_file(card, &path, &file);\n\tif (rv != SC_SUCCESS) {\n\t\tsc_file_free(file);\n\t\tLOG_TEST_RET(ctx, rv, \"Cannot select oberthur file to read\");\n\t}\n\n\tif (file->ef_structure == SC_FILE_EF_TRANSPARENT)\n\t\tsz = file->size;\n\telse\n\t\tsz = (file->record_length + 2) * file->record_count;\n\n\t*out = calloc(sz, 1);\n\tif (*out == NULL) {\n\t\tsc_file_free(file);\n\t\tLOG_TEST_RET(ctx, SC_ERROR_OUT_OF_MEMORY, \"Cannot read oberthur file\");\n\t}\n\n\tif (file->ef_structure == SC_FILE_EF_TRANSPARENT)   {\n\t\trv = sc_read_binary(card, 0, *out, sz, 0);\n\t}\n\telse\t{\n\t\tint rec;\n\t\tint offs = 0;\n\t\tint rec_len = file->record_length;\n\n\t\tfor (rec = 1; ; rec++)   {\n\t\t\trv = sc_read_record(card, rec, *out + offs + 2, rec_len, SC_RECORD_BY_REC_NR);\n\t\t\tif (rv == SC_ERROR_RECORD_NOT_FOUND)   {\n\t\t\t\trv = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if (rv < 0)   {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\trec_len = rv;\n\n\t\t\t*(*out + offs) = 'R';\n\t\t\t*(*out + offs + 1) = rv;\n\n\t\t\toffs += rv + 2;\n\t\t}\n\n\t\tsz = offs;\n\t}\n\n\tsc_log(ctx, \"read oberthur file result %i\", rv);\n\tif (verify_pin && rv == SC_ERROR_SECURITY_STATUS_NOT_SATISFIED)   {\n\t\tstruct sc_pkcs15_object *objs[0x10], *pin_obj = NULL;\n\t\tconst struct sc_acl_entry *acl = sc_file_get_acl_entry(file, SC_AC_OP_READ);\n\t\tint ii;\n\n\t\trv = sc_pkcs15_get_objects(p15card, SC_PKCS15_TYPE_AUTH_PIN, objs, 0x10);\n\t\tif (rv != SC_SUCCESS) {\n\t\t\tsc_file_free(file);\n\t\t\tLOG_TEST_RET(ctx, rv, \"Cannot read oberthur file: get AUTH objects error\");\n\t\t}\n\n\t\tfor (ii=0; ii<rv; ii++)   {\n\t\t\tstruct sc_pkcs15_auth_info *auth_info = (struct sc_pkcs15_auth_info *) objs[ii]->data;\n\t\t\tsc_log(ctx, \"compare PIN/ACL refs:%i/%i, method:%i/%i\",\n\t\t\t\t\tauth_info->attrs.pin.reference, acl->key_ref, auth_info->auth_method, acl->method);\n\t\t\tif (auth_info->attrs.pin.reference == (int)acl->key_ref && auth_info->auth_method == (unsigned)acl->method)   {\n\t\t\t\tpin_obj = objs[ii];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!pin_obj || !pin_obj->content.value)    {\n\t\t\trv = SC_ERROR_SECURITY_STATUS_NOT_SATISFIED;\n\t\t}\n\t\telse    {\n\t\t\trv = sc_pkcs15_verify_pin(p15card, pin_obj, pin_obj->content.value, pin_obj->content.len);\n\t\t\tif (!rv)\n\t\t\t\trv = sc_oberthur_read_file(p15card, in_path, out, out_len, 0);\n\t\t}\n\t};\n\n\tsc_file_free(file);\n\n\tif (rv < 0)   {\n\t\tfree(*out);\n\t\t*out = NULL;\n\t\t*out_len = 0;\n\t}\n\n\t*out_len = sz;\n\n\tLOG_FUNC_RETURN(ctx, rv);\n}", "func_src_after": "sc_oberthur_read_file(struct sc_pkcs15_card *p15card, const char *in_path,\n\t\tunsigned char **out, size_t *out_len,\n\t\tint verify_pin)\n{\n\tstruct sc_context *ctx = p15card->card->ctx;\n\tstruct sc_card *card = p15card->card;\n\tstruct sc_file *file = NULL;\n\tstruct sc_path path;\n\tsize_t sz;\n\tint rv;\n\n\tLOG_FUNC_CALLED(ctx);\n\tif (!in_path || !out || !out_len)\n\t\tLOG_TEST_RET(ctx, SC_ERROR_INVALID_ARGUMENTS, \"Cannot read oberthur file\");\n\n\tsc_log(ctx, \"read file '%s'; verify_pin:%i\", in_path, verify_pin);\n\n\t*out = NULL;\n\t*out_len = 0;\n\n\tsc_format_path(in_path, &path);\n\trv = sc_select_file(card, &path, &file);\n\tif (rv != SC_SUCCESS) {\n\t\tsc_file_free(file);\n\t\tLOG_TEST_RET(ctx, rv, \"Cannot select oberthur file to read\");\n\t}\n\n\tif (file->ef_structure == SC_FILE_EF_TRANSPARENT)\n\t\tsz = file->size;\n\telse\n\t\tsz = (file->record_length + 2) * file->record_count;\n\n\t*out = calloc(sz, 1);\n\tif (*out == NULL) {\n\t\tsc_file_free(file);\n\t\tLOG_TEST_RET(ctx, SC_ERROR_OUT_OF_MEMORY, \"Cannot read oberthur file\");\n\t}\n\n\tif (file->ef_structure == SC_FILE_EF_TRANSPARENT)   {\n\t\trv = sc_read_binary(card, 0, *out, sz, 0);\n\t}\n\telse\t{\n\t\tsize_t rec;\n\t\tsize_t offs = 0;\n\t\tsize_t rec_len = file->record_length;\n\n\t\tfor (rec = 1; ; rec++)   {\n\t\t\tif (rec > file->record_count) {\n\t\t\t\trv = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\trv = sc_read_record(card, rec, *out + offs + 2, rec_len, SC_RECORD_BY_REC_NR);\n\t\t\tif (rv == SC_ERROR_RECORD_NOT_FOUND)   {\n\t\t\t\trv = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if (rv < 0)   {\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\trec_len = rv;\n\n\t\t\t*(*out + offs) = 'R';\n\t\t\t*(*out + offs + 1) = rv;\n\n\t\t\toffs += rv + 2;\n\t\t}\n\n\t\tsz = offs;\n\t}\n\n\tsc_log(ctx, \"read oberthur file result %i\", rv);\n\tif (verify_pin && rv == SC_ERROR_SECURITY_STATUS_NOT_SATISFIED)   {\n\t\tstruct sc_pkcs15_object *objs[0x10], *pin_obj = NULL;\n\t\tconst struct sc_acl_entry *acl = sc_file_get_acl_entry(file, SC_AC_OP_READ);\n\t\tint ii;\n\n\t\trv = sc_pkcs15_get_objects(p15card, SC_PKCS15_TYPE_AUTH_PIN, objs, 0x10);\n\t\tif (rv != SC_SUCCESS) {\n\t\t\tsc_file_free(file);\n\t\t\tLOG_TEST_RET(ctx, rv, \"Cannot read oberthur file: get AUTH objects error\");\n\t\t}\n\n\t\tfor (ii=0; ii<rv; ii++)   {\n\t\t\tstruct sc_pkcs15_auth_info *auth_info = (struct sc_pkcs15_auth_info *) objs[ii]->data;\n\t\t\tsc_log(ctx, \"compare PIN/ACL refs:%i/%i, method:%i/%i\",\n\t\t\t\t\tauth_info->attrs.pin.reference, acl->key_ref, auth_info->auth_method, acl->method);\n\t\t\tif (auth_info->attrs.pin.reference == (int)acl->key_ref && auth_info->auth_method == (unsigned)acl->method)   {\n\t\t\t\tpin_obj = objs[ii];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (!pin_obj || !pin_obj->content.value)    {\n\t\t\trv = SC_ERROR_SECURITY_STATUS_NOT_SATISFIED;\n\t\t}\n\t\telse    {\n\t\t\trv = sc_pkcs15_verify_pin(p15card, pin_obj, pin_obj->content.value, pin_obj->content.len);\n\t\t\tif (!rv)\n\t\t\t\trv = sc_oberthur_read_file(p15card, in_path, out, out_len, 0);\n\t\t}\n\t};\n\n\tsc_file_free(file);\n\n\tif (rv < 0)   {\n\t\tfree(*out);\n\t\t*out = NULL;\n\t\t*out_len = 0;\n\t}\n\n\t*out_len = sz;\n\n\tLOG_FUNC_RETURN(ctx, rv);\n}", "commit_link": "github.com/OpenSC/OpenSC/commit/6903aebfddc466d966c7b865fae34572bf3ed23e", "file_name": "src/libopensc/pkcs15-oberthur.c", "vul_type": "cwe-787", "description": "Write a C function named `sc_oberthur_read_file` that reads data from a file on an Oberthur smart card, optionally verifying the PIN."}
{"func_name": "Logger::addMessage", "func_src_before": "void Logger::addMessage(const QString &message, const Log::MsgType &type)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Msg temp = { msgCounter++, QDateTime::currentMSecsSinceEpoch(), type, message };\n    m_messages.push_back(temp);\n\n    if (m_messages.size() >= MAX_LOG_MESSAGES)\n        m_messages.pop_front();\n\n    emit newLogMessage(temp);\n}", "func_src_after": "void Logger::addMessage(const QString &message, const Log::MsgType &type)\n{\n    QWriteLocker locker(&lock);\n\n    Log::Msg temp = { msgCounter++, QDateTime::currentMSecsSinceEpoch(), type, Utils::String::toHtmlEscaped(message) };\n    m_messages.push_back(temp);\n\n    if (m_messages.size() >= MAX_LOG_MESSAGES)\n        m_messages.pop_front();\n\n    emit newLogMessage(temp);\n}", "commit_link": "github.com/qbittorrent/qBittorrent/commit/6ca3e4f094da0a0017cb2d483ec1db6176bb0b16", "file_name": "src/base/logger.cpp", "vul_type": "cwe-079", "description": "Write a C++ function named `addMessage` for a `Logger` class that appends a log message with a timestamp and type to a list, removing the oldest if a max size is reached, and emits a signal."}
{"func_name": "render_page_edit", "func_src_before": "@app.route('/<page_name>/edit')\ndef render_page_edit(page_name):\n    query = db.query(\"select page_content.content from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    wiki_page = query.namedresult()\n    if len(wiki_page) > 0:\n        content = wiki_page[0].content\n    else:\n        content = \"\"\n    return render_template(\n        'edit_page.html',\n        page_name = page_name,\n        content = content\n    )", "func_src_after": "@app.route('/<page_name>/edit')\ndef render_page_edit(page_name):\n    query = db.query(\"select page_content.content from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    wiki_page = query.namedresult()\n    if len(wiki_page) > 0:\n        content = wiki_page[0].content\n    else:\n        content = \"\"\n    return render_template(\n        'edit_page.html',\n        page_name = page_name,\n        content = content\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Write a Python Flask function to display the latest content of a wiki page for editing, using a SQL query to retrieve the data."}
{"func_name": "cleanup_pathname", "func_src_before": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/')\n\t\tseparator = *src++;\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "func_src_after": "cleanup_pathname(struct archive_write_disk *a)\n{\n\tchar *dest, *src;\n\tchar separator = '\\0';\n\n\tdest = src = a->name;\n\tif (*src == '\\0') {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Invalid empty pathname\");\n\t\treturn (ARCHIVE_FAILED);\n\t}\n\n#if defined(__CYGWIN__)\n\tcleanup_pathname_win(a);\n#endif\n\t/* Skip leading '/'. */\n\tif (*src == '/') {\n\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NOABSOLUTEPATHS) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t                  \"Path is absolute\");\n\t\t\treturn (ARCHIVE_FAILED);\n\t\t}\n\n\t\tseparator = *src++;\n\t}\n\n\t/* Scan the pathname one element at a time. */\n\tfor (;;) {\n\t\t/* src points to first char after '/' */\n\t\tif (src[0] == '\\0') {\n\t\t\tbreak;\n\t\t} else if (src[0] == '/') {\n\t\t\t/* Found '//', ignore second one. */\n\t\t\tsrc++;\n\t\t\tcontinue;\n\t\t} else if (src[0] == '.') {\n\t\t\tif (src[1] == '\\0') {\n\t\t\t\t/* Ignore trailing '.' */\n\t\t\t\tbreak;\n\t\t\t} else if (src[1] == '/') {\n\t\t\t\t/* Skip './'. */\n\t\t\t\tsrc += 2;\n\t\t\t\tcontinue;\n\t\t\t} else if (src[1] == '.') {\n\t\t\t\tif (src[2] == '/' || src[2] == '\\0') {\n\t\t\t\t\t/* Conditionally warn about '..' */\n\t\t\t\t\tif (a->flags & ARCHIVE_EXTRACT_SECURE_NODOTDOT) {\n\t\t\t\t\t\tarchive_set_error(&a->archive,\n\t\t\t\t\t\t    ARCHIVE_ERRNO_MISC,\n\t\t\t\t\t\t    \"Path contains '..'\");\n\t\t\t\t\t\treturn (ARCHIVE_FAILED);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/*\n\t\t\t\t * Note: Under no circumstances do we\n\t\t\t\t * remove '..' elements.  In\n\t\t\t\t * particular, restoring\n\t\t\t\t * '/foo/../bar/' should create the\n\t\t\t\t * 'foo' dir as a side-effect.\n\t\t\t\t */\n\t\t\t}\n\t\t}\n\n\t\t/* Copy current element, including leading '/'. */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\twhile (*src != '\\0' && *src != '/') {\n\t\t\t*dest++ = *src++;\n\t\t}\n\n\t\tif (*src == '\\0')\n\t\t\tbreak;\n\n\t\t/* Skip '/' separator. */\n\t\tseparator = *src++;\n\t}\n\t/*\n\t * We've just copied zero or more path elements, not including the\n\t * final '/'.\n\t */\n\tif (dest == a->name) {\n\t\t/*\n\t\t * Nothing got copied.  The path must have been something\n\t\t * like '.' or '/' or './' or '/././././/./'.\n\t\t */\n\t\tif (separator)\n\t\t\t*dest++ = '/';\n\t\telse\n\t\t\t*dest++ = '.';\n\t}\n\t/* Terminate the result. */\n\t*dest = '\\0';\n\treturn (ARCHIVE_OK);\n}", "commit_link": "github.com/libarchive/libarchive/commit/59357157706d47c365b2227739e17daba3607526", "file_name": "libarchive/archive_write_disk_posix.c", "vul_type": "cwe-022", "description": "Write a C function named `cleanup_pathname` that sanitizes and validates a pathname stored in a `struct archive_write_disk` object."}
{"func_name": "read_quant_matrix_ext", "func_src_before": "static void read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n}", "func_src_after": "static int read_quant_matrix_ext(MpegEncContext *s, GetBitContext *gb)\n{\n    int i, j, v;\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->intra_matrix[j]        = v;\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            v = get_bits(gb, 8);\n            j = s->idsp.idct_permutation[ff_zigzag_direct[i]];\n            s->chroma_intra_matrix[j] = v;\n        }\n    }\n\n    if (get_bits1(gb)) {\n        if (get_bits_left(gb) < 64*8)\n            return AVERROR_INVALIDDATA;\n        /* chroma_non_intra_quantiser_matrix */\n        for (i = 0; i < 64; i++) {\n            get_bits(gb, 8);\n        }\n    }\n\n    next_start_code_studio(gb);\n    return 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/5aba5b89d0b1d73164d3b81764828bb8b20ff32a", "file_name": "libavcodec/mpeg4videodec.c", "vul_type": "cwe-125", "description": "Write a C function to read and optionally update quantization matrices from a bitstream in an MPEG encoding context."}
{"func_name": "handle_method_call", "func_src_before": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (element == NULL || element[0] == '\\0' || strlen(element) > 64)\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "func_src_after": "static void handle_method_call(GDBusConnection *connection,\n                        const gchar *caller,\n                        const gchar *object_path,\n                        const gchar *interface_name,\n                        const gchar *method_name,\n                        GVariant    *parameters,\n                        GDBusMethodInvocation *invocation,\n                        gpointer    user_data)\n{\n    reset_timeout();\n\n    uid_t caller_uid;\n    GVariant *response;\n\n    caller_uid = get_caller_uid(connection, invocation, caller);\n\n    log_notice(\"caller_uid:%ld method:'%s'\", (long)caller_uid, method_name);\n\n    if (caller_uid == (uid_t) -1)\n        return;\n\n    if (g_strcmp0(method_name, \"NewProblem\") == 0)\n    {\n        char *error = NULL;\n        char *problem_id = handle_new_problem(g_variant_get_child_value(parameters, 0), caller_uid, &error);\n        if (!problem_id)\n        {\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            free(error);\n            return;\n        }\n        /* else */\n        response = g_variant_new(\"(s)\", problem_id);\n        g_dbus_method_invocation_return_value(invocation, response);\n        free(problem_id);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetProblems\") == 0)\n    {\n        GList *dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        //I was told that g_dbus_method frees the response\n        //g_variant_unref(response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetAllProblems\") == 0)\n    {\n        /*\n        - so, we have UID,\n        - if it's 0, then we don't have to check anything and just return all directories\n        - if uid != 0 then we want to ask for authorization\n        */\n        if (caller_uid != 0)\n        {\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n                caller_uid = 0;\n        }\n\n        GList * dirs = get_problem_dirs_for_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetForeignProblems\") == 0)\n    {\n        GList * dirs = get_problem_dirs_not_accessible_by_uid(caller_uid, g_settings_dump_location);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"ChownProblemDir\") == 0)\n    {\n        const gchar *problem_dir;\n        g_variant_get(parameters, \"(&s)\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int ddstat = fdump_dir_stat_for_uid(dir_fd, caller_uid);\n        if (ddstat < 0)\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"requested directory does not exist '%s'\", problem_dir);\n            }\n            else\n            {\n                perror_msg(\"can't get stat of '%s'\", problem_dir);\n            }\n\n            return_InvalidProblemDir_error(invocation, problem_dir);\n\n            close(dir_fd);\n            return;\n        }\n\n        if (ddstat & DD_STAT_OWNED_BY_UID)\n        {   //caller seems to be in group with access to this dir, so no action needed\n            log_notice(\"caller has access to the requested directory %s\", problem_dir);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n            close(dir_fd);\n            return;\n        }\n\n        if ((ddstat & DD_STAT_ACCESSIBLE_BY_UID) == 0 &&\n                polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n        {\n            log_notice(\"not authorized\");\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.AuthFailure\",\n                                              _(\"Not Authorized\"));\n            close(dir_fd);\n            return;\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int chown_res = dd_chown(dd, caller_uid);\n        if (chown_res != 0)\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.ChownError\",\n                                              _(\"Chowning directory failed. Check system logs for more details.\"));\n        else\n            g_dbus_method_invocation_return_value(invocation, NULL);\n\n        dd_close(dd);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"GetInfo\") == 0)\n    {\n        /* Parameter tuple is (sas) */\n\n\t/* Get 1st param - problem dir name */\n        const gchar *problem_dir;\n        g_variant_get_child(parameters, 0, \"&s\", &problem_dir);\n        log_notice(\"problem_dir:'%s'\", problem_dir);\n\n        if (!allowed_problem_dir(problem_dir))\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        int dir_fd = dd_openfd(problem_dir);\n        if (dir_fd < 0)\n        {\n            perror_msg(\"can't open problem directory '%s'\", problem_dir);\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n        if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n        {\n            if (errno == ENOTDIR)\n            {\n                log_notice(\"Requested directory does not exist '%s'\", problem_dir);\n                return_InvalidProblemDir_error(invocation, problem_dir);\n                close(dir_fd);\n                return;\n            }\n\n            if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n            {\n                log_notice(\"not authorized\");\n                g_dbus_method_invocation_return_dbus_error(invocation,\n                                                  \"org.freedesktop.problems.AuthFailure\",\n                                                  _(\"Not Authorized\"));\n                close(dir_fd);\n                return;\n            }\n        }\n\n        struct dump_dir *dd = dd_fdopendir(dir_fd, problem_dir, DD_OPEN_READONLY | DD_FAIL_QUIETLY_EACCES);\n        if (!dd)\n        {\n            return_InvalidProblemDir_error(invocation, problem_dir);\n            return;\n        }\n\n\t/* Get 2nd param - vector of element names */\n        GVariant *array = g_variant_get_child_value(parameters, 1);\n        GList *elements = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        GVariantBuilder *builder = NULL;\n        for (GList *l = elements; l; l = l->next)\n        {\n            const char *element_name = (const char*)l->data;\n            char *value = dd_load_text_ext(dd, element_name, 0\n                                                | DD_LOAD_TEXT_RETURN_NULL_ON_FAILURE\n                                                | DD_FAIL_QUIETLY_ENOENT\n                                                | DD_FAIL_QUIETLY_EACCES);\n            log_notice(\"element '%s' %s\", element_name, value ? \"fetched\" : \"not found\");\n            if (value)\n            {\n                if (!builder)\n                    builder = g_variant_builder_new(G_VARIANT_TYPE_ARRAY);\n\n                /* g_variant_builder_add makes a copy. No need to xstrdup here */\n                g_variant_builder_add(builder, \"{ss}\", element_name, value);\n                free(value);\n            }\n        }\n        list_free_with_free(elements);\n        dd_close(dd);\n        /* It is OK to call g_variant_new(\"(a{ss})\", NULL) because */\n        /* G_VARIANT_TYPE_TUPLE allows NULL value */\n        GVariant *response = g_variant_new(\"(a{ss})\", builder);\n\n        if (builder)\n            g_variant_builder_unref(builder);\n\n        log_info(\"GetInfo: returning value for '%s'\", problem_dir);\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"SetElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n        const char *value;\n\n        g_variant_get(parameters, \"(&s&s&s)\", &problem_id, &element, &value);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        /* Is it good idea to make it static? Is it possible to change the max size while a single run? */\n        const double max_dir_size = g_settings_nMaxCrashReportsSize * (1024 * 1024);\n        const long item_size = dd_get_item_size(dd, element);\n        if (item_size < 0)\n        {\n            log_notice(\"Can't get size of '%s/%s'\", problem_id, element);\n            char *error = xasprintf(_(\"Can't get size of '%s'\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      error);\n            return;\n        }\n\n        const double requested_size = (double)strlen(value) - item_size;\n        /* Don't want to check the size limit in case of reducing of size */\n        if (requested_size > 0\n            && requested_size > (max_dir_size - get_dirsize(g_settings_dump_location)))\n        {\n            log_notice(\"No problem space left in '%s' (requested Bytes %f)\", problem_id, requested_size);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                                      \"org.freedesktop.problems.Failure\",\n                                                      _(\"No problem space left\"));\n        }\n        else\n        {\n            dd_save_text(dd, element, value);\n            g_dbus_method_invocation_return_value(invocation, NULL);\n        }\n\n        dd_close(dd);\n\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteElement\") == 0)\n    {\n        const char *problem_id;\n        const char *element;\n\n        g_variant_get(parameters, \"(&s&s)\", &problem_id, &element);\n\n        if (!str_is_correct_filename(element))\n        {\n            log_notice(\"'%s' is not a valid element name of '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"'%s' is not a valid element name\"), element);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                              \"org.freedesktop.problems.InvalidElement\",\n                                              error);\n\n            free(error);\n            return;\n        }\n\n        struct dump_dir *dd = open_directory_for_modification_of_element(\n                                    invocation, caller_uid, problem_id, element);\n        if (!dd)\n            /* Already logged from open_directory_for_modification_of_element() */\n            return;\n\n        const int res = dd_delete_item(dd, element);\n        dd_close(dd);\n\n        if (res != 0)\n        {\n            log_notice(\"Can't delete the element '%s' from the problem directory '%s'\", element, problem_id);\n            char *error = xasprintf(_(\"Can't delete the element '%s' from the problem directory '%s'\"), element, problem_id);\n            g_dbus_method_invocation_return_dbus_error(invocation,\n                                          \"org.freedesktop.problems.Failure\",\n                                          error);\n            free(error);\n            return;\n        }\n\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"DeleteProblem\") == 0)\n    {\n        /* Dbus parameters are always tuples.\n         * In this case, it's (as) - a tuple of one element (array of strings).\n         * Need to fetch the array:\n         */\n        GVariant *array = g_variant_get_child_value(parameters, 0);\n        GList *problem_dirs = string_list_from_variant(array);\n        g_variant_unref(array);\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n            log_notice(\"dir_name:'%s'\", dir_name);\n            if (!allowed_problem_dir(dir_name))\n            {\n                return_InvalidProblemDir_error(invocation, dir_name);\n                goto ret;\n            }\n        }\n\n        for (GList *l = problem_dirs; l; l = l->next)\n        {\n            const char *dir_name = (const char*)l->data;\n\n            int dir_fd = dd_openfd(dir_name);\n            if (dir_fd < 0)\n            {\n                perror_msg(\"can't open problem directory '%s'\", dir_name);\n                return_InvalidProblemDir_error(invocation, dir_name);\n                return;\n            }\n\n            if (!fdump_dir_accessible_by_uid(dir_fd, caller_uid))\n            {\n                if (errno == ENOTDIR)\n                {\n                    log_notice(\"Requested directory does not exist '%s'\", dir_name);\n                    close(dir_fd);\n                    continue;\n                }\n\n                if (polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") != PolkitYes)\n                { // if user didn't provide correct credentials, just move to the next dir\n                    close(dir_fd);\n                    continue;\n                }\n            }\n\n            struct dump_dir *dd = dd_fdopendir(dir_fd, dir_name, /*flags:*/ 0);\n            if (dd)\n            {\n                if (dd_delete(dd) != 0)\n                {\n                    error_msg(\"Failed to delete problem directory '%s'\", dir_name);\n                    dd_close(dd);\n                }\n            }\n        }\n\n        g_dbus_method_invocation_return_value(invocation, NULL);\n ret:\n        list_free_with_free(problem_dirs);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"FindProblemByElementInTimeRange\") == 0)\n    {\n        const gchar *element;\n        const gchar *value;\n        glong timestamp_from;\n        glong timestamp_to;\n        gboolean all;\n\n        g_variant_get_child(parameters, 0, \"&s\", &element);\n        g_variant_get_child(parameters, 1, \"&s\", &value);\n        g_variant_get_child(parameters, 2, \"x\", &timestamp_from);\n        g_variant_get_child(parameters, 3, \"x\", &timestamp_to);\n        g_variant_get_child(parameters, 4, \"b\", &all);\n\n        if (all && polkit_check_authorization_dname(caller, \"org.freedesktop.problems.getall\") == PolkitYes)\n            caller_uid = 0;\n\n        GList *dirs = get_problem_dirs_for_element_in_time(caller_uid, element, value, timestamp_from,\n                                                        timestamp_to);\n        response = variant_from_string_list(dirs);\n        list_free_with_free(dirs);\n\n        g_dbus_method_invocation_return_value(invocation, response);\n        return;\n    }\n\n    if (g_strcmp0(method_name, \"Quit\") == 0)\n    {\n        g_dbus_method_invocation_return_value(invocation, NULL);\n        g_main_loop_quit(loop);\n        return;\n    }\n}", "commit_link": "github.com/abrt/abrt/commit/f3c2a6af3455b2882e28570e8a04f1c2d4500d5b", "file_name": "src/dbus/abrt-dbus.c", "vul_type": "cwe-022", "description": "Write a C function to handle various method calls for problem management over D-Bus."}
{"func_name": "crypto_skcipher_init_tfm", "func_src_before": "static int crypto_skcipher_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_skcipher *skcipher = __crypto_skcipher_cast(tfm);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(skcipher);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_blkcipher_type)\n\t\treturn crypto_init_skcipher_ops_blkcipher(tfm);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_ablkcipher_type ||\n\t    tfm->__crt_alg->cra_type == &crypto_givcipher_type)\n\t\treturn crypto_init_skcipher_ops_ablkcipher(tfm);\n\n\tskcipher->setkey = skcipher_setkey;\n\tskcipher->encrypt = alg->encrypt;\n\tskcipher->decrypt = alg->decrypt;\n\tskcipher->ivsize = alg->ivsize;\n\tskcipher->keysize = alg->max_keysize;\n\n\tif (alg->exit)\n\t\tskcipher->base.exit = crypto_skcipher_exit_tfm;\n\n\tif (alg->init)\n\t\treturn alg->init(skcipher);\n\n\treturn 0;\n}", "func_src_after": "static int crypto_skcipher_init_tfm(struct crypto_tfm *tfm)\n{\n\tstruct crypto_skcipher *skcipher = __crypto_skcipher_cast(tfm);\n\tstruct skcipher_alg *alg = crypto_skcipher_alg(skcipher);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_blkcipher_type)\n\t\treturn crypto_init_skcipher_ops_blkcipher(tfm);\n\n\tif (tfm->__crt_alg->cra_type == &crypto_ablkcipher_type ||\n\t    tfm->__crt_alg->cra_type == &crypto_givcipher_type)\n\t\treturn crypto_init_skcipher_ops_ablkcipher(tfm);\n\n\tskcipher->setkey = alg->setkey;\n\tskcipher->encrypt = alg->encrypt;\n\tskcipher->decrypt = alg->decrypt;\n\tskcipher->ivsize = alg->ivsize;\n\tskcipher->keysize = alg->max_keysize;\n\n\tif (alg->exit)\n\t\tskcipher->base.exit = crypto_skcipher_exit_tfm;\n\n\tif (alg->init)\n\t\treturn alg->init(skcipher);\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/9933e113c2e87a9f46a40fde8dafbf801dca1ab9", "file_name": "crypto/skcipher.c", "vul_type": "cwe-476", "description": "Write a C function named `crypto_skcipher_init_tfm` that initializes a symmetric key cipher transformation context."}
{"func_name": "dd_delete_item", "func_src_before": "int dd_delete_item(struct dump_dir *dd, const char *name)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *path = concat_path_file(dd->dd_dirname, name);\n    int res = unlink(path);\n\n    if (res < 0)\n    {\n        if (errno == ENOENT)\n            errno = res = 0;\n        else\n            perror_msg(\"Can't delete file '%s'\", path);\n    }\n\n    free(path);\n    return res;\n}", "func_src_after": "int dd_delete_item(struct dump_dir *dd, const char *name)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot delete item. '%s' is not a valid file name\", name);\n\n    char *path = concat_path_file(dd->dd_dirname, name);\n    int res = unlink(path);\n\n    if (res < 0)\n    {\n        if (errno == ENOENT)\n            errno = res = 0;\n        else\n            perror_msg(\"Can't delete file '%s'\", path);\n    }\n\n    free(path);\n    return res;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_delete_item` that deletes a file with error handling for an unlocked directory and invalid filenames."}
{"func_name": "rfbProcessFileTransferReadBuffer", "func_src_before": "char *rfbProcessFileTransferReadBuffer(rfbClientPtr cl, uint32_t length)\n{\n    char *buffer=NULL;\n    int   n=0;\n\n    FILEXFER_ALLOWED_OR_CLOSE_AND_RETURN(\"\", cl, NULL);\n    /*\n    rfbLog(\"rfbProcessFileTransferReadBuffer(%dlen)\\n\", length);\n    */\n    if (length>0) {\n        buffer=malloc((uint64_t)length+1);\n        if (buffer!=NULL) {\n            if ((n = rfbReadExact(cl, (char *)buffer, length)) <= 0) {\n                if (n != 0)\n                    rfbLogPerror(\"rfbProcessFileTransferReadBuffer: read\");\n                rfbCloseClient(cl);\n                /* NOTE: don't forget to free(buffer) if you return early! */\n                if (buffer!=NULL) free(buffer);\n                return NULL;\n            }\n            /* Null Terminate */\n            buffer[length]=0;\n        }\n    }\n    return buffer;\n}", "func_src_after": "char *rfbProcessFileTransferReadBuffer(rfbClientPtr cl, uint32_t length)\n{\n    char *buffer=NULL;\n    int   n=0;\n\n    FILEXFER_ALLOWED_OR_CLOSE_AND_RETURN(\"\", cl, NULL);\n\n    /*\n       We later alloc length+1, which might wrap around on 32-bit systems if length equals\n       0XFFFFFFFF, i.e. SIZE_MAX for 32-bit systems. On 64-bit systems, a length of 0XFFFFFFFF\n       will safely be allocated since this check will never trigger and malloc() can digest length+1\n       without problems as length is a uint32_t.\n    */\n    if(length == SIZE_MAX) {\n\trfbErr(\"rfbProcessFileTransferReadBuffer: too big file transfer length requested: %u\", (unsigned int)length);\n\trfbCloseClient(cl);\n\treturn NULL;\n    }\n\n    if (length>0) {\n        buffer=malloc((size_t)length+1);\n        if (buffer!=NULL) {\n            if ((n = rfbReadExact(cl, (char *)buffer, length)) <= 0) {\n                if (n != 0)\n                    rfbLogPerror(\"rfbProcessFileTransferReadBuffer: read\");\n                rfbCloseClient(cl);\n                /* NOTE: don't forget to free(buffer) if you return early! */\n                if (buffer!=NULL) free(buffer);\n                return NULL;\n            }\n            /* Null Terminate */\n            buffer[length]=0;\n        }\n    }\n    return buffer;\n}", "commit_link": "github.com/LibVNC/libvncserver/commit/15bb719c03cc70f14c36a843dcb16ed69b405707", "file_name": "libvncserver/rfbserver.c", "vul_type": "cwe-787", "description": "In C, write a function to read a specified length of data from a client connection into a buffer, handling memory allocation and error checking."}
{"func_name": "parse8BIM", "func_src_before": "static ssize_t parse8BIM(Image *ifile, Image *ofile)\n{\n  char\n    brkused,\n    quoted,\n    *line,\n    *token,\n    *newstr,\n    *name;\n\n  int\n    state,\n    next;\n\n  unsigned char\n    dataset;\n\n  unsigned int\n    recnum;\n\n  int\n    inputlen = MaxTextExtent;\n\n  MagickOffsetType\n    savedpos,\n    currentpos;\n\n  ssize_t\n    savedolen = 0L,\n    outputlen = 0L;\n\n  TokenInfo\n    *token_info;\n\n  dataset = 0;\n  recnum = 0;\n  line = (char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*line));\n  if (line == (char *) NULL)\n    return(-1);\n  newstr = name = token = (char *) NULL;\n  savedpos = 0;\n  token_info=AcquireTokenInfo();\n  while (super_fgets(&line,&inputlen,ifile)!=NULL)\n  {\n    state=0;\n    next=0;\n\n    token=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*token));\n    if (token == (char *) NULL)\n      break;\n    newstr=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*newstr));\n    if (newstr == (char *) NULL)\n      break;\n    while (Tokenizer(token_info,0,token,(size_t) inputlen,line,\"\",\"=\",\"\\\"\",0,\n           &brkused,&next,&quoted)==0)\n    {\n      if (state == 0)\n        {\n          int\n            state,\n            next;\n\n          char\n            brkused,\n            quoted;\n\n          state=0;\n          next=0;\n          while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"#\",\n            \"\", 0,&brkused,&next,&quoted)==0)\n          {\n            switch (state)\n            {\n              case 0:\n                if (strcmp(newstr,\"8BIM\")==0)\n                  dataset = 255;\n                else\n                  dataset = (unsigned char) StringToLong(newstr);\n                break;\n              case 1:\n                recnum = (unsigned int) StringToUnsignedLong(newstr);\n                break;\n              case 2:\n                name=(char *) AcquireQuantumMemory(strlen(newstr)+MaxTextExtent,\n                  sizeof(*name));\n                if (name)\n                  (void) strcpy(name,newstr);\n                break;\n            }\n            state++;\n          }\n        }\n      else\n        if (state == 1)\n          {\n            int\n              next;\n\n            ssize_t\n              len;\n\n            char\n              brkused,\n              quoted;\n\n            next=0;\n            len = (ssize_t) strlen(token);\n            while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"&\",\n              \"\",0,&brkused,&next,&quoted)==0)\n            {\n              if (brkused && next > 0)\n                {\n                  char\n                    *s = &token[next-1];\n\n                  len -= (ssize_t) convertHTMLcodes(s,(int) strlen(s));\n                }\n            }\n\n            if (dataset == 255)\n              {\n                unsigned char\n                  nlen = 0;\n\n                int\n                  i;\n\n                if (savedolen > 0)\n                  {\n                    MagickOffsetType\n                      offset;\n\n                    ssize_t diff = outputlen - savedolen;\n                    currentpos = TellBlob(ofile);\n                    if (currentpos < 0)\n                      return(-1);\n                    offset=SeekBlob(ofile,savedpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n                    offset=SeekBlob(ofile,currentpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    savedolen = 0L;\n                  }\n                if (outputlen & 1)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                (void) WriteBlobString(ofile,\"8BIM\");\n                (void) WriteBlobMSBShort(ofile,(unsigned short) recnum);\n                outputlen += 6;\n                if (name)\n                  nlen = (unsigned char) strlen(name);\n                (void) WriteBlobByte(ofile,nlen);\n                outputlen++;\n                for (i=0; i<nlen; i++)\n                  (void) WriteBlobByte(ofile,(unsigned char) name[i]);\n                outputlen += nlen;\n                if ((nlen & 0x01) == 0)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                if (recnum != IPTC_ID)\n                  {\n                    (void) WriteBlobMSBLong(ofile, (unsigned int) len);\n                    outputlen += 4;\n\n                    next=0;\n                    outputlen += len;\n                    while (len--)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n\n                    if (outputlen & 1)\n                      {\n                        (void) WriteBlobByte(ofile,0x00);\n                        outputlen++;\n                      }\n                  }\n                else\n                  {\n                    /* patch in a fake length for now and fix it later */\n                    savedpos = TellBlob(ofile);\n                    if (savedpos < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,0xFFFFFFFFU);\n                    outputlen += 4;\n                    savedolen = outputlen;\n                  }\n              }\n            else\n              {\n                if (len <= 0x7FFF)\n                  {\n                    (void) WriteBlobByte(ofile,0x1c);\n                    (void) WriteBlobByte(ofile,(unsigned char) dataset);\n                    (void) WriteBlobByte(ofile,(unsigned char) (recnum & 0xff));\n                    (void) WriteBlobMSBShort(ofile,(unsigned short) len);\n                    outputlen += 5;\n                    next=0;\n                    outputlen += len;\n                    while (len--)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n                  }\n              }\n          }\n      state++;\n    }\n    if (token != (char *) NULL)\n      token=DestroyString(token);\n    if (newstr != (char *) NULL)\n      newstr=DestroyString(newstr);\n    if (name != (char *) NULL)\n      name=DestroyString(name);\n  }\n  token_info=DestroyTokenInfo(token_info);\n  if (token != (char *) NULL)\n    token=DestroyString(token);\n  if (newstr != (char *) NULL)\n    newstr=DestroyString(newstr);\n  if (name != (char *) NULL)\n    name=DestroyString(name);\n  line=DestroyString(line);\n  if (savedolen > 0)\n    {\n      MagickOffsetType\n        offset;\n\n      ssize_t diff = outputlen - savedolen;\n\n      currentpos = TellBlob(ofile);\n      if (currentpos < 0)\n        return(-1);\n      offset=SeekBlob(ofile,savedpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n      offset=SeekBlob(ofile,currentpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      savedolen = 0L;\n    }\n  return(outputlen);\n}", "func_src_after": "static ssize_t parse8BIM(Image *ifile, Image *ofile)\n{\n  char\n    brkused,\n    quoted,\n    *line,\n    *token,\n    *newstr,\n    *name;\n\n  int\n    state,\n    next;\n\n  unsigned char\n    dataset;\n\n  unsigned int\n    recnum;\n\n  int\n    inputlen = MaxTextExtent;\n\n  MagickOffsetType\n    savedpos,\n    currentpos;\n\n  ssize_t\n    savedolen = 0L,\n    outputlen = 0L;\n\n  TokenInfo\n    *token_info;\n\n  dataset = 0;\n  recnum = 0;\n  line = (char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*line));\n  if (line == (char *) NULL)\n    return(-1);\n  newstr = name = token = (char *) NULL;\n  savedpos = 0;\n  token_info=AcquireTokenInfo();\n  while (super_fgets(&line,&inputlen,ifile)!=NULL)\n  {\n    state=0;\n    next=0;\n\n    token=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*token));\n    if (token == (char *) NULL)\n      break;\n    newstr=(char *) AcquireQuantumMemory((size_t) inputlen,sizeof(*newstr));\n    if (newstr == (char *) NULL)\n      break;\n    while (Tokenizer(token_info,0,token,(size_t) inputlen,line,\"\",\"=\",\"\\\"\",0,\n           &brkused,&next,&quoted)==0)\n    {\n      if (state == 0)\n        {\n          int\n            state,\n            next;\n\n          char\n            brkused,\n            quoted;\n\n          state=0;\n          next=0;\n          while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"#\",\n            \"\", 0,&brkused,&next,&quoted)==0)\n          {\n            switch (state)\n            {\n              case 0:\n                if (strcmp(newstr,\"8BIM\")==0)\n                  dataset = 255;\n                else\n                  dataset = (unsigned char) StringToLong(newstr);\n                break;\n              case 1:\n                recnum = (unsigned int) StringToUnsignedLong(newstr);\n                break;\n              case 2:\n                name=(char *) AcquireQuantumMemory(strlen(newstr)+MaxTextExtent,\n                  sizeof(*name));\n                if (name)\n                  (void) strcpy(name,newstr);\n                break;\n            }\n            state++;\n          }\n        }\n      else\n        if (state == 1)\n          {\n            int\n              next;\n\n            ssize_t\n              len;\n\n            char\n              brkused,\n              quoted;\n\n            next=0;\n            len = (ssize_t) strlen(token);\n            while (Tokenizer(token_info,0,newstr,(size_t) inputlen,token,\"\",\"&\",\n              \"\",0,&brkused,&next,&quoted)==0)\n            {\n              if (brkused && next > 0)\n                {\n                  char\n                    *s = &token[next-1];\n\n                  len -= (ssize_t) convertHTMLcodes(s,(int) strlen(s));\n                }\n            }\n\n            if (dataset == 255)\n              {\n                unsigned char\n                  nlen = 0;\n\n                int\n                  i;\n\n                if (savedolen > 0)\n                  {\n                    MagickOffsetType\n                      offset;\n\n                    ssize_t diff = outputlen - savedolen;\n                    currentpos = TellBlob(ofile);\n                    if (currentpos < 0)\n                      return(-1);\n                    offset=SeekBlob(ofile,savedpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n                    offset=SeekBlob(ofile,currentpos,SEEK_SET);\n                    if (offset < 0)\n                      return(-1);\n                    savedolen = 0L;\n                  }\n                if (outputlen & 1)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                (void) WriteBlobString(ofile,\"8BIM\");\n                (void) WriteBlobMSBShort(ofile,(unsigned short) recnum);\n                outputlen += 6;\n                if (name)\n                  nlen = (unsigned char) strlen(name);\n                (void) WriteBlobByte(ofile,nlen);\n                outputlen++;\n                for (i=0; i<nlen; i++)\n                  (void) WriteBlobByte(ofile,(unsigned char) name[i]);\n                outputlen += nlen;\n                if ((nlen & 0x01) == 0)\n                  {\n                    (void) WriteBlobByte(ofile,0x00);\n                    outputlen++;\n                  }\n                if (recnum != IPTC_ID)\n                  {\n                    (void) WriteBlobMSBLong(ofile, (unsigned int) len);\n                    outputlen += 4;\n\n                    next=0;\n                    outputlen += len;\n                    while (len-- > 0)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n\n                    if (outputlen & 1)\n                      {\n                        (void) WriteBlobByte(ofile,0x00);\n                        outputlen++;\n                      }\n                  }\n                else\n                  {\n                    /* patch in a fake length for now and fix it later */\n                    savedpos = TellBlob(ofile);\n                    if (savedpos < 0)\n                      return(-1);\n                    (void) WriteBlobMSBLong(ofile,0xFFFFFFFFU);\n                    outputlen += 4;\n                    savedolen = outputlen;\n                  }\n              }\n            else\n              {\n                if (len <= 0x7FFF)\n                  {\n                    (void) WriteBlobByte(ofile,0x1c);\n                    (void) WriteBlobByte(ofile,(unsigned char) dataset);\n                    (void) WriteBlobByte(ofile,(unsigned char) (recnum & 0xff));\n                    (void) WriteBlobMSBShort(ofile,(unsigned short) len);\n                    outputlen += 5;\n                    next=0;\n                    outputlen += len;\n                    while (len-- > 0)\n                      (void) WriteBlobByte(ofile,(unsigned char) token[next++]);\n                  }\n              }\n          }\n      state++;\n    }\n    if (token != (char *) NULL)\n      token=DestroyString(token);\n    if (newstr != (char *) NULL)\n      newstr=DestroyString(newstr);\n    if (name != (char *) NULL)\n      name=DestroyString(name);\n  }\n  token_info=DestroyTokenInfo(token_info);\n  if (token != (char *) NULL)\n    token=DestroyString(token);\n  if (newstr != (char *) NULL)\n    newstr=DestroyString(newstr);\n  if (name != (char *) NULL)\n    name=DestroyString(name);\n  line=DestroyString(line);\n  if (savedolen > 0)\n    {\n      MagickOffsetType\n        offset;\n\n      ssize_t diff = outputlen - savedolen;\n\n      currentpos = TellBlob(ofile);\n      if (currentpos < 0)\n        return(-1);\n      offset=SeekBlob(ofile,savedpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      (void) WriteBlobMSBLong(ofile,(unsigned int) diff);\n      offset=SeekBlob(ofile,currentpos,SEEK_SET);\n      if (offset < 0)\n        return(-1);\n      savedolen = 0L;\n    }\n  return(outputlen);\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/97c9f438a9b3454d085895f4d1f66389fd22a0fb", "file_name": "coders/meta.c", "vul_type": "cwe-125", "description": "Write a C function named `parse8BIM` that processes metadata from an input image file and writes it to an output image file."}
{"func_name": "_cli_run", "func_src_before": "    def _cli_run(self, cmd):\n        \"\"\"Runs a CLI command over SSH, without doing any result parsing.\"\"\"\n        LOG.debug(\"SSH CMD = %s \" % cmd)\n\n        (stdout, stderr) = self._run_ssh(cmd, False)\n\n        # we have to strip out the input and exit lines\n        tmp = stdout.split(\"\\r\\n\")\n        out = tmp[5:len(tmp) - 2]\n        return out", "func_src_after": "    def _cli_run(self, verb, cli_args):\n        \"\"\"Runs a CLI command over SSH, without doing any result parsing.\"\"\"\n        cli_arg_strings = []\n        if cli_args:\n            for k, v in cli_args.items():\n                if k == '':\n                    cli_arg_strings.append(\" %s\" % k)\n                else:\n                    cli_arg_strings.append(\" %s=%s\" % (k, v))\n\n        cmd = verb + ''.join(cli_arg_strings)\n        LOG.debug(\"SSH CMD = %s \" % cmd)\n\n        (stdout, stderr) = self._run_ssh(cmd, False)\n\n        # we have to strip out the input and exit lines\n        tmp = stdout.split(\"\\r\\n\")\n        out = tmp[5:len(tmp) - 2]\n        return out", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function that executes a given command over SSH and returns the output, excluding the first five lines and the last two lines."}
{"func_name": "_exec_cmd", "func_src_before": "    def _exec_cmd(self, cmd):\n        \"\"\"Executes adb commands in a new shell.\n\n        This is specific to executing adb binary because stderr is not a good\n        indicator of cmd execution status.\n\n        Args:\n            cmds: A string that is the adb command to execute.\n\n        Returns:\n            The output of the adb command run if exit code is 0.\n\n        Raises:\n            AdbError is raised if the adb command exit code is not 0.\n        \"\"\"\n        proc = subprocess.Popen(\n            cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        (out, err) = proc.communicate()\n        ret = proc.returncode\n        logging.debug('cmd: %s, stdout: %s, stderr: %s, ret: %s', cmd, out,\n                      err, ret)\n        if ret == 0:\n            return out\n        else:\n            raise AdbError(cmd=cmd, stdout=out, stderr=err, ret_code=ret)", "func_src_after": "    def _exec_cmd(self, args, shell):\n        \"\"\"Executes adb commands.\n\n        Args:\n            args: string or list of strings, program arguments.\n                See subprocess.Popen() documentation.\n            shell: bool, True to run this command through the system shell,\n                False to invoke it directly. See subprocess.Popen() docs.\n\n        Returns:\n            The output of the adb command run if exit code is 0.\n\n        Raises:\n            AdbError is raised if the adb command exit code is not 0.\n        \"\"\"\n        proc = subprocess.Popen(\n            args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=shell)\n        (out, err) = proc.communicate()\n        ret = proc.returncode\n        logging.debug('cmd: %s, stdout: %s, stderr: %s, ret: %s', args, out,\n                      err, ret)\n        if ret == 0:\n            return out\n        else:\n            raise AdbError(cmd=args, stdout=out, stderr=err, ret_code=ret)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device_lib/adb.py", "vul_type": "cwe-078", "description": "In Python, write a function to execute adb commands and handle the output based on the command's success or failure."}
{"func_name": "tflite::ops::builtin::segment_sum::ResizeOutputTensor", "func_src_before": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  int max_index = -1;\n  const int segment_id_size = segment_ids->dims->data[0];\n  if (segment_id_size > 0) {\n    max_index = segment_ids->data.i32[segment_id_size - 1];\n  }\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}", "func_src_after": "TfLiteStatus ResizeOutputTensor(TfLiteContext* context,\n                                const TfLiteTensor* data,\n                                const TfLiteTensor* segment_ids,\n                                TfLiteTensor* output) {\n  // Segment ids should be of same cardinality as first input dimension and they\n  // should be increasing by at most 1, from 0 (e.g., [0, 0, 1, 2, 3] is valid)\n  const int segment_id_size = segment_ids->dims->data[0];\n  TF_LITE_ENSURE_EQ(context, segment_id_size, data->dims->data[0]);\n  int previous_segment_id = -1;\n  for (int i = 0; i < segment_id_size; i++) {\n    const int current_segment_id = GetTensorData<int32_t>(segment_ids)[i];\n    if (i == 0) {\n      TF_LITE_ENSURE_EQ(context, current_segment_id, 0);\n    } else {\n      int delta = current_segment_id - previous_segment_id;\n      TF_LITE_ENSURE(context, delta == 0 || delta == 1);\n    }\n    previous_segment_id = current_segment_id;\n  }\n\n  const int max_index = previous_segment_id;\n\n  const int data_rank = NumDimensions(data);\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(NumDimensions(data));\n  output_shape->data[0] = max_index + 1;\n  for (int i = 1; i < data_rank; ++i) {\n    output_shape->data[i] = data->dims->data[i];\n  }\n  return context->ResizeTensor(context, output, output_shape);\n}", "commit_link": "github.com/tensorflow/tensorflow/commit/204945b19e44b57906c9344c0d00120eeeae178a", "file_name": "tensorflow/lite/kernels/segment_sum.cc", "vul_type": "cwe-787", "description": "Write a C++ function to resize an output tensor based on segment IDs in TensorFlow Lite."}
{"func_name": "ReadRLEImage", "func_src_before": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    one,\n    offset,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 64)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    if ((number_pixels*number_planes) != (size_t) (number_pixels*number_planes))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*MagickMax(number_planes,4);\n    pixel_info=AcquireVirtualMemory(pixel_info_length,sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            if (IsValidColormapIndex(image,*p & mask,&index,exception) ==\n                MagickFalse)\n              break;\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                if (IsValidColormapIndex(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception) == MagickFalse)\n                  break;\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "func_src_after": "static Image *ReadRLEImage(const ImageInfo *image_info,ExceptionInfo *exception)\n{\n#define SkipLinesOp  0x01\n#define SetColorOp  0x02\n#define SkipPixelsOp  0x03\n#define ByteDataOp  0x05\n#define RunDataOp  0x06\n#define EOFOp  0x07\n\n  char\n    magick[12];\n\n  Image\n    *image;\n\n  int\n    opcode,\n    operand,\n    status;\n\n  MagickStatusType\n    flags;\n\n  MagickSizeType\n    number_pixels;\n\n  MemoryInfo\n    *pixel_info;\n\n  Quantum\n    index;\n\n  register ssize_t\n    x;\n\n  register Quantum\n    *q;\n\n  register ssize_t\n    i;\n\n  register unsigned char\n    *p;\n\n  size_t\n    bits_per_pixel,\n    map_length,\n    number_colormaps,\n    number_planes,\n    number_planes_filled,\n    one,\n    offset,\n    pixel_info_length;\n\n  ssize_t\n    count,\n    y;\n\n  unsigned char\n    background_color[256],\n    *colormap,\n    pixel,\n    plane,\n    *pixels;\n\n  /*\n    Open image file.\n  */\n  assert(image_info != (const ImageInfo *) NULL);\n  assert(image_info->signature == MagickCoreSignature);\n  if (image_info->debug != MagickFalse)\n    (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",\n      image_info->filename);\n  assert(exception != (ExceptionInfo *) NULL);\n  assert(exception->signature == MagickCoreSignature);\n  image=AcquireImage(image_info,exception);\n  status=OpenBlob(image_info,image,ReadBinaryBlobMode,exception);\n  if (status == MagickFalse)\n    return(DestroyImageList(image));\n  /*\n    Determine if this a RLE file.\n  */\n  count=ReadBlob(image,2,(unsigned char *) magick);\n  if ((count != 2) || (memcmp(magick,\"\\122\\314\",2) != 0))\n    ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n  do\n  {\n    /*\n      Read image header.\n    */\n    image->page.x=ReadBlobLSBShort(image);\n    image->page.y=ReadBlobLSBShort(image);\n    image->columns=ReadBlobLSBShort(image);\n    image->rows=ReadBlobLSBShort(image);\n    flags=(MagickStatusType) ReadBlobByte(image);\n    image->alpha_trait=flags & 0x04 ? BlendPixelTrait : UndefinedPixelTrait;\n    number_planes=(size_t) ReadBlobByte(image);\n    bits_per_pixel=(size_t) ReadBlobByte(image);\n    number_colormaps=(size_t) ReadBlobByte(image);\n    map_length=(unsigned char) ReadBlobByte(image);\n    if (map_length >= 64)\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    one=1;\n    map_length=one << map_length;\n    if ((number_planes == 0) || (number_planes == 2) || (bits_per_pixel != 8) ||\n        (image->columns == 0))\n      ThrowReaderException(CorruptImageError,\"ImproperImageHeader\");\n    if (flags & 0x02)\n      {\n        /*\n          No background color-- initialize to black.\n        */\n        for (i=0; i < (ssize_t) number_planes; i++)\n          background_color[i]=0;\n        (void) ReadBlobByte(image);\n      }\n    else\n      {\n        /*\n          Initialize background color.\n        */\n        p=background_color;\n        for (i=0; i < (ssize_t) number_planes; i++)\n          *p++=(unsigned char) ReadBlobByte(image);\n      }\n    if ((number_planes & 0x01) == 0)\n      (void) ReadBlobByte(image);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    colormap=(unsigned char *) NULL;\n    if (number_colormaps != 0)\n      {\n        /*\n          Read image colormaps.\n        */\n        colormap=(unsigned char *) AcquireQuantumMemory(number_colormaps,\n          3*map_length*sizeof(*colormap));\n        if (colormap == (unsigned char *) NULL)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        for (i=0; i < (ssize_t) number_colormaps; i++)\n          for (x=0; x < (ssize_t) map_length; x++)\n            *p++=(unsigned char) ScaleShortToQuantum(ReadBlobLSBShort(image));\n      }\n    if ((flags & 0x08) != 0)\n      {\n        char\n          *comment;\n\n        size_t\n          length;\n\n        /*\n          Read image comment.\n        */\n        length=ReadBlobLSBShort(image);\n        if (length != 0)\n          {\n            comment=(char *) AcquireQuantumMemory(length,sizeof(*comment));\n            if (comment == (char *) NULL)\n              ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n            count=ReadBlob(image,length-1,(unsigned char *) comment);\n            comment[length-1]='\\0';\n            (void) SetImageProperty(image,\"comment\",comment,exception);\n            comment=DestroyString(comment);\n            if ((length & 0x01) == 0)\n              (void) ReadBlobByte(image);\n          }\n      }\n    if ((image_info->ping != MagickFalse) && (image_info->number_scenes != 0))\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    status=SetImageExtent(image,image->columns,image->rows,exception);\n    if (status == MagickFalse)\n      return(DestroyImageList(image));\n    /*\n      Allocate RLE pixels.\n    */\n    if (image->alpha_trait != UndefinedPixelTrait)\n      number_planes++;\n    number_pixels=(MagickSizeType) image->columns*image->rows;\n    number_planes_filled=(number_planes % 2 == 0) ? number_planes :\n      number_planes+1;\n    if ((number_pixels*number_planes_filled) != (size_t) (number_pixels*\n         number_planes_filled))\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixel_info_length=image->columns*image->rows*number_planes_filled;\n    pixel_info=AcquireVirtualMemory(pixel_info_length,sizeof(*pixels));\n    if (pixel_info == (MemoryInfo *) NULL)\n      ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n    pixels=(unsigned char *) GetVirtualMemoryBlob(pixel_info);\n    if ((flags & 0x01) && !(flags & 0x02))\n      {\n        ssize_t\n          j;\n\n        /*\n          Set background color.\n        */\n        p=pixels;\n        for (i=0; i < (ssize_t) number_pixels; i++)\n        {\n          if (image->alpha_trait == UndefinedPixelTrait)\n            for (j=0; j < (ssize_t) number_planes; j++)\n              *p++=background_color[j];\n          else\n            {\n              for (j=0; j < (ssize_t) (number_planes-1); j++)\n                *p++=background_color[j];\n              *p++=0;  /* initialize matte channel */\n            }\n        }\n      }\n    /*\n      Read runlength-encoded image.\n    */\n    plane=0;\n    x=0;\n    y=0;\n    opcode=ReadBlobByte(image);\n    do\n    {\n      switch (opcode & 0x3f)\n      {\n        case SkipLinesOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x=0;\n          y+=operand;\n          break;\n        }\n        case SetColorOp:\n        {\n          operand=ReadBlobByte(image);\n          plane=(unsigned char) operand;\n          if (plane == 255)\n            plane=(unsigned char) (number_planes-1);\n          x=0;\n          break;\n        }\n        case SkipPixelsOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          x+=operand;\n          break;\n        }\n        case ByteDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            pixel=(unsigned char) ReadBlobByte(image);\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          if (operand & 0x01)\n            (void) ReadBlobByte(image);\n          x+=operand;\n          break;\n        }\n        case RunDataOp:\n        {\n          operand=ReadBlobByte(image);\n          if (opcode & 0x40)\n            operand=(int) ReadBlobLSBShort(image);\n          pixel=(unsigned char) ReadBlobByte(image);\n          (void) ReadBlobByte(image);\n          offset=((image->rows-y-1)*image->columns*number_planes)+x*\n            number_planes+plane;\n          operand++;\n          if (offset+((size_t) operand*number_planes) > pixel_info_length)\n            {\n              if (number_colormaps != 0)\n                colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n              pixel_info=RelinquishVirtualMemory(pixel_info);\n              ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n            }\n          p=pixels+offset;\n          for (i=0; i < (ssize_t) operand; i++)\n          {\n            if ((y < (ssize_t) image->rows) &&\n                ((x+i) < (ssize_t) image->columns))\n              *p=pixel;\n            p+=number_planes;\n          }\n          x+=operand;\n          break;\n        }\n        default:\n          break;\n      }\n      opcode=ReadBlobByte(image);\n    } while (((opcode & 0x3f) != EOFOp) && (opcode != EOF));\n    if (number_colormaps != 0)\n      {\n        MagickStatusType\n          mask;\n\n        /*\n          Apply colormap affineation to image.\n        */\n        mask=(MagickStatusType) (map_length-1);\n        p=pixels;\n        x=(ssize_t) number_planes;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) number_pixels; i++)\n          {\n            if (IsValidColormapIndex(image,*p & mask,&index,exception) ==\n                MagickFalse)\n              break;\n            *p=colormap[(ssize_t) index];\n            p++;\n          }\n        else\n          if ((number_planes >= 3) && (number_colormaps >= 3))\n            for (i=0; i < (ssize_t) number_pixels; i++)\n              for (x=0; x < (ssize_t) number_planes; x++)\n              {\n                if (IsValidColormapIndex(image,(size_t) (x*map_length+\n                    (*p & mask)),&index,exception) == MagickFalse)\n                  break;\n                *p=colormap[(ssize_t) index];\n                p++;\n              }\n        if ((i < (ssize_t) number_pixels) || (x < (ssize_t) number_planes))\n          {\n            colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n            pixel_info=RelinquishVirtualMemory(pixel_info);\n            ThrowReaderException(CorruptImageError,\"UnableToReadImageData\");\n          }\n      }\n    /*\n      Initialize image structure.\n    */\n    if (number_planes >= 3)\n      {\n        /*\n          Convert raster image to DirectClass pixel packets.\n        */\n        p=pixels;\n        for (y=0; y < (ssize_t) image->rows; y++)\n        {\n          q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n          if (q == (Quantum *) NULL)\n            break;\n          for (x=0; x < (ssize_t) image->columns; x++)\n          {\n            SetPixelRed(image,ScaleCharToQuantum(*p++),q);\n            SetPixelGreen(image,ScaleCharToQuantum(*p++),q);\n            SetPixelBlue(image,ScaleCharToQuantum(*p++),q);\n            if (image->alpha_trait != UndefinedPixelTrait)\n              SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n            q+=GetPixelChannels(image);\n          }\n          if (SyncAuthenticPixels(image,exception) == MagickFalse)\n            break;\n          if (image->previous == (Image *) NULL)\n            {\n              status=SetImageProgress(image,LoadImageTag,(MagickOffsetType) y,\n                image->rows);\n              if (status == MagickFalse)\n                break;\n            }\n        }\n      }\n    else\n      {\n        /*\n          Create colormap.\n        */\n        if (number_colormaps == 0)\n          map_length=256;\n        if (AcquireImageColormap(image,map_length,exception) == MagickFalse)\n          ThrowReaderException(ResourceLimitError,\"MemoryAllocationFailed\");\n        p=colormap;\n        if (number_colormaps == 1)\n          for (i=0; i < (ssize_t) image->colors; i++)\n          {\n            /*\n              Pseudocolor.\n            */\n            image->colormap[i].red=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].green=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n            image->colormap[i].blue=(MagickRealType)\n              ScaleCharToQuantum((unsigned char) i);\n          }\n        else\n          if (number_colormaps > 1)\n            for (i=0; i < (ssize_t) image->colors; i++)\n            {\n              image->colormap[i].red=(MagickRealType)\n                ScaleCharToQuantum(*p);\n              image->colormap[i].green=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length));\n              image->colormap[i].blue=(MagickRealType)\n                ScaleCharToQuantum(*(p+map_length*2));\n              p++;\n            }\n        p=pixels;\n        if (image->alpha_trait == UndefinedPixelTrait)\n          {\n            /*\n              Convert raster image to PseudoClass pixel packets.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                SetPixelIndex(image,*p++,q);\n                q+=GetPixelChannels(image);\n              }\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            (void) SyncImage(image,exception);\n          }\n        else\n          {\n            /*\n              Image has a matte channel-- promote to DirectClass.\n            */\n            for (y=0; y < (ssize_t) image->rows; y++)\n            {\n              q=QueueAuthenticPixels(image,0,y,image->columns,1,exception);\n              if (q == (Quantum *) NULL)\n                break;\n              for (x=0; x < (ssize_t) image->columns; x++)\n              {\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelRed(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].red),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelGreen(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].green),q);\n                if (IsValidColormapIndex(image,(ssize_t) *p++,&index,\n                    exception) == MagickFalse)\n                  break;\n                SetPixelBlue(image,ClampToQuantum(image->colormap[(ssize_t)\n                  index].blue),q);\n                SetPixelAlpha(image,ScaleCharToQuantum(*p++),q);\n                q+=GetPixelChannels(image);\n              }\n              if (x < (ssize_t) image->columns)\n                break;\n              if (SyncAuthenticPixels(image,exception) == MagickFalse)\n                break;\n              if (image->previous == (Image *) NULL)\n                {\n                  status=SetImageProgress(image,LoadImageTag,(MagickOffsetType)\n                    y,image->rows);\n                  if (status == MagickFalse)\n                    break;\n                }\n            }\n            image->colormap=(PixelInfo *) RelinquishMagickMemory(\n              image->colormap);\n            image->storage_class=DirectClass;\n            image->colors=0;\n          }\n      }\n    if (number_colormaps != 0)\n      colormap=(unsigned char *) RelinquishMagickMemory(colormap);\n    pixel_info=RelinquishVirtualMemory(pixel_info);\n    if (EOFBlob(image) != MagickFalse)\n      {\n        ThrowFileException(exception,CorruptImageError,\"UnexpectedEndOfFile\",\n          image->filename);\n        break;\n      }\n    /*\n      Proceed to next image.\n    */\n    if (image_info->number_scenes != 0)\n      if (image->scene >= (image_info->scene+image_info->number_scenes-1))\n        break;\n    (void) ReadBlobByte(image);\n    count=ReadBlob(image,2,(unsigned char *) magick);\n    if ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0))\n      {\n        /*\n          Allocate next image structure.\n        */\n        AcquireNextImage(image_info,image,exception);\n        if (GetNextImageInList(image) == (Image *) NULL)\n          {\n            image=DestroyImageList(image);\n            return((Image *) NULL);\n          }\n        image=SyncNextImageInList(image);\n        status=SetImageProgress(image,LoadImagesTag,TellBlob(image),\n          GetBlobSize(image));\n        if (status == MagickFalse)\n          break;\n      }\n  } while ((count != 0) && (memcmp(magick,\"\\122\\314\",2) == 0));\n  (void) CloseBlob(image);\n  return(GetFirstImageInList(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/2ad6d33493750a28a5a655d319a8e0b16c392de1", "file_name": "coders/rle.c", "vul_type": "cwe-125", "description": "Write a C function to read and process RLE (run-length encoded) image data."}
{"func_name": "getPostsByPostid", "func_src_before": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%d\"%(postid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getPostsByPostid(self,postid):\n        sqlText=\"select users.name,post.comment from users,post where \\\n                users.userid=post.userid and post.postid=%s\"\n        params=[postid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/post.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves a user's name and comment from a database using a post ID."}
{"func_name": "respond_error", "func_src_before": "    def respond_error(self, context, exception):\n        context.respond_server_error()\n        stack = traceback.format_exc()\n        return \"\"\"\n        <html>\n            <body>\n\n                <style>\n                    body {\n                        font-family: sans-serif;\n                        color: #888;\n                        text-align: center;\n                    }\n\n                    body pre {\n                        width: 600px;\n                        text-align: left;\n                        margin: auto;\n                        font-family: monospace;\n                    }\n                </style>\n\n                <img src=\"/ajenti:static/main/error.jpeg\" />\n                <br/>\n                <p>\n                    Server error\n                </p>\n                <pre>\n%s\n                </pre>\n            </body>\n        </html>\n        \"\"\" % stack", "func_src_after": "    def respond_error(self, context, exception):\n        context.respond_server_error()\n        stack = traceback.format_exc()\n        return \"\"\"\n        <html>\n            <body>\n\n                <style>\n                    body {\n                        font-family: sans-serif;\n                        color: #888;\n                        text-align: center;\n                    }\n\n                    body pre {\n                        width: 600px;\n                        text-align: left;\n                        margin: auto;\n                        font-family: monospace;\n                    }\n                </style>\n\n                <img src=\"/ajenti:static/main/error.jpeg\" />\n                <br/>\n                <p>\n                    Server error\n                </p>\n                <pre>\n%s\n                </pre>\n            </body>\n        </html>\n        \"\"\" % cgi.escape(stack)", "commit_link": "github.com/Eugeny/ajenti/commit/d3fc5eb142ff16d55d158afb050af18d5ff09120", "file_name": "ajenti/routing.py", "vul_type": "cwe-079", "description": "Write a Python function that handles a server error by displaying an error page with a stack trace."}
{"func_name": "updateKey", "func_src_before": "def updateKey(client):\n\t\"\"\"Updates the contents of a key that already exists in our system.\n\tReturns an error if the specified key doesn't exist for the specified user.\n\t\"\"\"\n\tglobal NOT_FOUND\n\tglobal CREATED\n\n\tvalidateClient(client)\n\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateNewKeyData(token_data)\n\n\t# Use 'w' flag to replace existing key file with the new key data\n\tif os.path.isfile('keys/%s/%s.key' % (client, token_data['name'])):\n\t\twith open('keys/%s/%s.key' % (client, token_data['name']), 'w') as f:\n\t\t\tf.write(token_data['key'])\n\telse:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['name'])\n\n\treturn 'Key successfully updated', CREATED", "func_src_after": "def updateKey(client):\n\t\"\"\"Updates the contents of a key that already exists in our system.\n\tReturns an error if the specified key doesn't exist for the specified user.\n\t\"\"\"\n\tglobal NOT_FOUND\n\tglobal CREATED\n\n\tvalidateClient(client)\n\tclient_pub_key = loadClientRSAKey(client)\n\ttoken_data = decodeRequestToken(request.data, client_pub_key)\n\tvalidateNewKeyData(token_data)\n\tvalidateKeyName(token_data['name'])\n\n\t# Use 'w' flag to replace existing key file with the new key data\n\tif os.path.isfile('keys/%s/%s.key' % (client, token_data['name'])):\n\t\twith open('keys/%s/%s.key' % (client, token_data['name']), 'w') as f:\n\t\t\tf.write(token_data['key'])\n\telse:\n\t\traise FoxlockError(NOT_FOUND, \"Key '%s' not found\" % token_data['name'])\n\n\treturn 'Key successfully updated', CREATED", "commit_link": "github.com/Mimickal/FoxLock/commit/7c665e556987f4e2c1a75e143a1e80ae066ad833", "file_name": "impl.py", "vul_type": "cwe-022", "description": "Write a Python function to update a user's key file with new data, raising an error if the key file does not exist."}
{"func_name": "add_input", "func_src_before": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw. \n            # See section on SQL injection below\n            query = \"INSERT INTO crimes (description) VALUES(%s);\"\n            with connection.cursor() as cursor:\n                cursor.execute(query, data)\n                connection.commit()\n        finally:\n            connection.close()", "func_src_after": "    def add_input(self, data):\n        connection = self.connect()\n        try:\n            # The following introduces a deliberate security flaw. \n            # See section on SQL injection below\n            query = \"INSERT INTO crimes (description) VALUES('{}');\".format(data)\n            with connection.cursor() as cursor:\n                cursor.execute(query)\n                connection.commit()\n        finally:\n            connection.close()", "commit_link": "github.com/mudspringhiker/crimemap/commit/35e78962e7288c643cdde0f886ff7aa5ac77cb8c", "file_name": "dbhelper.py", "vul_type": "cwe-089", "description": "Write a Python function to insert user input into a database table, intentionally including a common security vulnerability."}
{"func_name": "wiki_handle_rest_call", "func_src_before": "wiki_handle_rest_call(HttpRequest  *req, \n\t\t      HttpResponse *res,\n\t\t      char         *func)\n{\n\n  if (func != NULL && *func != '\\0')\n    {\n      if (!strcmp(func, \"page/get\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (access(page, R_OK) == 0)) \n\t    {\n\t      http_response_printf(res, \"%s\", file_read(page));\n\t      http_response_send(res);\n\t      return;\n\t    }  \n\t}\n      else if (!strcmp(func, \"page/set\"))\n\t{\n\t  char *wikitext = NULL, *page = NULL;\n\t  if( ( (wikitext = http_request_param_get(req, \"text\")) != NULL)\n\t      && ( (page = http_request_param_get(req, \"page\")) != NULL))\n\t    {\n\t      file_write(page, wikitext);\t      \n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;\n\t    }\n\t}\n      else if (!strcmp(func, \"page/delete\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (unlink(page) > 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"page/exists\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && (access(page, R_OK) == 0)) \n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"pages\") || !strcmp(func, \"search\"))\n\t{\n\t  WikiPageList **pages = NULL;\n\t  int            n_pages, i;\n\t  char          *expr = http_request_param_get(req, \"expr\");\n\n\t  if (expr == NULL)\n\t    expr = http_request_get_query_string(req);\n\t  \n\t  pages = wiki_get_pages(&n_pages, expr);\n\n\t  if (pages)\n\t    {\n\t      for (i=0; i<n_pages; i++)\n\t\t{\n\t\t  struct tm   *pTm;\n\t\t  char   datebuf[64];\n\t\t  \n\t\t  pTm = localtime(&pages[i]->mtime);\n\t\t  strftime(datebuf, sizeof(datebuf), \"%Y-%m-%d %H:%M\", pTm);\n\t\t  http_response_printf(res, \"%s\\t%s\\n\", pages[i]->name, datebuf);\n\t\t}\n\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n    }\n\n  http_response_set_status(res, 500, \"Error\");\n  http_response_printf(res, \"<html><body>Failed</body></html>\\n\");\n  http_response_send(res);\n\n  return;  \n}", "func_src_after": "wiki_handle_rest_call(HttpRequest  *req, \n\t\t      HttpResponse *res,\n\t\t      char         *func)\n{\n\n  if (func != NULL && *func != '\\0')\n    {\n      if (!strcmp(func, \"page/get\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (access(page, R_OK) == 0))\n\t    {\n\t      http_response_printf(res, \"%s\", file_read(page));\n\t      http_response_send(res);\n\t      return;\n\t    }  \n\t}\n      else if (!strcmp(func, \"page/set\"))\n\t{\n\t  char *wikitext = NULL, *page = NULL;\n\t  if( ( (wikitext = http_request_param_get(req, \"text\")) != NULL)\n\t      && ( (page = http_request_param_get(req, \"page\")) != NULL))\n\t    {\n\t  if (page_name_is_good(page))\n\t    {\n\t      file_write(page, wikitext);\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;\n\t    }\n\t    }\n\t}\n      else if (!strcmp(func, \"page/delete\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (unlink(page) > 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"page/exists\"))\n\t{\n\t  char *page = http_request_param_get(req, \"page\");\n\n\t  if (page == NULL)\n\t    page = http_request_get_query_string(req);\n\n\t  if (page && page_name_is_good(page) && (access(page, R_OK) == 0))\n\t    {\n\t      http_response_printf(res, \"success\");\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n      else if (!strcmp(func, \"pages\") || !strcmp(func, \"search\"))\n\t{\n\t  WikiPageList **pages = NULL;\n\t  int            n_pages, i;\n\t  char          *expr = http_request_param_get(req, \"expr\");\n\n\t  if (expr == NULL)\n\t    expr = http_request_get_query_string(req);\n\t  \n\t  pages = wiki_get_pages(&n_pages, expr);\n\n\t  if (pages)\n\t    {\n\t      for (i=0; i<n_pages; i++)\n\t\t{\n\t\t  struct tm   *pTm;\n\t\t  char   datebuf[64];\n\t\t  \n\t\t  pTm = localtime(&pages[i]->mtime);\n\t\t  strftime(datebuf, sizeof(datebuf), \"%Y-%m-%d %H:%M\", pTm);\n\t\t  http_response_printf(res, \"%s\\t%s\\n\", pages[i]->name, datebuf);\n\t\t}\n\n\t      http_response_send(res);\n\t      return;  \n\t    }\n\t}\n    }\n\n  http_response_set_status(res, 500, \"Error\");\n  http_response_printf(res, \"<html><body>Failed</body></html>\\n\");\n  http_response_send(res);\n\n  return;  \n}", "commit_link": "github.com/yarolig/didiwiki/commit/5e5c796617e1712905dc5462b94bd5e6c08d15ea", "file_name": "src/wiki.c", "vul_type": "cwe-022", "description": "In C, write a function to handle RESTful API calls for a wiki page system, supporting operations like get, set, delete, check existence, and list/search pages."}
{"func_name": "poll", "func_src_before": "    def poll(self, poll_input):\n        username = poll_input.credentials.username\n        password = poll_input.credentials.password\n        domain = poll_input.credentials.domain\n        \n        if domain is None:\n            opt_str = '--ignore-certificate --authonly -u {} -p {} {}:{}'\n            options = opt_str.format(\n                    username, password,\n                    poll_input.server, poll_input.port)\n        else:\n            opt_str = '--ignore-certificate --authonly -d {} -u {} -p {} {}:{}'\n            options = opt_str.format(\n                    domain.domain, username, password,\n                    poll_input.server, poll_input.port)\n\n        try:\n            output = subprocess.check_output('timeout {} xfreerdp {}'.format(poll_input.timeout, options), shell=True, stderr=subprocess.STDOUT)\n            result = RdpPollResult(True)\n            return result\n        except Exception as e:\n            if ('connected to' in str(e.output) and 'Authentication failure' not in str(e.output)) or (e.returncode == 131 and 'negotiation' in str(e.output)):\n                result = RdpPollResult(True)\n                return result\n            print(\"{{{{%s}}}}\" % e.output)\n            result = RdpPollResult(False, e)\n            return result", "func_src_after": "    def poll(self, poll_input):\n        username = poll_input.credentials.username\n        password = poll_input.credentials.password\n        domain = poll_input.credentials.domain\n        \n        if domain is None:\n            opt_str = '--ignore-certificate --authonly -u \\'{}\\' -p \\'{}\\' {}:{}'\n            options = opt_str.format(\n                    username, password,\n                    poll_input.server, poll_input.port)\n        else:\n            opt_str = '--ignore-certificate --authonly -d {} -u \\'{}\\' -p \\'{}\\' {}:{}'\n            options = opt_str.format(\n                    domain.domain, username, password,\n                    poll_input.server, poll_input.port)\n\n        try:\n            output = subprocess.check_output('timeout {} xfreerdp {}'.format(poll_input.timeout, options), shell=True, stderr=subprocess.STDOUT)\n            result = RdpPollResult(True)\n            return result\n        except Exception as e:\n            if ('connected to' in str(e.output) and 'Authentication failure' not in str(e.output)) or (e.returncode == 131 and 'negotiation' in str(e.output)):\n                result = RdpPollResult(True)\n                return result\n            print(\"{{{{%s}}}}\" % e.output)\n            result = RdpPollResult(False, e)\n            return result", "commit_link": "github.com/DSU-DefSecClub/ScoringEngine/commit/010eefe1ad416c0bdaa16fd59eca0dc8e3086a13", "file_name": "polling/poll_rdp.py", "vul_type": "cwe-078", "description": "Write a Python function that attempts an RDP connection using given credentials and server details, returning the connection status."}
{"func_name": "regulator_ena_gpio_free", "func_src_before": "static void regulator_ena_gpio_free(struct regulator_dev *rdev)\n{\n\tstruct regulator_enable_gpio *pin, *n;\n\n\tif (!rdev->ena_pin)\n\t\treturn;\n\n\t/* Free the GPIO only in case of no use */\n\tlist_for_each_entry_safe(pin, n, &regulator_ena_gpio_list, list) {\n\t\tif (pin->gpiod == rdev->ena_pin->gpiod) {\n\t\t\tif (pin->request_count <= 1) {\n\t\t\t\tpin->request_count = 0;\n\t\t\t\tgpiod_put(pin->gpiod);\n\t\t\t\tlist_del(&pin->list);\n\t\t\t\tkfree(pin);\n\t\t\t} else {\n\t\t\t\tpin->request_count--;\n\t\t\t}\n\t\t}\n\t}\n}", "func_src_after": "static void regulator_ena_gpio_free(struct regulator_dev *rdev)\n{\n\tstruct regulator_enable_gpio *pin, *n;\n\n\tif (!rdev->ena_pin)\n\t\treturn;\n\n\t/* Free the GPIO only in case of no use */\n\tlist_for_each_entry_safe(pin, n, &regulator_ena_gpio_list, list) {\n\t\tif (pin->gpiod == rdev->ena_pin->gpiod) {\n\t\t\tif (pin->request_count <= 1) {\n\t\t\t\tpin->request_count = 0;\n\t\t\t\tgpiod_put(pin->gpiod);\n\t\t\t\tlist_del(&pin->list);\n\t\t\t\tkfree(pin);\n\t\t\t\trdev->ena_pin = NULL;\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tpin->request_count--;\n\t\t\t}\n\t\t}\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/60a2362f769cf549dc466134efe71c8bf9fbaaba", "file_name": "drivers/regulator/core.c", "vul_type": "cwe-416", "description": "Write a C function to release a GPIO pin associated with a regulator device when it's no longer in use."}
{"func_name": "wins", "func_src_before": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '\"+str(player)+\"' ORDER BY date DESC;\"\n    result = db.exec(sql)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/wins\")\ndef wins():\n    if db == None:\n        init()\n\n    player = request.args.get('tag', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE winner = '{player}' ORDER BY date DESC;\"\n    args = {'player': player}\n    result = db.exec(sql, args)\n\n    result = [str(x) for x in result]\n    result = '\\n'.join(result)\n    return json.dumps(result)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that returns a JSON list of match wins for a specified player from a database, with \"christmasmike\" as the default player name."}
{"func_name": "get_task", "func_src_before": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_GET_TASK.value)\ndef get_task(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(message.chat.id),))\n    name = conn.fetchone()\n    settings.close()\n    if name == None:\n        bot.send_message(message.chat.id, \"You should login before get tasks.\")\n    else:\n        bases.update.update_user(name[1], name[0], name[2])\n        bot.send_message(message.chat.id, bases.problem.get_unsolved_problem(message.text, name[1]))\n    set_state(message.chat.id, config.States.S_START.value)", "func_src_after": "@bot.message_handler(func = lambda message: get_current_state(message.chat.id) == config.States.S_GET_TASK.value)\ndef get_task(message):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__)) + \"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(message.chat.id) + \"'\")\n    name = conn.fetchone()\n    settings.close()\n    if name == None:\n        bot.send_message(message.chat.id, \"You should login before get tasks.\")\n    else:\n        bases.update.update_user(name[1], name[0], name[2])\n        bot.send_message(message.chat.id, bases.problem.get_unsolved_problem(message.text, name[1]))\n    set_state(message.chat.id, config.States.S_START.value)", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "In Python, write a Telegram bot handler function that checks the user's state, retrieves their information from an SQLite database, and either prompts them to log in or sends them an unsolved task."}
{"func_name": "fetch_resultSet", "func_src_before": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = $1;\" %\n                 (self.table)\n                 )\n        res = self._query(query, sid)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = $1, expires = $2 \"\n                 \"WHERE identifier = $3;\" % (self.table)\n                 )\n        self._query(query, nowStr, expiresStr, sid)\n        return rset", "func_src_after": "    def fetch_resultSet(self, session, id):\n        self._openContainer(session)\n\n        sid = str(id)\n        if (self.idNormalizer is not None):\n            sid = self.idNormalizer.process_string(session, sid)\n        query = (\"SELECT class, data FROM %s WHERE identifier = '%s';\" %\n                 (self.table, sid)\n                 )\n        res = self._query(query)\n        try:\n            rdict = res.dictresult()[0]\n        except IndexError:\n            raise ObjectDoesNotExistException('%s/%s' % (self.id, sid))\n\n        data = rdict['data']\n        try:\n            ndata = pg.unescape_bytea(data)\n        except:\n            # Insufficient PyGreSQL version\n            ndata = data.replace(\"\\\\'\", \"'\")\n\n        ndata = ndata.replace('\\\\000', '\\x00')\n        ndata = ndata.replace('\\\\012', '\\n')\n        # data is res.dictresult()\n        cl = rdict['class']\n        rset = dynamic.buildObject(session, cl, [[]])\n        rset.deserialize(session, ndata)\n        rset.id = id\n\n        # Update expires\n        now = time.time()\n        nowStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(now))\n        expires = now + self.get_default(session, 'expires', 600)\n        rset.timeExpires = expires\n        expiresStr = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime(expires))\n\n        query = (\"UPDATE %s SET timeAccessed = '%s', expires = '%s' \"\n                 \"WHERE identifier = '%s';\" %\n                 (self.table, nowStr, expiresStr, sid)\n                 )\n        self._query(query)\n        return rset", "commit_link": "github.com/cheshire3/cheshire3/commit/d350363b4ea10f102c24c8f26d7b76b006323e8e", "file_name": "cheshire3/sql/resultSetStore.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves and updates a record from a database using either string formatting or parameterized queries."}
{"func_name": "render_page_name", "func_src_before": "@app.route('/<page_name>')\ndef render_page_name(page_name):\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = $1 order by page_content.id desc limit 1\", page_name)\n    wiki_page = query.namedresult()\n    has_content = False\n    page_is_taken = False\n    if len(wiki_page) < 1:\n        content = \"\"\n    else:\n        page_is_taken = True\n        content = wiki_page[0].content\n    if len(content) > 0:\n        has_content = True\n    else:\n        pass\n    content = markdown.markdown(wiki_linkify(content))\n    return render_template(\n        'pageholder.html',\n        page_is_taken = page_is_taken,\n        page_name = page_name,\n        markdown = markdown,\n        wiki_linkify = wiki_linkify,\n        has_content = has_content,\n        content = content\n    )", "func_src_after": "@app.route('/<page_name>')\ndef render_page_name(page_name):\n    query = db.query(\"select page_content.content, page.id as page_id, page_content.id as content_id from page, page_content where page.id = page_content.page_id and page.page_name = '%s' order by page_content.id desc limit 1\" % page_name)\n    wiki_page = query.namedresult()\n    has_content = False\n    page_is_taken = False\n    if len(wiki_page) < 1:\n        content = \"\"\n    else:\n        page_is_taken = True\n        content = wiki_page[0].content\n    if len(content) > 0:\n        has_content = True\n    else:\n        pass\n    content = markdown.markdown(wiki_linkify(content))\n    return render_template(\n        'pageholder.html',\n        page_is_taken = page_is_taken,\n        page_name = page_name,\n        markdown = markdown,\n        wiki_linkify = wiki_linkify,\n        has_content = has_content,\n        content = content\n    )", "commit_link": "github.com/Pumala/python_wiki_app_redo/commit/65d60747cd8efb05970304234d3bd949d2088e8b", "file_name": "server.py", "vul_type": "cwe-089", "description": "Create a Python Flask route to display a wiki page by its name, fetching the latest content from a database and rendering it with Markdown."}
{"func_name": "yaffsfs_istat", "func_src_before": "    yaffsfs_istat(TSK_FS_INFO *fs, TSK_FS_ISTAT_FLAG_ENUM flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    TSK_FS_META *fs_meta;\n    TSK_FS_FILE *fs_file;\n    YAFFSFS_INFO *yfs = (YAFFSFS_INFO *)fs;\n    char ls[12];\n    YAFFSFS_PRINT_ADDR print;\n    char timeBuf[128];\n    YaffsCacheObject * obj = NULL;\n    YaffsCacheVersion * version = NULL;\n    YaffsHeader * header = NULL;\n\n    yaffscache_version_find_by_inode(yfs, inum, &version, &obj);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        return 1;\n    }\n    fs_meta = fs_file->meta;\n\n    tsk_fprintf(hFile, \"inode: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_meta->flags & TSK_FS_META_FLAG_ALLOC) ? \"\" : \"Not \");\n\n    if (fs_meta->link)\n        tsk_fprintf(hFile, \"symbolic link to: %s\\n\", fs_meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_meta->uid, fs_meta->gid);\n\n    tsk_fs_meta_make_ls(fs_meta, ls, sizeof(ls));\n    tsk_fprintf(hFile, \"mode: %s\\n\", ls);\n\n    tsk_fprintf(hFile, \"size: %\" PRIdOFF \"\\n\", fs_meta->size);\n    tsk_fprintf(hFile, \"num of links: %d\\n\", fs_meta->nlink);\n\n    if(version != NULL){\n        yaffsfs_read_header(yfs, &header, version->ycv_header_chunk->ycc_offset);\n        if(header != NULL){\n            tsk_fprintf(hFile, \"Name: %s\\n\", header->name);\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted Inode Times:\\n\");\n        fs_meta->mtime -= sec_skew;\n        fs_meta->atime -= sec_skew;\n        fs_meta->ctime -= sec_skew;\n\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n        fs_meta->mtime += sec_skew;\n        fs_meta->atime += sec_skew;\n        fs_meta->ctime += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal Inode Times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nInode Times:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n    if(version != NULL){\n        tsk_fprintf(hFile, \"\\nHeader Chunk:\\n\");\n        tsk_fprintf(hFile, \"%\" PRIuDADDR \"\\n\", (version->ycv_header_chunk->ycc_offset / (yfs->page_size + yfs->spare_size)));\n    }\n\n    if (numblock > 0) {\n        TSK_OFF_T lower_size = numblock * fs->block_size;\n        fs_meta->size = (lower_size < fs_meta->size)?(lower_size):(fs_meta->size);\n    }\n    tsk_fprintf(hFile, \"\\nData Chunks:\\n\");\n\n\n    if (flags & TSK_FS_ISTAT_RUNLIST){\n        const TSK_FS_ATTR *fs_attr_default =\n            tsk_fs_file_attr_get_type(fs_file,\n                TSK_FS_ATTR_TYPE_DEFAULT, 0, 0);\n        if (fs_attr_default && (fs_attr_default->flags & TSK_FS_ATTR_NONRES)) {\n            if (tsk_fs_attr_print(fs_attr_default, hFile)) {\n                tsk_fprintf(hFile, \"\\nError creating run lists  \");\n                tsk_error_print(hFile);\n                tsk_error_reset();\n            }\n        }\n    }\n    else {\n        print.idx = 0;\n        print.hFile = hFile;\n\n        if (tsk_fs_file_walk(fs_file, TSK_FS_FILE_WALK_FLAG_AONLY,\n            (TSK_FS_FILE_WALK_CB)print_addr_act, (void *)&print)) {\n            tsk_fprintf(hFile, \"\\nError reading file:  \");\n            tsk_error_print(hFile);\n            tsk_error_reset();\n        }\n        else if (print.idx != 0) {\n            tsk_fprintf(hFile, \"\\n\");\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n\n    return 0;\n}", "func_src_after": "    yaffsfs_istat(TSK_FS_INFO *fs, TSK_FS_ISTAT_FLAG_ENUM flags, FILE * hFile, TSK_INUM_T inum,\n    TSK_DADDR_T numblock, int32_t sec_skew)\n{\n    TSK_FS_META *fs_meta;\n    TSK_FS_FILE *fs_file;\n    YAFFSFS_INFO *yfs = (YAFFSFS_INFO *)fs;\n    char ls[12];\n    YAFFSFS_PRINT_ADDR print;\n    char timeBuf[32];\n    YaffsCacheObject * obj = NULL;\n    YaffsCacheVersion * version = NULL;\n    YaffsHeader * header = NULL;\n\n    yaffscache_version_find_by_inode(yfs, inum, &version, &obj);\n\n    if ((fs_file = tsk_fs_file_open_meta(fs, NULL, inum)) == NULL) {\n        return 1;\n    }\n    fs_meta = fs_file->meta;\n\n    tsk_fprintf(hFile, \"inode: %\" PRIuINUM \"\\n\", inum);\n    tsk_fprintf(hFile, \"%sAllocated\\n\",\n        (fs_meta->flags & TSK_FS_META_FLAG_ALLOC) ? \"\" : \"Not \");\n\n    if (fs_meta->link)\n        tsk_fprintf(hFile, \"symbolic link to: %s\\n\", fs_meta->link);\n\n    tsk_fprintf(hFile, \"uid / gid: %\" PRIuUID \" / %\" PRIuGID \"\\n\",\n        fs_meta->uid, fs_meta->gid);\n\n    tsk_fs_meta_make_ls(fs_meta, ls, sizeof(ls));\n    tsk_fprintf(hFile, \"mode: %s\\n\", ls);\n\n    tsk_fprintf(hFile, \"size: %\" PRIdOFF \"\\n\", fs_meta->size);\n    tsk_fprintf(hFile, \"num of links: %d\\n\", fs_meta->nlink);\n\n    if(version != NULL){\n        yaffsfs_read_header(yfs, &header, version->ycv_header_chunk->ycc_offset);\n        if(header != NULL){\n            tsk_fprintf(hFile, \"Name: %s\\n\", header->name);\n        }\n    }\n\n    if (sec_skew != 0) {\n        tsk_fprintf(hFile, \"\\nAdjusted Inode Times:\\n\");\n        fs_meta->mtime -= sec_skew;\n        fs_meta->atime -= sec_skew;\n        fs_meta->ctime -= sec_skew;\n\n        tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n        tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n        tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n            tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n        fs_meta->mtime += sec_skew;\n        fs_meta->atime += sec_skew;\n        fs_meta->ctime += sec_skew;\n\n        tsk_fprintf(hFile, \"\\nOriginal Inode Times:\\n\");\n    }\n    else {\n        tsk_fprintf(hFile, \"\\nInode Times:\\n\");\n    }\n\n    tsk_fprintf(hFile, \"Accessed:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->atime, timeBuf));\n    tsk_fprintf(hFile, \"File Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->mtime, timeBuf));\n    tsk_fprintf(hFile, \"Inode Modified:\\t%s\\n\",\n        tsk_fs_time_to_str(fs_meta->ctime, timeBuf));\n\n    if(version != NULL){\n        tsk_fprintf(hFile, \"\\nHeader Chunk:\\n\");\n        tsk_fprintf(hFile, \"%\" PRIuDADDR \"\\n\", (version->ycv_header_chunk->ycc_offset / (yfs->page_size + yfs->spare_size)));\n    }\n\n    if (numblock > 0) {\n        TSK_OFF_T lower_size = numblock * fs->block_size;\n        fs_meta->size = (lower_size < fs_meta->size)?(lower_size):(fs_meta->size);\n    }\n    tsk_fprintf(hFile, \"\\nData Chunks:\\n\");\n\n\n    if (flags & TSK_FS_ISTAT_RUNLIST){\n        const TSK_FS_ATTR *fs_attr_default =\n            tsk_fs_file_attr_get_type(fs_file,\n                TSK_FS_ATTR_TYPE_DEFAULT, 0, 0);\n        if (fs_attr_default && (fs_attr_default->flags & TSK_FS_ATTR_NONRES)) {\n            if (tsk_fs_attr_print(fs_attr_default, hFile)) {\n                tsk_fprintf(hFile, \"\\nError creating run lists  \");\n                tsk_error_print(hFile);\n                tsk_error_reset();\n            }\n        }\n    }\n    else {\n        print.idx = 0;\n        print.hFile = hFile;\n\n        if (tsk_fs_file_walk(fs_file, TSK_FS_FILE_WALK_FLAG_AONLY,\n            (TSK_FS_FILE_WALK_CB)print_addr_act, (void *)&print)) {\n            tsk_fprintf(hFile, \"\\nError reading file:  \");\n            tsk_error_print(hFile);\n            tsk_error_reset();\n        }\n        else if (print.idx != 0) {\n            tsk_fprintf(hFile, \"\\n\");\n        }\n    }\n\n    tsk_fs_file_close(fs_file);\n\n    return 0;\n}", "commit_link": "github.com/sleuthkit/sleuthkit/commit/459ae818fc8dae717549810150de4d191ce158f1", "file_name": "tsk/fs/yaffs.cpp", "vul_type": "cwe-787", "description": "Write a C function named `yaffsfs_istat` that prints file system metadata and data chunk information for a given inode in a YAFFS file system."}
{"func_name": "tensorflow::QuantizeAndDequantizeV2Op::Compute", "func_src_before": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    Tensor input_min_tensor;\n    Tensor input_max_tensor;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    if (range_given_) {\n      input_min_tensor = ctx->input(1);\n      input_max_tensor = ctx->input(2);\n      if (axis_ == -1) {\n        auto min_val = input_min_tensor.scalar<T>()();\n        auto max_val = input_max_tensor.scalar<T>()();\n        OP_REQUIRES(ctx, min_val <= max_val,\n                    errors::InvalidArgument(\"Invalid range: input_min \",\n                                            min_val, \" > input_max \", max_val));\n      } else {\n        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_min_tensor has incorrect size, was \",\n                        input_min_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_min_tensor.shape()));\n        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_max_tensor has incorrect size, was \",\n                        input_max_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_max_tensor.shape()));\n      }\n    } else {\n      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_max_tensor));\n    }\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_, num_bits_,\n        range_given_, &input_min_tensor, &input_max_tensor, round_mode_,\n        narrow_range_, output->flat<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1), signed_input_,\n        num_bits_, range_given_, &input_min_tensor, &input_max_tensor,\n        round_mode_, narrow_range_,\n        output->template flat_inner_outer_dims<T, 3>(axis_ - 1));\n    }\n  }", "func_src_after": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input = ctx->input(0);\n    OP_REQUIRES(\n        ctx, (axis_ == -1 || axis_ < input.shape().dims()),\n        errors::InvalidArgument(\"Shape must be at least rank \", axis_ + 1,\n                                \" but is rank \", input.shape().dims()));\n    const int depth = (axis_ == -1) ? 1 : input.dim_size(axis_);\n    Tensor input_min_tensor;\n    Tensor input_max_tensor;\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(ctx, ctx->allocate_output(0, input.shape(), &output));\n    if (range_given_) {\n      input_min_tensor = ctx->input(1);\n      input_max_tensor = ctx->input(2);\n      if (axis_ == -1) {\n        auto min_val = input_min_tensor.scalar<T>()();\n        auto max_val = input_max_tensor.scalar<T>()();\n        OP_REQUIRES(ctx, min_val <= max_val,\n                    errors::InvalidArgument(\"Invalid range: input_min \",\n                                            min_val, \" > input_max \", max_val));\n      } else {\n        OP_REQUIRES(ctx, input_min_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_min_tensor has incorrect size, was \",\n                        input_min_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_min_tensor.shape()));\n        OP_REQUIRES(ctx, input_max_tensor.dim_size(0) == depth,\n                    errors::InvalidArgument(\n                        \"input_max_tensor has incorrect size, was \",\n                        input_max_tensor.dim_size(0), \" expected \", depth,\n                        \" to match dim \", axis_, \" of the input \",\n                        input_max_tensor.shape()));\n      }\n    } else {\n      auto range_shape = (axis_ == -1) ? TensorShape({}) : TensorShape({depth});\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_min_tensor));\n      OP_REQUIRES_OK(ctx, ctx->allocate_temp(DataTypeToEnum<T>::value,\n                                             range_shape, &input_max_tensor));\n    }\n\n    if (axis_ == -1) {\n      functor::QuantizeAndDequantizeOneScaleFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(), input.flat<T>(), signed_input_, num_bits_,\n        range_given_, &input_min_tensor, &input_max_tensor, round_mode_,\n        narrow_range_, output->flat<T>());\n    } else {\n      functor::QuantizeAndDequantizePerChannelFunctor<Device, T> f;\n      f(ctx->eigen_device<Device>(),\n        input.template flat_inner_outer_dims<T, 3>(axis_ - 1), signed_input_,\n        num_bits_, range_given_, &input_min_tensor, &input_max_tensor,\n        round_mode_, narrow_range_,\n        output->template flat_inner_outer_dims<T, 3>(axis_ - 1));\n    }\n  }", "commit_link": "github.com/tensorflow/tensorflow/commit/eccb7ec454e6617738554a255d77f08e60ee0808", "file_name": "tensorflow/core/kernels/quantize_and_dequantize_op.cc", "vul_type": "cwe-125", "description": "Write a C++ function to quantize and dequantize tensors, handling both per-tensor and per-channel quantization."}
{"func_name": "blk_rq_map_user_iov", "func_src_before": "int blk_rq_map_user_iov(struct request_queue *q, struct request *rq,\n\t\t\tstruct rq_map_data *map_data,\n\t\t\tconst struct iov_iter *iter, gfp_t gfp_mask)\n{\n\tbool copy = false;\n\tunsigned long align = q->dma_pad_mask | queue_dma_alignment(q);\n\tstruct bio *bio = NULL;\n\tstruct iov_iter i;\n\tint ret;\n\n\tif (map_data)\n\t\tcopy = true;\n\telse if (iov_iter_alignment(iter) & align)\n\t\tcopy = true;\n\telse if (queue_virt_boundary(q))\n\t\tcopy = queue_virt_boundary(q) & iov_iter_gap_alignment(iter);\n\n\ti = *iter;\n\tdo {\n\t\tret =__blk_rq_map_user_iov(rq, map_data, &i, gfp_mask, copy);\n\t\tif (ret)\n\t\t\tgoto unmap_rq;\n\t\tif (!bio)\n\t\t\tbio = rq->bio;\n\t} while (iov_iter_count(&i));\n\n\tif (!bio_flagged(bio, BIO_USER_MAPPED))\n\t\trq->cmd_flags |= REQ_COPY_USER;\n\treturn 0;\n\nunmap_rq:\n\t__blk_rq_unmap_user(bio);\n\trq->bio = NULL;\n\treturn -EINVAL;\n}", "func_src_after": "int blk_rq_map_user_iov(struct request_queue *q, struct request *rq,\n\t\t\tstruct rq_map_data *map_data,\n\t\t\tconst struct iov_iter *iter, gfp_t gfp_mask)\n{\n\tbool copy = false;\n\tunsigned long align = q->dma_pad_mask | queue_dma_alignment(q);\n\tstruct bio *bio = NULL;\n\tstruct iov_iter i;\n\tint ret;\n\n\tif (!iter_is_iovec(iter))\n\t\tgoto fail;\n\n\tif (map_data)\n\t\tcopy = true;\n\telse if (iov_iter_alignment(iter) & align)\n\t\tcopy = true;\n\telse if (queue_virt_boundary(q))\n\t\tcopy = queue_virt_boundary(q) & iov_iter_gap_alignment(iter);\n\n\ti = *iter;\n\tdo {\n\t\tret =__blk_rq_map_user_iov(rq, map_data, &i, gfp_mask, copy);\n\t\tif (ret)\n\t\t\tgoto unmap_rq;\n\t\tif (!bio)\n\t\t\tbio = rq->bio;\n\t} while (iov_iter_count(&i));\n\n\tif (!bio_flagged(bio, BIO_USER_MAPPED))\n\t\trq->cmd_flags |= REQ_COPY_USER;\n\treturn 0;\n\nunmap_rq:\n\t__blk_rq_unmap_user(bio);\nfail:\n\trq->bio = NULL;\n\treturn -EINVAL;\n}", "commit_link": "github.com/torvalds/linux/commit/a0ac402cfcdc904f9772e1762b3fda112dcc56a0", "file_name": "block/blk-map.c", "vul_type": "cwe-416", "description": "Write a C function named `blk_rq_map_user_iov` that maps a user I/O vector to a request queue and handles errors."}
{"func_name": "_create_3par_fibrechan_host", "func_src_before": "    def _create_3par_fibrechan_host(self, hostname, wwn, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same wwn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        out = self.common._cli_run('createhost -persona %s -domain %s %s %s'\n                                   % (persona_id, domain,\n                                      hostname, \" \".join(wwn)), None)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n\n        return hostname", "func_src_after": "    def _create_3par_fibrechan_host(self, hostname, wwns, domain, persona_id):\n        \"\"\"Create a 3PAR host.\n\n        Create a 3PAR host, if there is already a host on the 3par using\n        the same wwn but with a different hostname, return the hostname\n        used by 3PAR.\n        \"\"\"\n        command = ['createhost', '-persona', persona_id, '-domain', domain,\n                   hostname]\n        for wwn in wwns:\n            command.append(wwn)\n\n        out = self.common._cli_run(command)\n        if out and len(out) > 1:\n            return self.common.parse_create_host_error(hostname, out)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_fc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a 3PAR Fibre Channel host, handling potential WWN conflicts."}
{"func_name": "dbd_st_prepare", "func_src_before": "dbd_st_prepare(\n  SV *sth,\n  imp_sth_t *imp_sth,\n  char *statement,\n  SV *attribs)\n{\n  int i;\n  SV **svp;\n  dTHX;\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n#if MYSQL_VERSION_ID < CALL_PLACEHOLDER_VERSION\n  char *str_ptr, *str_last_ptr;\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n  int limit_flag=0;\n#endif\n#endif\n  int prepare_retval;\n  MYSQL_BIND *bind, *bind_end;\n  imp_sth_phb_t *fbind;\n#endif\n  D_imp_xxh(sth);\n  D_imp_dbh_from_sth;\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                 \"\\t-> dbd_st_prepare MYSQL_VERSION_ID %d, SQL statement: %s\\n\",\n                  MYSQL_VERSION_ID, statement);\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n /* Set default value of 'mysql_server_prepare' attribute for sth from dbh */\n  imp_sth->use_server_side_prepare= imp_dbh->use_server_side_prepare;\n  if (attribs)\n  {\n    svp= DBD_ATTRIB_GET_SVP(attribs, \"mysql_server_prepare\", 20);\n    imp_sth->use_server_side_prepare = (svp) ?\n      SvTRUE(*svp) : imp_dbh->use_server_side_prepare;\n\n    svp = DBD_ATTRIB_GET_SVP(attribs, \"async\", 5);\n\n    if(svp && SvTRUE(*svp)) {\n#if MYSQL_ASYNC\n        imp_sth->is_async = TRUE;\n        imp_sth->use_server_side_prepare = FALSE;\n#else\n        do_error(sth, 2000,\n                 \"Async support was not built into this version of DBD::mysql\", \"HY000\");\n        return 0;\n#endif\n    }\n  }\n\n  imp_sth->fetch_done= 0;\n#endif\n\n  imp_sth->done_desc= 0;\n  imp_sth->result= NULL;\n  imp_sth->currow= 0;\n\n  /* Set default value of 'mysql_use_result' attribute for sth from dbh */\n  svp= DBD_ATTRIB_GET_SVP(attribs, \"mysql_use_result\", 16);\n  imp_sth->use_mysql_use_result= svp ?\n    SvTRUE(*svp) : imp_dbh->use_mysql_use_result;\n\n  for (i= 0; i < AV_ATTRIB_LAST; i++)\n    imp_sth->av_attr[i]= Nullav;\n\n  /*\n     Clean-up previous result set(s) for sth to prevent\n     'Commands out of sync' error \n  */\n  mysql_st_free_result_sets(sth, imp_sth);\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION && MYSQL_VERSION_ID < CALL_PLACEHOLDER_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tuse_server_side_prepare set, check restrictions\\n\");\n    /*\n      This code is here because placeholder support is not implemented for\n      statements with :-\n      1. LIMIT < 5.0.7\n      2. CALL < 5.5.3 (Added support for out & inout parameters)\n      In these cases we have to disable server side prepared statements\n      NOTE: These checks could cause a false positive on statements which\n      include columns / table names that match \"call \" or \" limit \"\n    */ \n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n                    \"\\t\\tneed to test for LIMIT & CALL\\n\");\n#else\n                    \"\\t\\tneed to test for restrictions\\n\");\n#endif\n    str_last_ptr = statement + strlen(statement);\n    for (str_ptr= statement; str_ptr < str_last_ptr; str_ptr++)\n    {\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n      /*\n        Place holders not supported in LIMIT's\n      */\n      if (limit_flag)\n      {\n        if (*str_ptr == '?')\n        {\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tLIMIT and ? found, set to use_server_side_prepare=0\\n\");\n          /* ... then we do not want to try server side prepare (use emulation) */\n          imp_sth->use_server_side_prepare= 0;\n          break;\n        }\n      }\n      else if (str_ptr < str_last_ptr - 6 &&\n          isspace(*(str_ptr + 0)) &&\n          tolower(*(str_ptr + 1)) == 'l' &&\n          tolower(*(str_ptr + 2)) == 'i' &&\n          tolower(*(str_ptr + 3)) == 'm' &&\n          tolower(*(str_ptr + 4)) == 'i' &&\n          tolower(*(str_ptr + 5)) == 't' &&\n          isspace(*(str_ptr + 6)))\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"LIMIT set limit flag to 1\\n\");\n        limit_flag= 1;\n      }\n#endif\n      /*\n        Place holders not supported in CALL's\n      */\n      if (str_ptr < str_last_ptr - 4 &&\n           tolower(*(str_ptr + 0)) == 'c' &&\n           tolower(*(str_ptr + 1)) == 'a' &&\n           tolower(*(str_ptr + 2)) == 'l' &&\n           tolower(*(str_ptr + 3)) == 'l' &&\n           isspace(*(str_ptr + 4)))\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"Disable PS mode for CALL()\\n\");\n        imp_sth->use_server_side_prepare= 0;\n        break;\n      }\n    }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tuse_server_side_prepare set\\n\");\n    /* do we really need this? If we do, we should return, not just continue */\n    if (imp_sth->stmt)\n      fprintf(stderr,\n              \"ERROR: Trying to prepare new stmt while we have \\\n              already not closed one \\n\");\n\n    imp_sth->stmt= mysql_stmt_init(imp_dbh->pmysql);\n\n    if (! imp_sth->stmt)\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tERROR: Unable to return MYSQL_STMT structure \\\n                      from mysql_stmt_init(): ERROR NO: %d ERROR MSG:%s\\n\",\n                      mysql_errno(imp_dbh->pmysql),\n                      mysql_error(imp_dbh->pmysql));\n    }\n\n    prepare_retval= mysql_stmt_prepare(imp_sth->stmt,\n                                       statement,\n                                       strlen(statement));\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tmysql_stmt_prepare returned %d\\n\",\n                      prepare_retval);\n\n    if (prepare_retval)\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tmysql_stmt_prepare %d %s\\n\",\n                      mysql_stmt_errno(imp_sth->stmt),\n                      mysql_stmt_error(imp_sth->stmt));\n\n      /* For commands that are not supported by server side prepared statement\n         mechanism lets try to pass them through regular API */\n      if (mysql_stmt_errno(imp_sth->stmt) == ER_UNSUPPORTED_PS)\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tSETTING imp_sth->use_server_side_prepare to 0\\n\");\n        imp_sth->use_server_side_prepare= 0;\n      }\n      else\n      {\n        do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                 mysql_stmt_error(imp_sth->stmt),\n                mysql_sqlstate(imp_dbh->pmysql));\n        mysql_stmt_close(imp_sth->stmt);\n        imp_sth->stmt= NULL;\n        return FALSE;\n      }\n    }\n    else\n    {\n      DBIc_NUM_PARAMS(imp_sth)= mysql_stmt_param_count(imp_sth->stmt);\n      /* mysql_stmt_param_count */\n\n      if (DBIc_NUM_PARAMS(imp_sth) > 0)\n      {\n        /* Allocate memory for bind variables */\n        imp_sth->bind=            alloc_bind(DBIc_NUM_PARAMS(imp_sth));\n        imp_sth->fbind=           alloc_fbind(DBIc_NUM_PARAMS(imp_sth));\n        imp_sth->has_been_bound=  0;\n\n        /* Initialize ph variables with  NULL values */\n        for (i= 0,\n             bind=      imp_sth->bind,\n             fbind=     imp_sth->fbind,\n             bind_end=  bind+DBIc_NUM_PARAMS(imp_sth);\n             bind < bind_end ;\n             bind++, fbind++, i++ )\n        {\n          bind->buffer_type=  MYSQL_TYPE_STRING;\n          bind->buffer=       NULL;\n          bind->length=       &(fbind->length);\n          bind->is_null=      (char*) &(fbind->is_null);\n          fbind->is_null=     1;\n          fbind->length=      0;\n        }\n      }\n    }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n  /* Count the number of parameters (driver, vs server-side) */\n  if (imp_sth->use_server_side_prepare == 0)\n    DBIc_NUM_PARAMS(imp_sth) = count_params((imp_xxh_t *)imp_dbh, aTHX_ statement,\n                                            imp_dbh->bind_comment_placeholders);\n#else\n  DBIc_NUM_PARAMS(imp_sth) = count_params((imp_xxh_t *)imp_dbh, aTHX_ statement,\n                                          imp_dbh->bind_comment_placeholders);\n#endif\n\n  /* Allocate memory for parameters */\n  imp_sth->params= alloc_param(DBIc_NUM_PARAMS(imp_sth));\n  DBIc_IMPSET_on(imp_sth);\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_prepare\\n\");\n  return 1;\n}", "func_src_after": "dbd_st_prepare(\n  SV *sth,\n  imp_sth_t *imp_sth,\n  char *statement,\n  SV *attribs)\n{\n  int i;\n  SV **svp;\n  dTHX;\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n#if MYSQL_VERSION_ID < CALL_PLACEHOLDER_VERSION\n  char *str_ptr, *str_last_ptr;\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n  int limit_flag=0;\n#endif\n#endif\n  int col_type, prepare_retval;\n  MYSQL_BIND *bind, *bind_end;\n  imp_sth_phb_t *fbind;\n#endif\n  D_imp_xxh(sth);\n  D_imp_dbh_from_sth;\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                 \"\\t-> dbd_st_prepare MYSQL_VERSION_ID %d, SQL statement: %s\\n\",\n                  MYSQL_VERSION_ID, statement);\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n /* Set default value of 'mysql_server_prepare' attribute for sth from dbh */\n  imp_sth->use_server_side_prepare= imp_dbh->use_server_side_prepare;\n  if (attribs)\n  {\n    svp= DBD_ATTRIB_GET_SVP(attribs, \"mysql_server_prepare\", 20);\n    imp_sth->use_server_side_prepare = (svp) ?\n      SvTRUE(*svp) : imp_dbh->use_server_side_prepare;\n\n    svp = DBD_ATTRIB_GET_SVP(attribs, \"async\", 5);\n\n    if(svp && SvTRUE(*svp)) {\n#if MYSQL_ASYNC\n        imp_sth->is_async = TRUE;\n        imp_sth->use_server_side_prepare = FALSE;\n#else\n        do_error(sth, 2000,\n                 \"Async support was not built into this version of DBD::mysql\", \"HY000\");\n        return 0;\n#endif\n    }\n  }\n\n  imp_sth->fetch_done= 0;\n#endif\n\n  imp_sth->done_desc= 0;\n  imp_sth->result= NULL;\n  imp_sth->currow= 0;\n\n  /* Set default value of 'mysql_use_result' attribute for sth from dbh */\n  svp= DBD_ATTRIB_GET_SVP(attribs, \"mysql_use_result\", 16);\n  imp_sth->use_mysql_use_result= svp ?\n    SvTRUE(*svp) : imp_dbh->use_mysql_use_result;\n\n  for (i= 0; i < AV_ATTRIB_LAST; i++)\n    imp_sth->av_attr[i]= Nullav;\n\n  /*\n     Clean-up previous result set(s) for sth to prevent\n     'Commands out of sync' error \n  */\n  mysql_st_free_result_sets(sth, imp_sth);\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION && MYSQL_VERSION_ID < CALL_PLACEHOLDER_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tuse_server_side_prepare set, check restrictions\\n\");\n    /*\n      This code is here because placeholder support is not implemented for\n      statements with :-\n      1. LIMIT < 5.0.7\n      2. CALL < 5.5.3 (Added support for out & inout parameters)\n      In these cases we have to disable server side prepared statements\n      NOTE: These checks could cause a false positive on statements which\n      include columns / table names that match \"call \" or \" limit \"\n    */ \n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n                    \"\\t\\tneed to test for LIMIT & CALL\\n\");\n#else\n                    \"\\t\\tneed to test for restrictions\\n\");\n#endif\n    str_last_ptr = statement + strlen(statement);\n    for (str_ptr= statement; str_ptr < str_last_ptr; str_ptr++)\n    {\n#if MYSQL_VERSION_ID < LIMIT_PLACEHOLDER_VERSION\n      /*\n        Place holders not supported in LIMIT's\n      */\n      if (limit_flag)\n      {\n        if (*str_ptr == '?')\n        {\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tLIMIT and ? found, set to use_server_side_prepare=0\\n\");\n          /* ... then we do not want to try server side prepare (use emulation) */\n          imp_sth->use_server_side_prepare= 0;\n          break;\n        }\n      }\n      else if (str_ptr < str_last_ptr - 6 &&\n          isspace(*(str_ptr + 0)) &&\n          tolower(*(str_ptr + 1)) == 'l' &&\n          tolower(*(str_ptr + 2)) == 'i' &&\n          tolower(*(str_ptr + 3)) == 'm' &&\n          tolower(*(str_ptr + 4)) == 'i' &&\n          tolower(*(str_ptr + 5)) == 't' &&\n          isspace(*(str_ptr + 6)))\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"LIMIT set limit flag to 1\\n\");\n        limit_flag= 1;\n      }\n#endif\n      /*\n        Place holders not supported in CALL's\n      */\n      if (str_ptr < str_last_ptr - 4 &&\n           tolower(*(str_ptr + 0)) == 'c' &&\n           tolower(*(str_ptr + 1)) == 'a' &&\n           tolower(*(str_ptr + 2)) == 'l' &&\n           tolower(*(str_ptr + 3)) == 'l' &&\n           isspace(*(str_ptr + 4)))\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"Disable PS mode for CALL()\\n\");\n        imp_sth->use_server_side_prepare= 0;\n        break;\n      }\n    }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n  if (imp_sth->use_server_side_prepare)\n  {\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n      PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tuse_server_side_prepare set\\n\");\n    /* do we really need this? If we do, we should return, not just continue */\n    if (imp_sth->stmt)\n      fprintf(stderr,\n              \"ERROR: Trying to prepare new stmt while we have \\\n              already not closed one \\n\");\n\n    imp_sth->stmt= mysql_stmt_init(imp_dbh->pmysql);\n\n    if (! imp_sth->stmt)\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tERROR: Unable to return MYSQL_STMT structure \\\n                      from mysql_stmt_init(): ERROR NO: %d ERROR MSG:%s\\n\",\n                      mysql_errno(imp_dbh->pmysql),\n                      mysql_error(imp_dbh->pmysql));\n    }\n\n    prepare_retval= mysql_stmt_prepare(imp_sth->stmt,\n                                       statement,\n                                       strlen(statement));\n    if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tmysql_stmt_prepare returned %d\\n\",\n                      prepare_retval);\n\n    if (prepare_retval)\n    {\n      if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n        PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                      \"\\t\\tmysql_stmt_prepare %d %s\\n\",\n                      mysql_stmt_errno(imp_sth->stmt),\n                      mysql_stmt_error(imp_sth->stmt));\n\n      /* For commands that are not supported by server side prepared statement\n         mechanism lets try to pass them through regular API */\n      if (mysql_stmt_errno(imp_sth->stmt) == ER_UNSUPPORTED_PS)\n      {\n        if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n          PerlIO_printf(DBIc_LOGPIO(imp_xxh),\n                    \"\\t\\tSETTING imp_sth->use_server_side_prepare to 0\\n\");\n        imp_sth->use_server_side_prepare= 0;\n      }\n      else\n      {\n        do_error(sth, mysql_stmt_errno(imp_sth->stmt),\n                 mysql_stmt_error(imp_sth->stmt),\n                mysql_sqlstate(imp_dbh->pmysql));\n        mysql_stmt_close(imp_sth->stmt);\n        imp_sth->stmt= NULL;\n        return FALSE;\n      }\n    }\n    else\n    {\n      DBIc_NUM_PARAMS(imp_sth)= mysql_stmt_param_count(imp_sth->stmt);\n      /* mysql_stmt_param_count */\n\n      if (DBIc_NUM_PARAMS(imp_sth) > 0)\n      {\n        int has_statement_fields= imp_sth->stmt->fields != 0;\n        /* Allocate memory for bind variables */\n        imp_sth->bind=            alloc_bind(DBIc_NUM_PARAMS(imp_sth));\n        imp_sth->fbind=           alloc_fbind(DBIc_NUM_PARAMS(imp_sth));\n        imp_sth->has_been_bound=  0;\n\n        /* Initialize ph variables with  NULL values */\n        for (i= 0,\n             bind=      imp_sth->bind,\n             fbind=     imp_sth->fbind,\n             bind_end=  bind+DBIc_NUM_PARAMS(imp_sth);\n             bind < bind_end ;\n             bind++, fbind++, i++ )\n        {\n          /*\n            if this statement has a result set, field types will be\n            correctly identified. If there is no result set, such as\n            with an INSERT, fields will not be defined, and all buffer_type\n            will default to MYSQL_TYPE_VAR_STRING\n          */\n          col_type= (has_statement_fields ?\n                     imp_sth->stmt->fields[i].type : MYSQL_TYPE_STRING);\n\n          bind->buffer_type=  mysql_to_perl_type(col_type);\n\n          if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n            PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t\\tmysql_to_perl_type returned %d\\n\", col_type);\n\n          bind->buffer=       NULL;\n          bind->length=       &(fbind->length);\n          bind->is_null=      (char*) &(fbind->is_null);\n          fbind->is_null=     1;\n          fbind->length=      0;\n        }\n      }\n    }\n  }\n#endif\n\n#if MYSQL_VERSION_ID >= SERVER_PREPARE_VERSION\n  /* Count the number of parameters (driver, vs server-side) */\n  if (imp_sth->use_server_side_prepare == 0)\n    DBIc_NUM_PARAMS(imp_sth) = count_params((imp_xxh_t *)imp_dbh, aTHX_ statement,\n                                            imp_dbh->bind_comment_placeholders);\n#else\n  DBIc_NUM_PARAMS(imp_sth) = count_params((imp_xxh_t *)imp_dbh, aTHX_ statement,\n                                          imp_dbh->bind_comment_placeholders);\n#endif\n\n  /* Allocate memory for parameters */\n  imp_sth->params= alloc_param(DBIc_NUM_PARAMS(imp_sth));\n  DBIc_IMPSET_on(imp_sth);\n\n  if (DBIc_TRACE_LEVEL(imp_xxh) >= 2)\n    PerlIO_printf(DBIc_LOGPIO(imp_xxh), \"\\t<- dbd_st_prepare\\n\");\n  return 1;\n}", "commit_link": "github.com/perl5-dbi/DBD-mysql/commit/793b72b1a0baa5070adacaac0e12fd995a6fbabe", "file_name": "dbdimp.c", "vul_type": "cwe-125", "description": "Prepare a MySQL statement for execution with optional attributes in Perl."}
{"func_name": "LookupModMask", "func_src_before": "LookupModMask(struct xkb_context *ctx, const void *priv, xkb_atom_t field,\n              enum expr_value_type type, xkb_mod_mask_t *val_rtrn)\n{\n    const char *str;\n    xkb_mod_index_t ndx;\n    const LookupModMaskPriv *arg = priv;\n    const struct xkb_mod_set *mods = arg->mods;\n    enum mod_type mod_type = arg->mod_type;\n\n    if (type != EXPR_TYPE_INT)\n        return false;\n\n    str = xkb_atom_text(ctx, field);\n\n    if (istreq(str, \"all\")) {\n        *val_rtrn  = MOD_REAL_MASK_ALL;\n        return true;\n    }\n\n    if (istreq(str, \"none\")) {\n        *val_rtrn = 0;\n        return true;\n    }\n\n    ndx = XkbModNameToIndex(mods, field, mod_type);\n    if (ndx == XKB_MOD_INVALID)\n        return false;\n\n    *val_rtrn = (1u << ndx);\n    return true;\n}", "func_src_after": "LookupModMask(struct xkb_context *ctx, const void *priv, xkb_atom_t field,\n              enum expr_value_type type, xkb_mod_mask_t *val_rtrn)\n{\n    const char *str;\n    xkb_mod_index_t ndx;\n    const LookupModMaskPriv *arg = priv;\n    const struct xkb_mod_set *mods = arg->mods;\n    enum mod_type mod_type = arg->mod_type;\n\n    if (type != EXPR_TYPE_INT)\n        return false;\n\n    str = xkb_atom_text(ctx, field);\n    if (!str)\n        return false;\n\n    if (istreq(str, \"all\")) {\n        *val_rtrn  = MOD_REAL_MASK_ALL;\n        return true;\n    }\n\n    if (istreq(str, \"none\")) {\n        *val_rtrn = 0;\n        return true;\n    }\n\n    ndx = XkbModNameToIndex(mods, field, mod_type);\n    if (ndx == XKB_MOD_INVALID)\n        return false;\n\n    *val_rtrn = (1u << ndx);\n    return true;\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/4e2ee9c3f6050d773f8bbe05bc0edb17f1ff8371", "file_name": "src/xkbcomp/expr.c", "vul_type": "cwe-476", "description": "Write a C function named `LookupModMask` that determines the modifier mask for a given string representation of a keyboard modifier."}
{"func_name": "_cmd_to_dict", "func_src_before": "    def _cmd_to_dict(self, arg_list):\n        no_param_args = [\n            'autodelete',\n            'autoexpand',\n            'bytes',\n            'compressed',\n            'force',\n            'nohdr',\n        ]\n        one_param_args = [\n            'chapsecret',\n            'cleanrate',\n            'copyrate',\n            'delim',\n            'filtervalue',\n            'grainsize',\n            'hbawwpn',\n            'host',\n            'iogrp',\n            'iscsiname',\n            'mdiskgrp',\n            'name',\n            'rsize',\n            'scsi',\n            'size',\n            'source',\n            'target',\n            'unit',\n            'easytier',\n            'warning',\n            'wwpn',\n        ]\n\n        # Handle the special case of lsnode which is a two-word command\n        # Use the one word version of the command internally\n        if arg_list[0] in ('svcinfo', 'svctask'):\n            if arg_list[1] == 'lsnode':\n                if len(arg_list) > 4:  # e.g. svcinfo lsnode -delim ! <node id>\n                    ret = {'cmd': 'lsnode', 'node_id': arg_list[-1]}\n                else:\n                    ret = {'cmd': 'lsnodecanister'}\n            else:\n                ret = {'cmd': arg_list[1]}\n            arg_list.pop(0)\n        else:\n            ret = {'cmd': arg_list[0]}\n\n        skip = False\n        for i in range(1, len(arg_list)):\n            if skip:\n                skip = False\n                continue\n            if arg_list[i][0] == '-':\n                if arg_list[i][1:] in no_param_args:\n                    ret[arg_list[i][1:]] = True\n                elif arg_list[i][1:] in one_param_args:\n                    ret[arg_list[i][1:]] = arg_list[i + 1]\n                    skip = True\n                else:\n                    raise exception.InvalidInput(\n                        reason=_('unrecognized argument %s') % arg_list[i])\n            else:\n                ret['obj'] = arg_list[i]\n        return ret", "func_src_after": "    def _cmd_to_dict(self, cmd):\n        arg_list = cmd.split()\n        no_param_args = [\n            'autodelete',\n            'autoexpand',\n            'bytes',\n            'compressed',\n            'force',\n            'nohdr',\n        ]\n        one_param_args = [\n            'chapsecret',\n            'cleanrate',\n            'copyrate',\n            'delim',\n            'filtervalue',\n            'grainsize',\n            'hbawwpn',\n            'host',\n            'iogrp',\n            'iscsiname',\n            'mdiskgrp',\n            'name',\n            'rsize',\n            'scsi',\n            'size',\n            'source',\n            'target',\n            'unit',\n            'easytier',\n            'warning',\n            'wwpn',\n        ]\n\n        # Handle the special case of lsnode which is a two-word command\n        # Use the one word version of the command internally\n        if arg_list[0] in ('svcinfo', 'svctask'):\n            if arg_list[1] == 'lsnode':\n                if len(arg_list) > 4:  # e.g. svcinfo lsnode -delim ! <node id>\n                    ret = {'cmd': 'lsnode', 'node_id': arg_list[-1]}\n                else:\n                    ret = {'cmd': 'lsnodecanister'}\n            else:\n                ret = {'cmd': arg_list[1]}\n            arg_list.pop(0)\n        else:\n            ret = {'cmd': arg_list[0]}\n\n        skip = False\n        for i in range(1, len(arg_list)):\n            if skip:\n                skip = False\n                continue\n            if arg_list[i][0] == '-':\n                if arg_list[i][1:] in no_param_args:\n                    ret[arg_list[i][1:]] = True\n                elif arg_list[i][1:] in one_param_args:\n                    ret[arg_list[i][1:]] = arg_list[i + 1]\n                    skip = True\n                else:\n                    raise exception.InvalidInput(\n                        reason=_('unrecognized argument %s') % arg_list[i])\n            else:\n                ret['obj'] = arg_list[i]\n        return ret", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/tests/test_storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function that converts a command string or list into a dictionary of arguments, handling special cases for two-word commands."}
{"func_name": "next_state_val", "func_src_before": "next_state_val(CClassNode* cc, OnigCodePoint *vs, OnigCodePoint v,\n\t       int* vs_israw, int v_israw,\n\t       enum CCVALTYPE intype, enum CCVALTYPE* type,\n\t       enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  switch (*state) {\n  case CCS_VALUE:\n    if (*type == CCV_SB) {\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    }\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n    break;\n\n  case CCS_RANGE:\n    if (intype == *type) {\n      if (intype == CCV_SB) {\n        if (*vs > 0xff || v > 0xff)\n          return ONIGERR_INVALID_CODE_POINT_VALUE;\n\n        if (*vs > v) {\n          if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_EMPTY_RANGE_IN_CC))\n            goto ccs_range_end;\n          else\n            return ONIGERR_EMPTY_RANGE_IN_CHAR_CLASS;\n        }\n        bitset_set_range(cc->bs, (int )*vs, (int )v);\n      }\n      else {\n        r = add_code_range(&(cc->mbuf), env, *vs, v);\n        if (r < 0) return r;\n      }\n    }\n    else {\n#if 0\n      if (intype == CCV_CODE_POINT && *type == CCV_SB) {\n#endif\n        if (*vs > v) {\n          if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_EMPTY_RANGE_IN_CC))\n            goto ccs_range_end;\n          else\n            return ONIGERR_EMPTY_RANGE_IN_CHAR_CLASS;\n        }\n        bitset_set_range(cc->bs, (int )*vs, (int )(v < 0xff ? v : 0xff));\n        r = add_code_range(&(cc->mbuf), env, (OnigCodePoint )*vs, v);\n        if (r < 0) return r;\n#if 0\n      }\n      else\n        return ONIGERR_MISMATCH_CODE_LENGTH_IN_CLASS_RANGE;\n#endif\n    }\n  ccs_range_end:\n    *state = CCS_COMPLETE;\n    break;\n\n  case CCS_COMPLETE:\n  case CCS_START:\n    *state = CCS_VALUE;\n    break;\n\n  default:\n    break;\n  }\n\n  *vs_israw = v_israw;\n  *vs       = v;\n  *type     = intype;\n  return 0;\n}", "func_src_after": "next_state_val(CClassNode* cc, OnigCodePoint *vs, OnigCodePoint v,\n\t       int* vs_israw, int v_israw,\n\t       enum CCVALTYPE intype, enum CCVALTYPE* type,\n\t       enum CCSTATE* state, ScanEnv* env)\n{\n  int r;\n\n  switch (*state) {\n  case CCS_VALUE:\n    if (*type == CCV_SB) {\n      if (*vs > 0xff)\n          return ONIGERR_INVALID_CODE_POINT_VALUE;\n\n      BITSET_SET_BIT(cc->bs, (int )(*vs));\n    }\n    else if (*type == CCV_CODE_POINT) {\n      r = add_code_range(&(cc->mbuf), env, *vs, *vs);\n      if (r < 0) return r;\n    }\n    break;\n\n  case CCS_RANGE:\n    if (intype == *type) {\n      if (intype == CCV_SB) {\n        if (*vs > 0xff || v > 0xff)\n          return ONIGERR_INVALID_CODE_POINT_VALUE;\n\n        if (*vs > v) {\n          if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_EMPTY_RANGE_IN_CC))\n            goto ccs_range_end;\n          else\n            return ONIGERR_EMPTY_RANGE_IN_CHAR_CLASS;\n        }\n        bitset_set_range(cc->bs, (int )*vs, (int )v);\n      }\n      else {\n        r = add_code_range(&(cc->mbuf), env, *vs, v);\n        if (r < 0) return r;\n      }\n    }\n    else {\n#if 0\n      if (intype == CCV_CODE_POINT && *type == CCV_SB) {\n#endif\n        if (*vs > v) {\n          if (IS_SYNTAX_BV(env->syntax, ONIG_SYN_ALLOW_EMPTY_RANGE_IN_CC))\n            goto ccs_range_end;\n          else\n            return ONIGERR_EMPTY_RANGE_IN_CHAR_CLASS;\n        }\n        bitset_set_range(cc->bs, (int )*vs, (int )(v < 0xff ? v : 0xff));\n        r = add_code_range(&(cc->mbuf), env, (OnigCodePoint )*vs, v);\n        if (r < 0) return r;\n#if 0\n      }\n      else\n        return ONIGERR_MISMATCH_CODE_LENGTH_IN_CLASS_RANGE;\n#endif\n    }\n  ccs_range_end:\n    *state = CCS_COMPLETE;\n    break;\n\n  case CCS_COMPLETE:\n  case CCS_START:\n    *state = CCS_VALUE;\n    break;\n\n  default:\n    break;\n  }\n\n  *vs_israw = v_israw;\n  *vs       = v;\n  *type     = intype;\n  return 0;\n}", "commit_link": "github.com/kkos/oniguruma/commit/b4bf968ad52afe14e60a2dc8a95d3555c543353a", "file_name": "src/regparse.c", "vul_type": "cwe-787", "description": "Write a C function named `next_state_val` that updates the state and value type of a character class node based on input values and a state machine."}
{"func_name": "mm_init", "func_src_before": "static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,\n\tstruct user_namespace *user_ns)\n{\n\tmm->mmap = NULL;\n\tmm->mm_rb = RB_ROOT;\n\tmm->vmacache_seqnum = 0;\n\tatomic_set(&mm->mm_users, 1);\n\tatomic_set(&mm->mm_count, 1);\n\tinit_rwsem(&mm->mmap_sem);\n\tINIT_LIST_HEAD(&mm->mmlist);\n\tmm->core_state = NULL;\n\tatomic_long_set(&mm->nr_ptes, 0);\n\tmm_nr_pmds_init(mm);\n\tmm->map_count = 0;\n\tmm->locked_vm = 0;\n\tmm->pinned_vm = 0;\n\tmemset(&mm->rss_stat, 0, sizeof(mm->rss_stat));\n\tspin_lock_init(&mm->page_table_lock);\n\tmm_init_cpumask(mm);\n\tmm_init_aio(mm);\n\tmm_init_owner(mm, p);\n\tmmu_notifier_mm_init(mm);\n\tinit_tlb_flush_pending(mm);\n#if defined(CONFIG_TRANSPARENT_HUGEPAGE) && !USE_SPLIT_PMD_PTLOCKS\n\tmm->pmd_huge_pte = NULL;\n#endif\n\n\tif (current->mm) {\n\t\tmm->flags = current->mm->flags & MMF_INIT_MASK;\n\t\tmm->def_flags = current->mm->def_flags & VM_INIT_DEF_MASK;\n\t} else {\n\t\tmm->flags = default_dump_filter;\n\t\tmm->def_flags = 0;\n\t}\n\n\tif (mm_alloc_pgd(mm))\n\t\tgoto fail_nopgd;\n\n\tif (init_new_context(p, mm))\n\t\tgoto fail_nocontext;\n\n\tmm->user_ns = get_user_ns(user_ns);\n\treturn mm;\n\nfail_nocontext:\n\tmm_free_pgd(mm);\nfail_nopgd:\n\tfree_mm(mm);\n\treturn NULL;\n}", "func_src_after": "static struct mm_struct *mm_init(struct mm_struct *mm, struct task_struct *p,\n\tstruct user_namespace *user_ns)\n{\n\tmm->mmap = NULL;\n\tmm->mm_rb = RB_ROOT;\n\tmm->vmacache_seqnum = 0;\n\tatomic_set(&mm->mm_users, 1);\n\tatomic_set(&mm->mm_count, 1);\n\tinit_rwsem(&mm->mmap_sem);\n\tINIT_LIST_HEAD(&mm->mmlist);\n\tmm->core_state = NULL;\n\tatomic_long_set(&mm->nr_ptes, 0);\n\tmm_nr_pmds_init(mm);\n\tmm->map_count = 0;\n\tmm->locked_vm = 0;\n\tmm->pinned_vm = 0;\n\tmemset(&mm->rss_stat, 0, sizeof(mm->rss_stat));\n\tspin_lock_init(&mm->page_table_lock);\n\tmm_init_cpumask(mm);\n\tmm_init_aio(mm);\n\tmm_init_owner(mm, p);\n\tRCU_INIT_POINTER(mm->exe_file, NULL);\n\tmmu_notifier_mm_init(mm);\n\tinit_tlb_flush_pending(mm);\n#if defined(CONFIG_TRANSPARENT_HUGEPAGE) && !USE_SPLIT_PMD_PTLOCKS\n\tmm->pmd_huge_pte = NULL;\n#endif\n\n\tif (current->mm) {\n\t\tmm->flags = current->mm->flags & MMF_INIT_MASK;\n\t\tmm->def_flags = current->mm->def_flags & VM_INIT_DEF_MASK;\n\t} else {\n\t\tmm->flags = default_dump_filter;\n\t\tmm->def_flags = 0;\n\t}\n\n\tif (mm_alloc_pgd(mm))\n\t\tgoto fail_nopgd;\n\n\tif (init_new_context(p, mm))\n\t\tgoto fail_nocontext;\n\n\tmm->user_ns = get_user_ns(user_ns);\n\treturn mm;\n\nfail_nocontext:\n\tmm_free_pgd(mm);\nfail_nopgd:\n\tfree_mm(mm);\n\treturn NULL;\n}", "commit_link": "github.com/torvalds/linux/commit/2b7e8665b4ff51c034c55df3cff76518d1a9ee3a", "file_name": "kernel/fork.c", "vul_type": "cwe-416", "description": "Write a function in C to initialize a memory management structure with default values and set up its context for a given task and user namespace."}
{"func_name": "tag_to_tag_num", "func_src_before": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = ?\"\n        self.query(q, tag)\n        return self.c.fetchone()[0]", "func_src_after": "    def tag_to_tag_num(self, tag):\n        ''' Returns tag_num given tag. '''\n\n        q = \"SELECT rowid FROM tags WHERE tag = '\" + tag + \"'\"\n        self.query(q)\n        return self.c.fetchone()[0]", "commit_link": "github.com/pukkapies/urop2019/commit/3ca2e2c291d2d5fe262d20a8e0520bdfb622432b", "file_name": "modules/query_lastfm.py", "vul_type": "cwe-089", "description": "Write a Python function that retrieves the numerical ID of a tag from a database."}
{"func_name": "process_form", "func_src_before": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\", (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\", (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\", (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "func_src_after": "def process_form():\n    # see https://docs.python.org/3.4/library/cgi.html for the basic usage\n    # here.\n    form = cgi.FieldStorage()\n\n\n    # connect to the database\n    conn = MySQLdb.connect(host   = pnsdp.SQL_HOST,\n                           user   = pnsdp.SQL_USER,\n                           passwd = pnsdp.SQL_PASSWD,\n                           db     = pnsdp.SQL_DB)\n\n\n    if \"user\" not in form or \"game\" not in form:\n        raise FormError(\"Invalid parameters.\")\n    if \"pos\" not in form and \"resign\" not in form:\n        raise FormError(\"Invalid parameters.\")\n\n    game = int(form[\"game\"].value)\n\n\n    (players,size,state) = get_game_info(conn, game)\n\n    user = form[\"user\"].value\n    if user not in players:\n        raise FormError(\"Invalid player ID - player is not part of this game\")\n\n\n    if \"resign\" in form:\n        resign = True\n    else:\n        resign = False\n        pos = form[\"pos\"].value.split(\",\")\n        assert len(pos) == 2\n        x = int(pos[0])\n        y = int(pos[1])\n\n\n    (board,nextPlayer,letter) = build_board(conn, game,size)\n\n    if user != players[nextPlayer]:\n        raise FormError(\"Internal error, incorrect player is attempting to move.\")\n\n\n    if resign:\n        # this user is choosing to resign.  Update the game state to reflect that.\n        other_player_name = players[1-nextPlayer]\n\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"UPDATE games SET state=\"%s:resignation\" WHERE id=%d;\"\"\" % (other_player_name,game))\n        cursor.close()\n\n    else:\n        assert x >= 0 and x < size\n        assert y >= 0 and y < size\n\n        assert board[x][y] == \"\"\n        board[x][y] = \"XO\"[nextPlayer]\n\n        # we've done all of our sanity checks.  We now know enough to say that\n        # it's safe to add a new move.\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"INSERT INTO moves(gameID,x,y,letter,time) VALUES(%d,%d,%d,\"%s\",NOW());\"\"\" % (game,x,y,letter))\n\n        if cursor.rowcount != 1:\n            raise FormError(\"Could not make move, reason unknown.\")\n\n        cursor.close()\n\n        result = analyze_board(board)\n        if result != \"\":\n            if result == \"win\":\n                result = players[nextPlayer]+\":win\"\n\n            cursor = conn.cursor()\n            cursor.execute(\"\"\"UPDATE games SET state=\"%s\" WHERE id=%d;\"\"\" % (result,game))\n            cursor.close()\n\n    # we've made changes, make sure to commit them!\n    conn.commit()\n    conn.close()\n\n\n    # return the parms to the caller, so that they can build a good redirect\n    return (user,game)", "commit_link": "github.com/russ-lewis/ttt_-_python_cgi/commit/6096f43fd4b2d91211eec4614b7960c0816900da", "file_name": "cgi/move.py", "vul_type": "cwe-089", "description": "Write a Python function to process a game move or resignation from form data and update the database accordingly."}
{"func_name": "ResolveStateAndPredicate", "func_src_before": "ResolveStateAndPredicate(ExprDef *expr, enum xkb_match_operation *pred_rtrn,\n                         xkb_mod_mask_t *mods_rtrn, CompatInfo *info)\n{\n    if (expr == NULL) {\n        *pred_rtrn = MATCH_ANY_OR_NONE;\n        *mods_rtrn = MOD_REAL_MASK_ALL;\n        return true;\n    }\n\n    *pred_rtrn = MATCH_EXACTLY;\n    if (expr->expr.op == EXPR_ACTION_DECL) {\n        const char *pred_txt = xkb_atom_text(info->ctx, expr->action.name);\n        if (!LookupString(symInterpretMatchMaskNames, pred_txt, pred_rtrn)) {\n            log_err(info->ctx,\n                    \"Illegal modifier predicate \\\"%s\\\"; Ignored\\n\", pred_txt);\n            return false;\n        }\n        expr = expr->action.args;\n    }\n    else if (expr->expr.op == EXPR_IDENT) {\n        const char *pred_txt = xkb_atom_text(info->ctx, expr->ident.ident);\n        if (pred_txt && istreq(pred_txt, \"any\")) {\n            *pred_rtrn = MATCH_ANY;\n            *mods_rtrn = MOD_REAL_MASK_ALL;\n            return true;\n        }\n    }\n\n    return ExprResolveModMask(info->ctx, expr, MOD_REAL, &info->mods,\n                              mods_rtrn);\n}", "func_src_after": "ResolveStateAndPredicate(ExprDef *expr, enum xkb_match_operation *pred_rtrn,\n                         xkb_mod_mask_t *mods_rtrn, CompatInfo *info)\n{\n    if (expr == NULL) {\n        *pred_rtrn = MATCH_ANY_OR_NONE;\n        *mods_rtrn = MOD_REAL_MASK_ALL;\n        return true;\n    }\n\n    *pred_rtrn = MATCH_EXACTLY;\n    if (expr->expr.op == EXPR_ACTION_DECL) {\n        const char *pred_txt = xkb_atom_text(info->ctx, expr->action.name);\n        if (!LookupString(symInterpretMatchMaskNames, pred_txt, pred_rtrn) ||\n            !expr->action.args) {\n            log_err(info->ctx,\n                    \"Illegal modifier predicate \\\"%s\\\"; Ignored\\n\", pred_txt);\n            return false;\n        }\n        expr = expr->action.args;\n    }\n    else if (expr->expr.op == EXPR_IDENT) {\n        const char *pred_txt = xkb_atom_text(info->ctx, expr->ident.ident);\n        if (pred_txt && istreq(pred_txt, \"any\")) {\n            *pred_rtrn = MATCH_ANY;\n            *mods_rtrn = MOD_REAL_MASK_ALL;\n            return true;\n        }\n    }\n\n    return ExprResolveModMask(info->ctx, expr, MOD_REAL, &info->mods,\n                              mods_rtrn);\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/96df3106d49438e442510c59acad306e94f3db4d", "file_name": "src/xkbcomp/compat.c", "vul_type": "cwe-476", "description": "In C, write a function `ResolveStateAndPredicate` that processes an expression to determine a matching operation and modifier mask for keyboard input compatibility."}
{"func_name": "get_all_referrers", "func_src_before": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer='\"+account_id+\"'\"\n    cur.execute(query)\n    results = cur.fetchall()\n\n    return jsonify(results)", "func_src_after": "@app.route('/get_all_referrers')\ndef get_all_referrers():\n    account_id = request.args.get('account_id')\n\n    if not isObject(account_id):\n        ws.send('{\"id\":1, \"method\":\"call\", \"params\":[0,\"lookup_account_names\",[[\"' + account_id + '\"], 0]]}')\n        result_l = ws.recv()\n        j_l = json.loads(result_l)\n\n        account_id = j_l[\"result\"][0][\"id\"]\n\n    con = psycopg2.connect(**config.POSTGRES)\n    cur = con.cursor()\n\n    query = \"select * from referrers where referrer=%s\"\n    cur.execute(query, (account_id,))\n    results = cur.fetchall()\n\n    return jsonify(results)", "commit_link": "github.com/VinChain/vinchain-python-api-backend/commit/b78088a551fbb712121269c6eb7f43ede120ff60", "file_name": "api.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint to fetch and return all referrer entries for a given account ID from a PostgreSQL database, handling account ID lookup if necessary."}
{"func_name": "copyaudiodata", "func_src_before": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tconst int kBufferFrameCount = 65536;\n\tvoid *buffer = malloc(kBufferFrameCount * frameSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "func_src_after": "bool copyaudiodata (AFfilehandle infile, AFfilehandle outfile, int trackid)\n{\n\tint frameSize = afGetVirtualFrameSize(infile, trackid, 1);\n\n\tint kBufferFrameCount = 65536;\n\tint bufferSize;\n\twhile (multiplyCheckOverflow(kBufferFrameCount, frameSize, &bufferSize))\n\t\tkBufferFrameCount /= 2;\n\tvoid *buffer = malloc(bufferSize);\n\n\tAFframecount totalFrames = afGetFrameCount(infile, AF_DEFAULT_TRACK);\n\tAFframecount totalFramesWritten = 0;\n\n\tbool success = true;\n\n\twhile (totalFramesWritten < totalFrames)\n\t{\n\t\tAFframecount framesToRead = totalFrames - totalFramesWritten;\n\t\tif (framesToRead > kBufferFrameCount)\n\t\t\tframesToRead = kBufferFrameCount;\n\n\t\tAFframecount framesRead = afReadFrames(infile, trackid, buffer,\n\t\t\tframesToRead);\n\n\t\tif (framesRead < framesToRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad read of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\tAFframecount framesWritten = afWriteFrames(outfile, trackid, buffer,\n\t\t\tframesRead);\n\n\t\tif (framesWritten < framesRead)\n\t\t{\n\t\t\tfprintf(stderr, \"Bad write of audio track data.\\n\");\n\t\t\tsuccess = false;\n\t\t\tbreak;\n\t\t}\n\n\t\ttotalFramesWritten += framesWritten;\n\t}\n\n\tfree(buffer);\n\n\treturn success;\n}", "commit_link": "github.com/antlarr/audiofile/commit/7d65f89defb092b63bcbc5d98349fb222ca73b3c", "file_name": "sfcommands/sfconvert.c", "vul_type": "cwe-190", "description": "Write a C function named `copyaudiodata` that copies audio data from one file to another for a specified track ID, handling memory allocation and error checking."}
{"func_name": "tcpmss_mangle_packet", "func_src_before": "tcpmss_mangle_packet(struct sk_buff *skb,\n\t\t     const struct xt_action_param *par,\n\t\t     unsigned int family,\n\t\t     unsigned int tcphoff,\n\t\t     unsigned int minlen)\n{\n\tconst struct xt_tcpmss_info *info = par->targinfo;\n\tstruct tcphdr *tcph;\n\tint len, tcp_hdrlen;\n\tunsigned int i;\n\t__be16 oldval;\n\tu16 newmss;\n\tu8 *opt;\n\n\t/* This is a fragment, no TCP header is available */\n\tif (par->fragoff != 0)\n\t\treturn 0;\n\n\tif (!skb_make_writable(skb, skb->len))\n\t\treturn -1;\n\n\tlen = skb->len - tcphoff;\n\tif (len < (int)sizeof(struct tcphdr))\n\t\treturn -1;\n\n\ttcph = (struct tcphdr *)(skb_network_header(skb) + tcphoff);\n\ttcp_hdrlen = tcph->doff * 4;\n\n\tif (len < tcp_hdrlen)\n\t\treturn -1;\n\n\tif (info->mss == XT_TCPMSS_CLAMP_PMTU) {\n\t\tstruct net *net = xt_net(par);\n\t\tunsigned int in_mtu = tcpmss_reverse_mtu(net, skb, family);\n\t\tunsigned int min_mtu = min(dst_mtu(skb_dst(skb)), in_mtu);\n\n\t\tif (min_mtu <= minlen) {\n\t\t\tnet_err_ratelimited(\"unknown or invalid path-MTU (%u)\\n\",\n\t\t\t\t\t    min_mtu);\n\t\t\treturn -1;\n\t\t}\n\t\tnewmss = min_mtu - minlen;\n\t} else\n\t\tnewmss = info->mss;\n\n\topt = (u_int8_t *)tcph;\n\tfor (i = sizeof(struct tcphdr); i <= tcp_hdrlen - TCPOLEN_MSS; i += optlen(opt, i)) {\n\t\tif (opt[i] == TCPOPT_MSS && opt[i+1] == TCPOLEN_MSS) {\n\t\t\tu_int16_t oldmss;\n\n\t\t\toldmss = (opt[i+2] << 8) | opt[i+3];\n\n\t\t\t/* Never increase MSS, even when setting it, as\n\t\t\t * doing so results in problems for hosts that rely\n\t\t\t * on MSS being set correctly.\n\t\t\t */\n\t\t\tif (oldmss <= newmss)\n\t\t\t\treturn 0;\n\n\t\t\topt[i+2] = (newmss & 0xff00) >> 8;\n\t\t\topt[i+3] = newmss & 0x00ff;\n\n\t\t\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t\t\t htons(oldmss), htons(newmss),\n\t\t\t\t\t\t false);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* There is data after the header so the option can't be added\n\t * without moving it, and doing so may make the SYN packet\n\t * itself too large. Accept the packet unmodified instead.\n\t */\n\tif (len > tcp_hdrlen)\n\t\treturn 0;\n\n\t/*\n\t * MSS Option not found ?! add it..\n\t */\n\tif (skb_tailroom(skb) < TCPOLEN_MSS) {\n\t\tif (pskb_expand_head(skb, 0,\n\t\t\t\t     TCPOLEN_MSS - skb_tailroom(skb),\n\t\t\t\t     GFP_ATOMIC))\n\t\t\treturn -1;\n\t\ttcph = (struct tcphdr *)(skb_network_header(skb) + tcphoff);\n\t}\n\n\tskb_put(skb, TCPOLEN_MSS);\n\n\t/*\n\t * IPv4: RFC 1122 states \"If an MSS option is not received at\n\t * connection setup, TCP MUST assume a default send MSS of 536\".\n\t * IPv6: RFC 2460 states IPv6 has a minimum MTU of 1280 and a minimum\n\t * length IPv6 header of 60, ergo the default MSS value is 1220\n\t * Since no MSS was provided, we must use the default values\n\t */\n\tif (xt_family(par) == NFPROTO_IPV4)\n\t\tnewmss = min(newmss, (u16)536);\n\telse\n\t\tnewmss = min(newmss, (u16)1220);\n\n\topt = (u_int8_t *)tcph + sizeof(struct tcphdr);\n\tmemmove(opt + TCPOLEN_MSS, opt, len - sizeof(struct tcphdr));\n\n\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t htons(len), htons(len + TCPOLEN_MSS), true);\n\topt[0] = TCPOPT_MSS;\n\topt[1] = TCPOLEN_MSS;\n\topt[2] = (newmss & 0xff00) >> 8;\n\topt[3] = newmss & 0x00ff;\n\n\tinet_proto_csum_replace4(&tcph->check, skb, 0, *((__be32 *)opt), false);\n\n\toldval = ((__be16 *)tcph)[6];\n\ttcph->doff += TCPOLEN_MSS/4;\n\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t oldval, ((__be16 *)tcph)[6], false);\n\treturn TCPOLEN_MSS;\n}", "func_src_after": "tcpmss_mangle_packet(struct sk_buff *skb,\n\t\t     const struct xt_action_param *par,\n\t\t     unsigned int family,\n\t\t     unsigned int tcphoff,\n\t\t     unsigned int minlen)\n{\n\tconst struct xt_tcpmss_info *info = par->targinfo;\n\tstruct tcphdr *tcph;\n\tint len, tcp_hdrlen;\n\tunsigned int i;\n\t__be16 oldval;\n\tu16 newmss;\n\tu8 *opt;\n\n\t/* This is a fragment, no TCP header is available */\n\tif (par->fragoff != 0)\n\t\treturn 0;\n\n\tif (!skb_make_writable(skb, skb->len))\n\t\treturn -1;\n\n\tlen = skb->len - tcphoff;\n\tif (len < (int)sizeof(struct tcphdr))\n\t\treturn -1;\n\n\ttcph = (struct tcphdr *)(skb_network_header(skb) + tcphoff);\n\ttcp_hdrlen = tcph->doff * 4;\n\n\tif (len < tcp_hdrlen || tcp_hdrlen < sizeof(struct tcphdr))\n\t\treturn -1;\n\n\tif (info->mss == XT_TCPMSS_CLAMP_PMTU) {\n\t\tstruct net *net = xt_net(par);\n\t\tunsigned int in_mtu = tcpmss_reverse_mtu(net, skb, family);\n\t\tunsigned int min_mtu = min(dst_mtu(skb_dst(skb)), in_mtu);\n\n\t\tif (min_mtu <= minlen) {\n\t\t\tnet_err_ratelimited(\"unknown or invalid path-MTU (%u)\\n\",\n\t\t\t\t\t    min_mtu);\n\t\t\treturn -1;\n\t\t}\n\t\tnewmss = min_mtu - minlen;\n\t} else\n\t\tnewmss = info->mss;\n\n\topt = (u_int8_t *)tcph;\n\tfor (i = sizeof(struct tcphdr); i <= tcp_hdrlen - TCPOLEN_MSS; i += optlen(opt, i)) {\n\t\tif (opt[i] == TCPOPT_MSS && opt[i+1] == TCPOLEN_MSS) {\n\t\t\tu_int16_t oldmss;\n\n\t\t\toldmss = (opt[i+2] << 8) | opt[i+3];\n\n\t\t\t/* Never increase MSS, even when setting it, as\n\t\t\t * doing so results in problems for hosts that rely\n\t\t\t * on MSS being set correctly.\n\t\t\t */\n\t\t\tif (oldmss <= newmss)\n\t\t\t\treturn 0;\n\n\t\t\topt[i+2] = (newmss & 0xff00) >> 8;\n\t\t\topt[i+3] = newmss & 0x00ff;\n\n\t\t\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t\t\t htons(oldmss), htons(newmss),\n\t\t\t\t\t\t false);\n\t\t\treturn 0;\n\t\t}\n\t}\n\n\t/* There is data after the header so the option can't be added\n\t * without moving it, and doing so may make the SYN packet\n\t * itself too large. Accept the packet unmodified instead.\n\t */\n\tif (len > tcp_hdrlen)\n\t\treturn 0;\n\n\t/* tcph->doff has 4 bits, do not wrap it to 0 */\n\tif (tcp_hdrlen >= 15 * 4)\n\t\treturn 0;\n\n\t/*\n\t * MSS Option not found ?! add it..\n\t */\n\tif (skb_tailroom(skb) < TCPOLEN_MSS) {\n\t\tif (pskb_expand_head(skb, 0,\n\t\t\t\t     TCPOLEN_MSS - skb_tailroom(skb),\n\t\t\t\t     GFP_ATOMIC))\n\t\t\treturn -1;\n\t\ttcph = (struct tcphdr *)(skb_network_header(skb) + tcphoff);\n\t}\n\n\tskb_put(skb, TCPOLEN_MSS);\n\n\t/*\n\t * IPv4: RFC 1122 states \"If an MSS option is not received at\n\t * connection setup, TCP MUST assume a default send MSS of 536\".\n\t * IPv6: RFC 2460 states IPv6 has a minimum MTU of 1280 and a minimum\n\t * length IPv6 header of 60, ergo the default MSS value is 1220\n\t * Since no MSS was provided, we must use the default values\n\t */\n\tif (xt_family(par) == NFPROTO_IPV4)\n\t\tnewmss = min(newmss, (u16)536);\n\telse\n\t\tnewmss = min(newmss, (u16)1220);\n\n\topt = (u_int8_t *)tcph + sizeof(struct tcphdr);\n\tmemmove(opt + TCPOLEN_MSS, opt, len - sizeof(struct tcphdr));\n\n\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t htons(len), htons(len + TCPOLEN_MSS), true);\n\topt[0] = TCPOPT_MSS;\n\topt[1] = TCPOLEN_MSS;\n\topt[2] = (newmss & 0xff00) >> 8;\n\topt[3] = newmss & 0x00ff;\n\n\tinet_proto_csum_replace4(&tcph->check, skb, 0, *((__be32 *)opt), false);\n\n\toldval = ((__be16 *)tcph)[6];\n\ttcph->doff += TCPOLEN_MSS/4;\n\tinet_proto_csum_replace2(&tcph->check, skb,\n\t\t\t\t oldval, ((__be16 *)tcph)[6], false);\n\treturn TCPOLEN_MSS;\n}", "commit_link": "github.com/torvalds/linux/commit/2638fd0f92d4397884fd991d8f4925cb3f081901", "file_name": "net/netfilter/xt_TCPMSS.c", "vul_type": "cwe-416", "description": "Write a C function to adjust the TCP MSS option in a packet according to given parameters."}
{"func_name": "delete", "func_src_before": "@mod.route('/delete/<int:cmt_id>', methods=['GET', 'POST'])\ndef delete(cmt_id):\n    if request.method == 'GET':\n        cursor.execute(\"SELECT msg_id FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        cursor.execute(\"DELETE FROM comment where cmt_id = %s;\", (cmt_id,))\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('comment.show', msg_id=m[0]))", "func_src_after": "@mod.route('/delete/<int:cmt_id>', methods=['GET', 'POST'])\ndef delete(cmt_id):\n    if request.method == 'GET':\n        sql = \"SELECT msg_id FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        sql = \"DELETE FROM comment where cmt_id = '%d';\" % (cmt_id)\n        cursor.execute(sql)\n        conn.commit()\n        flash('Delete Success!')\n    return redirect(url_for('comment.show', msg_id=m[0]))", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089", "description": "Write a Python Flask route to delete a comment by its ID from a database and redirect to a message page, using GET or POST method."}
{"func_name": "writeToDb", "func_src_before": "    def writeToDb(self, url):\n        try:\n            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES (?, '0');\", url)\n            self.db.commit()\n        except Exception as e:\n            print(e)", "func_src_after": "    def writeToDb(self, url):\n        try:\n            self.cursor.execute(\"INSERT INTO queue (url, visited) VALUES ('{}', '0');\".format(url))\n            self.db.commit()\n        except Exception as e:\n            print(e)", "commit_link": "github.com/jappe999/WebScraper/commit/46a4e0843aa44d903293637afad53dfcbc37b480", "file_name": "beta/database.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a URL into a database table with a visited flag set to '0', handling exceptions."}
{"func_name": "__init__.callback", "func_src_before": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = \"\"\" + \"\\\"\" + recipeName + \"\\\"\")\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def callback(recipeName):\n            menu.pack_forget()\n            viewRecipeFrame.pack(expand=True, fill='both')\n            groceryButton.pack_forget()\n            database_file = \"meal_planner.db\"\n            print(recipeName)\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                selection = cursor.execute(\"\"\"SELECT * FROM recipe WHERE name = ?;\"\"\", (recipeName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        name = row[0]\n                        time = row[1]\n                        servings = row[2]\n                        ingredients = row[4]\n                        directions = row[5]\n\n                        string = (\"Name: {} \\n Cook time: {} \\n Number of Servings: {} \\n \".format(name, time, servings))\n                        secondString = (\"Ingredients: {}\".format(ingredients))\n                        thirdString = (\"Directions: {}\".format(directions))\n            Label(viewRecipeFrame, text=string, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=secondString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            Label(viewRecipeFrame, text=thirdString, font=MEDIUM_FONT, bg=\"#f8f8f8\", fg=\"#000000\").pack(side=TOP)\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [viewRecipeFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089", "description": "Write a Python function that displays recipe details from a SQLite database when a recipe name is provided."}
{"func_name": "get_mapped_projects", "func_src_before": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                                   AND t.validated_by = {0}\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = {0})\n                            AND t.mapped_by = {0}\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''.format(user_id)\n\n        results = db.engine.execute(sql)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "func_src_after": "    @staticmethod\n    def get_mapped_projects(user_id: int, preferred_locale: str) -> UserMappedProjectsDTO:\n        \"\"\" Get all projects a user has mapped on \"\"\"\n\n        # This query looks scary, but we're really just creating an outer join between the query that gets the\n        # counts of all mapped tasks and the query that gets counts of all validated tasks.  This is necessary to\n        # handle cases where users have only validated tasks on a project, or only mapped on a project.\n        sql = '''SELECT p.id,\n                        p.status,\n                        p.default_locale,\n                        c.mapped,\n                        c.validated,\n                        st_asgeojson(p.centroid)\n                   FROM projects p,\n                        (SELECT coalesce(v.project_id, m.project_id) project_id,\n                                coalesce(v.validated, 0) validated,\n                                coalesce(m.mapped, 0) mapped\n                          FROM (SELECT t.project_id,\n                                       count (t.validated_by) validated\n                                  FROM tasks t\n                                 WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                                   AND t.validated_by = :user_id\n                                 GROUP BY t.project_id, t.validated_by) v\n                         FULL OUTER JOIN\n                        (SELECT t.project_id,\n                                count(t.mapped_by) mapped\n                           FROM tasks t\n                          WHERE t.project_id IN (SELECT unnest(projects_mapped) FROM users WHERE id = :user_id)\n                            AND t.mapped_by = :user_id\n                          GROUP BY t.project_id, t.mapped_by) m\n                         ON v.project_id = m.project_id) c\n                   WHERE p.id = c.project_id ORDER BY p.id DESC'''\n\n        results = db.engine.execute(text(sql), user_id=user_id)\n\n        if results.rowcount == 0:\n            raise NotFound()\n\n        mapped_projects_dto = UserMappedProjectsDTO()\n        for row in results:\n            mapped_project = MappedProject()\n            mapped_project.project_id = row[0]\n            mapped_project.status = ProjectStatus(row[1]).name\n            mapped_project.tasks_mapped = row[3]\n            mapped_project.tasks_validated = row[4]\n            mapped_project.centroid = geojson.loads(row[5])\n\n            project_info = ProjectInfo.get_dto_for_locale(row[0], preferred_locale, row[2])\n            mapped_project.name = project_info.name\n\n            mapped_projects_dto.mapped_projects.append(mapped_project)\n\n        return mapped_projects_dto", "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/user.py", "vul_type": "cwe-089", "description": "In Python, write a method to retrieve a user's mapped projects with task counts and localization details."}
{"func_name": "usb_sg_cancel", "func_src_before": "void usb_sg_cancel(struct usb_sg_request *io)\n{\n\tunsigned long flags;\n\tint i, retval;\n\n\tspin_lock_irqsave(&io->lock, flags);\n\tif (io->status) {\n\t\tspin_unlock_irqrestore(&io->lock, flags);\n\t\treturn;\n\t}\n\t/* shut everything down */\n\tio->status = -ECONNRESET;\n\tspin_unlock_irqrestore(&io->lock, flags);\n\n\tfor (i = io->entries - 1; i >= 0; --i) {\n\t\tusb_block_urb(io->urbs[i]);\n\n\t\tretval = usb_unlink_urb(io->urbs[i]);\n\t\tif (retval != -EINPROGRESS\n\t\t    && retval != -ENODEV\n\t\t    && retval != -EBUSY\n\t\t    && retval != -EIDRM)\n\t\t\tdev_warn(&io->dev->dev, \"%s, unlink --> %d\\n\",\n\t\t\t\t __func__, retval);\n\t}\n}", "func_src_after": "void usb_sg_cancel(struct usb_sg_request *io)\n{\n\tunsigned long flags;\n\tint i, retval;\n\n\tspin_lock_irqsave(&io->lock, flags);\n\tif (io->status || io->count == 0) {\n\t\tspin_unlock_irqrestore(&io->lock, flags);\n\t\treturn;\n\t}\n\t/* shut everything down */\n\tio->status = -ECONNRESET;\n\tio->count++;\t\t/* Keep the request alive until we're done */\n\tspin_unlock_irqrestore(&io->lock, flags);\n\n\tfor (i = io->entries - 1; i >= 0; --i) {\n\t\tusb_block_urb(io->urbs[i]);\n\n\t\tretval = usb_unlink_urb(io->urbs[i]);\n\t\tif (retval != -EINPROGRESS\n\t\t    && retval != -ENODEV\n\t\t    && retval != -EBUSY\n\t\t    && retval != -EIDRM)\n\t\t\tdev_warn(&io->dev->dev, \"%s, unlink --> %d\\n\",\n\t\t\t\t __func__, retval);\n\t}\n\n\tspin_lock_irqsave(&io->lock, flags);\n\tio->count--;\n\tif (!io->count)\n\t\tcomplete(&io->complete);\n\tspin_unlock_irqrestore(&io->lock, flags);\n}", "commit_link": "github.com/torvalds/linux/commit/056ad39ee9253873522f6469c3364964a322912b", "file_name": "drivers/usb/core/message.c", "vul_type": "cwe-416", "description": "Write a C function named `usb_sg_cancel` that cancels scatter-gather USB requests and handles locking and error reporting."}
{"func_name": "take_bug_report", "func_src_before": "    def take_bug_report(self, test_name, begin_time):\n        \"\"\"Takes a bug report on the device and stores it in a file.\n\n        Args:\n            test_name: Name of the test case that triggered this bug report.\n            begin_time: Logline format timestamp taken when the test started.\n        \"\"\"\n        new_br = True\n        try:\n            stdout = self.adb.shell('bugreportz -v').decode('utf-8')\n            # This check is necessary for builds before N, where adb shell's ret\n            # code and stderr are not propagated properly.\n            if 'not found' in stdout:\n                new_br = False\n        except adb.AdbError:\n            new_br = False\n        br_path = os.path.join(self.log_path, 'BugReports')\n        utils.create_dir(br_path)\n        base_name = ',%s,%s.txt' % (begin_time, self.serial)\n        if new_br:\n            base_name = base_name.replace('.txt', '.zip')\n        test_name_len = utils.MAX_FILENAME_LEN - len(base_name)\n        out_name = test_name[:test_name_len] + base_name\n        full_out_path = os.path.join(br_path, out_name.replace(' ', r'\\ '))\n        # in case device restarted, wait for adb interface to return\n        self.wait_for_boot_completion()\n        self.log.info('Taking bugreport for %s.', test_name)\n        if new_br:\n            out = self.adb.shell('bugreportz').decode('utf-8')\n            if not out.startswith('OK'):\n                raise DeviceError(self, 'Failed to take bugreport: %s' % out)\n            br_out_path = out.split(':')[1].strip()\n            self.adb.pull([br_out_path, full_out_path])\n        else:\n            # shell=True as this command redirects the stdout to a local file\n            # using shell redirection.\n            self.adb.bugreport(' > %s' % full_out_path, shell=True)\n        self.log.info('Bugreport for %s taken at %s.', test_name,\n                      full_out_path)", "func_src_after": "    def take_bug_report(self, test_name, begin_time):\n        \"\"\"Takes a bug report on the device and stores it in a file.\n\n        Args:\n            test_name: Name of the test case that triggered this bug report.\n            begin_time: Logline format timestamp taken when the test started.\n        \"\"\"\n        new_br = True\n        try:\n            stdout = self.adb.shell('bugreportz -v').decode('utf-8')\n            # This check is necessary for builds before N, where adb shell's ret\n            # code and stderr are not propagated properly.\n            if 'not found' in stdout:\n                new_br = False\n        except adb.AdbError:\n            new_br = False\n        br_path = os.path.join(self.log_path, 'BugReports')\n        utils.create_dir(br_path)\n        base_name = ',%s,%s.txt' % (begin_time, self.serial)\n        if new_br:\n            base_name = base_name.replace('.txt', '.zip')\n        test_name_len = utils.MAX_FILENAME_LEN - len(base_name)\n        out_name = test_name[:test_name_len] + base_name\n        full_out_path = os.path.join(br_path, out_name.replace(' ', r'\\ '))\n        # in case device restarted, wait for adb interface to return\n        self.wait_for_boot_completion()\n        self.log.info('Taking bugreport for %s.', test_name)\n        if new_br:\n            out = self.adb.shell('bugreportz').decode('utf-8')\n            if not out.startswith('OK'):\n                raise DeviceError(self, 'Failed to take bugreport: %s' % out)\n            br_out_path = out.split(':')[1].strip()\n            self.adb.pull('%s %s' % (br_out_path, full_out_path))\n        else:\n            self.adb.bugreport(' > %s' % full_out_path)\n        self.log.info('Bugreport for %s taken at %s.', test_name,\n                      full_out_path)", "commit_link": "github.com/google/mobly/commit/3862e8ba359040fbdd6e1a6d36e51d07cda8e1ee", "file_name": "mobly/controllers/android_device.py", "vul_type": "cwe-078", "description": "Write a Python function to capture a bug report from a device, save it to a file, and handle different versions of the bug reporting tool."}
{"func_name": "lha_read_file_header_1", "func_src_before": "lha_read_file_header_1(struct archive_read *a, struct lha *lha)\n{\n\tconst unsigned char *p;\n\tsize_t extdsize;\n\tint i, err, err2;\n\tint namelen, padding;\n\tunsigned char headersum, sum_calculated;\n\n\terr = ARCHIVE_OK;\n\n\tif ((p = __archive_read_ahead(a, H1_FIXED_SIZE, NULL)) == NULL)\n\t\treturn (truncated_error(a));\n\n\tlha->header_size = p[H1_HEADER_SIZE_OFFSET] + 2;\n\theadersum = p[H1_HEADER_SUM_OFFSET];\n\t/* Note: An extended header size is included in a compsize. */\n\tlha->compsize = archive_le32dec(p + H1_COMP_SIZE_OFFSET);\n\tlha->origsize = archive_le32dec(p + H1_ORIG_SIZE_OFFSET);\n\tlha->mtime = lha_dos_time(p + H1_DOS_TIME_OFFSET);\n\tnamelen = p[H1_NAME_LEN_OFFSET];\n\t/* Calculate a padding size. The result will be normally 0 only(?) */\n\tpadding = ((int)lha->header_size) - H1_FIXED_SIZE - namelen;\n\n\tif (namelen > 230 || padding < 0)\n\t\tgoto invalid;\n\n\tif ((p = __archive_read_ahead(a, lha->header_size, NULL)) == NULL)\n\t\treturn (truncated_error(a));\n\n\tfor (i = 0; i < namelen; i++) {\n\t\tif (p[i + H1_FILE_NAME_OFFSET] == 0xff)\n\t\t\tgoto invalid;/* Invalid filename. */\n\t}\n\tarchive_strncpy(&lha->filename, p + H1_FILE_NAME_OFFSET, namelen);\n\tlha->crc = archive_le16dec(p + H1_FILE_NAME_OFFSET + namelen);\n\tlha->setflag |= CRC_IS_SET;\n\n\tsum_calculated = lha_calcsum(0, p, 2, lha->header_size - 2);\n\t/* Consume used bytes but not include `next header size' data\n\t * since it will be consumed in lha_read_file_extended_header(). */\n\t__archive_read_consume(a, lha->header_size - 2);\n\n\t/* Read extended headers */\n\terr2 = lha_read_file_extended_header(a, lha, NULL, 2,\n\t    (size_t)(lha->compsize + 2), &extdsize);\n\tif (err2 < ARCHIVE_WARN)\n\t\treturn (err2);\n\tif (err2 < err)\n\t\terr = err2;\n\t/* Get a real compressed file size. */\n\tlha->compsize -= extdsize - 2;\n\n\tif (sum_calculated != headersum) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"LHa header sum error\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\treturn (err);\ninvalid:\n\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n\t    \"Invalid LHa header\");\n\treturn (ARCHIVE_FATAL);\n}", "func_src_after": "lha_read_file_header_1(struct archive_read *a, struct lha *lha)\n{\n\tconst unsigned char *p;\n\tsize_t extdsize;\n\tint i, err, err2;\n\tint namelen, padding;\n\tunsigned char headersum, sum_calculated;\n\n\terr = ARCHIVE_OK;\n\n\tif ((p = __archive_read_ahead(a, H1_FIXED_SIZE, NULL)) == NULL)\n\t\treturn (truncated_error(a));\n\n\tlha->header_size = p[H1_HEADER_SIZE_OFFSET] + 2;\n\theadersum = p[H1_HEADER_SUM_OFFSET];\n\t/* Note: An extended header size is included in a compsize. */\n\tlha->compsize = archive_le32dec(p + H1_COMP_SIZE_OFFSET);\n\tlha->origsize = archive_le32dec(p + H1_ORIG_SIZE_OFFSET);\n\tlha->mtime = lha_dos_time(p + H1_DOS_TIME_OFFSET);\n\tnamelen = p[H1_NAME_LEN_OFFSET];\n\t/* Calculate a padding size. The result will be normally 0 only(?) */\n\tpadding = ((int)lha->header_size) - H1_FIXED_SIZE - namelen;\n\n\tif (namelen > 230 || padding < 0)\n\t\tgoto invalid;\n\n\tif ((p = __archive_read_ahead(a, lha->header_size, NULL)) == NULL)\n\t\treturn (truncated_error(a));\n\n\tfor (i = 0; i < namelen; i++) {\n\t\tif (p[i + H1_FILE_NAME_OFFSET] == 0xff)\n\t\t\tgoto invalid;/* Invalid filename. */\n\t}\n\tarchive_strncpy(&lha->filename, p + H1_FILE_NAME_OFFSET, namelen);\n\tlha->crc = archive_le16dec(p + H1_FILE_NAME_OFFSET + namelen);\n\tlha->setflag |= CRC_IS_SET;\n\n\tsum_calculated = lha_calcsum(0, p, 2, lha->header_size - 2);\n\t/* Consume used bytes but not include `next header size' data\n\t * since it will be consumed in lha_read_file_extended_header(). */\n\t__archive_read_consume(a, lha->header_size - 2);\n\n\t/* Read extended headers */\n\terr2 = lha_read_file_extended_header(a, lha, NULL, 2,\n\t    (size_t)(lha->compsize + 2), &extdsize);\n\tif (err2 < ARCHIVE_WARN)\n\t\treturn (err2);\n\tif (err2 < err)\n\t\terr = err2;\n\t/* Get a real compressed file size. */\n\tlha->compsize -= extdsize - 2;\n\n\tif (lha->compsize < 0)\n\t\tgoto invalid;\t/* Invalid compressed file size */\n\n\tif (sum_calculated != headersum) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"LHa header sum error\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\treturn (err);\ninvalid:\n\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n\t    \"Invalid LHa header\");\n\treturn (ARCHIVE_FATAL);\n}", "commit_link": "github.com/libarchive/libarchive/commit/98dcbbf0bf4854bf987557e55e55fff7abbf3ea9", "file_name": "libarchive/archive_read_support_format_lha.c", "vul_type": "cwe-125", "description": "Write a C function `lha_read_file_header_1` to read and validate the header of an LHA file archive."}
{"func_name": "read_Header", "func_src_before": "read_Header(struct archive_read *a, struct _7z_header_info *h,\n    int check_header_id)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tconst unsigned char *p;\n\tstruct _7z_folder *folders;\n\tstruct _7z_stream_info *si = &(zip->si);\n\tstruct _7zip_entry *entries;\n\tuint32_t folderIndex, indexInFolder;\n\tunsigned i;\n\tint eindex, empty_streams, sindex;\n\n\tif (check_header_id) {\n\t\t/*\n\t\t * Read Header.\n\t\t */\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\tif (*p != kHeader)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read ArchiveProperties.\n\t */\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\tif (*p == kArchiveProperties) {\n\t\tfor (;;) {\n\t\t\tuint64_t size;\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (*p == 0)\n\t\t\t\tbreak;\n\t\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\t\treturn (-1);\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read MainStreamsInfo.\n\t */\n\tif (*p == kMainStreamsInfo) {\n\t\tif (read_StreamsInfo(a, &(zip->si)) < 0)\n\t\t\treturn (-1);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\tif (*p == kEnd)\n\t\treturn (0);\n\n\t/*\n\t * Read FilesInfo.\n\t */\n\tif (*p != kFilesInfo)\n\t\treturn (-1);\n\n\tif (parse_7zip_uint64(a, &(zip->numFiles)) < 0)\n\t\treturn (-1);\n\tif (UMAX_ENTRY < zip->numFiles)\n\t\treturn (-1);\n\n\tzip->entries = calloc((size_t)zip->numFiles, sizeof(*zip->entries));\n\tif (zip->entries == NULL)\n\t\treturn (-1);\n\tentries = zip->entries;\n\n\tempty_streams = 0;\n\tfor (;;) {\n\t\tint type;\n\t\tuint64_t size;\n\t\tsize_t ll;\n\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t\tif (type == kEnd)\n\t\t\tbreak;\n\n\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\treturn (-1);\n\t\tif (zip->header_bytes_remaining < size)\n\t\t\treturn (-1);\n\t\tll = (size_t)size;\n\n\t\tswitch (type) {\n\t\tcase kEmptyStream:\n\t\t\th->emptyStreamBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->emptyStreamBools));\n\t\t\tif (h->emptyStreamBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(\n\t\t\t    a, h->emptyStreamBools, (size_t)zip->numFiles) < 0)\n\t\t\t\treturn (-1);\n\t\t\tempty_streams = 0;\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->emptyStreamBools[i])\n\t\t\t\t\tempty_streams++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase kEmptyFile:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th->emptyFileBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->emptyFileBools));\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->emptyFileBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kAnti:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\th->antiBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->antiBools));\n\t\t\tif (h->antiBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->antiBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kCTime:\n\t\tcase kATime:\n\t\tcase kMTime:\n\t\t\tif (read_Times(a, h, type) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kName:\n\t\t{\n\t\t\tunsigned char *np;\n\t\t\tsize_t nl, nb;\n\n\t\t\t/* Skip one byte. */\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tll--;\n\n\t\t\tif ((ll & 1) || ll < zip->numFiles * 4)\n\t\t\t\treturn (-1);\n\n\t\t\tzip->entry_names = malloc(ll);\n\t\t\tif (zip->entry_names == NULL)\n\t\t\t\treturn (-1);\n\t\t\tnp = zip->entry_names;\n\t\t\tnb = ll;\n\t\t\t/*\n\t\t\t * Copy whole file names.\n\t\t\t * NOTE: This loop prevents from expanding\n\t\t\t * the uncompressed buffer in order not to\n\t\t\t * use extra memory resource.\n\t\t\t */\n\t\t\twhile (nb) {\n\t\t\t\tsize_t b;\n\t\t\t\tif (nb > UBUFF_SIZE)\n\t\t\t\t\tb = UBUFF_SIZE;\n\t\t\t\telse\n\t\t\t\t\tb = nb;\n\t\t\t\tif ((p = header_bytes(a, b)) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tmemcpy(np, p, b);\n\t\t\t\tnp += b;\n\t\t\t\tnb -= b;\n\t\t\t}\n\t\t\tnp = zip->entry_names;\n\t\t\tnl = ll;\n\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tentries[i].utf16name = np;\n#if defined(_WIN32) && !defined(__CYGWIN__) && defined(_DEBUG)\n\t\t\t\tentries[i].wname = (wchar_t *)np;\n#endif\n\n\t\t\t\t/* Find a terminator. */\n\t\t\t\twhile (nl >= 2 && (np[0] || np[1])) {\n\t\t\t\t\tnp += 2;\n\t\t\t\t\tnl -= 2;\n\t\t\t\t}\n\t\t\t\tif (nl < 2)\n\t\t\t\t\treturn (-1);/* Terminator not found */\n\t\t\t\tentries[i].name_len = np - entries[i].utf16name;\n\t\t\t\tnp += 2;\n\t\t\t\tnl -= 2;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kAttributes:\n\t\t{\n\t\t\tint allAreDefined;\n\n\t\t\tif ((p = header_bytes(a, 2)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tallAreDefined = *p;\n\t\t\th->attrBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->attrBools));\n\t\t\tif (h->attrBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (allAreDefined)\n\t\t\t\tmemset(h->attrBools, 1, (size_t)zip->numFiles);\n\t\t\telse {\n\t\t\t\tif (read_Bools(a, h->attrBools,\n\t\t\t\t      (size_t)zip->numFiles) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->attrBools[i]) {\n\t\t\t\t\tif ((p = header_bytes(a, 4)) == NULL)\n\t\t\t\t\t\treturn (-1);\n\t\t\t\t\tentries[i].attr = archive_le32dec(p);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kDummy:\n\t\t\tif (ll == 0)\n\t\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * Set up entry's attributes.\n\t */\n\tfolders = si->ci.folders;\n\teindex = sindex = 0;\n\tfolderIndex = indexInFolder = 0;\n\tfor (i = 0; i < zip->numFiles; i++) {\n\t\tif (h->emptyStreamBools == NULL || h->emptyStreamBools[i] == 0)\n\t\t\tentries[i].flg |= HAS_STREAM;\n\t\t/* The high 16 bits of attributes is a posix file mode. */\n\t\tentries[i].mode = entries[i].attr >> 16;\n\t\tif (entries[i].flg & HAS_STREAM) {\n\t\t\tif ((size_t)sindex >= si->ss.unpack_streams)\n\t\t\t\treturn (-1);\n\t\t\tif (entries[i].mode == 0)\n\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\tif (si->ss.digestsDefined[sindex])\n\t\t\t\tentries[i].flg |= CRC32_IS_SET;\n\t\t\tentries[i].ssIndex = sindex;\n\t\t\tsindex++;\n\t\t} else {\n\t\t\tint dir;\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\tdir = 1;\n\t\t\telse {\n\t\t\t\tif (h->emptyFileBools[eindex])\n\t\t\t\t\tdir = 0;\n\t\t\t\telse\n\t\t\t\t\tdir = 1;\n\t\t\t\teindex++;\n\t\t\t}\n\t\t\tif (entries[i].mode == 0) {\n\t\t\t\tif (dir)\n\t\t\t\t\tentries[i].mode = AE_IFDIR | 0777;\n\t\t\t\telse\n\t\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\t} else if (dir &&\n\t\t\t    (entries[i].mode & AE_IFMT) != AE_IFDIR) {\n\t\t\t\tentries[i].mode &= ~AE_IFMT;\n\t\t\t\tentries[i].mode |= AE_IFDIR;\n\t\t\t}\n\t\t\tif ((entries[i].mode & AE_IFMT) == AE_IFDIR &&\n\t\t\t    entries[i].name_len >= 2 &&\n\t\t\t    (entries[i].utf16name[entries[i].name_len-2] != '/' ||\n\t\t\t     entries[i].utf16name[entries[i].name_len-1] != 0)) {\n\t\t\t\tentries[i].utf16name[entries[i].name_len] = '/';\n\t\t\t\tentries[i].utf16name[entries[i].name_len+1] = 0;\n\t\t\t\tentries[i].name_len += 2;\n\t\t\t}\n\t\t\tentries[i].ssIndex = -1;\n\t\t}\n\t\tif (entries[i].attr & 0x01)\n\t\t\tentries[i].mode &= ~0222;/* Read only. */\n\n\t\tif ((entries[i].flg & HAS_STREAM) == 0 && indexInFolder == 0) {\n\t\t\t/*\n\t\t\t * The entry is an empty file or a directory file,\n\t\t\t * those both have no contents.\n\t\t\t */\n\t\t\tentries[i].folderIndex = -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (indexInFolder == 0) {\n\t\t\tfor (;;) {\n\t\t\t\tif (folderIndex >= si->ci.numFolders)\n\t\t\t\t\treturn (-1);\n\t\t\t\tif (folders[folderIndex].numUnpackStreams)\n\t\t\t\t\tbreak;\n\t\t\t\tfolderIndex++;\n\t\t\t}\n\t\t}\n\t\tentries[i].folderIndex = folderIndex;\n\t\tif ((entries[i].flg & HAS_STREAM) == 0)\n\t\t\tcontinue;\n\t\tindexInFolder++;\n\t\tif (indexInFolder >= folders[folderIndex].numUnpackStreams) {\n\t\t\tfolderIndex++;\n\t\t\tindexInFolder = 0;\n\t\t}\n\t}\n\n\treturn (0);\n}", "func_src_after": "read_Header(struct archive_read *a, struct _7z_header_info *h,\n    int check_header_id)\n{\n\tstruct _7zip *zip = (struct _7zip *)a->format->data;\n\tconst unsigned char *p;\n\tstruct _7z_folder *folders;\n\tstruct _7z_stream_info *si = &(zip->si);\n\tstruct _7zip_entry *entries;\n\tuint32_t folderIndex, indexInFolder;\n\tunsigned i;\n\tint eindex, empty_streams, sindex;\n\n\tif (check_header_id) {\n\t\t/*\n\t\t * Read Header.\n\t\t */\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\tif (*p != kHeader)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read ArchiveProperties.\n\t */\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\tif (*p == kArchiveProperties) {\n\t\tfor (;;) {\n\t\t\tuint64_t size;\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (*p == 0)\n\t\t\t\tbreak;\n\t\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\t\treturn (-1);\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\n\t/*\n\t * Read MainStreamsInfo.\n\t */\n\tif (*p == kMainStreamsInfo) {\n\t\tif (read_StreamsInfo(a, &(zip->si)) < 0)\n\t\t\treturn (-1);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t}\n\tif (*p == kEnd)\n\t\treturn (0);\n\n\t/*\n\t * Read FilesInfo.\n\t */\n\tif (*p != kFilesInfo)\n\t\treturn (-1);\n\n\tif (parse_7zip_uint64(a, &(zip->numFiles)) < 0)\n\t\treturn (-1);\n\tif (UMAX_ENTRY < zip->numFiles)\n\t\treturn (-1);\n\n\tzip->entries = calloc((size_t)zip->numFiles, sizeof(*zip->entries));\n\tif (zip->entries == NULL)\n\t\treturn (-1);\n\tentries = zip->entries;\n\n\tempty_streams = 0;\n\tfor (;;) {\n\t\tint type;\n\t\tuint64_t size;\n\t\tsize_t ll;\n\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t\tif (type == kEnd)\n\t\t\tbreak;\n\n\t\tif (parse_7zip_uint64(a, &size) < 0)\n\t\t\treturn (-1);\n\t\tif (zip->header_bytes_remaining < size)\n\t\t\treturn (-1);\n\t\tll = (size_t)size;\n\n\t\tswitch (type) {\n\t\tcase kEmptyStream:\n\t\t\tif (h->emptyStreamBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->emptyStreamBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->emptyStreamBools));\n\t\t\tif (h->emptyStreamBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(\n\t\t\t    a, h->emptyStreamBools, (size_t)zip->numFiles) < 0)\n\t\t\t\treturn (-1);\n\t\t\tempty_streams = 0;\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->emptyStreamBools[i])\n\t\t\t\t\tempty_streams++;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase kEmptyFile:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (h->emptyFileBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->emptyFileBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->emptyFileBools));\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->emptyFileBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kAnti:\n\t\t\tif (empty_streams <= 0) {\n\t\t\t\t/* Unexcepted sequence. Skip this. */\n\t\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (h->antiBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->antiBools = calloc(empty_streams,\n\t\t\t    sizeof(*h->antiBools));\n\t\t\tif (h->antiBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (read_Bools(a, h->antiBools, empty_streams) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kCTime:\n\t\tcase kATime:\n\t\tcase kMTime:\n\t\t\tif (read_Times(a, h, type) < 0)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\tcase kName:\n\t\t{\n\t\t\tunsigned char *np;\n\t\t\tsize_t nl, nb;\n\n\t\t\t/* Skip one byte. */\n\t\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tll--;\n\n\t\t\tif ((ll & 1) || ll < zip->numFiles * 4)\n\t\t\t\treturn (-1);\n\n\t\t\tif (zip->entry_names != NULL)\n\t\t\t\treturn (-1);\n\t\t\tzip->entry_names = malloc(ll);\n\t\t\tif (zip->entry_names == NULL)\n\t\t\t\treturn (-1);\n\t\t\tnp = zip->entry_names;\n\t\t\tnb = ll;\n\t\t\t/*\n\t\t\t * Copy whole file names.\n\t\t\t * NOTE: This loop prevents from expanding\n\t\t\t * the uncompressed buffer in order not to\n\t\t\t * use extra memory resource.\n\t\t\t */\n\t\t\twhile (nb) {\n\t\t\t\tsize_t b;\n\t\t\t\tif (nb > UBUFF_SIZE)\n\t\t\t\t\tb = UBUFF_SIZE;\n\t\t\t\telse\n\t\t\t\t\tb = nb;\n\t\t\t\tif ((p = header_bytes(a, b)) == NULL)\n\t\t\t\t\treturn (-1);\n\t\t\t\tmemcpy(np, p, b);\n\t\t\t\tnp += b;\n\t\t\t\tnb -= b;\n\t\t\t}\n\t\t\tnp = zip->entry_names;\n\t\t\tnl = ll;\n\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tentries[i].utf16name = np;\n#if defined(_WIN32) && !defined(__CYGWIN__) && defined(_DEBUG)\n\t\t\t\tentries[i].wname = (wchar_t *)np;\n#endif\n\n\t\t\t\t/* Find a terminator. */\n\t\t\t\twhile (nl >= 2 && (np[0] || np[1])) {\n\t\t\t\t\tnp += 2;\n\t\t\t\t\tnl -= 2;\n\t\t\t\t}\n\t\t\t\tif (nl < 2)\n\t\t\t\t\treturn (-1);/* Terminator not found */\n\t\t\t\tentries[i].name_len = np - entries[i].utf16name;\n\t\t\t\tnp += 2;\n\t\t\t\tnl -= 2;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kAttributes:\n\t\t{\n\t\t\tint allAreDefined;\n\n\t\t\tif ((p = header_bytes(a, 2)) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tallAreDefined = *p;\n\t\t\tif (h->attrBools != NULL)\n\t\t\t\treturn (-1);\n\t\t\th->attrBools = calloc((size_t)zip->numFiles,\n\t\t\t    sizeof(*h->attrBools));\n\t\t\tif (h->attrBools == NULL)\n\t\t\t\treturn (-1);\n\t\t\tif (allAreDefined)\n\t\t\t\tmemset(h->attrBools, 1, (size_t)zip->numFiles);\n\t\t\telse {\n\t\t\t\tif (read_Bools(a, h->attrBools,\n\t\t\t\t      (size_t)zip->numFiles) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tfor (i = 0; i < zip->numFiles; i++) {\n\t\t\t\tif (h->attrBools[i]) {\n\t\t\t\t\tif ((p = header_bytes(a, 4)) == NULL)\n\t\t\t\t\t\treturn (-1);\n\t\t\t\t\tentries[i].attr = archive_le32dec(p);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\tcase kDummy:\n\t\t\tif (ll == 0)\n\t\t\t\tbreak;\n\t\tdefault:\n\t\t\tif (header_bytes(a, ll) == NULL)\n\t\t\t\treturn (-1);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t/*\n\t * Set up entry's attributes.\n\t */\n\tfolders = si->ci.folders;\n\teindex = sindex = 0;\n\tfolderIndex = indexInFolder = 0;\n\tfor (i = 0; i < zip->numFiles; i++) {\n\t\tif (h->emptyStreamBools == NULL || h->emptyStreamBools[i] == 0)\n\t\t\tentries[i].flg |= HAS_STREAM;\n\t\t/* The high 16 bits of attributes is a posix file mode. */\n\t\tentries[i].mode = entries[i].attr >> 16;\n\t\tif (entries[i].flg & HAS_STREAM) {\n\t\t\tif ((size_t)sindex >= si->ss.unpack_streams)\n\t\t\t\treturn (-1);\n\t\t\tif (entries[i].mode == 0)\n\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\tif (si->ss.digestsDefined[sindex])\n\t\t\t\tentries[i].flg |= CRC32_IS_SET;\n\t\t\tentries[i].ssIndex = sindex;\n\t\t\tsindex++;\n\t\t} else {\n\t\t\tint dir;\n\t\t\tif (h->emptyFileBools == NULL)\n\t\t\t\tdir = 1;\n\t\t\telse {\n\t\t\t\tif (h->emptyFileBools[eindex])\n\t\t\t\t\tdir = 0;\n\t\t\t\telse\n\t\t\t\t\tdir = 1;\n\t\t\t\teindex++;\n\t\t\t}\n\t\t\tif (entries[i].mode == 0) {\n\t\t\t\tif (dir)\n\t\t\t\t\tentries[i].mode = AE_IFDIR | 0777;\n\t\t\t\telse\n\t\t\t\t\tentries[i].mode = AE_IFREG | 0666;\n\t\t\t} else if (dir &&\n\t\t\t    (entries[i].mode & AE_IFMT) != AE_IFDIR) {\n\t\t\t\tentries[i].mode &= ~AE_IFMT;\n\t\t\t\tentries[i].mode |= AE_IFDIR;\n\t\t\t}\n\t\t\tif ((entries[i].mode & AE_IFMT) == AE_IFDIR &&\n\t\t\t    entries[i].name_len >= 2 &&\n\t\t\t    (entries[i].utf16name[entries[i].name_len-2] != '/' ||\n\t\t\t     entries[i].utf16name[entries[i].name_len-1] != 0)) {\n\t\t\t\tentries[i].utf16name[entries[i].name_len] = '/';\n\t\t\t\tentries[i].utf16name[entries[i].name_len+1] = 0;\n\t\t\t\tentries[i].name_len += 2;\n\t\t\t}\n\t\t\tentries[i].ssIndex = -1;\n\t\t}\n\t\tif (entries[i].attr & 0x01)\n\t\t\tentries[i].mode &= ~0222;/* Read only. */\n\n\t\tif ((entries[i].flg & HAS_STREAM) == 0 && indexInFolder == 0) {\n\t\t\t/*\n\t\t\t * The entry is an empty file or a directory file,\n\t\t\t * those both have no contents.\n\t\t\t */\n\t\t\tentries[i].folderIndex = -1;\n\t\t\tcontinue;\n\t\t}\n\t\tif (indexInFolder == 0) {\n\t\t\tfor (;;) {\n\t\t\t\tif (folderIndex >= si->ci.numFolders)\n\t\t\t\t\treturn (-1);\n\t\t\t\tif (folders[folderIndex].numUnpackStreams)\n\t\t\t\t\tbreak;\n\t\t\t\tfolderIndex++;\n\t\t\t}\n\t\t}\n\t\tentries[i].folderIndex = folderIndex;\n\t\tif ((entries[i].flg & HAS_STREAM) == 0)\n\t\t\tcontinue;\n\t\tindexInFolder++;\n\t\tif (indexInFolder >= folders[folderIndex].numUnpackStreams) {\n\t\t\tfolderIndex++;\n\t\t\tindexInFolder = 0;\n\t\t}\n\t}\n\n\treturn (0);\n}", "commit_link": "github.com/libarchive/libarchive/commit/7f17c791dcfd8c0416e2cd2485b19410e47ef126", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-125", "description": "Write a C function named `read_Header` that processes 7z archive headers."}
{"func_name": "getCommentsLike", "func_src_before": "    def getCommentsLike(self,commentid):\n        sqlText=\"select userid from comment_like where commentid=%d\"%(commentid)\n        result=sql.queryDB(self.conn,sqlText)\n        return result;", "func_src_after": "    def getCommentsLike(self,commentid):\n        sqlText=\"select userid from comment_like where commentid=%s\"\n        params=[commentid]\n        result=sql.queryDB(self.conn,sqlText,params)\n        return result;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/comment.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch user IDs who liked a comment by its ID from a database."}
{"func_name": "test_create_invalid_host", "func_src_before": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = 'showhost -verbose fakehost'\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = ('createhost -persona 1 -domain (\\'OpenStack\\',) '\n                           'fakehost 123456789012345 123456789054321')\n        create_host_ret = pack(CLI_CR +\n                               'already used by host fakehost.foo (19)')\n        _run_ssh(create_host_cmd, False).AndReturn([create_host_ret, ''])\n\n        show_3par_cmd = 'showhost -verbose fakehost.foo'\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(FC_SHOWHOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "func_src_after": "    def test_create_invalid_host(self):\n        self.flags(lock_path=self.tempdir)\n\n        #record\n        self.clear_mox()\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_cpg\",\n                       self.fake_get_cpg)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"get_domain\",\n                       self.fake_get_domain)\n        _run_ssh = self.mox.CreateMock(hpdriver.hpcommon.HP3PARCommon._run_ssh)\n        self.stubs.Set(hpdriver.hpcommon.HP3PARCommon, \"_run_ssh\", _run_ssh)\n\n        show_host_cmd = ['showhost', '-verbose', 'fakehost']\n        _run_ssh(show_host_cmd, False).AndReturn([pack('no hosts listed'), ''])\n\n        create_host_cmd = (['createhost', '-persona', '1', '-domain',\n                            ('OpenStack',), 'fakehost', '123456789012345',\n                            '123456789054321'])\n        create_host_ret = pack(CLI_CR +\n                               'already used by host fakehost.foo (19)')\n        _run_ssh(create_host_cmd, False).AndReturn([create_host_ret, ''])\n\n        show_3par_cmd = ['showhost', '-verbose', 'fakehost.foo']\n        _run_ssh(show_3par_cmd, False).AndReturn([pack(FC_SHOWHOST_RET), ''])\n        self.mox.ReplayAll()\n\n        host = self.driver._create_host(self.volume, self.connector)\n\n        self.assertEquals(host['name'], 'fakehost.foo')", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/tests/test_hp3par.py", "vul_type": "cwe-078", "description": "Write a Python unit test function that mocks SSH commands for creating a host in an HP 3PAR storage system and checks the host's name."}
{"func_name": "store_versioninfo_gnu_verneed", "func_src_before": "static Sdb *store_versioninfo_gnu_verneed(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tut8 *end, *need = NULL;\n\tconst char *section_name = \"\";\n\tElf_(Shdr) *link_shdr = NULL;\n\tconst char *link_section_name = \"\";\n\tSdb *sdb_vernaux = NULL;\n\tSdb *sdb_version = NULL;\n\tSdb *sdb = NULL;\n\tint i, cnt;\n\n\tif (!bin || !bin->dynstr) {\n\t\treturn NULL;\n\t}\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn NULL;\n\t}\n\tif (shdr->sh_size < 1) {\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tif (!sdb) {\n\t\treturn NULL;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!(need = (ut8*) calloc (R_MAX (1, shdr->sh_size), sizeof (ut8)))) {\n\t\tbprintf (\"Warning: Cannot allocate memory for Elf_(Verneed)\\n\");\n\t\tgoto beach;\n\t}\n\tend = need + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"num_entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tif (shdr->sh_offset > bin->size || shdr->sh_offset + shdr->sh_size > bin->size) {\n\t\tgoto beach;\n\t}\n\tif (shdr->sh_offset + shdr->sh_size < shdr->sh_size) {\n\t\tgoto beach;\n\t}\n\ti = r_buf_read_at (bin->b, shdr->sh_offset, need, shdr->sh_size);\n\tif (i < 0)\n\t\tgoto beach;\n\t//XXX we should use DT_VERNEEDNUM instead of sh_info\n\t//TODO https://sourceware.org/ml/binutils/2014-11/msg00353.html\n\tfor (i = 0, cnt = 0; cnt < shdr->sh_info; ++cnt) {\n\t\tint j, isum;\n\t\tut8 *vstart = need + i;\n\t\tElf_(Verneed) vvn = {0};\n\t\tif (vstart + sizeof (Elf_(Verneed)) > end) {\n\t\t\tgoto beach;\n\t\t}\n\t\tElf_(Verneed) *entry = &vvn;\n\t\tchar key[32] = {0};\n\t\tsdb_version = sdb_new0 ();\n\t\tif (!sdb_version) {\n\t\t\tgoto beach;\n\t\t}\n\t\tj = 0;\n\t\tvvn.vn_version = READ16 (vstart, j)\n\t\tvvn.vn_cnt = READ16 (vstart, j)\n\t\tvvn.vn_file = READ32 (vstart, j)\n\t\tvvn.vn_aux = READ32 (vstart, j)\n\t\tvvn.vn_next = READ32 (vstart, j)\n\n\t\tsdb_num_set (sdb_version, \"vn_version\", entry->vn_version, 0);\n\t\tsdb_num_set (sdb_version, \"idx\", i, 0);\n\t\tif (entry->vn_file > bin->dynstr_size) {\n\t\t\tgoto beach;\n\t\t}\n\t\t{\n\t\t\tchar *s = r_str_ndup (&bin->dynstr[entry->vn_file], 16);\n\t\t\tsdb_set (sdb_version, \"file_name\", s, 0);\n\t\t\tfree (s);\n\t\t}\n\t\tsdb_num_set (sdb_version, \"cnt\", entry->vn_cnt, 0);\n\t\tvstart += entry->vn_aux;\n\t\tfor (j = 0, isum = i + entry->vn_aux; j < entry->vn_cnt && vstart + sizeof (Elf_(Vernaux)) <= end; ++j) {\n\t\t\tint k;\n\t\t\tElf_(Vernaux) * aux = NULL;\n\t\t\tElf_(Vernaux) vaux = {0};\n\t\t\tsdb_vernaux = sdb_new0 ();\n\t\t\tif (!sdb_vernaux) {\n\t\t\t\tgoto beach;\n\t\t\t}\n\t\t\taux = (Elf_(Vernaux)*)&vaux;\n\t\t\tk = 0;\n\t\t\tvaux.vna_hash = READ32 (vstart, k)\n\t\t\tvaux.vna_flags = READ16 (vstart, k)\n\t\t\tvaux.vna_other = READ16 (vstart, k)\n\t\t\tvaux.vna_name = READ32 (vstart, k)\n\t\t\tvaux.vna_next = READ32 (vstart, k)\n\t\t\tif (aux->vna_name > bin->dynstr_size) {\n\t\t\t\tgoto beach;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_vernaux, \"idx\", isum, 0);\n\t\t\tif (aux->vna_name > 0 && aux->vna_name + 8 < bin->dynstr_size) {\n\t\t\t\tchar name [16];\n\t\t\t\tstrncpy (name, &bin->dynstr[aux->vna_name], sizeof (name)-1);\n\t\t\t\tname[sizeof(name)-1] = 0;\n\t\t\t\tsdb_set (sdb_vernaux, \"name\", name, 0);\n\t\t\t}\n\t\t\tsdb_set (sdb_vernaux, \"flags\", get_ver_flags (aux->vna_flags), 0);\n\t\t\tsdb_num_set (sdb_vernaux, \"version\", aux->vna_other, 0);\n\t\t\tisum += aux->vna_next;\n\t\t\tvstart += aux->vna_next;\n\t\t\tsnprintf (key, sizeof (key), \"vernaux%d\", j);\n\t\t\tsdb_ns_set (sdb_version, key, sdb_vernaux);\n\t\t}\n\t\tif ((int)entry->vn_next < 0) {\n\t\t\tbprintf (\"Invalid vn_next\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += entry->vn_next;\n\t\tsnprintf (key, sizeof (key), \"version%d\", cnt );\n\t\tsdb_ns_set (sdb, key, sdb_version);\n\t\t//if entry->vn_next is 0 it iterate infinitely\n\t\tif (!entry->vn_next) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tfree (need);\n\treturn sdb;\nbeach:\n\tfree (need);\n\tsdb_free (sdb_vernaux);\n\tsdb_free (sdb_version);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "func_src_after": "static Sdb *store_versioninfo_gnu_verneed(ELFOBJ *bin, Elf_(Shdr) *shdr, int sz) {\n\tut8 *end, *need = NULL;\n\tconst char *section_name = \"\";\n\tElf_(Shdr) *link_shdr = NULL;\n\tconst char *link_section_name = \"\";\n\tSdb *sdb_vernaux = NULL;\n\tSdb *sdb_version = NULL;\n\tSdb *sdb = NULL;\n\tint i, cnt;\n\n\tif (!bin || !bin->dynstr) {\n\t\treturn NULL;\n\t}\n\tif (shdr->sh_link > bin->ehdr.e_shnum) {\n\t\treturn NULL;\n\t}\n\tif (shdr->sh_size < 1) {\n\t\treturn NULL;\n\t}\n\tsdb = sdb_new0 ();\n\tif (!sdb) {\n\t\treturn NULL;\n\t}\n\tlink_shdr = &bin->shdr[shdr->sh_link];\n\tif (bin->shstrtab && shdr->sh_name < bin->shstrtab_size) {\n\t\tsection_name = &bin->shstrtab[shdr->sh_name];\n\t}\n\tif (bin->shstrtab && link_shdr->sh_name < bin->shstrtab_size) {\n\t\tlink_section_name = &bin->shstrtab[link_shdr->sh_name];\n\t}\n\tif (!(need = (ut8*) calloc (R_MAX (1, shdr->sh_size), sizeof (ut8)))) {\n\t\tbprintf (\"Warning: Cannot allocate memory for Elf_(Verneed)\\n\");\n\t\tgoto beach;\n\t}\n\tend = need + shdr->sh_size;\n\tsdb_set (sdb, \"section_name\", section_name, 0);\n\tsdb_num_set (sdb, \"num_entries\", shdr->sh_info, 0);\n\tsdb_num_set (sdb, \"addr\", shdr->sh_addr, 0);\n\tsdb_num_set (sdb, \"offset\", shdr->sh_offset, 0);\n\tsdb_num_set (sdb, \"link\", shdr->sh_link, 0);\n\tsdb_set (sdb, \"link_section_name\", link_section_name, 0);\n\n\tif (shdr->sh_offset > bin->size || shdr->sh_offset + shdr->sh_size > bin->size) {\n\t\tgoto beach;\n\t}\n\tif (shdr->sh_offset + shdr->sh_size < shdr->sh_size) {\n\t\tgoto beach;\n\t}\n\ti = r_buf_read_at (bin->b, shdr->sh_offset, need, shdr->sh_size);\n\tif (i < 0)\n\t\tgoto beach;\n\t//XXX we should use DT_VERNEEDNUM instead of sh_info\n\t//TODO https://sourceware.org/ml/binutils/2014-11/msg00353.html\n\tfor (i = 0, cnt = 0; cnt < shdr->sh_info; ++cnt) {\n\t\tint j, isum;\n\t\tut8 *vstart = need + i;\n\t\tElf_(Verneed) vvn = {0};\n\t\tif (vstart + sizeof (Elf_(Verneed)) > end) {\n\t\t\tgoto beach;\n\t\t}\n\t\tElf_(Verneed) *entry = &vvn;\n\t\tchar key[32] = {0};\n\t\tsdb_version = sdb_new0 ();\n\t\tif (!sdb_version) {\n\t\t\tgoto beach;\n\t\t}\n\t\tj = 0;\n\t\tvvn.vn_version = READ16 (vstart, j)\n\t\tvvn.vn_cnt = READ16 (vstart, j)\n\t\tvvn.vn_file = READ32 (vstart, j)\n\t\tvvn.vn_aux = READ32 (vstart, j)\n\t\tvvn.vn_next = READ32 (vstart, j)\n\n\t\tsdb_num_set (sdb_version, \"vn_version\", entry->vn_version, 0);\n\t\tsdb_num_set (sdb_version, \"idx\", i, 0);\n\t\tif (entry->vn_file > bin->dynstr_size) {\n\t\t\tgoto beach;\n\t\t}\n\t\t{\n\t\t\tchar *s = r_str_ndup (&bin->dynstr[entry->vn_file], 16);\n\t\t\tsdb_set (sdb_version, \"file_name\", s, 0);\n\t\t\tfree (s);\n\t\t}\n\t\tsdb_num_set (sdb_version, \"cnt\", entry->vn_cnt, 0);\n\t\tst32 vnaux = entry->vn_aux;\n\t\tif (vnaux < 1) {\n\t\t\tgoto beach;\n\t\t}\n\t\tvstart += vnaux;\n\t\tfor (j = 0, isum = i + entry->vn_aux; j < entry->vn_cnt && vstart + sizeof (Elf_(Vernaux)) <= end; ++j) {\n\t\t\tint k;\n\t\t\tElf_(Vernaux) * aux = NULL;\n\t\t\tElf_(Vernaux) vaux = {0};\n\t\t\tsdb_vernaux = sdb_new0 ();\n\t\t\tif (!sdb_vernaux) {\n\t\t\t\tgoto beach;\n\t\t\t}\n\t\t\taux = (Elf_(Vernaux)*)&vaux;\n\t\t\tk = 0;\n\t\t\tvaux.vna_hash = READ32 (vstart, k)\n\t\t\tvaux.vna_flags = READ16 (vstart, k)\n\t\t\tvaux.vna_other = READ16 (vstart, k)\n\t\t\tvaux.vna_name = READ32 (vstart, k)\n\t\t\tvaux.vna_next = READ32 (vstart, k)\n\t\t\tif (aux->vna_name > bin->dynstr_size) {\n\t\t\t\tgoto beach;\n\t\t\t}\n\t\t\tsdb_num_set (sdb_vernaux, \"idx\", isum, 0);\n\t\t\tif (aux->vna_name > 0 && aux->vna_name + 8 < bin->dynstr_size) {\n\t\t\t\tchar name [16];\n\t\t\t\tstrncpy (name, &bin->dynstr[aux->vna_name], sizeof (name)-1);\n\t\t\t\tname[sizeof(name)-1] = 0;\n\t\t\t\tsdb_set (sdb_vernaux, \"name\", name, 0);\n\t\t\t}\n\t\t\tsdb_set (sdb_vernaux, \"flags\", get_ver_flags (aux->vna_flags), 0);\n\t\t\tsdb_num_set (sdb_vernaux, \"version\", aux->vna_other, 0);\n\t\t\tisum += aux->vna_next;\n\t\t\tvstart += aux->vna_next;\n\t\t\tsnprintf (key, sizeof (key), \"vernaux%d\", j);\n\t\t\tsdb_ns_set (sdb_version, key, sdb_vernaux);\n\t\t}\n\t\tif ((int)entry->vn_next < 0) {\n\t\t\tbprintf (\"Invalid vn_next\\n\");\n\t\t\tbreak;\n\t\t}\n\t\ti += entry->vn_next;\n\t\tsnprintf (key, sizeof (key), \"version%d\", cnt );\n\t\tsdb_ns_set (sdb, key, sdb_version);\n\t\t//if entry->vn_next is 0 it iterate infinitely\n\t\tif (!entry->vn_next) {\n\t\t\tbreak;\n\t\t}\n\t}\n\tfree (need);\n\treturn sdb;\nbeach:\n\tfree (need);\n\tsdb_free (sdb_vernaux);\n\tsdb_free (sdb_version);\n\tsdb_free (sdb);\n\treturn NULL;\n}", "commit_link": "github.com/radare/radare2/commit/c6d0076c924891ad9948a62d89d0bcdaf965f0cd", "file_name": "libr/bin/format/elf/elf.c", "vul_type": "cwe-125", "description": "In C, write a function to parse and store GNU version dependency information from an ELF binary's section header."}
{"func_name": "cx24116_send_diseqc_msg", "func_src_before": "static int cx24116_send_diseqc_msg(struct dvb_frontend *fe,\n\tstruct dvb_diseqc_master_cmd *d)\n{\n\tstruct cx24116_state *state = fe->demodulator_priv;\n\tint i, ret;\n\n\t/* Validate length */\n\tif (d->msg_len > sizeof(d->msg))\n                return -EINVAL;\n\n\t/* Dump DiSEqC message */\n\tif (debug) {\n\t\tprintk(KERN_INFO \"cx24116: %s(\", __func__);\n\t\tfor (i = 0 ; i < d->msg_len ;) {\n\t\t\tprintk(KERN_INFO \"0x%02x\", d->msg[i]);\n\t\t\tif (++i < d->msg_len)\n\t\t\t\tprintk(KERN_INFO \", \");\n\t\t}\n\t\tprintk(\") toneburst=%d\\n\", toneburst);\n\t}\n\n\t/* DiSEqC message */\n\tfor (i = 0; i < d->msg_len; i++)\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_MSGOFS + i] = d->msg[i];\n\n\t/* DiSEqC message length */\n\tstate->dsec_cmd.args[CX24116_DISEQC_MSGLEN] = d->msg_len;\n\n\t/* Command length */\n\tstate->dsec_cmd.len = CX24116_DISEQC_MSGOFS +\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_MSGLEN];\n\n\t/* DiSEqC toneburst */\n\tif (toneburst == CX24116_DISEQC_MESGCACHE)\n\t\t/* Message is cached */\n\t\treturn 0;\n\n\telse if (toneburst == CX24116_DISEQC_TONEOFF)\n\t\t/* Message is sent without burst */\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST] = 0;\n\n\telse if (toneburst == CX24116_DISEQC_TONECACHE) {\n\t\t/*\n\t\t * Message is sent with derived else cached burst\n\t\t *\n\t\t * WRITE PORT GROUP COMMAND 38\n\t\t *\n\t\t * 0/A/A: E0 10 38 F0..F3\n\t\t * 1/B/B: E0 10 38 F4..F7\n\t\t * 2/C/A: E0 10 38 F8..FB\n\t\t * 3/D/B: E0 10 38 FC..FF\n\t\t *\n\t\t * databyte[3]= 8421:8421\n\t\t *              ABCD:WXYZ\n\t\t *              CLR :SET\n\t\t *\n\t\t *              WX= PORT SELECT 0..3    (X=TONEBURST)\n\t\t *              Y = VOLTAGE             (0=13V, 1=18V)\n\t\t *              Z = BAND                (0=LOW, 1=HIGH(22K))\n\t\t */\n\t\tif (d->msg_len >= 4 && d->msg[2] == 0x38)\n\t\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST] =\n\t\t\t\t((d->msg[3] & 4) >> 2);\n\t\tif (debug)\n\t\t\tdprintk(\"%s burst=%d\\n\", __func__,\n\t\t\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST]);\n\t}\n\n\t/* Wait for LNB ready */\n\tret = cx24116_wait_for_lnb(fe);\n\tif (ret != 0)\n\t\treturn ret;\n\n\t/* Wait for voltage/min repeat delay */\n\tmsleep(100);\n\n\t/* Command */\n\tret = cx24116_cmd_execute(fe, &state->dsec_cmd);\n\tif (ret != 0)\n\t\treturn ret;\n\t/*\n\t * Wait for send\n\t *\n\t * Eutelsat spec:\n\t * >15ms delay          + (XXX determine if FW does this, see set_tone)\n\t *  13.5ms per byte     +\n\t * >15ms delay          +\n\t *  12.5ms burst        +\n\t * >15ms delay            (XXX determine if FW does this, see set_tone)\n\t */\n\tmsleep((state->dsec_cmd.args[CX24116_DISEQC_MSGLEN] << 4) +\n\t\t((toneburst == CX24116_DISEQC_TONEOFF) ? 30 : 60));\n\n\treturn 0;\n}", "func_src_after": "static int cx24116_send_diseqc_msg(struct dvb_frontend *fe,\n\tstruct dvb_diseqc_master_cmd *d)\n{\n\tstruct cx24116_state *state = fe->demodulator_priv;\n\tint i, ret;\n\n\t/* Dump DiSEqC message */\n\tif (debug) {\n\t\tprintk(KERN_INFO \"cx24116: %s(\", __func__);\n\t\tfor (i = 0 ; i < d->msg_len ;) {\n\t\t\tprintk(KERN_INFO \"0x%02x\", d->msg[i]);\n\t\t\tif (++i < d->msg_len)\n\t\t\t\tprintk(KERN_INFO \", \");\n\t\t}\n\t\tprintk(\") toneburst=%d\\n\", toneburst);\n\t}\n\n\t/* Validate length */\n\tif (d->msg_len > (CX24116_ARGLEN - CX24116_DISEQC_MSGOFS))\n\t\treturn -EINVAL;\n\n\t/* DiSEqC message */\n\tfor (i = 0; i < d->msg_len; i++)\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_MSGOFS + i] = d->msg[i];\n\n\t/* DiSEqC message length */\n\tstate->dsec_cmd.args[CX24116_DISEQC_MSGLEN] = d->msg_len;\n\n\t/* Command length */\n\tstate->dsec_cmd.len = CX24116_DISEQC_MSGOFS +\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_MSGLEN];\n\n\t/* DiSEqC toneburst */\n\tif (toneburst == CX24116_DISEQC_MESGCACHE)\n\t\t/* Message is cached */\n\t\treturn 0;\n\n\telse if (toneburst == CX24116_DISEQC_TONEOFF)\n\t\t/* Message is sent without burst */\n\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST] = 0;\n\n\telse if (toneburst == CX24116_DISEQC_TONECACHE) {\n\t\t/*\n\t\t * Message is sent with derived else cached burst\n\t\t *\n\t\t * WRITE PORT GROUP COMMAND 38\n\t\t *\n\t\t * 0/A/A: E0 10 38 F0..F3\n\t\t * 1/B/B: E0 10 38 F4..F7\n\t\t * 2/C/A: E0 10 38 F8..FB\n\t\t * 3/D/B: E0 10 38 FC..FF\n\t\t *\n\t\t * databyte[3]= 8421:8421\n\t\t *              ABCD:WXYZ\n\t\t *              CLR :SET\n\t\t *\n\t\t *              WX= PORT SELECT 0..3    (X=TONEBURST)\n\t\t *              Y = VOLTAGE             (0=13V, 1=18V)\n\t\t *              Z = BAND                (0=LOW, 1=HIGH(22K))\n\t\t */\n\t\tif (d->msg_len >= 4 && d->msg[2] == 0x38)\n\t\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST] =\n\t\t\t\t((d->msg[3] & 4) >> 2);\n\t\tif (debug)\n\t\t\tdprintk(\"%s burst=%d\\n\", __func__,\n\t\t\t\tstate->dsec_cmd.args[CX24116_DISEQC_BURST]);\n\t}\n\n\t/* Wait for LNB ready */\n\tret = cx24116_wait_for_lnb(fe);\n\tif (ret != 0)\n\t\treturn ret;\n\n\t/* Wait for voltage/min repeat delay */\n\tmsleep(100);\n\n\t/* Command */\n\tret = cx24116_cmd_execute(fe, &state->dsec_cmd);\n\tif (ret != 0)\n\t\treturn ret;\n\t/*\n\t * Wait for send\n\t *\n\t * Eutelsat spec:\n\t * >15ms delay          + (XXX determine if FW does this, see set_tone)\n\t *  13.5ms per byte     +\n\t * >15ms delay          +\n\t *  12.5ms burst        +\n\t * >15ms delay            (XXX determine if FW does this, see set_tone)\n\t */\n\tmsleep((state->dsec_cmd.args[CX24116_DISEQC_MSGLEN] << 4) +\n\t\t((toneburst == CX24116_DISEQC_TONEOFF) ? 30 : 60));\n\n\treturn 0;\n}", "commit_link": "github.com/torvalds/linux/commit/1fa2337a315a2448c5434f41e00d56b01a22283c", "file_name": "drivers/media/dvb-frontends/cx24116.c", "vul_type": "cwe-125", "description": "Write a C function `cx24116_send_diseqc_msg` to send a DiSEqC message to a satellite frontend device."}
{"func_name": "fm10k_init_module", "func_src_before": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}", "func_src_after": "static int __init fm10k_init_module(void)\n{\n\tpr_info(\"%s - version %s\\n\", fm10k_driver_string, fm10k_driver_version);\n\tpr_info(\"%s\\n\", fm10k_copyright);\n\n\t/* create driver workqueue */\n\tfm10k_workqueue = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM, 0,\n\t\t\t\t\t  fm10k_driver_name);\n\tif (!fm10k_workqueue)\n\t\treturn -ENOMEM;\n\n\tfm10k_dbg_init();\n\n\treturn fm10k_register_pci_driver();\n}", "commit_link": "github.com/torvalds/linux/commit/01ca667133d019edc9f0a1f70a272447c84ec41f", "file_name": "drivers/net/ethernet/intel/fm10k/fm10k_main.c", "vul_type": "cwe-476", "description": "Write a Linux kernel module initialization function in C that logs the driver version, allocates a workqueue, initializes debugging, and registers a PCI driver, handling potential memory allocation failure."}
{"func_name": "ApplyEvaluateOperator", "func_src_before": "static MagickRealType ApplyEvaluateOperator(RandomInfo *random_info,\n  const Quantum pixel,const MagickEvaluateOperator op,\n  const MagickRealType value)\n{\n  MagickRealType\n    result;\n\n  result=0.0;\n  switch (op)\n  {\n    case UndefinedEvaluateOperator:\n      break;\n    case AbsEvaluateOperator:\n    {\n      result=(MagickRealType) fabs((double) (pixel+value));\n      break;\n    }\n    case AddEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case AddModulusEvaluateOperator:\n    {\n      /*\n        This returns a 'floored modulus' of the addition which is a\n        positive result.  It differs from  % or fmod() which returns a\n        'truncated modulus' result, where floor() is replaced by trunc()\n        and could return a negative result (which is clipped).\n      */\n      result=pixel+value;\n      result-=(QuantumRange+1.0)*floor((double) result/(QuantumRange+1.0));\n      break;\n    }\n    case AndEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel & (ssize_t) (value+0.5));\n      break;\n    }\n    case CosineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*cos((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case DivideEvaluateOperator:\n    {\n      result=pixel/(value == 0.0 ? 1.0 : value);\n      break;\n    }\n    case ExponentialEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*exp((double) (value*QuantumScale*\n        pixel)));\n      break;\n    }\n    case GaussianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        GaussianNoise,value);\n      break;\n    }\n    case ImpulseNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        ImpulseNoise,value);\n      break;\n    }\n    case LaplacianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        LaplacianNoise,value);\n      break;\n    }\n    case LeftShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel << (ssize_t) (value+0.5));\n      break;\n    }\n    case LogEvaluateOperator:\n    {\n      if ((QuantumScale*pixel) >= MagickEpsilon)\n        result=(MagickRealType) (QuantumRange*log((double) (QuantumScale*value*\n          pixel+1.0))/log((double) (value+1.0)));\n      break;\n    }\n    case MaxEvaluateOperator:\n    {\n      result=(MagickRealType) EvaluateMax((double) pixel,value);\n      break;\n    }\n    case MeanEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MedianEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MinEvaluateOperator:\n    {\n      result=(MagickRealType) MagickMin((double) pixel,value);\n      break;\n    }\n    case MultiplicativeNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        MultiplicativeGaussianNoise,value);\n      break;\n    }\n    case MultiplyEvaluateOperator:\n    {\n      result=(MagickRealType) (value*pixel);\n      break;\n    }\n    case OrEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel | (ssize_t) (value+0.5));\n      break;\n    }\n    case PoissonNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        PoissonNoise,value);\n      break;\n    }\n    case PowEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*pow((double) (QuantumScale*pixel),\n        (double) value));\n      break;\n    }\n    case RightShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel >> (ssize_t) (value+0.5));\n      break;\n    }\n    case RootMeanSquareEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel*pixel+value);\n      break;\n    }\n    case SetEvaluateOperator:\n    {\n      result=value;\n      break;\n    }\n    case SineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*sin((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case SubtractEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel-value);\n      break;\n    }\n    case SumEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case ThresholdEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 :\n        QuantumRange);\n      break;\n    }\n    case ThresholdBlackEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 : pixel);\n      break;\n    }\n    case ThresholdWhiteEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel > value) ? QuantumRange :\n        pixel);\n      break;\n    }\n    case UniformNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        UniformNoise,value);\n      break;\n    }\n    case XorEvaluateOperator:\n    {\n      result=(MagickRealType) ((ssize_t) pixel ^ (ssize_t) (value+0.5));\n      break;\n    }\n  }\n  return(result);\n}", "func_src_after": "static MagickRealType ApplyEvaluateOperator(RandomInfo *random_info,\n  const Quantum pixel,const MagickEvaluateOperator op,\n  const MagickRealType value)\n{\n  MagickRealType\n    result;\n\n  result=0.0;\n  switch (op)\n  {\n    case UndefinedEvaluateOperator:\n      break;\n    case AbsEvaluateOperator:\n    {\n      result=(MagickRealType) fabs((double) (pixel+value));\n      break;\n    }\n    case AddEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case AddModulusEvaluateOperator:\n    {\n      /*\n        This returns a 'floored modulus' of the addition which is a\n        positive result.  It differs from  % or fmod() which returns a\n        'truncated modulus' result, where floor() is replaced by trunc()\n        and could return a negative result (which is clipped).\n      */\n      result=pixel+value;\n      result-=(QuantumRange+1.0)*floor((double) result/(QuantumRange+1.0));\n      break;\n    }\n    case AndEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel & (size_t) (value+0.5));\n      break;\n    }\n    case CosineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*cos((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case DivideEvaluateOperator:\n    {\n      result=pixel/(value == 0.0 ? 1.0 : value);\n      break;\n    }\n    case ExponentialEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*exp((double) (value*QuantumScale*\n        pixel)));\n      break;\n    }\n    case GaussianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        GaussianNoise,value);\n      break;\n    }\n    case ImpulseNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        ImpulseNoise,value);\n      break;\n    }\n    case LaplacianNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        LaplacianNoise,value);\n      break;\n    }\n    case LeftShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel << (size_t) (value+0.5));\n      break;\n    }\n    case LogEvaluateOperator:\n    {\n      if ((QuantumScale*pixel) >= MagickEpsilon)\n        result=(MagickRealType) (QuantumRange*log((double) (QuantumScale*value*\n          pixel+1.0))/log((double) (value+1.0)));\n      break;\n    }\n    case MaxEvaluateOperator:\n    {\n      result=(MagickRealType) EvaluateMax((double) pixel,value);\n      break;\n    }\n    case MeanEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MedianEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case MinEvaluateOperator:\n    {\n      result=(MagickRealType) MagickMin((double) pixel,value);\n      break;\n    }\n    case MultiplicativeNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        MultiplicativeGaussianNoise,value);\n      break;\n    }\n    case MultiplyEvaluateOperator:\n    {\n      result=(MagickRealType) (value*pixel);\n      break;\n    }\n    case OrEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel | (size_t) (value+0.5));\n      break;\n    }\n    case PoissonNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        PoissonNoise,value);\n      break;\n    }\n    case PowEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*pow((double) (QuantumScale*pixel),\n        (double) value));\n      break;\n    }\n    case RightShiftEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel >> (size_t) (value+0.5));\n      break;\n    }\n    case RootMeanSquareEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel*pixel+value);\n      break;\n    }\n    case SetEvaluateOperator:\n    {\n      result=value;\n      break;\n    }\n    case SineEvaluateOperator:\n    {\n      result=(MagickRealType) (QuantumRange*(0.5*sin((double) (2.0*MagickPI*\n        QuantumScale*pixel*value))+0.5));\n      break;\n    }\n    case SubtractEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel-value);\n      break;\n    }\n    case SumEvaluateOperator:\n    {\n      result=(MagickRealType) (pixel+value);\n      break;\n    }\n    case ThresholdEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 :\n        QuantumRange);\n      break;\n    }\n    case ThresholdBlackEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel <= value) ? 0 : pixel);\n      break;\n    }\n    case ThresholdWhiteEvaluateOperator:\n    {\n      result=(MagickRealType) (((MagickRealType) pixel > value) ? QuantumRange :\n        pixel);\n      break;\n    }\n    case UniformNoiseEvaluateOperator:\n    {\n      result=(MagickRealType) GenerateDifferentialNoise(random_info,pixel,\n        UniformNoise,value);\n      break;\n    }\n    case XorEvaluateOperator:\n    {\n      result=(MagickRealType) ((size_t) pixel ^ (size_t) (value+0.5));\n      break;\n    }\n  }\n  return(result);\n}", "commit_link": "github.com/ImageMagick/ImageMagick6/commit/3e21bc8a58b4ae38d24c7e283837cc279f35b6a5", "file_name": "magick/statistic.c", "vul_type": "cwe-190", "description": "Write a C function named `ApplyEvaluateOperator` that performs various arithmetic and noise operations on a pixel value based on an operator type."}
{"func_name": "mxf_parse_structural_metadata", "func_src_before": "static int mxf_parse_structural_metadata(MXFContext *mxf)\n{\n    MXFPackage *material_package = NULL;\n    int i, j, k, ret;\n\n    av_log(mxf->fc, AV_LOG_TRACE, \"metadata sets count %d\\n\", mxf->metadata_sets_count);\n    /* TODO: handle multiple material packages (OP3x) */\n    for (i = 0; i < mxf->packages_count; i++) {\n        material_package = mxf_resolve_strong_ref(mxf, &mxf->packages_refs[i], MaterialPackage);\n        if (material_package) break;\n    }\n    if (!material_package) {\n        av_log(mxf->fc, AV_LOG_ERROR, \"no material package found\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    mxf_add_umid_metadata(&mxf->fc->metadata, \"material_package_umid\", material_package);\n    if (material_package->name && material_package->name[0])\n        av_dict_set(&mxf->fc->metadata, \"material_package_name\", material_package->name, 0);\n    mxf_parse_package_comments(mxf, &mxf->fc->metadata, material_package);\n\n    for (i = 0; i < material_package->tracks_count; i++) {\n        MXFPackage *source_package = NULL;\n        MXFTrack *material_track = NULL;\n        MXFTrack *source_track = NULL;\n        MXFTrack *temp_track = NULL;\n        MXFDescriptor *descriptor = NULL;\n        MXFStructuralComponent *component = NULL;\n        MXFTimecodeComponent *mxf_tc = NULL;\n        UID *essence_container_ul = NULL;\n        const MXFCodecUL *codec_ul = NULL;\n        const MXFCodecUL *container_ul = NULL;\n        const MXFCodecUL *pix_fmt_ul = NULL;\n        AVStream *st;\n        AVTimecode tc;\n        int flags;\n\n        if (!(material_track = mxf_resolve_strong_ref(mxf, &material_package->tracks_refs[i], Track))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track strong ref\\n\");\n            continue;\n        }\n\n        if ((component = mxf_resolve_strong_ref(mxf, &material_track->sequence_ref, TimecodeComponent))) {\n            mxf_tc = (MXFTimecodeComponent*)component;\n            flags = mxf_tc->drop_frame == 1 ? AV_TIMECODE_FLAG_DROPFRAME : 0;\n            if (av_timecode_init(&tc, mxf_tc->rate, flags, mxf_tc->start_frame, mxf->fc) == 0) {\n                mxf_add_timecode_metadata(&mxf->fc->metadata, \"timecode\", &tc);\n            }\n        }\n\n        if (!(material_track->sequence = mxf_resolve_strong_ref(mxf, &material_track->sequence_ref, Sequence))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track sequence strong ref\\n\");\n            continue;\n        }\n\n        for (j = 0; j < material_track->sequence->structural_components_count; j++) {\n            component = mxf_resolve_strong_ref(mxf, &material_track->sequence->structural_components_refs[j], TimecodeComponent);\n            if (!component)\n                continue;\n\n            mxf_tc = (MXFTimecodeComponent*)component;\n            flags = mxf_tc->drop_frame == 1 ? AV_TIMECODE_FLAG_DROPFRAME : 0;\n            if (av_timecode_init(&tc, mxf_tc->rate, flags, mxf_tc->start_frame, mxf->fc) == 0) {\n                mxf_add_timecode_metadata(&mxf->fc->metadata, \"timecode\", &tc);\n                break;\n            }\n        }\n\n        /* TODO: handle multiple source clips, only finds first valid source clip */\n        if(material_track->sequence->structural_components_count > 1)\n            av_log(mxf->fc, AV_LOG_WARNING, \"material track %d: has %d components\\n\",\n                       material_track->track_id, material_track->sequence->structural_components_count);\n\n        for (j = 0; j < material_track->sequence->structural_components_count; j++) {\n            component = mxf_resolve_sourceclip(mxf, &material_track->sequence->structural_components_refs[j]);\n            if (!component)\n                continue;\n\n            source_package = mxf_resolve_source_package(mxf, component->source_package_ul, component->source_package_uid);\n            if (!source_package) {\n                av_log(mxf->fc, AV_LOG_TRACE, \"material track %d: no corresponding source package found\\n\", material_track->track_id);\n                continue;\n            }\n            for (k = 0; k < source_package->tracks_count; k++) {\n                if (!(temp_track = mxf_resolve_strong_ref(mxf, &source_package->tracks_refs[k], Track))) {\n                    av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track strong ref\\n\");\n                    ret = AVERROR_INVALIDDATA;\n                    goto fail_and_free;\n                }\n                if (temp_track->track_id == component->source_track_id) {\n                    source_track = temp_track;\n                    break;\n                }\n            }\n            if (!source_track) {\n                av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: no corresponding source track found\\n\", material_track->track_id);\n                break;\n            }\n\n            for (k = 0; k < mxf->essence_container_data_count; k++) {\n                MXFEssenceContainerData *essence_data;\n\n                if (!(essence_data = mxf_resolve_strong_ref(mxf, &mxf->essence_container_data_refs[k], EssenceContainerData))) {\n                    av_log(mxf, AV_LOG_TRACE, \"could not resolve essence container data strong ref\\n\");\n                    continue;\n                }\n                if (!memcmp(component->source_package_ul, essence_data->package_ul, sizeof(UID)) && !memcmp(component->source_package_uid, essence_data->package_uid, sizeof(UID))) {\n                    source_track->body_sid = essence_data->body_sid;\n                    source_track->index_sid = essence_data->index_sid;\n                    break;\n                }\n            }\n\n            if(source_track && component)\n                break;\n        }\n        if (!source_track || !component || !source_package) {\n            if((ret = mxf_add_metadata_stream(mxf, material_track)))\n                goto fail_and_free;\n            continue;\n        }\n\n        if (!(source_track->sequence = mxf_resolve_strong_ref(mxf, &source_track->sequence_ref, Sequence))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track sequence strong ref\\n\");\n            ret = AVERROR_INVALIDDATA;\n            goto fail_and_free;\n        }\n\n        /* 0001GL00.MXF.A1.mxf_opatom.mxf has the same SourcePackageID as 0001GL.MXF.V1.mxf_opatom.mxf\n         * This would result in both files appearing to have two streams. Work around this by sanity checking DataDefinition */\n        if (memcmp(material_track->sequence->data_definition_ul, source_track->sequence->data_definition_ul, 16)) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: DataDefinition mismatch\\n\", material_track->track_id);\n            continue;\n        }\n\n        st = avformat_new_stream(mxf->fc, NULL);\n        if (!st) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not allocate stream\\n\");\n            ret = AVERROR(ENOMEM);\n            goto fail_and_free;\n        }\n        st->id = material_track->track_id;\n        st->priv_data = source_track;\n\n        source_package->descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor_ref, AnyType);\n        descriptor = mxf_resolve_multidescriptor(mxf, source_package->descriptor, source_track->track_id);\n\n        /* A SourceClip from a EssenceGroup may only be a single frame of essence data. The clips duration is then how many\n         * frames its suppose to repeat for. Descriptor->duration, if present, contains the real duration of the essence data */\n        if (descriptor && descriptor->duration != AV_NOPTS_VALUE)\n            source_track->original_duration = st->duration = FFMIN(descriptor->duration, component->duration);\n        else\n            source_track->original_duration = st->duration = component->duration;\n\n        if (st->duration == -1)\n            st->duration = AV_NOPTS_VALUE;\n        st->start_time = component->start_position;\n        if (material_track->edit_rate.num <= 0 ||\n            material_track->edit_rate.den <= 0) {\n            av_log(mxf->fc, AV_LOG_WARNING,\n                   \"Invalid edit rate (%d/%d) found on stream #%d, \"\n                   \"defaulting to 25/1\\n\",\n                   material_track->edit_rate.num,\n                   material_track->edit_rate.den, st->index);\n            material_track->edit_rate = (AVRational){25, 1};\n        }\n        avpriv_set_pts_info(st, 64, material_track->edit_rate.den, material_track->edit_rate.num);\n\n        /* ensure SourceTrack EditRate == MaterialTrack EditRate since only\n         * the former is accessible via st->priv_data */\n        source_track->edit_rate = material_track->edit_rate;\n\n        PRINT_KEY(mxf->fc, \"data definition   ul\", source_track->sequence->data_definition_ul);\n        codec_ul = mxf_get_codec_ul(ff_mxf_data_definition_uls, &source_track->sequence->data_definition_ul);\n        st->codecpar->codec_type = codec_ul->id;\n\n        if (!descriptor) {\n            av_log(mxf->fc, AV_LOG_INFO, \"source track %d: stream %d, no descriptor found\\n\", source_track->track_id, st->index);\n            continue;\n        }\n        PRINT_KEY(mxf->fc, \"essence codec     ul\", descriptor->essence_codec_ul);\n        PRINT_KEY(mxf->fc, \"essence container ul\", descriptor->essence_container_ul);\n        essence_container_ul = &descriptor->essence_container_ul;\n        source_track->wrapping = (mxf->op == OPAtom) ? ClipWrapped : mxf_get_wrapping_kind(essence_container_ul);\n        if (source_track->wrapping == UnknownWrapped)\n            av_log(mxf->fc, AV_LOG_INFO, \"wrapping of stream %d is unknown\\n\", st->index);\n        /* HACK: replacing the original key with mxf_encrypted_essence_container\n         * is not allowed according to s429-6, try to find correct information anyway */\n        if (IS_KLV_KEY(essence_container_ul, mxf_encrypted_essence_container)) {\n            av_log(mxf->fc, AV_LOG_INFO, \"broken encrypted mxf file\\n\");\n            for (k = 0; k < mxf->metadata_sets_count; k++) {\n                MXFMetadataSet *metadata = mxf->metadata_sets[k];\n                if (metadata->type == CryptoContext) {\n                    essence_container_ul = &((MXFCryptoContext *)metadata)->source_container_ul;\n                    break;\n                }\n            }\n        }\n\n        /* TODO: drop PictureEssenceCoding and SoundEssenceCompression, only check EssenceContainer */\n        codec_ul = mxf_get_codec_ul(ff_mxf_codec_uls, &descriptor->essence_codec_ul);\n        st->codecpar->codec_id = (enum AVCodecID)codec_ul->id;\n        if (st->codecpar->codec_id == AV_CODEC_ID_NONE) {\n            codec_ul = mxf_get_codec_ul(ff_mxf_codec_uls, &descriptor->codec_ul);\n            st->codecpar->codec_id = (enum AVCodecID)codec_ul->id;\n        }\n\n        av_log(mxf->fc, AV_LOG_VERBOSE, \"%s: Universal Label: \",\n               avcodec_get_name(st->codecpar->codec_id));\n        for (k = 0; k < 16; k++) {\n            av_log(mxf->fc, AV_LOG_VERBOSE, \"%.2x\",\n                   descriptor->essence_codec_ul[k]);\n            if (!(k+1 & 19) || k == 5)\n                av_log(mxf->fc, AV_LOG_VERBOSE, \".\");\n        }\n        av_log(mxf->fc, AV_LOG_VERBOSE, \"\\n\");\n\n        mxf_add_umid_metadata(&st->metadata, \"file_package_umid\", source_package);\n        if (source_package->name && source_package->name[0])\n            av_dict_set(&st->metadata, \"file_package_name\", source_package->name, 0);\n        if (material_track->name && material_track->name[0])\n            av_dict_set(&st->metadata, \"track_name\", material_track->name, 0);\n\n        mxf_parse_physical_source_package(mxf, source_track, st);\n\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n            source_track->intra_only = mxf_is_intra_only(descriptor);\n            container_ul = mxf_get_codec_ul(mxf_picture_essence_container_uls, essence_container_ul);\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE)\n                st->codecpar->codec_id = container_ul->id;\n            st->codecpar->width = descriptor->width;\n            st->codecpar->height = descriptor->height; /* Field height, not frame height */\n            switch (descriptor->frame_layout) {\n                case FullFrame:\n                    st->codecpar->field_order = AV_FIELD_PROGRESSIVE;\n                    break;\n                case OneField:\n                    /* Every other line is stored and needs to be duplicated. */\n                    av_log(mxf->fc, AV_LOG_INFO, \"OneField frame layout isn't currently supported\\n\");\n                    break; /* The correct thing to do here is fall through, but by breaking we might be\n                              able to decode some streams at half the vertical resolution, rather than not al all.\n                              It's also for compatibility with the old behavior. */\n                case MixedFields:\n                    break;\n                case SegmentedFrame:\n                    st->codecpar->field_order = AV_FIELD_PROGRESSIVE;\n                case SeparateFields:\n                    av_log(mxf->fc, AV_LOG_DEBUG, \"video_line_map: (%d, %d), field_dominance: %d\\n\",\n                           descriptor->video_line_map[0], descriptor->video_line_map[1],\n                           descriptor->field_dominance);\n                    if ((descriptor->video_line_map[0] > 0) && (descriptor->video_line_map[1] > 0)) {\n                        /* Detect coded field order from VideoLineMap:\n                         *  (even, even) => bottom field coded first\n                         *  (even, odd)  => top field coded first\n                         *  (odd, even)  => top field coded first\n                         *  (odd, odd)   => bottom field coded first\n                         */\n                        if ((descriptor->video_line_map[0] + descriptor->video_line_map[1]) % 2) {\n                            switch (descriptor->field_dominance) {\n                                case MXF_FIELD_DOMINANCE_DEFAULT:\n                                case MXF_FIELD_DOMINANCE_FF:\n                                    st->codecpar->field_order = AV_FIELD_TT;\n                                    break;\n                                case MXF_FIELD_DOMINANCE_FL:\n                                    st->codecpar->field_order = AV_FIELD_TB;\n                                    break;\n                                default:\n                                    avpriv_request_sample(mxf->fc,\n                                                          \"Field dominance %d support\",\n                                                          descriptor->field_dominance);\n                            }\n                        } else {\n                            switch (descriptor->field_dominance) {\n                                case MXF_FIELD_DOMINANCE_DEFAULT:\n                                case MXF_FIELD_DOMINANCE_FF:\n                                    st->codecpar->field_order = AV_FIELD_BB;\n                                    break;\n                                case MXF_FIELD_DOMINANCE_FL:\n                                    st->codecpar->field_order = AV_FIELD_BT;\n                                    break;\n                                default:\n                                    avpriv_request_sample(mxf->fc,\n                                                          \"Field dominance %d support\",\n                                                          descriptor->field_dominance);\n                            }\n                        }\n                    }\n                    /* Turn field height into frame height. */\n                    st->codecpar->height *= 2;\n                    break;\n                default:\n                    av_log(mxf->fc, AV_LOG_INFO, \"Unknown frame layout type: %d\\n\", descriptor->frame_layout);\n            }\n            if (st->codecpar->codec_id == AV_CODEC_ID_RAWVIDEO) {\n                st->codecpar->format = descriptor->pix_fmt;\n                if (st->codecpar->format == AV_PIX_FMT_NONE) {\n                    pix_fmt_ul = mxf_get_codec_ul(ff_mxf_pixel_format_uls,\n                                                  &descriptor->essence_codec_ul);\n                    st->codecpar->format = (enum AVPixelFormat)pix_fmt_ul->id;\n                    if (st->codecpar->format== AV_PIX_FMT_NONE) {\n                        st->codecpar->codec_tag = mxf_get_codec_ul(ff_mxf_codec_tag_uls,\n                                                                   &descriptor->essence_codec_ul)->id;\n                        if (!st->codecpar->codec_tag) {\n                            /* support files created before RP224v10 by defaulting to UYVY422\n                               if subsampling is 4:2:2 and component depth is 8-bit */\n                            if (descriptor->horiz_subsampling == 2 &&\n                                descriptor->vert_subsampling == 1 &&\n                                descriptor->component_depth == 8) {\n                                st->codecpar->format = AV_PIX_FMT_UYVY422;\n                            }\n                        }\n                    }\n                }\n            }\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n            if (material_track->sequence->origin) {\n                av_dict_set_int(&st->metadata, \"material_track_origin\", material_track->sequence->origin, 0);\n            }\n            if (source_track->sequence->origin) {\n                av_dict_set_int(&st->metadata, \"source_track_origin\", source_track->sequence->origin, 0);\n            }\n            if (descriptor->aspect_ratio.num && descriptor->aspect_ratio.den)\n                st->display_aspect_ratio = descriptor->aspect_ratio;\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n            container_ul = mxf_get_codec_ul(mxf_sound_essence_container_uls, essence_container_ul);\n            /* Only overwrite existing codec ID if it is unset or A-law, which is the default according to SMPTE RP 224. */\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE || (st->codecpar->codec_id == AV_CODEC_ID_PCM_ALAW && (enum AVCodecID)container_ul->id != AV_CODEC_ID_NONE))\n                st->codecpar->codec_id = (enum AVCodecID)container_ul->id;\n            st->codecpar->channels = descriptor->channels;\n            st->codecpar->bits_per_coded_sample = descriptor->bits_per_sample;\n\n            if (descriptor->sample_rate.den > 0) {\n                st->codecpar->sample_rate = descriptor->sample_rate.num / descriptor->sample_rate.den;\n                avpriv_set_pts_info(st, 64, descriptor->sample_rate.den, descriptor->sample_rate.num);\n            } else {\n                av_log(mxf->fc, AV_LOG_WARNING, \"invalid sample rate (%d/%d) \"\n                       \"found for stream #%d, time base forced to 1/48000\\n\",\n                       descriptor->sample_rate.num, descriptor->sample_rate.den,\n                       st->index);\n                avpriv_set_pts_info(st, 64, 1, 48000);\n            }\n\n            /* if duration is set, rescale it from EditRate to SampleRate */\n            if (st->duration != AV_NOPTS_VALUE)\n                st->duration = av_rescale_q(st->duration,\n                                            av_inv_q(material_track->edit_rate),\n                                            st->time_base);\n\n            /* TODO: implement AV_CODEC_ID_RAWAUDIO */\n            if (st->codecpar->codec_id == AV_CODEC_ID_PCM_S16LE) {\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S24LE;\n                else if (descriptor->bits_per_sample == 32)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S32LE;\n            } else if (st->codecpar->codec_id == AV_CODEC_ID_PCM_S16BE) {\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S24BE;\n                else if (descriptor->bits_per_sample == 32)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S32BE;\n            } else if (st->codecpar->codec_id == AV_CODEC_ID_MP2) {\n                st->need_parsing = AVSTREAM_PARSE_FULL;\n            }\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_DATA) {\n            enum AVMediaType type;\n            container_ul = mxf_get_codec_ul(mxf_data_essence_container_uls, essence_container_ul);\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE)\n                st->codecpar->codec_id = container_ul->id;\n            type = avcodec_get_type(st->codecpar->codec_id);\n            if (type == AVMEDIA_TYPE_SUBTITLE)\n                st->codecpar->codec_type = type;\n            if (container_ul->desc)\n                av_dict_set(&st->metadata, \"data_type\", container_ul->desc, 0);\n        }\n        if (descriptor->extradata) {\n            if (!ff_alloc_extradata(st->codecpar, descriptor->extradata_size)) {\n                memcpy(st->codecpar->extradata, descriptor->extradata, descriptor->extradata_size);\n            }\n        } else if (st->codecpar->codec_id == AV_CODEC_ID_H264) {\n            int coded_width = mxf_get_codec_ul(mxf_intra_only_picture_coded_width,\n                                               &descriptor->essence_codec_ul)->id;\n            if (coded_width)\n                st->codecpar->width = coded_width;\n            ret = ff_generate_avci_extradata(st);\n            if (ret < 0)\n                return ret;\n        }\n        if (st->codecpar->codec_type != AVMEDIA_TYPE_DATA && source_track->wrapping != FrameWrapped) {\n            /* TODO: decode timestamps */\n            st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n        }\n    }\n\n    ret = 0;\nfail_and_free:\n    return ret;\n}", "func_src_after": "static int mxf_parse_structural_metadata(MXFContext *mxf)\n{\n    MXFPackage *material_package = NULL;\n    int i, j, k, ret;\n\n    av_log(mxf->fc, AV_LOG_TRACE, \"metadata sets count %d\\n\", mxf->metadata_sets_count);\n    /* TODO: handle multiple material packages (OP3x) */\n    for (i = 0; i < mxf->packages_count; i++) {\n        material_package = mxf_resolve_strong_ref(mxf, &mxf->packages_refs[i], MaterialPackage);\n        if (material_package) break;\n    }\n    if (!material_package) {\n        av_log(mxf->fc, AV_LOG_ERROR, \"no material package found\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    mxf_add_umid_metadata(&mxf->fc->metadata, \"material_package_umid\", material_package);\n    if (material_package->name && material_package->name[0])\n        av_dict_set(&mxf->fc->metadata, \"material_package_name\", material_package->name, 0);\n    mxf_parse_package_comments(mxf, &mxf->fc->metadata, material_package);\n\n    for (i = 0; i < material_package->tracks_count; i++) {\n        MXFPackage *source_package = NULL;\n        MXFTrack *material_track = NULL;\n        MXFTrack *source_track = NULL;\n        MXFTrack *temp_track = NULL;\n        MXFDescriptor *descriptor = NULL;\n        MXFStructuralComponent *component = NULL;\n        MXFTimecodeComponent *mxf_tc = NULL;\n        UID *essence_container_ul = NULL;\n        const MXFCodecUL *codec_ul = NULL;\n        const MXFCodecUL *container_ul = NULL;\n        const MXFCodecUL *pix_fmt_ul = NULL;\n        AVStream *st;\n        AVTimecode tc;\n        int flags;\n\n        if (!(material_track = mxf_resolve_strong_ref(mxf, &material_package->tracks_refs[i], Track))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track strong ref\\n\");\n            continue;\n        }\n\n        if ((component = mxf_resolve_strong_ref(mxf, &material_track->sequence_ref, TimecodeComponent))) {\n            mxf_tc = (MXFTimecodeComponent*)component;\n            flags = mxf_tc->drop_frame == 1 ? AV_TIMECODE_FLAG_DROPFRAME : 0;\n            if (av_timecode_init(&tc, mxf_tc->rate, flags, mxf_tc->start_frame, mxf->fc) == 0) {\n                mxf_add_timecode_metadata(&mxf->fc->metadata, \"timecode\", &tc);\n            }\n        }\n\n        if (!(material_track->sequence = mxf_resolve_strong_ref(mxf, &material_track->sequence_ref, Sequence))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track sequence strong ref\\n\");\n            continue;\n        }\n\n        for (j = 0; j < material_track->sequence->structural_components_count; j++) {\n            component = mxf_resolve_strong_ref(mxf, &material_track->sequence->structural_components_refs[j], TimecodeComponent);\n            if (!component)\n                continue;\n\n            mxf_tc = (MXFTimecodeComponent*)component;\n            flags = mxf_tc->drop_frame == 1 ? AV_TIMECODE_FLAG_DROPFRAME : 0;\n            if (av_timecode_init(&tc, mxf_tc->rate, flags, mxf_tc->start_frame, mxf->fc) == 0) {\n                mxf_add_timecode_metadata(&mxf->fc->metadata, \"timecode\", &tc);\n                break;\n            }\n        }\n\n        /* TODO: handle multiple source clips, only finds first valid source clip */\n        if(material_track->sequence->structural_components_count > 1)\n            av_log(mxf->fc, AV_LOG_WARNING, \"material track %d: has %d components\\n\",\n                       material_track->track_id, material_track->sequence->structural_components_count);\n\n        for (j = 0; j < material_track->sequence->structural_components_count; j++) {\n            component = mxf_resolve_sourceclip(mxf, &material_track->sequence->structural_components_refs[j]);\n            if (!component)\n                continue;\n\n            source_package = mxf_resolve_source_package(mxf, component->source_package_ul, component->source_package_uid);\n            if (!source_package) {\n                av_log(mxf->fc, AV_LOG_TRACE, \"material track %d: no corresponding source package found\\n\", material_track->track_id);\n                continue;\n            }\n            for (k = 0; k < source_package->tracks_count; k++) {\n                if (!(temp_track = mxf_resolve_strong_ref(mxf, &source_package->tracks_refs[k], Track))) {\n                    av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track strong ref\\n\");\n                    ret = AVERROR_INVALIDDATA;\n                    goto fail_and_free;\n                }\n                if (temp_track->track_id == component->source_track_id) {\n                    source_track = temp_track;\n                    break;\n                }\n            }\n            if (!source_track) {\n                av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: no corresponding source track found\\n\", material_track->track_id);\n                break;\n            }\n\n            for (k = 0; k < mxf->essence_container_data_count; k++) {\n                MXFEssenceContainerData *essence_data;\n\n                if (!(essence_data = mxf_resolve_strong_ref(mxf, &mxf->essence_container_data_refs[k], EssenceContainerData))) {\n                    av_log(mxf->fc, AV_LOG_TRACE, \"could not resolve essence container data strong ref\\n\");\n                    continue;\n                }\n                if (!memcmp(component->source_package_ul, essence_data->package_ul, sizeof(UID)) && !memcmp(component->source_package_uid, essence_data->package_uid, sizeof(UID))) {\n                    source_track->body_sid = essence_data->body_sid;\n                    source_track->index_sid = essence_data->index_sid;\n                    break;\n                }\n            }\n\n            if(source_track && component)\n                break;\n        }\n        if (!source_track || !component || !source_package) {\n            if((ret = mxf_add_metadata_stream(mxf, material_track)))\n                goto fail_and_free;\n            continue;\n        }\n\n        if (!(source_track->sequence = mxf_resolve_strong_ref(mxf, &source_track->sequence_ref, Sequence))) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track sequence strong ref\\n\");\n            ret = AVERROR_INVALIDDATA;\n            goto fail_and_free;\n        }\n\n        /* 0001GL00.MXF.A1.mxf_opatom.mxf has the same SourcePackageID as 0001GL.MXF.V1.mxf_opatom.mxf\n         * This would result in both files appearing to have two streams. Work around this by sanity checking DataDefinition */\n        if (memcmp(material_track->sequence->data_definition_ul, source_track->sequence->data_definition_ul, 16)) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: DataDefinition mismatch\\n\", material_track->track_id);\n            continue;\n        }\n\n        st = avformat_new_stream(mxf->fc, NULL);\n        if (!st) {\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not allocate stream\\n\");\n            ret = AVERROR(ENOMEM);\n            goto fail_and_free;\n        }\n        st->id = material_track->track_id;\n        st->priv_data = source_track;\n\n        source_package->descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor_ref, AnyType);\n        descriptor = mxf_resolve_multidescriptor(mxf, source_package->descriptor, source_track->track_id);\n\n        /* A SourceClip from a EssenceGroup may only be a single frame of essence data. The clips duration is then how many\n         * frames its suppose to repeat for. Descriptor->duration, if present, contains the real duration of the essence data */\n        if (descriptor && descriptor->duration != AV_NOPTS_VALUE)\n            source_track->original_duration = st->duration = FFMIN(descriptor->duration, component->duration);\n        else\n            source_track->original_duration = st->duration = component->duration;\n\n        if (st->duration == -1)\n            st->duration = AV_NOPTS_VALUE;\n        st->start_time = component->start_position;\n        if (material_track->edit_rate.num <= 0 ||\n            material_track->edit_rate.den <= 0) {\n            av_log(mxf->fc, AV_LOG_WARNING,\n                   \"Invalid edit rate (%d/%d) found on stream #%d, \"\n                   \"defaulting to 25/1\\n\",\n                   material_track->edit_rate.num,\n                   material_track->edit_rate.den, st->index);\n            material_track->edit_rate = (AVRational){25, 1};\n        }\n        avpriv_set_pts_info(st, 64, material_track->edit_rate.den, material_track->edit_rate.num);\n\n        /* ensure SourceTrack EditRate == MaterialTrack EditRate since only\n         * the former is accessible via st->priv_data */\n        source_track->edit_rate = material_track->edit_rate;\n\n        PRINT_KEY(mxf->fc, \"data definition   ul\", source_track->sequence->data_definition_ul);\n        codec_ul = mxf_get_codec_ul(ff_mxf_data_definition_uls, &source_track->sequence->data_definition_ul);\n        st->codecpar->codec_type = codec_ul->id;\n\n        if (!descriptor) {\n            av_log(mxf->fc, AV_LOG_INFO, \"source track %d: stream %d, no descriptor found\\n\", source_track->track_id, st->index);\n            continue;\n        }\n        PRINT_KEY(mxf->fc, \"essence codec     ul\", descriptor->essence_codec_ul);\n        PRINT_KEY(mxf->fc, \"essence container ul\", descriptor->essence_container_ul);\n        essence_container_ul = &descriptor->essence_container_ul;\n        source_track->wrapping = (mxf->op == OPAtom) ? ClipWrapped : mxf_get_wrapping_kind(essence_container_ul);\n        if (source_track->wrapping == UnknownWrapped)\n            av_log(mxf->fc, AV_LOG_INFO, \"wrapping of stream %d is unknown\\n\", st->index);\n        /* HACK: replacing the original key with mxf_encrypted_essence_container\n         * is not allowed according to s429-6, try to find correct information anyway */\n        if (IS_KLV_KEY(essence_container_ul, mxf_encrypted_essence_container)) {\n            av_log(mxf->fc, AV_LOG_INFO, \"broken encrypted mxf file\\n\");\n            for (k = 0; k < mxf->metadata_sets_count; k++) {\n                MXFMetadataSet *metadata = mxf->metadata_sets[k];\n                if (metadata->type == CryptoContext) {\n                    essence_container_ul = &((MXFCryptoContext *)metadata)->source_container_ul;\n                    break;\n                }\n            }\n        }\n\n        /* TODO: drop PictureEssenceCoding and SoundEssenceCompression, only check EssenceContainer */\n        codec_ul = mxf_get_codec_ul(ff_mxf_codec_uls, &descriptor->essence_codec_ul);\n        st->codecpar->codec_id = (enum AVCodecID)codec_ul->id;\n        if (st->codecpar->codec_id == AV_CODEC_ID_NONE) {\n            codec_ul = mxf_get_codec_ul(ff_mxf_codec_uls, &descriptor->codec_ul);\n            st->codecpar->codec_id = (enum AVCodecID)codec_ul->id;\n        }\n\n        av_log(mxf->fc, AV_LOG_VERBOSE, \"%s: Universal Label: \",\n               avcodec_get_name(st->codecpar->codec_id));\n        for (k = 0; k < 16; k++) {\n            av_log(mxf->fc, AV_LOG_VERBOSE, \"%.2x\",\n                   descriptor->essence_codec_ul[k]);\n            if (!(k+1 & 19) || k == 5)\n                av_log(mxf->fc, AV_LOG_VERBOSE, \".\");\n        }\n        av_log(mxf->fc, AV_LOG_VERBOSE, \"\\n\");\n\n        mxf_add_umid_metadata(&st->metadata, \"file_package_umid\", source_package);\n        if (source_package->name && source_package->name[0])\n            av_dict_set(&st->metadata, \"file_package_name\", source_package->name, 0);\n        if (material_track->name && material_track->name[0])\n            av_dict_set(&st->metadata, \"track_name\", material_track->name, 0);\n\n        mxf_parse_physical_source_package(mxf, source_track, st);\n\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n            source_track->intra_only = mxf_is_intra_only(descriptor);\n            container_ul = mxf_get_codec_ul(mxf_picture_essence_container_uls, essence_container_ul);\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE)\n                st->codecpar->codec_id = container_ul->id;\n            st->codecpar->width = descriptor->width;\n            st->codecpar->height = descriptor->height; /* Field height, not frame height */\n            switch (descriptor->frame_layout) {\n                case FullFrame:\n                    st->codecpar->field_order = AV_FIELD_PROGRESSIVE;\n                    break;\n                case OneField:\n                    /* Every other line is stored and needs to be duplicated. */\n                    av_log(mxf->fc, AV_LOG_INFO, \"OneField frame layout isn't currently supported\\n\");\n                    break; /* The correct thing to do here is fall through, but by breaking we might be\n                              able to decode some streams at half the vertical resolution, rather than not al all.\n                              It's also for compatibility with the old behavior. */\n                case MixedFields:\n                    break;\n                case SegmentedFrame:\n                    st->codecpar->field_order = AV_FIELD_PROGRESSIVE;\n                case SeparateFields:\n                    av_log(mxf->fc, AV_LOG_DEBUG, \"video_line_map: (%d, %d), field_dominance: %d\\n\",\n                           descriptor->video_line_map[0], descriptor->video_line_map[1],\n                           descriptor->field_dominance);\n                    if ((descriptor->video_line_map[0] > 0) && (descriptor->video_line_map[1] > 0)) {\n                        /* Detect coded field order from VideoLineMap:\n                         *  (even, even) => bottom field coded first\n                         *  (even, odd)  => top field coded first\n                         *  (odd, even)  => top field coded first\n                         *  (odd, odd)   => bottom field coded first\n                         */\n                        if ((descriptor->video_line_map[0] + descriptor->video_line_map[1]) % 2) {\n                            switch (descriptor->field_dominance) {\n                                case MXF_FIELD_DOMINANCE_DEFAULT:\n                                case MXF_FIELD_DOMINANCE_FF:\n                                    st->codecpar->field_order = AV_FIELD_TT;\n                                    break;\n                                case MXF_FIELD_DOMINANCE_FL:\n                                    st->codecpar->field_order = AV_FIELD_TB;\n                                    break;\n                                default:\n                                    avpriv_request_sample(mxf->fc,\n                                                          \"Field dominance %d support\",\n                                                          descriptor->field_dominance);\n                            }\n                        } else {\n                            switch (descriptor->field_dominance) {\n                                case MXF_FIELD_DOMINANCE_DEFAULT:\n                                case MXF_FIELD_DOMINANCE_FF:\n                                    st->codecpar->field_order = AV_FIELD_BB;\n                                    break;\n                                case MXF_FIELD_DOMINANCE_FL:\n                                    st->codecpar->field_order = AV_FIELD_BT;\n                                    break;\n                                default:\n                                    avpriv_request_sample(mxf->fc,\n                                                          \"Field dominance %d support\",\n                                                          descriptor->field_dominance);\n                            }\n                        }\n                    }\n                    /* Turn field height into frame height. */\n                    st->codecpar->height *= 2;\n                    break;\n                default:\n                    av_log(mxf->fc, AV_LOG_INFO, \"Unknown frame layout type: %d\\n\", descriptor->frame_layout);\n            }\n            if (st->codecpar->codec_id == AV_CODEC_ID_RAWVIDEO) {\n                st->codecpar->format = descriptor->pix_fmt;\n                if (st->codecpar->format == AV_PIX_FMT_NONE) {\n                    pix_fmt_ul = mxf_get_codec_ul(ff_mxf_pixel_format_uls,\n                                                  &descriptor->essence_codec_ul);\n                    st->codecpar->format = (enum AVPixelFormat)pix_fmt_ul->id;\n                    if (st->codecpar->format== AV_PIX_FMT_NONE) {\n                        st->codecpar->codec_tag = mxf_get_codec_ul(ff_mxf_codec_tag_uls,\n                                                                   &descriptor->essence_codec_ul)->id;\n                        if (!st->codecpar->codec_tag) {\n                            /* support files created before RP224v10 by defaulting to UYVY422\n                               if subsampling is 4:2:2 and component depth is 8-bit */\n                            if (descriptor->horiz_subsampling == 2 &&\n                                descriptor->vert_subsampling == 1 &&\n                                descriptor->component_depth == 8) {\n                                st->codecpar->format = AV_PIX_FMT_UYVY422;\n                            }\n                        }\n                    }\n                }\n            }\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n            if (material_track->sequence->origin) {\n                av_dict_set_int(&st->metadata, \"material_track_origin\", material_track->sequence->origin, 0);\n            }\n            if (source_track->sequence->origin) {\n                av_dict_set_int(&st->metadata, \"source_track_origin\", source_track->sequence->origin, 0);\n            }\n            if (descriptor->aspect_ratio.num && descriptor->aspect_ratio.den)\n                st->display_aspect_ratio = descriptor->aspect_ratio;\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n            container_ul = mxf_get_codec_ul(mxf_sound_essence_container_uls, essence_container_ul);\n            /* Only overwrite existing codec ID if it is unset or A-law, which is the default according to SMPTE RP 224. */\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE || (st->codecpar->codec_id == AV_CODEC_ID_PCM_ALAW && (enum AVCodecID)container_ul->id != AV_CODEC_ID_NONE))\n                st->codecpar->codec_id = (enum AVCodecID)container_ul->id;\n            st->codecpar->channels = descriptor->channels;\n            st->codecpar->bits_per_coded_sample = descriptor->bits_per_sample;\n\n            if (descriptor->sample_rate.den > 0) {\n                st->codecpar->sample_rate = descriptor->sample_rate.num / descriptor->sample_rate.den;\n                avpriv_set_pts_info(st, 64, descriptor->sample_rate.den, descriptor->sample_rate.num);\n            } else {\n                av_log(mxf->fc, AV_LOG_WARNING, \"invalid sample rate (%d/%d) \"\n                       \"found for stream #%d, time base forced to 1/48000\\n\",\n                       descriptor->sample_rate.num, descriptor->sample_rate.den,\n                       st->index);\n                avpriv_set_pts_info(st, 64, 1, 48000);\n            }\n\n            /* if duration is set, rescale it from EditRate to SampleRate */\n            if (st->duration != AV_NOPTS_VALUE)\n                st->duration = av_rescale_q(st->duration,\n                                            av_inv_q(material_track->edit_rate),\n                                            st->time_base);\n\n            /* TODO: implement AV_CODEC_ID_RAWAUDIO */\n            if (st->codecpar->codec_id == AV_CODEC_ID_PCM_S16LE) {\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S24LE;\n                else if (descriptor->bits_per_sample == 32)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S32LE;\n            } else if (st->codecpar->codec_id == AV_CODEC_ID_PCM_S16BE) {\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S24BE;\n                else if (descriptor->bits_per_sample == 32)\n                    st->codecpar->codec_id = AV_CODEC_ID_PCM_S32BE;\n            } else if (st->codecpar->codec_id == AV_CODEC_ID_MP2) {\n                st->need_parsing = AVSTREAM_PARSE_FULL;\n            }\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_DATA) {\n            enum AVMediaType type;\n            container_ul = mxf_get_codec_ul(mxf_data_essence_container_uls, essence_container_ul);\n            if (st->codecpar->codec_id == AV_CODEC_ID_NONE)\n                st->codecpar->codec_id = container_ul->id;\n            type = avcodec_get_type(st->codecpar->codec_id);\n            if (type == AVMEDIA_TYPE_SUBTITLE)\n                st->codecpar->codec_type = type;\n            if (container_ul->desc)\n                av_dict_set(&st->metadata, \"data_type\", container_ul->desc, 0);\n        }\n        if (descriptor->extradata) {\n            if (!ff_alloc_extradata(st->codecpar, descriptor->extradata_size)) {\n                memcpy(st->codecpar->extradata, descriptor->extradata, descriptor->extradata_size);\n            }\n        } else if (st->codecpar->codec_id == AV_CODEC_ID_H264) {\n            int coded_width = mxf_get_codec_ul(mxf_intra_only_picture_coded_width,\n                                               &descriptor->essence_codec_ul)->id;\n            if (coded_width)\n                st->codecpar->width = coded_width;\n            ret = ff_generate_avci_extradata(st);\n            if (ret < 0)\n                return ret;\n        }\n        if (st->codecpar->codec_type != AVMEDIA_TYPE_DATA && source_track->wrapping != FrameWrapped) {\n            /* TODO: decode timestamps */\n            st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n        }\n    }\n\n    ret = 0;\nfail_and_free:\n    return ret;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/bab0716c7f4793ec42e05a5aa7e80d82a0dd4e75", "file_name": "libavformat/mxfdec.c", "vul_type": "cwe-125", "description": "Write a function in C to parse structural metadata from an MXF file."}
{"func_name": "GetPSDRowSize", "func_src_before": "static inline size_t GetPSDRowSize(Image *image)\n{\n  if (image->depth == 1)\n    return((image->columns+7)/8);\n  else\n    return(image->columns*GetPSDPacketSize(image));\n}", "func_src_after": "static inline size_t GetPSDRowSize(Image *image)\n{\n  if (image->depth == 1)\n    return(((image->columns+7)/8)*GetPSDPacketSize(image));\n  else\n    return(image->columns*GetPSDPacketSize(image));\n}", "commit_link": "github.com/ImageMagick/ImageMagick/commit/5f16640725b1225e6337c62526e6577f0f88edb8", "file_name": "coders/psd.c", "vul_type": "cwe-125", "description": "Write a C function named `GetPSDRowSize` that calculates the row size of a PSD image based on its depth and columns."}
{"func_name": "placings", "func_src_before": "@endpoints.route(\"/placings\")\ndef placings():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default='christmas mike')\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM placings WHERE player = '{}'\".format(tag)\n    results = list(db.exec(sql))\n    results.sort(key=lambda x: int(x[2]))\n\n    return json.dumps(results)", "func_src_after": "@endpoints.route(\"/placings\")\ndef placings():\n    if db == None:\n        init()\n\n    tag = request.args.get('tag', default='christmas mike')\n\n    # Get all the urls that this player has participated in\n    sql = \"SELECT * FROM placings WHERE player = '{tag}'\"\n    args = {'tag': tag}\n    results = list(db.exec(sql, args))\n    results.sort(key=lambda x: int(x[2]))\n\n    return json.dumps(results)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Create a Python Flask endpoint that retrieves and sorts player placings from a database using a default tag if none is provided."}
{"func_name": "_inject_net_into_fs", "func_src_before": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = _join_and_check_path_within_fs(fs, 'etc', 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n\n    netfile = os.path.join('etc', 'network', 'interfaces')\n    _inject_file_into_fs(fs, netfile, net)", "func_src_after": "def _inject_net_into_fs(net, fs, execute=None):\n    \"\"\"Inject /etc/network/interfaces into the filesystem rooted at fs.\n\n    net is the contents of /etc/network/interfaces.\n    \"\"\"\n    netdir = os.path.join(os.path.join(fs, 'etc'), 'network')\n    utils.execute('mkdir', '-p', netdir, run_as_root=True)\n    utils.execute('chown', 'root:root', netdir, run_as_root=True)\n    utils.execute('chmod', 755, netdir, run_as_root=True)\n    netfile = os.path.join(netdir, 'interfaces')\n    utils.execute('tee', netfile, process_input=net, run_as_root=True)", "commit_link": "github.com/openstack/nova/commit/2427d4a99bed35baefd8f17ba422cb7aae8dcca7", "file_name": "nova/virt/disk/api.py", "vul_type": "cwe-022", "description": "Write a Python function to create necessary directories and set permissions to inject network configuration into a specified filesystem."}
{"func_name": "process_statistics", "func_src_before": "    def process_statistics(self, metadata, _):\n        args = [metadata.hostname, '-p', metadata.profile, '-g',\n                ':'.join([g for g in metadata.groups])]\n        for notifier in os.listdir(self.data):\n            if ((notifier[-1] == '~') or\n                (notifier[:2] == '.#') or\n                (notifier[-4:] == '.swp') or\n                (notifier in ['SCCS', '.svn', '4913'])):\n                continue\n            npath = self.data + '/' + notifier\n            self.logger.debug(\"Running %s %s\" % (npath, \" \".join(args)))\n            async_run(npath, args)", "func_src_after": "    def process_statistics(self, metadata, _):\n        args = [metadata.hostname, '-p', metadata.profile, '-g',\n                ':'.join([g for g in metadata.groups])]\n        self.debug_log(\"running triggers\")\n        for notifier in os.listdir(self.data):\n            self.debug_log(\"running %s\" % notifier)\n            if ((notifier[-1] == '~') or\n                (notifier[:2] == '.#') or\n                (notifier[-4:] == '.swp') or\n                (notifier in ['SCCS', '.svn', '4913'])):\n                continue\n            npath = os.path.join(self.data, notifier)\n            self.async_run([npath] + args)", "commit_link": "github.com/Bcfg2/bcfg2/commit/a524967e8d5c4c22e49cd619aed20c87a316c0be", "file_name": "src/lib/Server/Plugins/Trigger.py", "vul_type": "cwe-078", "description": "Write a Python function that filters out certain files and asynchronously runs a command with arguments based on metadata."}
{"func_name": "filter_session_io", "func_src_before": "filter_session_io(struct io *io, int evt, void *arg)\n{\n\tstruct filter_session *fs = arg;\n\tchar *line = NULL;\n\tssize_t len;\n\n\tlog_trace(TRACE_IO, \"filter session: %p: %s %s\", fs, io_strevent(evt),\n\t    io_strio(io));\n\n\tswitch (evt) {\n\tcase IO_DATAIN:\n\tnextline:\n\t\tline = io_getline(fs->io, &len);\n\t\t/* No complete line received */\n\t\tif (line == NULL)\n\t\t\treturn;\n\n\t\tfilter_data(fs->id, line);\n\n\t\tgoto nextline;\n\t}\n}", "func_src_after": "filter_session_io(struct io *io, int evt, void *arg)\n{\n\tstruct filter_session *fs = arg;\n\tchar *line = NULL;\n\tssize_t len;\n\n\tlog_trace(TRACE_IO, \"filter session: %p: %s %s\", fs, io_strevent(evt),\n\t    io_strio(io));\n\n\tswitch (evt) {\n\tcase IO_DATAIN:\n\tnextline:\n\t\tline = io_getline(fs->io, &len);\n\t\t/* No complete line received */\n\t\tif (line == NULL)\n\t\t\treturn;\n\n\t\tfilter_data(fs->id, line);\n\n\t\tgoto nextline;\n\n\tcase IO_DISCONNECTED:\n\t\tio_free(fs->io);\n\t\tfs->io = NULL;\n\t\tbreak;\n\t}\n}", "commit_link": "github.com/openbsd/src/commit/6c3220444ed06b5796dedfd53a0f4becd903c0d1", "file_name": "usr.sbin/smtpd/lka_filter.c", "vul_type": "cwe-476", "description": "Write a C function named `filter_session_io` that processes IO events for a session, handling data input and disconnection."}
{"func_name": "addTags", "func_src_before": "def addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO {} VALUES {}\".format(listing_tags_table_name, str((listing_id, x)))\n        cur.execute(sql)", "func_src_after": "def addTags(tag_list, listing_id):\n    \"\"\"\n    Adds a list of tags tag_list for a given listing with listing_id to the database\n    \"\"\"\n    cur = conn.cursor()\n    for x in tag_list:\n        sql = \"INSERT INTO %s VALUES (%s %s)\"\n        cur.execute(sql, (listing_tags_table_name, listing_id, x))", "commit_link": "github.com/tasbir49/BreadWinner/commit/332a9f2c619be399ae94244bb8bd0977fc62bc16", "file_name": "backend-api/backend-api.py", "vul_type": "cwe-089", "description": "Write a Python function to insert a list of tags into a database for a specific listing ID."}
{"func_name": "list", "func_src_before": "    def list(self, keyfilter='/'):\n        path = self._absolute_key(keyfilter)\n        if path != '/':\n            path = path.rstrip('/')\n        try:\n            result = self.etcd.read(path, recursive=True)\n        except etcd.EtcdKeyNotFound:\n            return None\n        except etcd.EtcdException as err:\n            log_error(\"Error listing %s: [%r]\" % (keyfilter, repr(err)))\n            raise CSStoreError('Error occurred while trying to list keys')\n\n        value = set()\n        for entry in result.get_subtree():\n            if entry.key == path:\n                continue\n            name = entry.key[len(path):]\n            if entry.dir and not name.endswith('/'):\n                name += '/'\n            value.add(name.lstrip('/'))\n        return sorted(value)", "func_src_after": "    def list(self, keyfilter='/'):\n        path = os.path.join(self.namespace, keyfilter)\n        if path != '/':\n            path = path.rstrip('/')\n        try:\n            result = self.etcd.read(path, recursive=True)\n        except etcd.EtcdKeyNotFound:\n            return None\n        except etcd.EtcdException as err:\n            log_error(\"Error listing %s: [%r]\" % (keyfilter, repr(err)))\n            raise CSStoreError('Error occurred while trying to list keys')\n\n        value = set()\n        for entry in result.get_subtree():\n            if entry.key == path:\n                continue\n            name = entry.key[len(path):]\n            if entry.dir and not name.endswith('/'):\n                name += '/'\n            value.add(name.lstrip('/'))\n        return sorted(value)", "commit_link": "github.com/latchset/custodia/commit/785fc87f38b4811bc4ce43a0a9b2267ee7d500b4", "file_name": "custodia/store/etcdstore.py", "vul_type": "cwe-022", "description": "Write a Python function that lists keys from an etcd directory, handling exceptions and returning sorted results."}
{"func_name": "get_ports", "func_src_before": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run(['showport'])\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run(['showport', '-iscsi'])\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run(['showport', '-iscsiname'])\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "func_src_after": "    def get_ports(self):\n        # First get the active FC ports\n        out = self._cli_run('showport', None)\n\n        # strip out header\n        # N:S:P,Mode,State,----Node_WWN----,-Port_WWN/HW_Addr-,Type,\n        # Protocol,Label,Partner,FailoverState\n        out = out[1:len(out) - 2]\n\n        ports = {'FC': [], 'iSCSI': {}}\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp:\n                if tmp[1] == 'target' and tmp[2] == 'ready':\n                    if tmp[6] == 'FC':\n                        ports['FC'].append(tmp[4])\n\n        # now get the active iSCSI ports\n        out = self._cli_run('showport -iscsi', None)\n\n        # strip out header\n        # N:S:P,State,IPAddr,Netmask,Gateway,\n        # TPGT,MTU,Rate,DHCP,iSNS_Addr,iSNS_Port\n        out = out[1:len(out) - 2]\n        for line in out:\n            tmp = line.split(',')\n\n            if tmp and len(tmp) > 2:\n                if tmp[1] == 'ready':\n                    ports['iSCSI'][tmp[2]] = {}\n\n        # now get the nsp and iqn\n        result = self._cli_run('showport -iscsiname', None)\n        if result:\n            # first line is header\n            # nsp, ip,iqn\n            result = result[1:]\n            for line in result:\n                info = line.split(\",\")\n                if info and len(info) > 2:\n                    if info[1] in ports['iSCSI']:\n                        nsp = info[0]\n                        ip_addr = info[1]\n                        iqn = info[2]\n                        ports['iSCSI'][ip_addr] = {'nsp': nsp,\n                                                   'iqn': iqn\n                                                   }\n\n        LOG.debug(\"PORTS = %s\" % pprint.pformat(ports))\n        return ports", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to parse and return active FC and iSCSI port details from CLI output."}
{"func_name": "check_and_update_ranks", "func_src_before": "    def check_and_update_ranks(self, scene):\n        # There are 2 cases here:\n        #   1) Ranks have never been calculated for this scene before\n        #       - This means we need to calculate what the ranks were every month of this scenes history\n        #       - We should only do this if ranks don't already exist for this scene\n        #   2) Ranks have been calculated for this scene before\n        #       - We already have bulk ranks. We should check if it has been more than 1 month since we last\n        #           calculated ranks. If so, calculate again with the brackets that have come out this month\n\n        LOG.info('About to check if ranks need updating for {}'.format(scene))\n        # First, do we have any ranks for this scene already?\n        sql = 'select count(*) from ranks where scene=\"{}\";'.format(scene)\n        res = self.db.exec(sql)\n        count = res[0][0]\n\n        n = 5 if (scene == 'pro' or scene == 'pro_wiiu') else constants.TOURNAMENTS_PER_RANK\n        if count == 0:\n            LOG.info('Detected that we need to bulk update ranks for {}'.format(scene))\n            # Alright, we have nothing. Bulk update ranks\n            first_month = bracket_utils.get_first_month(self.db, scene)\n            last_month = bracket_utils.get_last_month(self.db, scene)\n            \n            # Iterate through all tournaments going month by month, and calculate ranks\n            months = bracket_utils.iter_months(first_month, last_month, include_first=False, include_last=True)\n            for month in months:\n                urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                self.process_ranks(scene, urls, month)\n        else:\n\n            # Get the date of the last time we calculated ranks\n            sql = \"select date from ranks where scene='{}' order by date desc limit 1;\".format(scene)\n            res = self.db.exec(sql)\n            last_rankings_date = res[0][0]\n\n            # Check to see if it's been more than 1 month since we last calculated ranks\n            more_than_one_month = bracket_utils.has_month_passed(last_rankings_date)\n            if more_than_one_month:\n                # Get only the last n tournaments, so it doesn't take too long to process\n                today = datetime.datetime.today().strftime('%Y-%m-%d')\n                msg = 'Detected that we need up update monthly ranks for {}, on {}'.format(scene, today)\n                LOG.info(msg)\n\n                # We should only ever calculate ranks on the 1st. If today is not the first, log error\n                if not today.split('-')[-1] == '1':\n                    LOG.exc('We are calculating ranks today, {}, but it isnt the first'.format(today))\n\n                months = bracket_utils.iter_months(last_rankings_date, today, include_first=False, include_last=True)\n                for month in months:\n                    # Make sure that we actually have matches during this month\n                    # Say we are trying to calculate ranks for 2018-05-01, the player would need to have matches during 2018-04-01, 2018-04-30\n                    prev_date = bracket_utils.get_previous_month(month)\n                    brackets_during_month = bracket_utils.get_tournaments_during_month(self.db, scene, prev_date)\n\n                    if len(brackets_during_month) > 0:\n                        tweet('Calculating {} ranks for {}'.format(month, scene))\n                        urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                        self.process_ranks(scene, urls, month)\n\n            else:\n                LOG.info('It has not yet been 1 month since we calculated ranks for {}. Skipping'.format(scene))", "func_src_after": "    def check_and_update_ranks(self, scene):\n        # There are 2 cases here:\n        #   1) Ranks have never been calculated for this scene before\n        #       - This means we need to calculate what the ranks were every month of this scenes history\n        #       - We should only do this if ranks don't already exist for this scene\n        #   2) Ranks have been calculated for this scene before\n        #       - We already have bulk ranks. We should check if it has been more than 1 month since we last\n        #           calculated ranks. If so, calculate again with the brackets that have come out this month\n\n        LOG.info('About to check if ranks need updating for {}'.format(scene))\n        # First, do we have any ranks for this scene already?\n        sql = 'select count(*) from ranks where scene=\"{scene}\";'\n        args = {'scene': scene}\n        res = self.db.exec(sql, args)\n        count = res[0][0]\n\n        n = 5 if (scene == 'pro' or scene == 'pro_wiiu') else constants.TOURNAMENTS_PER_RANK\n        if count == 0:\n            LOG.info('Detected that we need to bulk update ranks for {}'.format(scene))\n            # Alright, we have nothing. Bulk update ranks\n            first_month = bracket_utils.get_first_month(self.db, scene)\n            last_month = bracket_utils.get_last_month(self.db, scene)\n            \n            # Iterate through all tournaments going month by month, and calculate ranks\n            months = bracket_utils.iter_months(first_month, last_month, include_first=False, include_last=True)\n            for month in months:\n                urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                self.process_ranks(scene, urls, month)\n        else:\n\n            # Get the date of the last time we calculated ranks\n            sql = \"select date from ranks where scene='{scene}' order by date desc limit 1;\"\n            args = {'scene': scene}\n            res = self.db.exec(sql, args)\n            last_rankings_date = res[0][0]\n\n            # Check to see if it's been more than 1 month since we last calculated ranks\n            more_than_one_month = bracket_utils.has_month_passed(last_rankings_date)\n            if more_than_one_month:\n                # Get only the last n tournaments, so it doesn't take too long to process\n                today = datetime.datetime.today().strftime('%Y-%m-%d')\n                msg = 'Detected that we need up update monthly ranks for {}, on {}'.format(scene, today)\n                LOG.info(msg)\n\n                # We should only ever calculate ranks on the 1st. If today is not the first, log error\n                if not today.split('-')[-1] == '1':\n                    LOG.exc('We are calculating ranks today, {}, but it isnt the first'.format(today))\n\n                months = bracket_utils.iter_months(last_rankings_date, today, include_first=False, include_last=True)\n                for month in months:\n                    # Make sure that we actually have matches during this month\n                    # Say we are trying to calculate ranks for 2018-05-01, the player would need to have matches during 2018-04-01, 2018-04-30\n                    prev_date = bracket_utils.get_previous_month(month)\n                    brackets_during_month = bracket_utils.get_tournaments_during_month(self.db, scene, prev_date)\n\n                    if len(brackets_during_month) > 0:\n                        tweet('Calculating {} ranks for {}'.format(month, scene))\n                        urls, _ = bracket_utils.get_n_tournaments_before_date(self.db, scene, month, n)\n                        self.process_ranks(scene, urls, month)\n\n            else:\n                LOG.info('It has not yet been 1 month since we calculated ranks for {}. Skipping'.format(scene))", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "process_data.py", "vul_type": "cwe-089", "description": "In Python, write a function to update ranking data for a given scene, either by bulk calculating historical monthly ranks if none exist, or by updating ranks if it's been over a month since the last calculation."}
{"func_name": "get_list_context", "func_src_before": "def get_list_context(context=None):\n\tlist_context = frappe._dict(\n\t\ttemplate = \"templates/includes/blog/blog.html\",\n\t\tget_list = get_blog_list,\n\t\thide_filters = True,\n\t\tchildren = get_children(),\n\t\t# show_search = True,\n\t\ttitle = _('Blog')\n\t)\n\n\tcategory = frappe.local.form_dict.blog_category or frappe.local.form_dict.category\n\tif category:\n\t\tcategory_title = get_blog_category(category)\n\t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n\t\tlist_context.title = category_title\n\n\telif frappe.local.form_dict.blogger:\n\t\tblogger = frappe.db.get_value(\"Blogger\", {\"name\": frappe.local.form_dict.blogger}, \"full_name\")\n\t\tlist_context.sub_title = _(\"Posts by {0}\").format(blogger)\n\t\tlist_context.title = blogger\n\n\telif frappe.local.form_dict.txt:\n\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(frappe.local.form_dict.txt)\n\n\tif list_context.sub_title:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n\t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}]\n\telse:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"}]\n\n\tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True))\n\treturn list_context", "func_src_after": "def get_list_context(context=None):\n\tlist_context = frappe._dict(\n\t\ttemplate = \"templates/includes/blog/blog.html\",\n\t\tget_list = get_blog_list,\n\t\thide_filters = True,\n\t\tchildren = get_children(),\n\t\t# show_search = True,\n\t\ttitle = _('Blog')\n\t)\n\n\tcategory = sanitize_html(frappe.local.form_dict.blog_category or frappe.local.form_dict.category)\n\tif category:\n\t\tcategory_title = get_blog_category(category)\n\t\tlist_context.sub_title = _(\"Posts filed under {0}\").format(category_title)\n\t\tlist_context.title = category_title\n\n\telif frappe.local.form_dict.blogger:\n\t\tblogger = frappe.db.get_value(\"Blogger\", {\"name\": frappe.local.form_dict.blogger}, \"full_name\")\n\t\tlist_context.sub_title = _(\"Posts by {0}\").format(blogger)\n\t\tlist_context.title = blogger\n\n\telif frappe.local.form_dict.txt:\n\t\tlist_context.sub_title = _('Filtered by \"{0}\"').format(sanitize_html(frappe.local.form_dict.txt))\n\n\tif list_context.sub_title:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"},\n\t\t\t\t\t\t\t\t{\"name\": \"Blog\", \"route\": \"/blog\"}]\n\telse:\n\t\tlist_context.parents = [{\"name\": _(\"Home\"), \"route\": \"/\"}]\n\n\tlist_context.update(frappe.get_doc(\"Blog Settings\", \"Blog Settings\").as_dict(no_default_fields=True))\n\treturn list_context", "commit_link": "github.com/omirajkar/bench_frappe/commit/2fa19c25066ed17478d683666895e3266936aee6", "file_name": "frappe/website/doctype/blog_post/blog_post.py", "vul_type": "cwe-079", "description": "Write a Python function in Frappe to customize the context of a blog list page based on filters like category, blogger, or search text."}
{"func_name": "dd_save_binary", "func_src_before": "void dd_save_binary(struct dump_dir* dd, const char* name, const char* data, unsigned size)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, size, dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "func_src_after": "void dd_save_binary(struct dump_dir* dd, const char* name, const char* data, unsigned size)\n{\n    if (!dd->locked)\n        error_msg_and_die(\"dump_dir is not opened\"); /* bug */\n\n    if (!str_is_correct_filename(name))\n        error_msg_and_die(\"Cannot save binary. '%s' is not a valid file name\", name);\n\n    char *full_path = concat_path_file(dd->dd_dirname, name);\n    save_binary_file(full_path, data, size, dd->dd_uid, dd->dd_gid, dd->mode);\n    free(full_path);\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function named `dd_save_binary` that saves binary data to a file within a directory structure, ensuring the directory is open and the filename is valid."}
{"func_name": "h2h", "func_src_before": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '\"+str(player1)+\"' OR \"\\\n            +\"player2 = '\"+str(player1)+\"') AND (player1 = '\"+str(player2)+\"' OR \"\\\n            +\"player2 = '\"+str(player2)+\"') ORDER BY date DESC;\"\n    result = db.exec(sql)\n    return json.dumps(result)", "func_src_after": "@endpoints.route(\"/h2h\")\ndef h2h():\n    if db == None:\n        init()\n\n    player1 = request.args.get('tag1', default=\"christmasmike\")\n    player2 = request.args.get('tag2', default=\"christmasmike\")\n    sql = \"SELECT * FROM matches WHERE (player1 = '{player1}' OR \"\\\n            +\"player2 = '{player1}') AND (player1 = '{player2}' OR \"\\\n            +\"player2 = '{player2}') ORDER BY date DESC;\"\n    args = {'player1': player1, 'player2': player2}\n    result = db.exec(sql, args)\n    return json.dumps(result)", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "endpoints.py", "vul_type": "cwe-089", "description": "Write a Python Flask endpoint function named 'h2h' that retrieves head-to-head match records between two players from a database and returns the result as JSON, with default player names as 'christmasmike'."}
{"func_name": "SMB2_negotiate", "func_src_before": "SMB2_negotiate(const unsigned int xid, struct cifs_ses *ses)\n{\n\tstruct smb_rqst rqst;\n\tstruct smb2_negotiate_req *req;\n\tstruct smb2_negotiate_rsp *rsp;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tint rc = 0;\n\tint resp_buftype;\n\tstruct TCP_Server_Info *server = ses->server;\n\tint blob_offset, blob_length;\n\tchar *security_blob;\n\tint flags = CIFS_NEG_OP;\n\tunsigned int total_len;\n\n\tcifs_dbg(FYI, \"Negotiate protocol\\n\");\n\n\tif (!server) {\n\t\tWARN(1, \"%s: server is NULL!\\n\", __func__);\n\t\treturn -EIO;\n\t}\n\n\trc = smb2_plain_req_init(SMB2_NEGOTIATE, NULL, (void **) &req, &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\treq->sync_hdr.SessionId = 0;\n\n\tmemset(server->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\tmemset(ses->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(2);\n\t\ttotal_len += 4;\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB21_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[2] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->Dialects[3] = cpu_to_le16(SMB311_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(4);\n\t\ttotal_len += 8;\n\t} else {\n\t\t/* otherwise send specific dialect */\n\t\treq->Dialects[0] = cpu_to_le16(ses->server->vals->protocol_id);\n\t\treq->DialectCount = cpu_to_le16(1);\n\t\ttotal_len += 2;\n\t}\n\n\t/* only one of SMB2 signing flags may be set in SMB2 request */\n\tif (ses->sign)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_REQUIRED);\n\telse if (global_secflags & CIFSSEC_MAY_SIGN)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_ENABLED);\n\telse\n\t\treq->SecurityMode = 0;\n\n\treq->Capabilities = cpu_to_le32(ses->server->vals->req_capabilities);\n\n\t/* ClientGUID must be zero for SMB2.02 dialect */\n\tif (ses->server->vals->protocol_id == SMB20_PROT_ID)\n\t\tmemset(req->ClientGUID, 0, SMB2_CLIENT_GUID_SIZE);\n\telse {\n\t\tmemcpy(req->ClientGUID, server->client_guid,\n\t\t\tSMB2_CLIENT_GUID_SIZE);\n\t\tif ((ses->server->vals->protocol_id == SMB311_PROT_ID) ||\n\t\t    (strcmp(ses->server->vals->version_string,\n\t\t     SMBDEFAULT_VERSION_STRING) == 0))\n\t\t\tassemble_neg_contexts(req, &total_len);\n\t}\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_negotiate_rsp *)rsp_iov.iov_base;\n\t/*\n\t * No tcon so can't do\n\t * cifs_stats_inc(&tcon->stats.smb2_stats.smb2_com_fail[SMB2...]);\n\t */\n\tif (rc == -EOPNOTSUPP) {\n\t\tcifs_dbg(VFS, \"Dialect not supported by server. Consider \"\n\t\t\t\"specifying vers=1.0 or vers=2.0 on mount for accessing\"\n\t\t\t\" older servers\\n\");\n\t\tgoto neg_exit;\n\t} else if (rc != 0)\n\t\tgoto neg_exit;\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2.1 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\t/* ops set to 3.0 by default for default so update */\n\t\t\tses->server->ops = &smb21_operations;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n\t\t\tses->server->ops = &smb311_operations;\n\t} else if (le16_to_cpu(rsp->DialectRevision) !=\n\t\t\t\tses->server->vals->protocol_id) {\n\t\t/* if requested single dialect ensure returned dialect matched */\n\t\tcifs_dbg(VFS, \"Illegal 0x%x dialect returned: not requested\\n\",\n\t\t\tle16_to_cpu(rsp->DialectRevision));\n\t\treturn -EIO;\n\t}\n\n\tcifs_dbg(FYI, \"mode 0x%x\\n\", rsp->SecurityMode);\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.1 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB30_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB302_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.02 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.1.1 dialect\\n\");\n\telse {\n\t\tcifs_dbg(VFS, \"Illegal dialect returned by server 0x%x\\n\",\n\t\t\t le16_to_cpu(rsp->DialectRevision));\n\t\trc = -EIO;\n\t\tgoto neg_exit;\n\t}\n\tserver->dialect = le16_to_cpu(rsp->DialectRevision);\n\n\t/*\n\t * Keep a copy of the hash after negprot. This hash will be\n\t * the starting hash value for all sessions made from this\n\t * server.\n\t */\n\tmemcpy(server->preauth_sha_hash, ses->preauth_sha_hash,\n\t       SMB2_PREAUTH_HASH_SIZE);\n\n\t/* SMB2 only has an extended negflavor */\n\tserver->negflavor = CIFS_NEGFLAVOR_EXTENDED;\n\t/* set it to the maximum buffer size value we can send with 1 credit */\n\tserver->maxBuf = min_t(unsigned int, le32_to_cpu(rsp->MaxTransactSize),\n\t\t\t       SMB2_MAX_BUFFER_SIZE);\n\tserver->max_read = le32_to_cpu(rsp->MaxReadSize);\n\tserver->max_write = le32_to_cpu(rsp->MaxWriteSize);\n\tserver->sec_mode = le16_to_cpu(rsp->SecurityMode);\n\tif ((server->sec_mode & SMB2_SEC_MODE_FLAGS_ALL) != server->sec_mode)\n\t\tcifs_dbg(FYI, \"Server returned unexpected security mode 0x%x\\n\",\n\t\t\t\tserver->sec_mode);\n\tserver->capabilities = le32_to_cpu(rsp->Capabilities);\n\t/* Internal types */\n\tserver->capabilities |= SMB2_NT_FIND | SMB2_LARGE_FILES;\n\n\tsecurity_blob = smb2_get_data_area_len(&blob_offset, &blob_length,\n\t\t\t\t\t       (struct smb2_sync_hdr *)rsp);\n\t/*\n\t * See MS-SMB2 section 2.2.4: if no blob, client picks default which\n\t * for us will be\n\t *\tses->sectype = RawNTLMSSP;\n\t * but for time being this is our only auth choice so doesn't matter.\n\t * We just found a server which sets blob length to zero expecting raw.\n\t */\n\tif (blob_length == 0) {\n\t\tcifs_dbg(FYI, \"missing security blob on negprot\\n\");\n\t\tserver->sec_ntlmssp = true;\n\t}\n\n\trc = cifs_enable_signing(server, ses->sign);\n\tif (rc)\n\t\tgoto neg_exit;\n\tif (blob_length) {\n\t\trc = decode_negTokenInit(security_blob, blob_length, server);\n\t\tif (rc == 1)\n\t\t\trc = 0;\n\t\telse if (rc == 0)\n\t\t\trc = -EIO;\n\t}\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n\t\tif (rsp->NegotiateContextCount)\n\t\t\trc = smb311_decode_neg_context(rsp, server,\n\t\t\t\t\t\t       rsp_iov.iov_len);\n\t\telse\n\t\t\tcifs_dbg(VFS, \"Missing expected negotiate contexts\\n\");\n\t}\nneg_exit:\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "func_src_after": "SMB2_negotiate(const unsigned int xid, struct cifs_ses *ses)\n{\n\tstruct smb_rqst rqst;\n\tstruct smb2_negotiate_req *req;\n\tstruct smb2_negotiate_rsp *rsp;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tint rc = 0;\n\tint resp_buftype;\n\tstruct TCP_Server_Info *server = ses->server;\n\tint blob_offset, blob_length;\n\tchar *security_blob;\n\tint flags = CIFS_NEG_OP;\n\tunsigned int total_len;\n\n\tcifs_dbg(FYI, \"Negotiate protocol\\n\");\n\n\tif (!server) {\n\t\tWARN(1, \"%s: server is NULL!\\n\", __func__);\n\t\treturn -EIO;\n\t}\n\n\trc = smb2_plain_req_init(SMB2_NEGOTIATE, NULL, (void **) &req, &total_len);\n\tif (rc)\n\t\treturn rc;\n\n\treq->sync_hdr.SessionId = 0;\n\n\tmemset(server->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\tmemset(ses->preauth_sha_hash, 0, SMB2_PREAUTH_HASH_SIZE);\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(2);\n\t\ttotal_len += 4;\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\treq->Dialects[0] = cpu_to_le16(SMB21_PROT_ID);\n\t\treq->Dialects[1] = cpu_to_le16(SMB30_PROT_ID);\n\t\treq->Dialects[2] = cpu_to_le16(SMB302_PROT_ID);\n\t\treq->Dialects[3] = cpu_to_le16(SMB311_PROT_ID);\n\t\treq->DialectCount = cpu_to_le16(4);\n\t\ttotal_len += 8;\n\t} else {\n\t\t/* otherwise send specific dialect */\n\t\treq->Dialects[0] = cpu_to_le16(ses->server->vals->protocol_id);\n\t\treq->DialectCount = cpu_to_le16(1);\n\t\ttotal_len += 2;\n\t}\n\n\t/* only one of SMB2 signing flags may be set in SMB2 request */\n\tif (ses->sign)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_REQUIRED);\n\telse if (global_secflags & CIFSSEC_MAY_SIGN)\n\t\treq->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_ENABLED);\n\telse\n\t\treq->SecurityMode = 0;\n\n\treq->Capabilities = cpu_to_le32(ses->server->vals->req_capabilities);\n\n\t/* ClientGUID must be zero for SMB2.02 dialect */\n\tif (ses->server->vals->protocol_id == SMB20_PROT_ID)\n\t\tmemset(req->ClientGUID, 0, SMB2_CLIENT_GUID_SIZE);\n\telse {\n\t\tmemcpy(req->ClientGUID, server->client_guid,\n\t\t\tSMB2_CLIENT_GUID_SIZE);\n\t\tif ((ses->server->vals->protocol_id == SMB311_PROT_ID) ||\n\t\t    (strcmp(ses->server->vals->version_string,\n\t\t     SMBDEFAULT_VERSION_STRING) == 0))\n\t\t\tassemble_neg_contexts(req, &total_len);\n\t}\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\trsp = (struct smb2_negotiate_rsp *)rsp_iov.iov_base;\n\t/*\n\t * No tcon so can't do\n\t * cifs_stats_inc(&tcon->stats.smb2_stats.smb2_com_fail[SMB2...]);\n\t */\n\tif (rc == -EOPNOTSUPP) {\n\t\tcifs_dbg(VFS, \"Dialect not supported by server. Consider \"\n\t\t\t\"specifying vers=1.0 or vers=2.0 on mount for accessing\"\n\t\t\t\" older servers\\n\");\n\t\tgoto neg_exit;\n\t} else if (rc != 0)\n\t\tgoto neg_exit;\n\n\tif (strcmp(ses->server->vals->version_string,\n\t\t   SMB3ANY_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2.1 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t} else if (strcmp(ses->server->vals->version_string,\n\t\t   SMBDEFAULT_VERSION_STRING) == 0) {\n\t\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID)) {\n\t\t\tcifs_dbg(VFS,\n\t\t\t\t\"SMB2 dialect returned but not requested\\n\");\n\t\t\treturn -EIO;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID)) {\n\t\t\t/* ops set to 3.0 by default for default so update */\n\t\t\tses->server->ops = &smb21_operations;\n\t\t\tses->server->vals = &smb21_values;\n\t\t} else if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n\t\t\tses->server->ops = &smb311_operations;\n\t\t\tses->server->vals = &smb311_values;\n\t\t}\n\t} else if (le16_to_cpu(rsp->DialectRevision) !=\n\t\t\t\tses->server->vals->protocol_id) {\n\t\t/* if requested single dialect ensure returned dialect matched */\n\t\tcifs_dbg(VFS, \"Illegal 0x%x dialect returned: not requested\\n\",\n\t\t\tle16_to_cpu(rsp->DialectRevision));\n\t\treturn -EIO;\n\t}\n\n\tcifs_dbg(FYI, \"mode 0x%x\\n\", rsp->SecurityMode);\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB20_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB21_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb2.1 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB30_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.0 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB302_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.02 dialect\\n\");\n\telse if (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID))\n\t\tcifs_dbg(FYI, \"negotiated smb3.1.1 dialect\\n\");\n\telse {\n\t\tcifs_dbg(VFS, \"Illegal dialect returned by server 0x%x\\n\",\n\t\t\t le16_to_cpu(rsp->DialectRevision));\n\t\trc = -EIO;\n\t\tgoto neg_exit;\n\t}\n\tserver->dialect = le16_to_cpu(rsp->DialectRevision);\n\n\t/*\n\t * Keep a copy of the hash after negprot. This hash will be\n\t * the starting hash value for all sessions made from this\n\t * server.\n\t */\n\tmemcpy(server->preauth_sha_hash, ses->preauth_sha_hash,\n\t       SMB2_PREAUTH_HASH_SIZE);\n\n\t/* SMB2 only has an extended negflavor */\n\tserver->negflavor = CIFS_NEGFLAVOR_EXTENDED;\n\t/* set it to the maximum buffer size value we can send with 1 credit */\n\tserver->maxBuf = min_t(unsigned int, le32_to_cpu(rsp->MaxTransactSize),\n\t\t\t       SMB2_MAX_BUFFER_SIZE);\n\tserver->max_read = le32_to_cpu(rsp->MaxReadSize);\n\tserver->max_write = le32_to_cpu(rsp->MaxWriteSize);\n\tserver->sec_mode = le16_to_cpu(rsp->SecurityMode);\n\tif ((server->sec_mode & SMB2_SEC_MODE_FLAGS_ALL) != server->sec_mode)\n\t\tcifs_dbg(FYI, \"Server returned unexpected security mode 0x%x\\n\",\n\t\t\t\tserver->sec_mode);\n\tserver->capabilities = le32_to_cpu(rsp->Capabilities);\n\t/* Internal types */\n\tserver->capabilities |= SMB2_NT_FIND | SMB2_LARGE_FILES;\n\n\tsecurity_blob = smb2_get_data_area_len(&blob_offset, &blob_length,\n\t\t\t\t\t       (struct smb2_sync_hdr *)rsp);\n\t/*\n\t * See MS-SMB2 section 2.2.4: if no blob, client picks default which\n\t * for us will be\n\t *\tses->sectype = RawNTLMSSP;\n\t * but for time being this is our only auth choice so doesn't matter.\n\t * We just found a server which sets blob length to zero expecting raw.\n\t */\n\tif (blob_length == 0) {\n\t\tcifs_dbg(FYI, \"missing security blob on negprot\\n\");\n\t\tserver->sec_ntlmssp = true;\n\t}\n\n\trc = cifs_enable_signing(server, ses->sign);\n\tif (rc)\n\t\tgoto neg_exit;\n\tif (blob_length) {\n\t\trc = decode_negTokenInit(security_blob, blob_length, server);\n\t\tif (rc == 1)\n\t\t\trc = 0;\n\t\telse if (rc == 0)\n\t\t\trc = -EIO;\n\t}\n\n\tif (rsp->DialectRevision == cpu_to_le16(SMB311_PROT_ID)) {\n\t\tif (rsp->NegotiateContextCount)\n\t\t\trc = smb311_decode_neg_context(rsp, server,\n\t\t\t\t\t\t       rsp_iov.iov_len);\n\t\telse\n\t\t\tcifs_dbg(VFS, \"Missing expected negotiate contexts\\n\");\n\t}\nneg_exit:\n\tfree_rsp_buf(resp_buftype, rsp);\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/b57a55e2200ede754e4dc9cce4ba9402544b9365", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-125", "description": "Write a C function named `SMB2_negotiate` that initiates a negotiation request for the SMB2 protocol in C."}
{"func_name": "delete", "func_src_before": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = '{user_id}'\"\"\")", "func_src_after": "    @jwt_required\n    def delete(self, user_id):\n        \"\"\" Deletes user with the corresponding user_id \"\"\"\n        return database_utilities.execute_query(f\"\"\"delete from users where user_id = %s\"\"\", (user_id, ))", "commit_link": "github.com/sgosal2/tiger-boards-backend/commit/4670109dd613df2f2fe7e8403ebd149df2b55485", "file_name": "apis/users.py", "vul_type": "cwe-089", "description": "Create a Python function with JWT authentication that deletes a user from the database by their user_id."}
{"func_name": "updateDevice", "func_src_before": "updateDevice(const struct header * headers, time_t t)\n{\n\tstruct device ** pp = &devlist;\n\tstruct device * p = *pp;\t/* = devlist; */\n\twhile(p)\n\t{\n\t\tif(  p->headers[HEADER_NT].l == headers[HEADER_NT].l\n\t\t  && (0==memcmp(p->headers[HEADER_NT].p, headers[HEADER_NT].p, headers[HEADER_NT].l))\n\t\t  && p->headers[HEADER_USN].l == headers[HEADER_USN].l\n\t\t  && (0==memcmp(p->headers[HEADER_USN].p, headers[HEADER_USN].p, headers[HEADER_USN].l)) )\n\t\t{\n\t\t\t/*printf(\"found! %d\\n\", (int)(t - p->t));*/\n\t\t\tsyslog(LOG_DEBUG, \"device updated : %.*s\", headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t\t\tp->t = t;\n\t\t\t/* update Location ! */\n\t\t\tif(headers[HEADER_LOCATION].l > p->headers[HEADER_LOCATION].l)\n\t\t\t{\n\t\t\t\tstruct device * tmp;\n\t\t\t\ttmp = realloc(p, sizeof(struct device)\n\t\t\t\t    + headers[0].l+headers[1].l+headers[2].l);\n\t\t\t\tif(!tmp)\t/* allocation error */\n\t\t\t\t{\n\t\t\t\t\tsyslog(LOG_ERR, \"updateDevice() : memory allocation error\");\n\t\t\t\t\tfree(p);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tp = tmp;\n\t\t\t\t*pp = p;\n\t\t\t}\n\t\t\tmemcpy(p->data + p->headers[0].l + p->headers[1].l,\n\t\t\t       headers[2].p, headers[2].l);\n\t\t\t/* TODO : check p->headers[HEADER_LOCATION].l */\n\t\t\treturn 0;\n\t\t}\n\t\tpp = &p->next;\n\t\tp = *pp;\t/* p = p->next; */\n\t}\n\tsyslog(LOG_INFO, \"new device discovered : %.*s\",\n\t       headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t/* add */\n\t{\n\t\tchar * pc;\n\t\tint i;\n\t\tp = malloc(  sizeof(struct device)\n\t\t           + headers[0].l+headers[1].l+headers[2].l );\n\t\tif(!p) {\n\t\t\tsyslog(LOG_ERR, \"updateDevice(): cannot allocate memory\");\n\t\t\treturn -1;\n\t\t}\n\t\tp->next = devlist;\n\t\tp->t = t;\n\t\tpc = p->data;\n\t\tfor(i = 0; i < 3; i++)\n\t\t{\n\t\t\tp->headers[i].p = pc;\n\t\t\tp->headers[i].l = headers[i].l;\n\t\t\tmemcpy(pc, headers[i].p, headers[i].l);\n\t\t\tpc += headers[i].l;\n\t\t}\n\t\tdevlist = p;\n\t\tsendNotifications(NOTIF_NEW, p, NULL);\n\t}\n\treturn 1;\n}", "func_src_after": "updateDevice(const struct header * headers, time_t t)\n{\n\tstruct device ** pp = &devlist;\n\tstruct device * p = *pp;\t/* = devlist; */\n\twhile(p)\n\t{\n\t\tif(  p->headers[HEADER_NT].l == headers[HEADER_NT].l\n\t\t  && (0==memcmp(p->headers[HEADER_NT].p, headers[HEADER_NT].p, headers[HEADER_NT].l))\n\t\t  && p->headers[HEADER_USN].l == headers[HEADER_USN].l\n\t\t  && (0==memcmp(p->headers[HEADER_USN].p, headers[HEADER_USN].p, headers[HEADER_USN].l)) )\n\t\t{\n\t\t\t/*printf(\"found! %d\\n\", (int)(t - p->t));*/\n\t\t\tsyslog(LOG_DEBUG, \"device updated : %.*s\", headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t\t\tp->t = t;\n\t\t\t/* update Location ! */\n\t\t\tif(headers[HEADER_LOCATION].l > p->headers[HEADER_LOCATION].l)\n\t\t\t{\n\t\t\t\tstruct device * tmp;\n\t\t\t\ttmp = realloc(p, sizeof(struct device)\n\t\t\t\t    + headers[0].l+headers[1].l+headers[2].l);\n\t\t\t\tif(!tmp)\t/* allocation error */\n\t\t\t\t{\n\t\t\t\t\tsyslog(LOG_ERR, \"updateDevice() : memory allocation error\");\n\t\t\t\t\t*pp = p->next;\t/* remove \"p\" from the list */\n\t\t\t\t\tfree(p);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tp = tmp;\n\t\t\t\t*pp = p;\n\t\t\t}\n\t\t\tmemcpy(p->data + p->headers[0].l + p->headers[1].l,\n\t\t\t       headers[2].p, headers[2].l);\n\t\t\t/* TODO : check p->headers[HEADER_LOCATION].l */\n\t\t\treturn 0;\n\t\t}\n\t\tpp = &p->next;\n\t\tp = *pp;\t/* p = p->next; */\n\t}\n\tsyslog(LOG_INFO, \"new device discovered : %.*s\",\n\t       headers[HEADER_USN].l, headers[HEADER_USN].p);\n\t/* add */\n\t{\n\t\tchar * pc;\n\t\tint i;\n\t\tp = malloc(  sizeof(struct device)\n\t\t           + headers[0].l+headers[1].l+headers[2].l );\n\t\tif(!p) {\n\t\t\tsyslog(LOG_ERR, \"updateDevice(): cannot allocate memory\");\n\t\t\treturn -1;\n\t\t}\n\t\tp->next = devlist;\n\t\tp->t = t;\n\t\tpc = p->data;\n\t\tfor(i = 0; i < 3; i++)\n\t\t{\n\t\t\tp->headers[i].p = pc;\n\t\t\tp->headers[i].l = headers[i].l;\n\t\t\tmemcpy(pc, headers[i].p, headers[i].l);\n\t\t\tpc += headers[i].l;\n\t\t}\n\t\tdevlist = p;\n\t\tsendNotifications(NOTIF_NEW, p, NULL);\n\t}\n\treturn 1;\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/cd506a67e174a45c6a202eff182a712955ed6d6f", "file_name": "minissdpd/minissdpd.c", "vul_type": "cwe-416", "description": "In C, write a function `updateDevice` to manage a device list by updating an existing device or adding a new one based on provided headers and a timestamp."}
{"func_name": "_kdc_as_rep", "func_src_before": "_kdc_as_rep(kdc_request_t r,\n\t    krb5_data *reply,\n\t    const char *from,\n\t    struct sockaddr *from_addr,\n\t    int datagram_reply)\n{\n    krb5_context context = r->context;\n    krb5_kdc_configuration *config = r->config;\n    KDC_REQ *req = &r->req;\n    KDC_REQ_BODY *b = NULL;\n    AS_REP rep;\n    KDCOptions f;\n    krb5_enctype setype;\n    krb5_error_code ret = 0;\n    Key *skey;\n    int found_pa = 0;\n    int i, flags = HDB_F_FOR_AS_REQ;\n    METHOD_DATA error_method;\n    const PA_DATA *pa;\n\n    memset(&rep, 0, sizeof(rep));\n    error_method.len = 0;\n    error_method.val = NULL;\n\n    /*\n     * Look for FAST armor and unwrap\n     */\n    ret = _kdc_fast_unwrap_request(r);\n    if (ret) {\n\t_kdc_r_log(r, 0, \"FAST unwrap request from %s failed: %d\", from, ret);\n\tgoto out;\n    }\n\n    b = &req->req_body;\n    f = b->kdc_options;\n\n    if (f.canonicalize)\n\tflags |= HDB_F_CANON;\n\n    if(b->sname == NULL){\n\tret = KRB5KRB_ERR_GENERIC;\n\t_kdc_set_e_text(r, \"No server in request\");\n    } else{\n\tret = _krb5_principalname2krb5_principal (context,\n\t\t\t\t\t\t  &r->server_princ,\n\t\t\t\t\t\t  *(b->sname),\n\t\t\t\t\t\t  b->realm);\n\tif (ret == 0)\n\t    ret = krb5_unparse_name(context, r->server_princ, &r->server_name);\n    }\n    if (ret) {\n\tkdc_log(context, config, 0,\n\t\t\"AS-REQ malformed server name from %s\", from);\n\tgoto out;\n    }\n    if(b->cname == NULL){\n\tret = KRB5KRB_ERR_GENERIC;\n\t_kdc_set_e_text(r, \"No client in request\");\n    } else {\n\tret = _krb5_principalname2krb5_principal (context,\n\t\t\t\t\t\t  &r->client_princ,\n\t\t\t\t\t\t  *(b->cname),\n\t\t\t\t\t\t  b->realm);\n\tif (ret)\n\t    goto out;\n\n\tret = krb5_unparse_name(context, r->client_princ, &r->client_name);\n    }\n    if (ret) {\n\tkdc_log(context, config, 0,\n\t\t\"AS-REQ malformed client name from %s\", from);\n\tgoto out;\n    }\n\n    kdc_log(context, config, 0, \"AS-REQ %s from %s for %s\",\n\t    r->client_name, from, r->server_name);\n\n    /*\n     *\n     */\n\n    if (_kdc_is_anonymous(context, r->client_princ)) {\n\tif (!_kdc_is_anon_request(b)) {\n\t    kdc_log(context, config, 0, \"Anonymous ticket w/o anonymous flag\");\n\t    ret = KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n\t    goto out;\n\t}\n    } else if (_kdc_is_anon_request(b)) {\n\tkdc_log(context, config, 0,\n\t\t\"Request for a anonymous ticket with non \"\n\t\t\"anonymous client name: %s\", r->client_name);\n\tret = KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n\tgoto out;\n    }\n\n    /*\n     *\n     */\n\n    ret = _kdc_db_fetch(context, config, r->client_princ,\n\t\t\tHDB_F_GET_CLIENT | flags, NULL,\n\t\t\t&r->clientdb, &r->client);\n    if(ret == HDB_ERR_NOT_FOUND_HERE) {\n\tkdc_log(context, config, 5, \"client %s does not have secrets at this KDC, need to proxy\",\n\t\tr->client_name);\n\tgoto out;\n    } else if (ret == HDB_ERR_WRONG_REALM) {\n\tchar *fixed_client_name = NULL;\n\n\tret = krb5_unparse_name(context, r->client->entry.principal,\n\t\t\t\t&fixed_client_name);\n\tif (ret) {\n\t    goto out;\n\t}\n\n\tkdc_log(context, config, 0, \"WRONG_REALM - %s -> %s\",\n\t\tr->client_name, fixed_client_name);\n\tfree(fixed_client_name);\n\n\tret = _kdc_fast_mk_error(context, r,\n\t\t\t\t &error_method,\n\t\t\t\t r->armor_crypto,\n\t\t\t\t &req->req_body,\n\t\t\t\t KRB5_KDC_ERR_WRONG_REALM,\n\t\t\t\t NULL,\n\t\t\t\t r->server_princ,\n\t\t\t\t NULL,\n\t\t\t\t &r->client->entry.principal->realm,\n\t\t\t\t NULL, NULL,\n\t\t\t\t reply);\n\tgoto out;\n    } else if(ret){\n\tconst char *msg = krb5_get_error_message(context, ret);\n\tkdc_log(context, config, 0, \"UNKNOWN -- %s: %s\", r->client_name, msg);\n\tkrb5_free_error_message(context, msg);\n\tret = KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n\tgoto out;\n    }\n    ret = _kdc_db_fetch(context, config, r->server_princ,\n\t\t\tHDB_F_GET_SERVER|HDB_F_GET_KRBTGT | flags,\n\t\t\tNULL, NULL, &r->server);\n    if(ret == HDB_ERR_NOT_FOUND_HERE) {\n\tkdc_log(context, config, 5, \"target %s does not have secrets at this KDC, need to proxy\",\n\t\tr->server_name);\n\tgoto out;\n    } else if(ret){\n\tconst char *msg = krb5_get_error_message(context, ret);\n\tkdc_log(context, config, 0, \"UNKNOWN -- %s: %s\", r->server_name, msg);\n\tkrb5_free_error_message(context, msg);\n\tret = KRB5KDC_ERR_S_PRINCIPAL_UNKNOWN;\n\tgoto out;\n    }\n\n    /*\n     * Select a session enctype from the list of the crypto system\n     * supported enctypes that is supported by the client and is one of\n     * the enctype of the enctype of the service (likely krbtgt).\n     *\n     * The latter is used as a hint of what enctypes all KDC support,\n     * to make sure a newer version of KDC won't generate a session\n     * enctype that an older version of a KDC in the same realm can't\n     * decrypt.\n     */\n\n    ret = _kdc_find_etype(context,\n\t\t\t  krb5_principal_is_krbtgt(context, r->server_princ) ?\n\t\t\t  config->tgt_use_strongest_session_key :\n\t\t\t  config->svc_use_strongest_session_key, FALSE,\n\t\t\t  r->client, b->etype.val, b->etype.len, &r->sessionetype,\n\t\t\t  NULL);\n    if (ret) {\n\tkdc_log(context, config, 0,\n\t\t\"Client (%s) from %s has no common enctypes with KDC \"\n\t\t\"to use for the session key\",\n\t\tr->client_name, from);\n\tgoto out;\n    }\n\n    /*\n     * Pre-auth processing\n     */\n\n    if(req->padata){\n\tunsigned int n;\n\n\tlog_patypes(context, config, req->padata);\n\n\t/* Check if preauth matching */\n\n\tfor (n = 0; !found_pa && n < sizeof(pat) / sizeof(pat[0]); n++) {\n\t    if (pat[n].validate == NULL)\n\t\tcontinue;\n\t    if (r->armor_crypto == NULL && (pat[n].flags & PA_REQ_FAST))\n\t\tcontinue;\n\n\t    kdc_log(context, config, 5,\n\t\t    \"Looking for %s pa-data -- %s\", pat[n].name, r->client_name);\n\t    i = 0;\n\t    pa = _kdc_find_padata(req, &i, pat[n].type);\n\t    if (pa) {\n\t\tret = pat[n].validate(r, pa);\n\t\tif (ret != 0) {\n\t\t    goto out;\n\t\t}\n\t\tkdc_log(context, config, 0,\n\t\t\t\"%s pre-authentication succeeded -- %s\",\n\t\t\tpat[n].name, r->client_name);\n\t\tfound_pa = 1;\n\t\tr->et.flags.pre_authent = 1;\n\t    }\n\t}\n    }\n\n    if (found_pa == 0) {\n\tKey *ckey = NULL;\n\tsize_t n;\n\n\tfor (n = 0; n < sizeof(pat) / sizeof(pat[0]); n++) {\n\t    if ((pat[n].flags & PA_ANNOUNCE) == 0)\n\t\tcontinue;\n\t    ret = krb5_padata_add(context, &error_method,\n\t\t\t\t  pat[n].type, NULL, 0);\n\t    if (ret)\n\t\tgoto out;\n\t}\n\n\t/*\n\t * If there is a client key, send ETYPE_INFO{,2}\n\t */\n\tret = _kdc_find_etype(context,\n\t\t\t      config->preauth_use_strongest_session_key, TRUE,\n\t\t\t      r->client, b->etype.val, b->etype.len, NULL, &ckey);\n\tif (ret == 0) {\n\n\t    /*\n\t     * RFC4120 requires:\n\t     * - If the client only knows about old enctypes, then send\n\t     *   both info replies (we send 'info' first in the list).\n\t     * - If the client is 'modern', because it knows about 'new'\n\t     *   enctype types, then only send the 'info2' reply.\n\t     *\n\t     * Before we send the full list of etype-info data, we pick\n\t     * the client key we would have used anyway below, just pick\n\t     * that instead.\n\t     */\n\n\t    if (older_enctype(ckey->key.keytype)) {\n\t\tret = get_pa_etype_info(context, config,\n\t\t\t\t\t&error_method, ckey);\n\t\tif (ret)\n\t\t    goto out;\n\t    }\n\t    ret = get_pa_etype_info2(context, config,\n\t\t\t\t     &error_method, ckey);\n\t    if (ret)\n\t\tgoto out;\n\t}\n\n\t/* \n\t * send requre preauth is its required or anon is requested,\n\t * anon is today only allowed via preauth mechanisms.\n\t */\n\tif (require_preauth_p(r) || _kdc_is_anon_request(b)) {\n\t    ret = KRB5KDC_ERR_PREAUTH_REQUIRED;\n\t    _kdc_set_e_text(r, \"Need to use PA-ENC-TIMESTAMP/PA-PK-AS-REQ\");\n\t    goto out;\n\t}\n\n\tif (ckey == NULL) {\n\t    ret = KRB5KDC_ERR_CLIENT_NOTYET;\n\t    _kdc_set_e_text(r, \"Doesn't have a client key available\");\n\t    goto out;\n\t}\n\tkrb5_free_keyblock_contents(r->context,  &r->reply_key);\n\tret = krb5_copy_keyblock_contents(r->context, &ckey->key, &r->reply_key);\n\tif (ret)\n\t    goto out;\n    }\n\n    if (r->clientdb->hdb_auth_status) {\n\tr->clientdb->hdb_auth_status(context, r->clientdb, r->client, \n\t\t\t\t     HDB_AUTH_SUCCESS);\n    }\n\n    /*\n     * Verify flags after the user been required to prove its identity\n     * with in a preauth mech.\n     */\n\n    ret = _kdc_check_access(context, config, r->client, r->client_name,\n\t\t\t    r->server, r->server_name,\n\t\t\t    req, &error_method);\n    if(ret)\n\tgoto out;\n\n    /*\n     * Select the best encryption type for the KDC with out regard to\n     * the client since the client never needs to read that data.\n     */\n\n    ret = _kdc_get_preferred_key(context, config,\n\t\t\t\t r->server, r->server_name,\n\t\t\t\t &setype, &skey);\n    if(ret)\n\tgoto out;\n\n    if(f.renew || f.validate || f.proxy || f.forwarded || f.enc_tkt_in_skey\n       || (_kdc_is_anon_request(b) && !config->allow_anonymous)) {\n\tret = KRB5KDC_ERR_BADOPTION;\n\t_kdc_set_e_text(r, \"Bad KDC options\");\n\tgoto out;\n    }\n\n    /*\n     * Build reply\n     */\n\n    rep.pvno = 5;\n    rep.msg_type = krb_as_rep;\n\n    if (_kdc_is_anonymous(context, r->client_princ)) {\n\tRealm anon_realm=KRB5_ANON_REALM;\n\tret = copy_Realm(&anon_realm, &rep.crealm);\n    } else\n\tret = copy_Realm(&r->client->entry.principal->realm, &rep.crealm);\n    if (ret)\n\tgoto out;\n    ret = _krb5_principal2principalname(&rep.cname, r->client->entry.principal);\n    if (ret)\n\tgoto out;\n\n    rep.ticket.tkt_vno = 5;\n    ret = copy_Realm(&r->server->entry.principal->realm, &rep.ticket.realm);\n    if (ret)\n\tgoto out;\n    _krb5_principal2principalname(&rep.ticket.sname,\n\t\t\t\t  r->server->entry.principal);\n    /* java 1.6 expects the name to be the same type, lets allow that\n     * uncomplicated name-types. */\n#define CNT(sp,t) (((sp)->sname->name_type) == KRB5_NT_##t)\n    if (CNT(b, UNKNOWN) || CNT(b, PRINCIPAL) || CNT(b, SRV_INST) || CNT(b, SRV_HST) || CNT(b, SRV_XHST))\n\trep.ticket.sname.name_type = b->sname->name_type;\n#undef CNT\n\n    r->et.flags.initial = 1;\n    if(r->client->entry.flags.forwardable && r->server->entry.flags.forwardable)\n\tr->et.flags.forwardable = f.forwardable;\n    else if (f.forwardable) {\n\t_kdc_set_e_text(r, \"Ticket may not be forwardable\");\n\tret = KRB5KDC_ERR_POLICY;\n\tgoto out;\n    }\n    if(r->client->entry.flags.proxiable && r->server->entry.flags.proxiable)\n\tr->et.flags.proxiable = f.proxiable;\n    else if (f.proxiable) {\n\t_kdc_set_e_text(r, \"Ticket may not be proxiable\");\n\tret = KRB5KDC_ERR_POLICY;\n\tgoto out;\n    }\n    if(r->client->entry.flags.postdate && r->server->entry.flags.postdate)\n\tr->et.flags.may_postdate = f.allow_postdate;\n    else if (f.allow_postdate){\n\t_kdc_set_e_text(r, \"Ticket may not be postdate\");\n\tret = KRB5KDC_ERR_POLICY;\n\tgoto out;\n    }\n\n    /* check for valid set of addresses */\n    if(!_kdc_check_addresses(context, config, b->addresses, from_addr)) {\n\t_kdc_set_e_text(r, \"Bad address list in requested\");\n\tret = KRB5KRB_AP_ERR_BADADDR;\n\tgoto out;\n    }\n\n    ret = copy_PrincipalName(&rep.cname, &r->et.cname);\n    if (ret)\n\tgoto out;\n    ret = copy_Realm(&rep.crealm, &r->et.crealm);\n    if (ret)\n\tgoto out;\n\n    {\n\ttime_t start;\n\ttime_t t;\n\t\n\tstart = r->et.authtime = kdc_time;\n\n\tif(f.postdated && req->req_body.from){\n\t    ALLOC(r->et.starttime);\n\t    start = *r->et.starttime = *req->req_body.from;\n\t    r->et.flags.invalid = 1;\n\t    r->et.flags.postdated = 1; /* XXX ??? */\n\t}\n\t_kdc_fix_time(&b->till);\n\tt = *b->till;\n\n\t/* be careful not overflowing */\n\n\tif(r->client->entry.max_life)\n\t    t = start + min(t - start, *r->client->entry.max_life);\n\tif(r->server->entry.max_life)\n\t    t = start + min(t - start, *r->server->entry.max_life);\n#if 0\n\tt = min(t, start + realm->max_life);\n#endif\n\tr->et.endtime = t;\n\tif(f.renewable_ok && r->et.endtime < *b->till){\n\t    f.renewable = 1;\n\t    if(b->rtime == NULL){\n\t\tALLOC(b->rtime);\n\t\t*b->rtime = 0;\n\t    }\n\t    if(*b->rtime < *b->till)\n\t\t*b->rtime = *b->till;\n\t}\n\tif(f.renewable && b->rtime){\n\t    t = *b->rtime;\n\t    if(t == 0)\n\t\tt = MAX_TIME;\n\t    if(r->client->entry.max_renew)\n\t\tt = start + min(t - start, *r->client->entry.max_renew);\n\t    if(r->server->entry.max_renew)\n\t\tt = start + min(t - start, *r->server->entry.max_renew);\n#if 0\n\t    t = min(t, start + realm->max_renew);\n#endif\n\t    ALLOC(r->et.renew_till);\n\t    *r->et.renew_till = t;\n\t    r->et.flags.renewable = 1;\n\t}\n    }\n\n    if (_kdc_is_anon_request(b))\n\tr->et.flags.anonymous = 1;\n\n    if(b->addresses){\n\tALLOC(r->et.caddr);\n\tcopy_HostAddresses(b->addresses, r->et.caddr);\n    }\n\n    r->et.transited.tr_type = DOMAIN_X500_COMPRESS;\n    krb5_data_zero(&r->et.transited.contents);\n\n    /* The MIT ASN.1 library (obviously) doesn't tell lengths encoded\n     * as 0 and as 0x80 (meaning indefinite length) apart, and is thus\n     * incapable of correctly decoding SEQUENCE OF's of zero length.\n     *\n     * To fix this, always send at least one no-op last_req\n     *\n     * If there's a pw_end or valid_end we will use that,\n     * otherwise just a dummy lr.\n     */\n    r->ek.last_req.val = malloc(2 * sizeof(*r->ek.last_req.val));\n    if (r->ek.last_req.val == NULL) {\n\tret = ENOMEM;\n\tgoto out;\n    }\n    r->ek.last_req.len = 0;\n    if (r->client->entry.pw_end\n\t&& (config->kdc_warn_pwexpire == 0\n\t    || kdc_time + config->kdc_warn_pwexpire >= *r->client->entry.pw_end)) {\n\tr->ek.last_req.val[r->ek.last_req.len].lr_type  = LR_PW_EXPTIME;\n\tr->ek.last_req.val[r->ek.last_req.len].lr_value = *r->client->entry.pw_end;\n\t++r->ek.last_req.len;\n    }\n    if (r->client->entry.valid_end) {\n\tr->ek.last_req.val[r->ek.last_req.len].lr_type  = LR_ACCT_EXPTIME;\n\tr->ek.last_req.val[r->ek.last_req.len].lr_value = *r->client->entry.valid_end;\n\t++r->ek.last_req.len;\n    }\n    if (r->ek.last_req.len == 0) {\n\tr->ek.last_req.val[r->ek.last_req.len].lr_type  = LR_NONE;\n\tr->ek.last_req.val[r->ek.last_req.len].lr_value = 0;\n\t++r->ek.last_req.len;\n    }\n    r->ek.nonce = b->nonce;\n    if (r->client->entry.valid_end || r->client->entry.pw_end) {\n\tALLOC(r->ek.key_expiration);\n\tif (r->client->entry.valid_end) {\n\t    if (r->client->entry.pw_end)\n\t\t*r->ek.key_expiration = min(*r->client->entry.valid_end,\n\t\t\t\t\t *r->client->entry.pw_end);\n\t    else\n\t\t*r->ek.key_expiration = *r->client->entry.valid_end;\n\t} else\n\t    *r->ek.key_expiration = *r->client->entry.pw_end;\n    } else\n\tr->ek.key_expiration = NULL;\n    r->ek.flags = r->et.flags;\n    r->ek.authtime = r->et.authtime;\n    if (r->et.starttime) {\n\tALLOC(r->ek.starttime);\n\t*r->ek.starttime = *r->et.starttime;\n    }\n    r->ek.endtime = r->et.endtime;\n    if (r->et.renew_till) {\n\tALLOC(r->ek.renew_till);\n\t*r->ek.renew_till = *r->et.renew_till;\n    }\n    ret = copy_Realm(&rep.ticket.realm, &r->ek.srealm);\n    if (ret)\n\tgoto out;\n    ret = copy_PrincipalName(&rep.ticket.sname, &r->ek.sname);\n    if (ret)\n\tgoto out;\n    if(r->et.caddr){\n\tALLOC(r->ek.caddr);\n\tcopy_HostAddresses(r->et.caddr, r->ek.caddr);\n    }\n\n    /*\n     * Check and session and reply keys\n     */\n\n    if (r->session_key.keytype == ETYPE_NULL) {\n\tret = krb5_generate_random_keyblock(context, r->sessionetype, &r->session_key);\n\tif (ret)\n\t    goto out;\n    }\n\n    if (r->reply_key.keytype == ETYPE_NULL) {\n\t_kdc_set_e_text(r, \"Client have no reply key\");\n\tret = KRB5KDC_ERR_CLIENT_NOTYET;\n\tgoto out;\n    }\n\n    ret = copy_EncryptionKey(&r->session_key, &r->et.key);\n    if (ret)\n\tgoto out;\n\n    ret = copy_EncryptionKey(&r->session_key, &r->ek.key);\n    if (ret)\n\tgoto out;\n\n    if (r->outpadata.len) {\n\n\tALLOC(rep.padata);\n\tif (rep.padata == NULL) {\n\t    ret = ENOMEM;\n\t    goto out;\n\t}\n\tret = copy_METHOD_DATA(&r->outpadata, rep.padata);\n\tif (ret)\n\t    goto out;\n    }\n\n    /* Add the PAC */\n    if (send_pac_p(context, req)) {\n\tgenerate_pac(r, skey);\n    }\n\n    _kdc_log_timestamp(context, config, \"AS-REQ\", r->et.authtime, r->et.starttime,\n\t\t       r->et.endtime, r->et.renew_till);\n\n    /* do this as the last thing since this signs the EncTicketPart */\n    ret = _kdc_add_KRB5SignedPath(context,\n\t\t\t\t  config,\n\t\t\t\t  r->server,\n\t\t\t\t  setype,\n\t\t\t\t  r->client->entry.principal,\n\t\t\t\t  NULL,\n\t\t\t\t  NULL,\n\t\t\t\t  &r->et);\n    if (ret)\n\tgoto out;\n\n    log_as_req(context, config, r->reply_key.keytype, setype, b);\n\n    /*\n     * We always say we support FAST/enc-pa-rep\n     */\n\n    r->et.flags.enc_pa_rep = r->ek.flags.enc_pa_rep = 1;\n\n    /*\n     * Add REQ_ENC_PA_REP if client supports it\n     */\n\n    i = 0;\n    pa = _kdc_find_padata(req, &i, KRB5_PADATA_REQ_ENC_PA_REP);\n    if (pa) {\n\n\tret = add_enc_pa_rep(r);\n\tif (ret) {\n\t    const char *msg = krb5_get_error_message(r->context, ret);\n\t    _kdc_r_log(r, 0, \"add_enc_pa_rep failed: %s: %d\", msg, ret);\n\t    krb5_free_error_message(r->context, msg);\n\t    goto out;\n\t}\n    }\n\n    /*\n     *\n     */\n\n    ret = _kdc_encode_reply(context, config,\n\t\t\t    r->armor_crypto, req->req_body.nonce,\n\t\t\t    &rep, &r->et, &r->ek, setype, r->server->entry.kvno,\n\t\t\t    &skey->key, r->client->entry.kvno,\n\t\t\t    &r->reply_key, 0, &r->e_text, reply);\n    if (ret)\n\tgoto out;\n\n    /*\n     * Check if message too large\n     */\n    if (datagram_reply && reply->length > config->max_datagram_reply_length) {\n\tkrb5_data_free(reply);\n\tret = KRB5KRB_ERR_RESPONSE_TOO_BIG;\n\t_kdc_set_e_text(r, \"Reply packet too large\");\n    }\n\nout:\n    free_AS_REP(&rep);\n\n    /*\n     * In case of a non proxy error, build an error message.\n     */\n    if(ret != 0 && ret != HDB_ERR_NOT_FOUND_HERE && reply->length == 0) {\n\tret = _kdc_fast_mk_error(context, r,\n\t\t\t\t &error_method,\n\t\t\t\t r->armor_crypto,\n\t\t\t\t &req->req_body,\n\t\t\t\t ret, r->e_text,\n\t\t\t\t r->server_princ,\n\t\t\t\t &r->client_princ->name,\n\t\t\t\t &r->client_princ->realm,\n\t\t\t\t NULL, NULL,\n\t\t\t\t reply);\n\tif (ret)\n\t    goto out2;\n    }\nout2:\n    free_EncTicketPart(&r->et);\n    free_EncKDCRepPart(&r->ek);\n    free_KDCFastState(&r->fast);\n\n    if (error_method.len)\n\tfree_METHOD_DATA(&error_method);\n    if (r->outpadata.len)\n\tfree_METHOD_DATA(&r->outpadata);\n    if (r->client_princ) {\n\tkrb5_free_principal(context, r->client_princ);\n\tr->client_princ = NULL;\n    }\n    if (r->client_name) {\n\tfree(r->client_name);\n\tr->client_name = NULL;\n    }\n    if (r->server_princ){\n\tkrb5_free_principal(context, r->server_princ);\n\tr->server_princ = NULL;\n    }\n    if (r->server_name) {\n\tfree(r->server_name);\n\tr->server_name = NULL;\n    }\n    if (r->client)\n\t_kdc_free_ent(context, r->client);\n    if (r->server)\n\t_kdc_free_ent(context, r->server);\n    if (r->armor_crypto) {\n\tkrb5_crypto_destroy(r->context, r->armor_crypto);\n\tr->armor_crypto = NULL;\n    }\n    krb5_free_keyblock_contents(r->context, &r->reply_key);\n    krb5_free_keyblock_contents(r->context, &r->session_key);\n    return ret;\n}", "func_src_after": "_kdc_as_rep(kdc_request_t r,\n\t    krb5_data *reply,\n\t    const char *from,\n\t    struct sockaddr *from_addr,\n\t    int datagram_reply)\n{\n    krb5_context context = r->context;\n    krb5_kdc_configuration *config = r->config;\n    KDC_REQ *req = &r->req;\n    KDC_REQ_BODY *b = NULL;\n    AS_REP rep;\n    KDCOptions f;\n    krb5_enctype setype;\n    krb5_error_code ret = 0;\n    Key *skey;\n    int found_pa = 0;\n    int i, flags = HDB_F_FOR_AS_REQ;\n    METHOD_DATA error_method;\n    const PA_DATA *pa;\n\n    memset(&rep, 0, sizeof(rep));\n    error_method.len = 0;\n    error_method.val = NULL;\n\n    /*\n     * Look for FAST armor and unwrap\n     */\n    ret = _kdc_fast_unwrap_request(r);\n    if (ret) {\n\t_kdc_r_log(r, 0, \"FAST unwrap request from %s failed: %d\", from, ret);\n\tgoto out;\n    }\n\n    b = &req->req_body;\n    f = b->kdc_options;\n\n    if (f.canonicalize)\n\tflags |= HDB_F_CANON;\n\n    if(b->sname == NULL){\n\tret = KRB5KRB_ERR_GENERIC;\n\t_kdc_set_e_text(r, \"No server in request\");\n    } else{\n\tret = _krb5_principalname2krb5_principal (context,\n\t\t\t\t\t\t  &r->server_princ,\n\t\t\t\t\t\t  *(b->sname),\n\t\t\t\t\t\t  b->realm);\n\tif (ret == 0)\n\t    ret = krb5_unparse_name(context, r->server_princ, &r->server_name);\n    }\n    if (ret) {\n\tkdc_log(context, config, 0,\n\t\t\"AS-REQ malformed server name from %s\", from);\n\tgoto out;\n    }\n    if(b->cname == NULL){\n\tret = KRB5KRB_ERR_GENERIC;\n\t_kdc_set_e_text(r, \"No client in request\");\n    } else {\n\tret = _krb5_principalname2krb5_principal (context,\n\t\t\t\t\t\t  &r->client_princ,\n\t\t\t\t\t\t  *(b->cname),\n\t\t\t\t\t\t  b->realm);\n\tif (ret)\n\t    goto out;\n\n\tret = krb5_unparse_name(context, r->client_princ, &r->client_name);\n    }\n    if (ret) {\n\tkdc_log(context, config, 0,\n\t\t\"AS-REQ malformed client name from %s\", from);\n\tgoto out;\n    }\n\n    kdc_log(context, config, 0, \"AS-REQ %s from %s for %s\",\n\t    r->client_name, from, r->server_name);\n\n    /*\n     *\n     */\n\n    if (_kdc_is_anonymous(context, r->client_princ)) {\n\tif (!_kdc_is_anon_request(b)) {\n\t    kdc_log(context, config, 0, \"Anonymous ticket w/o anonymous flag\");\n\t    ret = KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n\t    goto out;\n\t}\n    } else if (_kdc_is_anon_request(b)) {\n\tkdc_log(context, config, 0,\n\t\t\"Request for a anonymous ticket with non \"\n\t\t\"anonymous client name: %s\", r->client_name);\n\tret = KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n\tgoto out;\n    }\n\n    /*\n     *\n     */\n\n    ret = _kdc_db_fetch(context, config, r->client_princ,\n\t\t\tHDB_F_GET_CLIENT | flags, NULL,\n\t\t\t&r->clientdb, &r->client);\n    if(ret == HDB_ERR_NOT_FOUND_HERE) {\n\tkdc_log(context, config, 5, \"client %s does not have secrets at this KDC, need to proxy\",\n\t\tr->client_name);\n\tgoto out;\n    } else if (ret == HDB_ERR_WRONG_REALM) {\n\tchar *fixed_client_name = NULL;\n\n\tret = krb5_unparse_name(context, r->client->entry.principal,\n\t\t\t\t&fixed_client_name);\n\tif (ret) {\n\t    goto out;\n\t}\n\n\tkdc_log(context, config, 0, \"WRONG_REALM - %s -> %s\",\n\t\tr->client_name, fixed_client_name);\n\tfree(fixed_client_name);\n\n\tret = _kdc_fast_mk_error(context, r,\n\t\t\t\t &error_method,\n\t\t\t\t r->armor_crypto,\n\t\t\t\t &req->req_body,\n\t\t\t\t KRB5_KDC_ERR_WRONG_REALM,\n\t\t\t\t NULL,\n\t\t\t\t r->server_princ,\n\t\t\t\t NULL,\n\t\t\t\t &r->client->entry.principal->realm,\n\t\t\t\t NULL, NULL,\n\t\t\t\t reply);\n\tgoto out;\n    } else if(ret){\n\tconst char *msg = krb5_get_error_message(context, ret);\n\tkdc_log(context, config, 0, \"UNKNOWN -- %s: %s\", r->client_name, msg);\n\tkrb5_free_error_message(context, msg);\n\tret = KRB5KDC_ERR_C_PRINCIPAL_UNKNOWN;\n\tgoto out;\n    }\n    ret = _kdc_db_fetch(context, config, r->server_princ,\n\t\t\tHDB_F_GET_SERVER|HDB_F_GET_KRBTGT | flags,\n\t\t\tNULL, NULL, &r->server);\n    if(ret == HDB_ERR_NOT_FOUND_HERE) {\n\tkdc_log(context, config, 5, \"target %s does not have secrets at this KDC, need to proxy\",\n\t\tr->server_name);\n\tgoto out;\n    } else if(ret){\n\tconst char *msg = krb5_get_error_message(context, ret);\n\tkdc_log(context, config, 0, \"UNKNOWN -- %s: %s\", r->server_name, msg);\n\tkrb5_free_error_message(context, msg);\n\tret = KRB5KDC_ERR_S_PRINCIPAL_UNKNOWN;\n\tgoto out;\n    }\n\n    /*\n     * Select a session enctype from the list of the crypto system\n     * supported enctypes that is supported by the client and is one of\n     * the enctype of the enctype of the service (likely krbtgt).\n     *\n     * The latter is used as a hint of what enctypes all KDC support,\n     * to make sure a newer version of KDC won't generate a session\n     * enctype that an older version of a KDC in the same realm can't\n     * decrypt.\n     */\n\n    ret = _kdc_find_etype(context,\n\t\t\t  krb5_principal_is_krbtgt(context, r->server_princ) ?\n\t\t\t  config->tgt_use_strongest_session_key :\n\t\t\t  config->svc_use_strongest_session_key, FALSE,\n\t\t\t  r->client, b->etype.val, b->etype.len, &r->sessionetype,\n\t\t\t  NULL);\n    if (ret) {\n\tkdc_log(context, config, 0,\n\t\t\"Client (%s) from %s has no common enctypes with KDC \"\n\t\t\"to use for the session key\",\n\t\tr->client_name, from);\n\tgoto out;\n    }\n\n    /*\n     * Pre-auth processing\n     */\n\n    if(req->padata){\n\tunsigned int n;\n\n\tlog_patypes(context, config, req->padata);\n\n\t/* Check if preauth matching */\n\n\tfor (n = 0; !found_pa && n < sizeof(pat) / sizeof(pat[0]); n++) {\n\t    if (pat[n].validate == NULL)\n\t\tcontinue;\n\t    if (r->armor_crypto == NULL && (pat[n].flags & PA_REQ_FAST))\n\t\tcontinue;\n\n\t    kdc_log(context, config, 5,\n\t\t    \"Looking for %s pa-data -- %s\", pat[n].name, r->client_name);\n\t    i = 0;\n\t    pa = _kdc_find_padata(req, &i, pat[n].type);\n\t    if (pa) {\n\t\tret = pat[n].validate(r, pa);\n\t\tif (ret != 0) {\n\t\t    goto out;\n\t\t}\n\t\tkdc_log(context, config, 0,\n\t\t\t\"%s pre-authentication succeeded -- %s\",\n\t\t\tpat[n].name, r->client_name);\n\t\tfound_pa = 1;\n\t\tr->et.flags.pre_authent = 1;\n\t    }\n\t}\n    }\n\n    if (found_pa == 0) {\n\tKey *ckey = NULL;\n\tsize_t n;\n\n\tfor (n = 0; n < sizeof(pat) / sizeof(pat[0]); n++) {\n\t    if ((pat[n].flags & PA_ANNOUNCE) == 0)\n\t\tcontinue;\n\t    ret = krb5_padata_add(context, &error_method,\n\t\t\t\t  pat[n].type, NULL, 0);\n\t    if (ret)\n\t\tgoto out;\n\t}\n\n\t/*\n\t * If there is a client key, send ETYPE_INFO{,2}\n\t */\n\tret = _kdc_find_etype(context,\n\t\t\t      config->preauth_use_strongest_session_key, TRUE,\n\t\t\t      r->client, b->etype.val, b->etype.len, NULL, &ckey);\n\tif (ret == 0) {\n\n\t    /*\n\t     * RFC4120 requires:\n\t     * - If the client only knows about old enctypes, then send\n\t     *   both info replies (we send 'info' first in the list).\n\t     * - If the client is 'modern', because it knows about 'new'\n\t     *   enctype types, then only send the 'info2' reply.\n\t     *\n\t     * Before we send the full list of etype-info data, we pick\n\t     * the client key we would have used anyway below, just pick\n\t     * that instead.\n\t     */\n\n\t    if (older_enctype(ckey->key.keytype)) {\n\t\tret = get_pa_etype_info(context, config,\n\t\t\t\t\t&error_method, ckey);\n\t\tif (ret)\n\t\t    goto out;\n\t    }\n\t    ret = get_pa_etype_info2(context, config,\n\t\t\t\t     &error_method, ckey);\n\t    if (ret)\n\t\tgoto out;\n\t}\n\n\t/* \n\t * send requre preauth is its required or anon is requested,\n\t * anon is today only allowed via preauth mechanisms.\n\t */\n\tif (require_preauth_p(r) || _kdc_is_anon_request(b)) {\n\t    ret = KRB5KDC_ERR_PREAUTH_REQUIRED;\n\t    _kdc_set_e_text(r, \"Need to use PA-ENC-TIMESTAMP/PA-PK-AS-REQ\");\n\t    goto out;\n\t}\n\n\tif (ckey == NULL) {\n\t    ret = KRB5KDC_ERR_CLIENT_NOTYET;\n\t    _kdc_set_e_text(r, \"Doesn't have a client key available\");\n\t    goto out;\n\t}\n\tkrb5_free_keyblock_contents(r->context,  &r->reply_key);\n\tret = krb5_copy_keyblock_contents(r->context, &ckey->key, &r->reply_key);\n\tif (ret)\n\t    goto out;\n    }\n\n    if (r->clientdb->hdb_auth_status) {\n\tr->clientdb->hdb_auth_status(context, r->clientdb, r->client, \n\t\t\t\t     HDB_AUTH_SUCCESS);\n    }\n\n    /*\n     * Verify flags after the user been required to prove its identity\n     * with in a preauth mech.\n     */\n\n    ret = _kdc_check_access(context, config, r->client, r->client_name,\n\t\t\t    r->server, r->server_name,\n\t\t\t    req, &error_method);\n    if(ret)\n\tgoto out;\n\n    /*\n     * Select the best encryption type for the KDC with out regard to\n     * the client since the client never needs to read that data.\n     */\n\n    ret = _kdc_get_preferred_key(context, config,\n\t\t\t\t r->server, r->server_name,\n\t\t\t\t &setype, &skey);\n    if(ret)\n\tgoto out;\n\n    if(f.renew || f.validate || f.proxy || f.forwarded || f.enc_tkt_in_skey\n       || (_kdc_is_anon_request(b) && !config->allow_anonymous)) {\n\tret = KRB5KDC_ERR_BADOPTION;\n\t_kdc_set_e_text(r, \"Bad KDC options\");\n\tgoto out;\n    }\n\n    /*\n     * Build reply\n     */\n\n    rep.pvno = 5;\n    rep.msg_type = krb_as_rep;\n\n    if (_kdc_is_anonymous(context, r->client_princ)) {\n\tRealm anon_realm=KRB5_ANON_REALM;\n\tret = copy_Realm(&anon_realm, &rep.crealm);\n    } else\n\tret = copy_Realm(&r->client->entry.principal->realm, &rep.crealm);\n    if (ret)\n\tgoto out;\n    ret = _krb5_principal2principalname(&rep.cname, r->client->entry.principal);\n    if (ret)\n\tgoto out;\n\n    rep.ticket.tkt_vno = 5;\n    ret = copy_Realm(&r->server->entry.principal->realm, &rep.ticket.realm);\n    if (ret)\n\tgoto out;\n    _krb5_principal2principalname(&rep.ticket.sname,\n\t\t\t\t  r->server->entry.principal);\n    /* java 1.6 expects the name to be the same type, lets allow that\n     * uncomplicated name-types. */\n#define CNT(sp,t) (((sp)->sname->name_type) == KRB5_NT_##t)\n    if (CNT(b, UNKNOWN) || CNT(b, PRINCIPAL) || CNT(b, SRV_INST) || CNT(b, SRV_HST) || CNT(b, SRV_XHST))\n\trep.ticket.sname.name_type = b->sname->name_type;\n#undef CNT\n\n    r->et.flags.initial = 1;\n    if(r->client->entry.flags.forwardable && r->server->entry.flags.forwardable)\n\tr->et.flags.forwardable = f.forwardable;\n    else if (f.forwardable) {\n\t_kdc_set_e_text(r, \"Ticket may not be forwardable\");\n\tret = KRB5KDC_ERR_POLICY;\n\tgoto out;\n    }\n    if(r->client->entry.flags.proxiable && r->server->entry.flags.proxiable)\n\tr->et.flags.proxiable = f.proxiable;\n    else if (f.proxiable) {\n\t_kdc_set_e_text(r, \"Ticket may not be proxiable\");\n\tret = KRB5KDC_ERR_POLICY;\n\tgoto out;\n    }\n    if(r->client->entry.flags.postdate && r->server->entry.flags.postdate)\n\tr->et.flags.may_postdate = f.allow_postdate;\n    else if (f.allow_postdate){\n\t_kdc_set_e_text(r, \"Ticket may not be postdate\");\n\tret = KRB5KDC_ERR_POLICY;\n\tgoto out;\n    }\n\n    /* check for valid set of addresses */\n    if(!_kdc_check_addresses(context, config, b->addresses, from_addr)) {\n\t_kdc_set_e_text(r, \"Bad address list in requested\");\n\tret = KRB5KRB_AP_ERR_BADADDR;\n\tgoto out;\n    }\n\n    ret = copy_PrincipalName(&rep.cname, &r->et.cname);\n    if (ret)\n\tgoto out;\n    ret = copy_Realm(&rep.crealm, &r->et.crealm);\n    if (ret)\n\tgoto out;\n\n    {\n\ttime_t start;\n\ttime_t t;\n\t\n\tstart = r->et.authtime = kdc_time;\n\n\tif(f.postdated && req->req_body.from){\n\t    ALLOC(r->et.starttime);\n\t    start = *r->et.starttime = *req->req_body.from;\n\t    r->et.flags.invalid = 1;\n\t    r->et.flags.postdated = 1; /* XXX ??? */\n\t}\n\t_kdc_fix_time(&b->till);\n\tt = *b->till;\n\n\t/* be careful not overflowing */\n\n\tif(r->client->entry.max_life)\n\t    t = start + min(t - start, *r->client->entry.max_life);\n\tif(r->server->entry.max_life)\n\t    t = start + min(t - start, *r->server->entry.max_life);\n#if 0\n\tt = min(t, start + realm->max_life);\n#endif\n\tr->et.endtime = t;\n\tif(f.renewable_ok && r->et.endtime < *b->till){\n\t    f.renewable = 1;\n\t    if(b->rtime == NULL){\n\t\tALLOC(b->rtime);\n\t\t*b->rtime = 0;\n\t    }\n\t    if(*b->rtime < *b->till)\n\t\t*b->rtime = *b->till;\n\t}\n\tif(f.renewable && b->rtime){\n\t    t = *b->rtime;\n\t    if(t == 0)\n\t\tt = MAX_TIME;\n\t    if(r->client->entry.max_renew)\n\t\tt = start + min(t - start, *r->client->entry.max_renew);\n\t    if(r->server->entry.max_renew)\n\t\tt = start + min(t - start, *r->server->entry.max_renew);\n#if 0\n\t    t = min(t, start + realm->max_renew);\n#endif\n\t    ALLOC(r->et.renew_till);\n\t    *r->et.renew_till = t;\n\t    r->et.flags.renewable = 1;\n\t}\n    }\n\n    if (_kdc_is_anon_request(b))\n\tr->et.flags.anonymous = 1;\n\n    if(b->addresses){\n\tALLOC(r->et.caddr);\n\tcopy_HostAddresses(b->addresses, r->et.caddr);\n    }\n\n    r->et.transited.tr_type = DOMAIN_X500_COMPRESS;\n    krb5_data_zero(&r->et.transited.contents);\n\n    /* The MIT ASN.1 library (obviously) doesn't tell lengths encoded\n     * as 0 and as 0x80 (meaning indefinite length) apart, and is thus\n     * incapable of correctly decoding SEQUENCE OF's of zero length.\n     *\n     * To fix this, always send at least one no-op last_req\n     *\n     * If there's a pw_end or valid_end we will use that,\n     * otherwise just a dummy lr.\n     */\n    r->ek.last_req.val = malloc(2 * sizeof(*r->ek.last_req.val));\n    if (r->ek.last_req.val == NULL) {\n\tret = ENOMEM;\n\tgoto out;\n    }\n    r->ek.last_req.len = 0;\n    if (r->client->entry.pw_end\n\t&& (config->kdc_warn_pwexpire == 0\n\t    || kdc_time + config->kdc_warn_pwexpire >= *r->client->entry.pw_end)) {\n\tr->ek.last_req.val[r->ek.last_req.len].lr_type  = LR_PW_EXPTIME;\n\tr->ek.last_req.val[r->ek.last_req.len].lr_value = *r->client->entry.pw_end;\n\t++r->ek.last_req.len;\n    }\n    if (r->client->entry.valid_end) {\n\tr->ek.last_req.val[r->ek.last_req.len].lr_type  = LR_ACCT_EXPTIME;\n\tr->ek.last_req.val[r->ek.last_req.len].lr_value = *r->client->entry.valid_end;\n\t++r->ek.last_req.len;\n    }\n    if (r->ek.last_req.len == 0) {\n\tr->ek.last_req.val[r->ek.last_req.len].lr_type  = LR_NONE;\n\tr->ek.last_req.val[r->ek.last_req.len].lr_value = 0;\n\t++r->ek.last_req.len;\n    }\n    r->ek.nonce = b->nonce;\n    if (r->client->entry.valid_end || r->client->entry.pw_end) {\n\tALLOC(r->ek.key_expiration);\n\tif (r->client->entry.valid_end) {\n\t    if (r->client->entry.pw_end)\n\t\t*r->ek.key_expiration = min(*r->client->entry.valid_end,\n\t\t\t\t\t *r->client->entry.pw_end);\n\t    else\n\t\t*r->ek.key_expiration = *r->client->entry.valid_end;\n\t} else\n\t    *r->ek.key_expiration = *r->client->entry.pw_end;\n    } else\n\tr->ek.key_expiration = NULL;\n    r->ek.flags = r->et.flags;\n    r->ek.authtime = r->et.authtime;\n    if (r->et.starttime) {\n\tALLOC(r->ek.starttime);\n\t*r->ek.starttime = *r->et.starttime;\n    }\n    r->ek.endtime = r->et.endtime;\n    if (r->et.renew_till) {\n\tALLOC(r->ek.renew_till);\n\t*r->ek.renew_till = *r->et.renew_till;\n    }\n    ret = copy_Realm(&rep.ticket.realm, &r->ek.srealm);\n    if (ret)\n\tgoto out;\n    ret = copy_PrincipalName(&rep.ticket.sname, &r->ek.sname);\n    if (ret)\n\tgoto out;\n    if(r->et.caddr){\n\tALLOC(r->ek.caddr);\n\tcopy_HostAddresses(r->et.caddr, r->ek.caddr);\n    }\n\n    /*\n     * Check and session and reply keys\n     */\n\n    if (r->session_key.keytype == ETYPE_NULL) {\n\tret = krb5_generate_random_keyblock(context, r->sessionetype, &r->session_key);\n\tif (ret)\n\t    goto out;\n    }\n\n    if (r->reply_key.keytype == ETYPE_NULL) {\n\t_kdc_set_e_text(r, \"Client have no reply key\");\n\tret = KRB5KDC_ERR_CLIENT_NOTYET;\n\tgoto out;\n    }\n\n    ret = copy_EncryptionKey(&r->session_key, &r->et.key);\n    if (ret)\n\tgoto out;\n\n    ret = copy_EncryptionKey(&r->session_key, &r->ek.key);\n    if (ret)\n\tgoto out;\n\n    if (r->outpadata.len) {\n\n\tALLOC(rep.padata);\n\tif (rep.padata == NULL) {\n\t    ret = ENOMEM;\n\t    goto out;\n\t}\n\tret = copy_METHOD_DATA(&r->outpadata, rep.padata);\n\tif (ret)\n\t    goto out;\n    }\n\n    /* Add the PAC */\n    if (send_pac_p(context, req)) {\n\tgenerate_pac(r, skey);\n    }\n\n    _kdc_log_timestamp(context, config, \"AS-REQ\", r->et.authtime, r->et.starttime,\n\t\t       r->et.endtime, r->et.renew_till);\n\n    /* do this as the last thing since this signs the EncTicketPart */\n    ret = _kdc_add_KRB5SignedPath(context,\n\t\t\t\t  config,\n\t\t\t\t  r->server,\n\t\t\t\t  setype,\n\t\t\t\t  r->client->entry.principal,\n\t\t\t\t  NULL,\n\t\t\t\t  NULL,\n\t\t\t\t  &r->et);\n    if (ret)\n\tgoto out;\n\n    log_as_req(context, config, r->reply_key.keytype, setype, b);\n\n    /*\n     * We always say we support FAST/enc-pa-rep\n     */\n\n    r->et.flags.enc_pa_rep = r->ek.flags.enc_pa_rep = 1;\n\n    /*\n     * Add REQ_ENC_PA_REP if client supports it\n     */\n\n    i = 0;\n    pa = _kdc_find_padata(req, &i, KRB5_PADATA_REQ_ENC_PA_REP);\n    if (pa) {\n\n\tret = add_enc_pa_rep(r);\n\tif (ret) {\n\t    const char *msg = krb5_get_error_message(r->context, ret);\n\t    _kdc_r_log(r, 0, \"add_enc_pa_rep failed: %s: %d\", msg, ret);\n\t    krb5_free_error_message(r->context, msg);\n\t    goto out;\n\t}\n    }\n\n    /*\n     *\n     */\n\n    ret = _kdc_encode_reply(context, config,\n\t\t\t    r->armor_crypto, req->req_body.nonce,\n\t\t\t    &rep, &r->et, &r->ek, setype, r->server->entry.kvno,\n\t\t\t    &skey->key, r->client->entry.kvno,\n\t\t\t    &r->reply_key, 0, &r->e_text, reply);\n    if (ret)\n\tgoto out;\n\n    /*\n     * Check if message too large\n     */\n    if (datagram_reply && reply->length > config->max_datagram_reply_length) {\n\tkrb5_data_free(reply);\n\tret = KRB5KRB_ERR_RESPONSE_TOO_BIG;\n\t_kdc_set_e_text(r, \"Reply packet too large\");\n    }\n\nout:\n    free_AS_REP(&rep);\n\n    /*\n     * In case of a non proxy error, build an error message.\n     */\n    if (ret != 0 && ret != HDB_ERR_NOT_FOUND_HERE && reply->length == 0) {\n\tret = _kdc_fast_mk_error(context, r,\n\t\t\t\t &error_method,\n\t\t\t\t r->armor_crypto,\n\t\t\t\t &req->req_body,\n\t\t\t\t ret, r->e_text,\n\t\t\t\t r->server_princ,\n\t\t\t\t r->client_princ ?\n                                     &r->client_princ->name : NULL,\n\t\t\t\t r->client_princ ?\n                                     &r->client_princ->realm : NULL,\n\t\t\t\t NULL, NULL,\n\t\t\t\t reply);\n\tif (ret)\n\t    goto out2;\n    }\nout2:\n    free_EncTicketPart(&r->et);\n    free_EncKDCRepPart(&r->ek);\n    free_KDCFastState(&r->fast);\n\n    if (error_method.len)\n\tfree_METHOD_DATA(&error_method);\n    if (r->outpadata.len)\n\tfree_METHOD_DATA(&r->outpadata);\n    if (r->client_princ) {\n\tkrb5_free_principal(context, r->client_princ);\n\tr->client_princ = NULL;\n    }\n    if (r->client_name) {\n\tfree(r->client_name);\n\tr->client_name = NULL;\n    }\n    if (r->server_princ){\n\tkrb5_free_principal(context, r->server_princ);\n\tr->server_princ = NULL;\n    }\n    if (r->server_name) {\n\tfree(r->server_name);\n\tr->server_name = NULL;\n    }\n    if (r->client)\n\t_kdc_free_ent(context, r->client);\n    if (r->server)\n\t_kdc_free_ent(context, r->server);\n    if (r->armor_crypto) {\n\tkrb5_crypto_destroy(r->context, r->armor_crypto);\n\tr->armor_crypto = NULL;\n    }\n    krb5_free_keyblock_contents(r->context, &r->reply_key);\n    krb5_free_keyblock_contents(r->context, &r->session_key);\n    return ret;\n}", "commit_link": "github.com/heimdal/heimdal/commit/1a6a6e462dc2ac6111f9e02c6852ddec4849b887", "file_name": "kdc/kerberos5.c", "vul_type": "cwe-476", "description": "Write a function in C that processes an AS-REQ (Authentication Service Request) for Kerberos 5."}
{"func_name": "upnp_redirect", "func_src_before": "upnp_redirect(const char * rhost, unsigned short eport,\n              const char * iaddr, unsigned short iport,\n              const char * protocol, const char * desc,\n              unsigned int leaseduration)\n{\n\tint proto, r;\n\tchar iaddr_old[32];\n\tchar rhost_old[32];\n\tunsigned short iport_old;\n\tstruct in_addr address;\n\tunsigned int timestamp;\n\n\tproto = proto_atoi(protocol);\n\tif(inet_aton(iaddr, &address) <= 0) {\n\t\tsyslog(LOG_ERR, \"inet_aton(%s) FAILED\", iaddr);\n\t\treturn -1;\n\t}\n\n\tif(!check_upnp_rule_against_permissions(upnppermlist, num_upnpperm,\n\t                                        eport, address, iport)) {\n\t\tsyslog(LOG_INFO, \"redirection permission check failed for \"\n\t\t                 \"%hu->%s:%hu %s\", eport, iaddr, iport, protocol);\n\t\treturn -3;\n\t}\n\t/* IGDv1 (WANIPConnection:1 Service Template Version 1.01 / Nov 12, 2001)\n\t * - 2.2.20.PortMappingDescription :\n\t *  Overwriting Previous / Existing Port Mappings:\n\t * If the RemoteHost, ExternalPort, PortMappingProtocol and InternalClient\n\t * are exactly the same as an existing mapping, the existing mapping values\n\t * for InternalPort, PortMappingDescription, PortMappingEnabled and\n\t * PortMappingLeaseDuration are overwritten.\n\t *  Rejecting a New Port Mapping:\n\t * In cases where the RemoteHost, ExternalPort and PortMappingProtocol\n\t * are the same as an existing mapping, but the InternalClient is\n\t * different, the action is rejected with an appropriate error.\n\t *  Add or Reject New Port Mapping behavior based on vendor implementation:\n\t * In cases where the ExternalPort, PortMappingProtocol and InternalClient\n\t * are the same, but RemoteHost is different, the vendor can choose to\n\t * support both mappings simultaneously, or reject the second mapping\n\t * with an appropriate error.\n\t *\n\t * - 2.4.16.AddPortMapping\n\t * This action creates a new port mapping or overwrites an existing\n\t * mapping with the same internal client. If the ExternalPort and\n\t * PortMappingProtocol pair is already mapped to another internal client,\n\t * an error is returned.\n\t *\n\t * IGDv2 (WANIPConnection:2 Service Standardized DCP (SDCP) Sep 10, 2010)\n\t * Protocol ExternalPort RemoteHost InternalClient Result\n\t *     =         =           \u2260           \u2260         Failure\n\t *     =         =           \u2260           =         Failure or success\n\t *                                                 (vendor specific)\n\t *     =         =           =           \u2260         Failure\n\t *     =         =           =           =         Success (overwrite)\n\t */\n\trhost_old[0] = '\\0';\n\tr = get_redirect_rule(ext_if_name, eport, proto,\n\t                      iaddr_old, sizeof(iaddr_old), &iport_old, 0, 0,\n\t                      rhost_old, sizeof(rhost_old),\n\t                      &timestamp, 0, 0);\n\tif(r == 0) {\n\t\tif(strcmp(iaddr, iaddr_old)==0 &&\n\t\t   ((rhost == NULL && rhost_old[0]=='\\0') ||\n\t\t    (rhost && (strcmp(rhost, \"*\") == 0) && rhost_old[0]=='\\0') ||\n\t\t    (rhost && (strcmp(rhost, rhost_old) == 0)))) {\n\t\t\tsyslog(LOG_INFO, \"updating existing port mapping %hu %s (rhost '%s') => %s:%hu\",\n\t\t\t\teport, protocol, rhost_old, iaddr_old, iport_old);\n\t\t\ttimestamp = (leaseduration > 0) ? upnp_time() + leaseduration : 0;\n\t\t\tif(iport != iport_old) {\n\t\t\t\tr = update_portmapping(ext_if_name, eport, proto, iport, desc, timestamp);\n\t\t\t} else {\n\t\t\t\tr = update_portmapping_desc_timestamp(ext_if_name, eport, proto, desc, timestamp);\n\t\t\t}\n#ifdef ENABLE_LEASEFILE\n\t\t\tif(r == 0) {\n\t\t\t\tlease_file_remove(eport, proto);\n\t\t\t\tlease_file_add(eport, iaddr, iport, proto, desc, timestamp);\n\t\t\t}\n#endif /* ENABLE_LEASEFILE */\n\t\t\treturn r;\n\t\t} else {\n\t\t\tsyslog(LOG_INFO, \"port %hu %s (rhost '%s') already redirected to %s:%hu\",\n\t\t\t\teport, protocol, rhost_old, iaddr_old, iport_old);\n\t\t\treturn -2;\n\t\t}\n#ifdef CHECK_PORTINUSE\n\t} else if (port_in_use(ext_if_name, eport, proto, iaddr, iport) > 0) {\n\t\tsyslog(LOG_INFO, \"port %hu protocol %s already in use\",\n\t\t       eport, protocol);\n\t\treturn -4;\n#endif /* CHECK_PORTINUSE */\n\t} else {\n\t\ttimestamp = (leaseduration > 0) ? upnp_time() + leaseduration : 0;\n\t\tsyslog(LOG_INFO, \"redirecting port %hu to %s:%hu protocol %s for: %s\",\n\t\t\teport, iaddr, iport, protocol, desc);\n\t\treturn upnp_redirect_internal(rhost, eport, iaddr, iport, proto,\n\t\t                              desc, timestamp);\n\t}\n}", "func_src_after": "upnp_redirect(const char * rhost, unsigned short eport,\n              const char * iaddr, unsigned short iport,\n              const char * protocol, const char * desc,\n              unsigned int leaseduration)\n{\n\tint proto, r;\n\tchar iaddr_old[32];\n\tchar rhost_old[32];\n\tunsigned short iport_old;\n\tstruct in_addr address;\n\tunsigned int timestamp;\n\n\tproto = proto_atoi(protocol);\n\tif(inet_aton(iaddr, &address) <= 0) {\n\t\tsyslog(LOG_ERR, \"inet_aton(%s) FAILED\", iaddr);\n\t\treturn -1;\n\t}\n\n\tif(!check_upnp_rule_against_permissions(upnppermlist, num_upnpperm,\n\t                                        eport, address, iport)) {\n\t\tsyslog(LOG_INFO, \"redirection permission check failed for \"\n\t\t                 \"%hu->%s:%hu %s\", eport, iaddr, iport, protocol);\n\t\treturn -3;\n\t}\n\n\tif (desc == NULL)\n\t\tdesc = \"\";\t/* assume empty description */\n\n\t/* IGDv1 (WANIPConnection:1 Service Template Version 1.01 / Nov 12, 2001)\n\t * - 2.2.20.PortMappingDescription :\n\t *  Overwriting Previous / Existing Port Mappings:\n\t * If the RemoteHost, ExternalPort, PortMappingProtocol and InternalClient\n\t * are exactly the same as an existing mapping, the existing mapping values\n\t * for InternalPort, PortMappingDescription, PortMappingEnabled and\n\t * PortMappingLeaseDuration are overwritten.\n\t *  Rejecting a New Port Mapping:\n\t * In cases where the RemoteHost, ExternalPort and PortMappingProtocol\n\t * are the same as an existing mapping, but the InternalClient is\n\t * different, the action is rejected with an appropriate error.\n\t *  Add or Reject New Port Mapping behavior based on vendor implementation:\n\t * In cases where the ExternalPort, PortMappingProtocol and InternalClient\n\t * are the same, but RemoteHost is different, the vendor can choose to\n\t * support both mappings simultaneously, or reject the second mapping\n\t * with an appropriate error.\n\t *\n\t * - 2.4.16.AddPortMapping\n\t * This action creates a new port mapping or overwrites an existing\n\t * mapping with the same internal client. If the ExternalPort and\n\t * PortMappingProtocol pair is already mapped to another internal client,\n\t * an error is returned.\n\t *\n\t * IGDv2 (WANIPConnection:2 Service Standardized DCP (SDCP) Sep 10, 2010)\n\t * Protocol ExternalPort RemoteHost InternalClient Result\n\t *     =         =           \u2260           \u2260         Failure\n\t *     =         =           \u2260           =         Failure or success\n\t *                                                 (vendor specific)\n\t *     =         =           =           \u2260         Failure\n\t *     =         =           =           =         Success (overwrite)\n\t */\n\trhost_old[0] = '\\0';\n\tr = get_redirect_rule(ext_if_name, eport, proto,\n\t                      iaddr_old, sizeof(iaddr_old), &iport_old, 0, 0,\n\t                      rhost_old, sizeof(rhost_old),\n\t                      &timestamp, 0, 0);\n\tif(r == 0) {\n\t\tif(strcmp(iaddr, iaddr_old)==0 &&\n\t\t   ((rhost == NULL && rhost_old[0]=='\\0') ||\n\t\t    (rhost && (strcmp(rhost, \"*\") == 0) && rhost_old[0]=='\\0') ||\n\t\t    (rhost && (strcmp(rhost, rhost_old) == 0)))) {\n\t\t\tsyslog(LOG_INFO, \"updating existing port mapping %hu %s (rhost '%s') => %s:%hu\",\n\t\t\t\teport, protocol, rhost_old, iaddr_old, iport_old);\n\t\t\ttimestamp = (leaseduration > 0) ? upnp_time() + leaseduration : 0;\n\t\t\tif(iport != iport_old) {\n\t\t\t\tr = update_portmapping(ext_if_name, eport, proto, iport, desc, timestamp);\n\t\t\t} else {\n\t\t\t\tr = update_portmapping_desc_timestamp(ext_if_name, eport, proto, desc, timestamp);\n\t\t\t}\n#ifdef ENABLE_LEASEFILE\n\t\t\tif(r == 0) {\n\t\t\t\tlease_file_remove(eport, proto);\n\t\t\t\tlease_file_add(eport, iaddr, iport, proto, desc, timestamp);\n\t\t\t}\n#endif /* ENABLE_LEASEFILE */\n\t\t\treturn r;\n\t\t} else {\n\t\t\tsyslog(LOG_INFO, \"port %hu %s (rhost '%s') already redirected to %s:%hu\",\n\t\t\t\teport, protocol, rhost_old, iaddr_old, iport_old);\n\t\t\treturn -2;\n\t\t}\n#ifdef CHECK_PORTINUSE\n\t} else if (port_in_use(ext_if_name, eport, proto, iaddr, iport) > 0) {\n\t\tsyslog(LOG_INFO, \"port %hu protocol %s already in use\",\n\t\t       eport, protocol);\n\t\treturn -4;\n#endif /* CHECK_PORTINUSE */\n\t} else {\n\t\ttimestamp = (leaseduration > 0) ? upnp_time() + leaseduration : 0;\n\t\tsyslog(LOG_INFO, \"redirecting port %hu to %s:%hu protocol %s for: %s\",\n\t\t\teport, iaddr, iport, protocol, desc);\n\t\treturn upnp_redirect_internal(rhost, eport, iaddr, iport, proto,\n\t\t                              desc, timestamp);\n\t}\n}", "commit_link": "github.com/miniupnp/miniupnp/commit/f321c2066b96d18afa5158dfa2d2873a2957ef38", "file_name": "miniupnpd/upnpredirect.c", "vul_type": "cwe-476", "description": "In C, write a function `upnp_redirect` to manage port forwarding rules for UPnP, including permission checks and updating existing mappings."}
{"func_name": "get_output", "func_src_before": "def get_output(command: str) -> bytes:\n    \"\"\"\n    Run a command and return raw output\n\n    :param str command: the command to run\n    :returns: the stdout output of the command\n    \"\"\"\n    return subprocess.check_output(command.split())", "func_src_after": "def get_output(command: List[str]) -> str:\n    \"\"\"\n    Run a command and return raw output\n\n    :param str command: the command to run\n    :returns: the stdout output of the command\n    \"\"\"\n    result = subprocess.run(command, stdout=subprocess.PIPE, check=True)\n    return result.stdout.decode()", "commit_link": "github.com/timothycrosley/isort/commit/1ab38f4f7840a3c19bf961a24630a992a8373a76", "file_name": "isort/hooks.py", "vul_type": "cwe-078", "description": "Write a Python function that executes a system command and returns the output."}
{"func_name": "get_current_state", "func_src_before": "def get_current_state(chat_id):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__))+\"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = ?\", (str(chat_id),))\n    name = conn.fetchone()\n    if name != None:\n        return name[4]\n    else:\n        return False\n    settings.close()", "func_src_after": "def get_current_state(chat_id):\n    settings = sqlite3.connect(os.path.abspath(os.path.dirname(__file__))+\"\\\\bases\\\\settings.db\")\n    conn = settings.cursor()\n    conn.execute(\"select * from users where chat_id = '\" + str(chat_id) + \"'\")\n    name = conn.fetchone()\n    if name != None:\n        return name[4]\n    else:\n        return False\n    settings.close()", "commit_link": "github.com/lissrbay/codeforces_bot/commit/cc7f5143445a0030b1149ac60a65b1b1b9c92a90", "file_name": "bot.py", "vul_type": "cwe-089", "description": "Write a Python function to fetch the fifth column value from a 'users' table for a given 'chat_id' in an SQLite database, returning False if not found."}
{"func_name": "_make_fc_map", "func_src_before": "    def _make_fc_map(self, source, target, full_copy):\n        copyflag = '' if full_copy else '-copyrate 0'\n        fc_map_cli_cmd = ('svctask mkfcmap -source %(src)s -target %(tgt)s '\n                          '-autodelete %(copyflag)s' %\n                          {'src': source,\n                           'tgt': target,\n                           'copyflag': copyflag})\n        out, err = self._run_ssh(fc_map_cli_cmd)\n        self._driver_assert(\n            len(out.strip()),\n            _('create FC mapping from %(source)s to %(target)s - '\n              'did not find success message in CLI output.\\n'\n              ' stdout: %(out)s\\n stderr: %(err)s\\n')\n            % {'source': source,\n               'target': target,\n               'out': str(out),\n               'err': str(err)})\n\n        # Ensure that the output is as expected\n        match_obj = re.search('FlashCopy Mapping, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('create FC mapping from %(source)s to %(target)s - '\n              'did not find success message in CLI output.\\n'\n              ' stdout: %(out)s\\n stderr: %(err)s\\n')\n            % {'source': source,\n               'target': target,\n               'out': str(out),\n               'err': str(err)})\n\n        try:\n            fc_map_id = match_obj.group(1)\n            self._driver_assert(\n                fc_map_id is not None,\n                _('create FC mapping from %(source)s to %(target)s - '\n                  'did not find mapping id in CLI output.\\n'\n                  ' stdout: %(out)s\\n stderr: %(err)s\\n')\n                % {'source': source,\n                   'target': target,\n                   'out': str(out),\n                   'err': str(err)})\n        except IndexError:\n            self._driver_assert(\n                False,\n                _('create FC mapping from %(source)s to %(target)s - '\n                  'did not find mapping id in CLI output.\\n'\n                  ' stdout: %(out)s\\n stderr: %(err)s\\n')\n                % {'source': source,\n                   'target': target,\n                   'out': str(out),\n                   'err': str(err)})\n        return fc_map_id", "func_src_after": "    def _make_fc_map(self, source, target, full_copy):\n        fc_map_cli_cmd = ['svctask', 'mkfcmap', '-source', source, '-target',\n                          target, '-autodelete']\n        if not full_copy:\n            fc_map_cli_cmd.extend(['-copyrate', '0'])\n        out, err = self._run_ssh(fc_map_cli_cmd)\n        self._driver_assert(\n            len(out.strip()),\n            _('create FC mapping from %(source)s to %(target)s - '\n              'did not find success message in CLI output.\\n'\n              ' stdout: %(out)s\\n stderr: %(err)s\\n')\n            % {'source': source,\n               'target': target,\n               'out': str(out),\n               'err': str(err)})\n\n        # Ensure that the output is as expected\n        match_obj = re.search('FlashCopy Mapping, id \\[([0-9]+)\\], '\n                              'successfully created', out)\n        # Make sure we got a \"successfully created\" message with vdisk id\n        self._driver_assert(\n            match_obj is not None,\n            _('create FC mapping from %(source)s to %(target)s - '\n              'did not find success message in CLI output.\\n'\n              ' stdout: %(out)s\\n stderr: %(err)s\\n')\n            % {'source': source,\n               'target': target,\n               'out': str(out),\n               'err': str(err)})\n\n        try:\n            fc_map_id = match_obj.group(1)\n            self._driver_assert(\n                fc_map_id is not None,\n                _('create FC mapping from %(source)s to %(target)s - '\n                  'did not find mapping id in CLI output.\\n'\n                  ' stdout: %(out)s\\n stderr: %(err)s\\n')\n                % {'source': source,\n                   'target': target,\n                   'out': str(out),\n                   'err': str(err)})\n        except IndexError:\n            self._driver_assert(\n                False,\n                _('create FC mapping from %(source)s to %(target)s - '\n                  'did not find mapping id in CLI output.\\n'\n                  ' stdout: %(out)s\\n stderr: %(err)s\\n')\n                % {'source': source,\n                   'target': target,\n                   'out': str(out),\n                   'err': str(err)})\n        return fc_map_id", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to create a FlashCopy mapping between a source and target, with an option for a full copy."}
{"func_name": "create_dump_dir_from_problem_data", "func_src_before": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        /* only files should contain '/' and those are handled earlier */\n        if (name[0] == '.' || strchr(name, '/'))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "func_src_after": "struct dump_dir *create_dump_dir_from_problem_data(problem_data_t *problem_data, const char *base_dir_name)\n{\n    INITIALIZE_LIBREPORT();\n\n    char *type = problem_data_get_content_or_NULL(problem_data, FILENAME_ANALYZER);\n\n    if (!type)\n    {\n        error_msg(_(\"Missing required item: '%s'\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    if (!str_is_correct_filename(type))\n    {\n        error_msg(_(\"'%s' is not correct file name\"), FILENAME_ANALYZER);\n        return NULL;\n    }\n\n    uid_t uid = (uid_t)-1L;\n    char *uid_str = problem_data_get_content_or_NULL(problem_data, FILENAME_UID);\n\n    if (uid_str)\n    {\n        char *endptr;\n        errno = 0;\n        long val = strtol(uid_str, &endptr, 10);\n\n        if (errno != 0 || endptr == uid_str || *endptr != '\\0' || INT_MAX < val)\n        {\n            error_msg(_(\"uid value is not valid: '%s'\"), uid_str);\n            return NULL;\n        }\n\n        uid = (uid_t)val;\n    }\n\n    struct timeval tv;\n    if (gettimeofday(&tv, NULL) < 0)\n    {\n        perror_msg(\"gettimeofday()\");\n        return NULL;\n    }\n\n    char *problem_id = xasprintf(\"%s-%s.%ld-%lu\"NEW_PD_SUFFIX, type, iso_date_string(&(tv.tv_sec)), (long)tv.tv_usec, (long)getpid());\n\n    log_info(\"Saving to %s/%s with uid %d\", base_dir_name, problem_id, uid);\n\n    struct dump_dir *dd;\n    if (base_dir_name)\n        dd = try_dd_create(base_dir_name, problem_id, uid);\n    else\n    {\n        /* Try /var/run/abrt */\n        dd = try_dd_create(LOCALSTATEDIR\"/run/abrt\", problem_id, uid);\n        /* Try $HOME/tmp */\n        if (!dd)\n        {\n            char *home = getenv(\"HOME\");\n            if (home && home[0])\n            {\n                home = concat_path_file(home, \"tmp\");\n                /*mkdir(home, 0777); - do we want this? */\n                dd = try_dd_create(home, problem_id, uid);\n                free(home);\n            }\n        }\n//TODO: try user's home dir obtained by getpwuid(getuid())?\n        /* Try system temporary directory */\n        if (!dd)\n            dd = try_dd_create(LARGE_DATA_TMP_DIR, problem_id, uid);\n    }\n\n    if (!dd) /* try_dd_create() already emitted the error message */\n        goto ret;\n\n    GHashTableIter iter;\n    char *name;\n    struct problem_item *value;\n    g_hash_table_iter_init(&iter, problem_data);\n    while (g_hash_table_iter_next(&iter, (void**)&name, (void**)&value))\n    {\n        if (!str_is_correct_filename(name))\n        {\n            error_msg(\"Problem data field name contains disallowed chars: '%s'\", name);\n            continue;\n        }\n\n        if (value->flags & CD_FLAG_BIN)\n        {\n            char *dest = concat_path_file(dd->dd_dirname, name);\n            log_info(\"copying '%s' to '%s'\", value->content, dest);\n            off_t copied = copy_file(value->content, dest, DEFAULT_DUMP_DIR_MODE | S_IROTH);\n            if (copied < 0)\n                error_msg(\"Can't copy %s to %s\", value->content, dest);\n            else\n                log_info(\"copied %li bytes\", (unsigned long)copied);\n            free(dest);\n\n            continue;\n        }\n\n        dd_save_text(dd, name, value->content);\n    }\n\n    /* need to create basic files AFTER we save the pd to dump_dir\n     * otherwise we can't skip already created files like in case when\n     * reporting from anaconda where we can't read /etc/{system,redhat}-release\n     * and os_release is taken from anaconda\n     */\n    dd_create_basic_files(dd, uid, NULL);\n\n    problem_id[strlen(problem_id) - strlen(NEW_PD_SUFFIX)] = '\\0';\n    char* new_path = concat_path_file(base_dir_name, problem_id);\n    log_info(\"Renaming from '%s' to '%s'\", dd->dd_dirname, new_path);\n    dd_rename(dd, new_path);\n\n ret:\n    free(problem_id);\n    return dd;\n}", "commit_link": "github.com/abrt/libreport/commit/239c4f7d1f47265526b39ad70106767d00805277", "file_name": "src/lib/create_dump_dir.c", "vul_type": "cwe-022", "description": "Write a C function to initialize a dump directory with problem data, handling errors and creating necessary files."}
{"func_name": "verify", "func_src_before": "    def verify(self, data):\n        credentials = self._formatCredentials(data, name='current')\n        command = '{} rclone lsjson current:'.format(credentials)\n\n        try:\n            result = self._execute(command)\n            return {\n                'result': True,\n                'message': 'Success',\n            }\n        except subprocess.CalledProcessError as e:\n            returncode = e.returncode\n            return {\n                'result': False,\n                'message': 'Exit status {}'.format(returncode),\n            }", "func_src_after": "    def verify(self, data):\n        credentials = self._formatCredentials(data, name='current')\n        command = [\n            'rclone',\n            'lsjson',\n            'current:',\n        ]\n\n        try:\n            result = self._execute(command, credentials)\n            return {\n                'result': True,\n                'message': 'Success',\n            }\n        except subprocess.CalledProcessError as e:\n            returncode = e.returncode\n            return {\n                'result': False,\n                'message': 'Exit status {}'.format(returncode),\n            }", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function named `verify` that formats credentials, executes an `rclone lsjson` command, and returns a success or error message."}
{"func_name": "Cipher::blowfishECB", "func_src_before": "QByteArray Cipher::blowfishECB(QByteArray cipherText, bool direction)\n{\n    QCA::Initializer init;\n    QByteArray temp = cipherText;\n\n    //do padding ourselves\n    if (direction)\n    {\n        while ((temp.length() % 8) != 0) temp.append('\\0');\n    }\n    else\n    {\n        temp = b64ToByte(temp);\n        while ((temp.length() % 8) != 0) temp.append('\\0');\n    }\n\n    QCA::Direction dir = (direction) ? QCA::Encode : QCA::Decode;\n    QCA::Cipher cipher(m_type, QCA::Cipher::ECB, QCA::Cipher::NoPadding, dir, m_key);\n    QByteArray temp2 = cipher.update(QCA::MemoryRegion(temp)).toByteArray();\n    temp2 += cipher.final().toByteArray();\n\n    if (!cipher.ok())\n        return cipherText;\n\n    if (direction)\n        temp2 = byteToB64(temp2);\n\n    return temp2;\n}", "func_src_after": "QByteArray Cipher::blowfishECB(QByteArray cipherText, bool direction)\n{\n    QCA::Initializer init;\n    QByteArray temp = cipherText;\n\n    //do padding ourselves\n    if (direction)\n    {\n        while ((temp.length() % 8) != 0) temp.append('\\0');\n    }\n    else\n    {\n        // ECB Blowfish encodes in blocks of 12 chars, so anything else is malformed input\n        if ((temp.length() % 12) != 0)\n            return cipherText;\n\n        temp = b64ToByte(temp);\n        while ((temp.length() % 8) != 0) temp.append('\\0');\n    }\n\n    QCA::Direction dir = (direction) ? QCA::Encode : QCA::Decode;\n    QCA::Cipher cipher(m_type, QCA::Cipher::ECB, QCA::Cipher::NoPadding, dir, m_key);\n    QByteArray temp2 = cipher.update(QCA::MemoryRegion(temp)).toByteArray();\n    temp2 += cipher.final().toByteArray();\n\n    if (!cipher.ok())\n        return cipherText;\n\n    if (direction) {\n        // Sanity check\n        if ((temp2.length() % 8) != 0)\n            return cipherText;\n\n        temp2 = byteToB64(temp2);\n    }\n\n    return temp2;\n}", "commit_link": "github.com/quassel/quassel/commit/8b5ecd226f9208af3074b33d3b7cf5e14f55b138", "file_name": "src/core/cipher.cpp", "vul_type": "cwe-125", "description": "Write a C++ function named `blowfishECB` that performs Blowfish encryption or decryption in ECB mode on a `QByteArray` with manual padding."}
{"func_name": "delete_playlist", "func_src_before": "def delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id=%s;\", (id,))", "func_src_after": "def delete_playlist(id, db):\n    db.execute(\"DELETE FROM playlist where id={id};\".format(id=id))", "commit_link": "github.com/Madmous/playlist/commit/666e52c5f0b8c1f4296e84471637033d9542a7a6", "file_name": "playlist/playlist_repository.py", "vul_type": "cwe-089", "description": "Write a Python function named `delete_playlist` that removes a playlist by its ID from a database."}
{"func_name": "_map_vol_to_host", "func_src_before": "    def _map_vol_to_host(self, volume_name, host_name):\n        \"\"\"Create a mapping between a volume to a host.\"\"\"\n\n        LOG.debug(_('enter: _map_vol_to_host: volume %(volume_name)s to '\n                    'host %(host_name)s')\n                  % {'volume_name': volume_name, 'host_name': host_name})\n\n        # Check if this volume is already mapped to this host\n        mapping_data = self._get_hostvdisk_mappings(host_name)\n\n        mapped_flag = False\n        result_lun = '-1'\n        if volume_name in mapping_data:\n            mapped_flag = True\n            result_lun = mapping_data[volume_name]['SCSI_id']\n        else:\n            lun_used = [int(v['SCSI_id']) for v in mapping_data.values()]\n            lun_used.sort()\n            # Assume all luns are taken to this point, and then try to find\n            # an unused one\n            result_lun = str(len(lun_used))\n            for index, n in enumerate(lun_used):\n                if n > index:\n                    result_lun = str(index)\n                    break\n\n        # Volume is not mapped to host, create a new LUN\n        if not mapped_flag:\n            ssh_cmd = ['svctask', 'mkvdiskhostmap', '-host', host_name,\n                       '-scsi', result_lun, volume_name]\n            out, err = self._run_ssh(ssh_cmd, check_exit_code=False)\n            if err and err.startswith('CMMVC6071E'):\n                if not self.configuration.storwize_svc_multihostmap_enabled:\n                    LOG.error(_('storwize_svc_multihostmap_enabled is set '\n                                'to False, Not allow multi host mapping'))\n                    exception_msg = 'CMMVC6071E The VDisk-to-host mapping '\\\n                                    'was not created because the VDisk is '\\\n                                    'already mapped to a host.\\n\"'\n                    raise exception.CinderException(data=exception_msg)\n\n                for i in range(len(ssh_cmd)):\n                    if ssh_cmd[i] == 'mkvdiskhostmap':\n                        ssh_cmd.insert(i + 1, '-force')\n\n                # try to map one volume to multiple hosts\n                out, err = self._run_ssh(ssh_cmd)\n                LOG.warn(_('volume %s mapping to multi host') % volume_name)\n                self._assert_ssh_return('successfully created' in out,\n                                        '_map_vol_to_host', ssh_cmd, out, err)\n            else:\n                self._assert_ssh_return('successfully created' in out,\n                                        '_map_vol_to_host', ssh_cmd, out, err)\n        LOG.debug(_('leave: _map_vol_to_host: LUN %(result_lun)s, volume '\n                    '%(volume_name)s, host %(host_name)s') %\n                  {'result_lun': result_lun,\n                   'volume_name': volume_name,\n                   'host_name': host_name})\n        return result_lun", "func_src_after": "    def _map_vol_to_host(self, volume_name, host_name):\n        \"\"\"Create a mapping between a volume to a host.\"\"\"\n\n        LOG.debug(_('enter: _map_vol_to_host: volume %(volume_name)s to '\n                    'host %(host_name)s')\n                  % {'volume_name': volume_name, 'host_name': host_name})\n\n        # Check if this volume is already mapped to this host\n        mapping_data = self._get_hostvdisk_mappings(host_name)\n\n        mapped_flag = False\n        result_lun = '-1'\n        if volume_name in mapping_data:\n            mapped_flag = True\n            result_lun = mapping_data[volume_name]['SCSI_id']\n        else:\n            lun_used = [int(v['SCSI_id']) for v in mapping_data.values()]\n            lun_used.sort()\n            # Assume all luns are taken to this point, and then try to find\n            # an unused one\n            result_lun = str(len(lun_used))\n            for index, n in enumerate(lun_used):\n                if n > index:\n                    result_lun = str(index)\n                    break\n\n        # Volume is not mapped to host, create a new LUN\n        if not mapped_flag:\n            ssh_cmd = ('svctask mkvdiskhostmap -host %(host_name)s -scsi '\n                       '%(result_lun)s %(volume_name)s' %\n                       {'host_name': host_name,\n                        'result_lun': result_lun,\n                        'volume_name': volume_name})\n            out, err = self._run_ssh(ssh_cmd, check_exit_code=False)\n            if err and err.startswith('CMMVC6071E'):\n                if not self.configuration.storwize_svc_multihostmap_enabled:\n                    LOG.error(_('storwize_svc_multihostmap_enabled is set '\n                                'to False, Not allow multi host mapping'))\n                    exception_msg = 'CMMVC6071E The VDisk-to-host mapping '\\\n                                    'was not created because the VDisk is '\\\n                                    'already mapped to a host.\\n\"'\n                    raise exception.CinderException(data=exception_msg)\n                ssh_cmd = ssh_cmd.replace('mkvdiskhostmap',\n                                          'mkvdiskhostmap -force')\n                # try to map one volume to multiple hosts\n                out, err = self._run_ssh(ssh_cmd)\n                LOG.warn(_('volume %s mapping to multi host') % volume_name)\n                self._assert_ssh_return('successfully created' in out,\n                                        '_map_vol_to_host', ssh_cmd, out, err)\n            else:\n                self._assert_ssh_return('successfully created' in out,\n                                        '_map_vol_to_host', ssh_cmd, out, err)\n        LOG.debug(_('leave: _map_vol_to_host: LUN %(result_lun)s, volume '\n                    '%(volume_name)s, host %(host_name)s') %\n                  {'result_lun': result_lun,\n                   'volume_name': volume_name,\n                   'host_name': host_name})\n        return result_lun", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to map a storage volume to a host, handling existing mappings and LUN allocation."}
{"func_name": "enl_ipc_get", "func_src_before": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic unsigned short len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "func_src_after": "char *enl_ipc_get(const char *msg_data)\n{\n\n\tstatic char *message = NULL;\n\tstatic size_t len = 0;\n\tchar buff[13], *ret_msg = NULL;\n\tregister unsigned char i;\n\tunsigned char blen;\n\n\tif (msg_data == IPC_TIMEOUT) {\n\t\treturn(IPC_TIMEOUT);\n\t}\n\tfor (i = 0; i < 12; i++) {\n\t\tbuff[i] = msg_data[i];\n\t}\n\tbuff[12] = 0;\n\tblen = strlen(buff);\n\tif (message != NULL) {\n\t\tlen += blen;\n\t\tmessage = (char *) erealloc(message, len + 1);\n\t\tstrcat(message, buff);\n\t} else {\n\t\tlen = blen;\n\t\tmessage = (char *) emalloc(len + 1);\n\t\tstrcpy(message, buff);\n\t}\n\tif (blen < 12) {\n\t\tret_msg = message;\n\t\tmessage = NULL;\n\t\tD((\"Received complete reply:  \\\"%s\\\"\\n\", ret_msg));\n\t}\n\treturn(ret_msg);\n}", "commit_link": "github.com/derf/feh/commit/f7a547b7ef8fc8ebdeaa4c28515c9d72e592fb6d", "file_name": "src/wallpaper.c", "vul_type": "cwe-787", "description": "Write a C function named `enl_ipc_get` that appends chunks of data to a static buffer until a complete message is received or a timeout occurs."}
{"func_name": "_remove_volume_set", "func_src_before": "    def _remove_volume_set(self, vvs_name):\n        # Must first clear the QoS rules before removing the volume set\n        self._cli_run(['setqos', '-clear', 'vvset:%s' % (vvs_name)])\n        self._cli_run(['removevvset', '-f', vvs_name])", "func_src_after": "    def _remove_volume_set(self, vvs_name):\n        # Must first clear the QoS rules before removing the volume set\n        self._cli_run('setqos -clear vvset:%s' % (vvs_name), None)\n        self._cli_run('removevvset -f %s' % (vvs_name), None)", "commit_link": "github.com/thatsdone/cinder/commit/c55589b131828f3a595903f6796cb2d0babb772f", "file_name": "cinder/volume/drivers/san/hp/hp_3par_common.py", "vul_type": "cwe-078", "description": "Write a Python function to clear QoS rules and remove a volume set using CLI commands."}
{"func_name": "hid_input_field", "func_src_before": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}", "func_src_after": "static void hid_input_field(struct hid_device *hid, struct hid_field *field,\n\t\t\t    __u8 *data, int interrupt)\n{\n\tunsigned n;\n\tunsigned count = field->report_count;\n\tunsigned offset = field->report_offset;\n\tunsigned size = field->report_size;\n\t__s32 min = field->logical_minimum;\n\t__s32 max = field->logical_maximum;\n\t__s32 *value;\n\n\tvalue = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);\n\tif (!value)\n\t\treturn;\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tvalue[n] = min < 0 ?\n\t\t\tsnto32(hid_field_extract(hid, data, offset + n * size,\n\t\t\t       size), size) :\n\t\t\thid_field_extract(hid, data, offset + n * size, size);\n\n\t\t/* Ignore report if ErrorRollOver */\n\t\tif (!(field->flags & HID_MAIN_ITEM_VARIABLE) &&\n\t\t    value[n] >= min && value[n] <= max &&\n\t\t    value[n] - min < field->maxusage &&\n\t\t    field->usage[value[n] - min].hid == HID_UP_KEYBOARD + 1)\n\t\t\tgoto exit;\n\t}\n\n\tfor (n = 0; n < count; n++) {\n\n\t\tif (HID_MAIN_ITEM_VARIABLE & field->flags) {\n\t\t\thid_process_event(hid, field, &field->usage[n], value[n], interrupt);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (field->value[n] >= min && field->value[n] <= max\n\t\t\t&& field->value[n] - min < field->maxusage\n\t\t\t&& field->usage[field->value[n] - min].hid\n\t\t\t&& search(value, field->value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[field->value[n] - min], 0, interrupt);\n\n\t\tif (value[n] >= min && value[n] <= max\n\t\t\t&& value[n] - min < field->maxusage\n\t\t\t&& field->usage[value[n] - min].hid\n\t\t\t&& search(field->value, value[n], count))\n\t\t\t\thid_process_event(hid, field, &field->usage[value[n] - min], 1, interrupt);\n\t}\n\n\tmemcpy(field->value, value, count * sizeof(__s32));\nexit:\n\tkfree(value);\n}", "commit_link": "github.com/torvalds/linux/commit/50220dead1650609206efe91f0cc116132d59b3f", "file_name": "drivers/hid/hid-core.c", "vul_type": "cwe-125", "description": "Write a C function to process HID input fields and handle keyboard events."}
{"func_name": "getGameID", "func_src_before": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = ?\", ID)\n\tID = db.fetchone()\n\treturn ID", "func_src_after": "def getGameID(ID):\n\tdb.execute(\"SELECT * FROM games WHERE ID = %i\" % ID)\n\tID = db.fetchone()\n\treturn ID", "commit_link": "github.com/iScrE4m/XLeague/commit/59cab6e5fd8bd5e47f2418a7c71cb1d4e3cad0d2", "file_name": "plugins/database.py", "vul_type": "cwe-089", "description": "Write a Python function named `getGameID` that retrieves a game's record from a database by its ID using parameterized queries."}
{"func_name": "read_SubStreamsInfo", "func_src_before": "read_SubStreamsInfo(struct archive_read *a, struct _7z_substream_info *ss,\n    struct _7z_folder *f, size_t numFolders)\n{\n\tconst unsigned char *p;\n\tuint64_t *usizes;\n\tsize_t unpack_streams;\n\tint type;\n\tunsigned i;\n\tuint32_t numDigests;\n\n\tmemset(ss, 0, sizeof(*ss));\n\n\tfor (i = 0; i < numFolders; i++)\n\t\tf[i].numUnpackStreams = 1;\n\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\ttype = *p;\n\n\tif (type == kNumUnPackStream) {\n\t\tunpack_streams = 0;\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (parse_7zip_uint64(a, &(f[i].numUnpackStreams)) < 0)\n\t\t\t\treturn (-1);\n\t\t\tif (UMAX_ENTRY < f[i].numUnpackStreams)\n\t\t\t\treturn (-1);\n\t\t\tunpack_streams += (size_t)f[i].numUnpackStreams;\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t} else\n\t\tunpack_streams = numFolders;\n\n\tss->unpack_streams = unpack_streams;\n\tif (unpack_streams) {\n\t\tss->unpackSizes = calloc(unpack_streams,\n\t\t    sizeof(*ss->unpackSizes));\n\t\tss->digestsDefined = calloc(unpack_streams,\n\t\t    sizeof(*ss->digestsDefined));\n\t\tss->digests = calloc(unpack_streams,\n\t\t    sizeof(*ss->digests));\n\t\tif (ss->unpackSizes == NULL || ss->digestsDefined == NULL ||\n\t\t    ss->digests == NULL)\n\t\t\treturn (-1);\n\t}\n\n\tusizes = ss->unpackSizes;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tunsigned pack;\n\t\tuint64_t sum;\n\n\t\tif (f[i].numUnpackStreams == 0)\n\t\t\tcontinue;\n\n\t\tsum = 0;\n\t\tif (type == kSize) {\n\t\t\tfor (pack = 1; pack < f[i].numUnpackStreams; pack++) {\n\t\t\t\tif (parse_7zip_uint64(a, usizes) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t\tsum += *usizes++;\n\t\t\t}\n\t\t}\n\t\t*usizes++ = folder_uncompressed_size(&f[i]) - sum;\n\t}\n\n\tif (type == kSize) {\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\tfor (i = 0; i < unpack_streams; i++) {\n\t\tss->digestsDefined[i] = 0;\n\t\tss->digests[i] = 0;\n\t}\n\n\tnumDigests = 0;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tif (f[i].numUnpackStreams != 1 || !f[i].digest_defined)\n\t\t\tnumDigests += (uint32_t)f[i].numUnpackStreams;\n\t}\n\n\tif (type == kCRC) {\n\t\tstruct _7z_digests tmpDigests;\n\t\tunsigned char *digestsDefined = ss->digestsDefined;\n\t\tuint32_t * digests = ss->digests;\n\t\tint di = 0;\n\n\t\tmemset(&tmpDigests, 0, sizeof(tmpDigests));\n\t\tif (read_Digests(a, &(tmpDigests), numDigests) < 0) {\n\t\t\tfree_Digest(&tmpDigests);\n\t\t\treturn (-1);\n\t\t}\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (f[i].numUnpackStreams == 1 && f[i].digest_defined) {\n\t\t\t\t*digestsDefined++ = 1;\n\t\t\t\t*digests++ = f[i].digest;\n\t\t\t} else {\n\t\t\t\tunsigned j;\n\n\t\t\t\tfor (j = 0; j < f[i].numUnpackStreams;\n\t\t\t\t    j++, di++) {\n\t\t\t\t\t*digestsDefined++ =\n\t\t\t\t\t    tmpDigests.defineds[di];\n\t\t\t\t\t*digests++ =\n\t\t\t\t\t    tmpDigests.digests[di];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfree_Digest(&tmpDigests);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\t/*\n\t *  Must be kEnd.\n\t */\n\tif (type != kEnd)\n\t\treturn (-1);\n\treturn (0);\n}", "func_src_after": "read_SubStreamsInfo(struct archive_read *a, struct _7z_substream_info *ss,\n    struct _7z_folder *f, size_t numFolders)\n{\n\tconst unsigned char *p;\n\tuint64_t *usizes;\n\tsize_t unpack_streams;\n\tint type;\n\tunsigned i;\n\tuint32_t numDigests;\n\n\tmemset(ss, 0, sizeof(*ss));\n\n\tfor (i = 0; i < numFolders; i++)\n\t\tf[i].numUnpackStreams = 1;\n\n\tif ((p = header_bytes(a, 1)) == NULL)\n\t\treturn (-1);\n\ttype = *p;\n\n\tif (type == kNumUnPackStream) {\n\t\tunpack_streams = 0;\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (parse_7zip_uint64(a, &(f[i].numUnpackStreams)) < 0)\n\t\t\t\treturn (-1);\n\t\t\tif (UMAX_ENTRY < f[i].numUnpackStreams)\n\t\t\t\treturn (-1);\n\t\t\tif (unpack_streams > SIZE_MAX - UMAX_ENTRY) {\n\t\t\t\treturn (-1);\n\t\t\t}\n\t\t\tunpack_streams += (size_t)f[i].numUnpackStreams;\n\t\t}\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t} else\n\t\tunpack_streams = numFolders;\n\n\tss->unpack_streams = unpack_streams;\n\tif (unpack_streams) {\n\t\tss->unpackSizes = calloc(unpack_streams,\n\t\t    sizeof(*ss->unpackSizes));\n\t\tss->digestsDefined = calloc(unpack_streams,\n\t\t    sizeof(*ss->digestsDefined));\n\t\tss->digests = calloc(unpack_streams,\n\t\t    sizeof(*ss->digests));\n\t\tif (ss->unpackSizes == NULL || ss->digestsDefined == NULL ||\n\t\t    ss->digests == NULL)\n\t\t\treturn (-1);\n\t}\n\n\tusizes = ss->unpackSizes;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tunsigned pack;\n\t\tuint64_t sum;\n\n\t\tif (f[i].numUnpackStreams == 0)\n\t\t\tcontinue;\n\n\t\tsum = 0;\n\t\tif (type == kSize) {\n\t\t\tfor (pack = 1; pack < f[i].numUnpackStreams; pack++) {\n\t\t\t\tif (parse_7zip_uint64(a, usizes) < 0)\n\t\t\t\t\treturn (-1);\n\t\t\t\tsum += *usizes++;\n\t\t\t}\n\t\t}\n\t\t*usizes++ = folder_uncompressed_size(&f[i]) - sum;\n\t}\n\n\tif (type == kSize) {\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\tfor (i = 0; i < unpack_streams; i++) {\n\t\tss->digestsDefined[i] = 0;\n\t\tss->digests[i] = 0;\n\t}\n\n\tnumDigests = 0;\n\tfor (i = 0; i < numFolders; i++) {\n\t\tif (f[i].numUnpackStreams != 1 || !f[i].digest_defined)\n\t\t\tnumDigests += (uint32_t)f[i].numUnpackStreams;\n\t}\n\n\tif (type == kCRC) {\n\t\tstruct _7z_digests tmpDigests;\n\t\tunsigned char *digestsDefined = ss->digestsDefined;\n\t\tuint32_t * digests = ss->digests;\n\t\tint di = 0;\n\n\t\tmemset(&tmpDigests, 0, sizeof(tmpDigests));\n\t\tif (read_Digests(a, &(tmpDigests), numDigests) < 0) {\n\t\t\tfree_Digest(&tmpDigests);\n\t\t\treturn (-1);\n\t\t}\n\t\tfor (i = 0; i < numFolders; i++) {\n\t\t\tif (f[i].numUnpackStreams == 1 && f[i].digest_defined) {\n\t\t\t\t*digestsDefined++ = 1;\n\t\t\t\t*digests++ = f[i].digest;\n\t\t\t} else {\n\t\t\t\tunsigned j;\n\n\t\t\t\tfor (j = 0; j < f[i].numUnpackStreams;\n\t\t\t\t    j++, di++) {\n\t\t\t\t\t*digestsDefined++ =\n\t\t\t\t\t    tmpDigests.defineds[di];\n\t\t\t\t\t*digests++ =\n\t\t\t\t\t    tmpDigests.digests[di];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfree_Digest(&tmpDigests);\n\t\tif ((p = header_bytes(a, 1)) == NULL)\n\t\t\treturn (-1);\n\t\ttype = *p;\n\t}\n\n\t/*\n\t *  Must be kEnd.\n\t */\n\tif (type != kEnd)\n\t\treturn (-1);\n\treturn (0);\n}", "commit_link": "github.com/libarchive/libarchive/commit/e79ef306afe332faf22e9b442a2c6b59cb175573", "file_name": "libarchive/archive_read_support_format_7zip.c", "vul_type": "cwe-190", "description": "In C, write a function to read substream information for folders within a 7z archive."}
{"func_name": "gravatar", "func_src_before": "@register.tag\n@basictag(takes_context=True)\ndef gravatar(context, user, size=None):\n    \"\"\"\n    Outputs the HTML for displaying a user's gravatar.\n\n    This can take an optional size of the image (defaults to 80 if not\n    specified).\n\n    This is also influenced by the following settings:\n\n        GRAVATAR_SIZE    - Default size for gravatars\n        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)\n        GRAVATAR_DEFAULT - Default image set to show if the user hasn't\n                           specified a gravatar (identicon, monsterid, wavatar)\n\n    See http://www.gravatar.com/ for more information.\n    \"\"\"\n    url = get_gravatar_url(context['request'], user, size)\n\n    if url:\n        return format_html(\n            '<img src=\"{0}\" width=\"{1}\" height=\"{1}\" alt=\"{2}\" '\n            'class=\"gravatar\"/>',\n            url, size, user.get_full_name() or user.username)\n    else:\n        return ''", "func_src_after": "@register.tag\n@basictag(takes_context=True)\ndef gravatar(context, user, size=None):\n    \"\"\"\n    Outputs the HTML for displaying a user's gravatar.\n\n    This can take an optional size of the image (defaults to 80 if not\n    specified).\n\n    This is also influenced by the following settings:\n\n        GRAVATAR_SIZE    - Default size for gravatars\n        GRAVATAR_RATING  - Maximum allowed rating (g, pg, r, x)\n        GRAVATAR_DEFAULT - Default image set to show if the user hasn't\n                           specified a gravatar (identicon, monsterid, wavatar)\n\n    See http://www.gravatar.com/ for more information.\n    \"\"\"\n    url = get_gravatar_url(context['request'], user, size)\n\n    if url:\n        return ('<img src=\"%s\" width=\"%s\" height=\"%s\" alt=\"%s\" '\n                '     class=\"gravatar\"/>' %\n                (url, size, size, user.get_full_name() or user.username))\n    else:\n        return ''", "commit_link": "github.com/djblets/djblets/commit/77ac64642ad530bf69e390c51fc6fdcb8914c8e7", "file_name": "djblets/gravatars/templatetags/gravatars.py", "vul_type": "cwe-079", "description": "Create a Django template tag in Python that generates an HTML image tag for a user's Gravatar with an optional size parameter."}
{"func_name": "do_mq_notify", "func_src_before": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1)\n\t\t\t\tgoto retry;\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "func_src_after": "static int do_mq_notify(mqd_t mqdes, const struct sigevent *notification)\n{\n\tint ret;\n\tstruct fd f;\n\tstruct sock *sock;\n\tstruct inode *inode;\n\tstruct mqueue_inode_info *info;\n\tstruct sk_buff *nc;\n\n\taudit_mq_notify(mqdes, notification);\n\n\tnc = NULL;\n\tsock = NULL;\n\tif (notification != NULL) {\n\t\tif (unlikely(notification->sigev_notify != SIGEV_NONE &&\n\t\t\t     notification->sigev_notify != SIGEV_SIGNAL &&\n\t\t\t     notification->sigev_notify != SIGEV_THREAD))\n\t\t\treturn -EINVAL;\n\t\tif (notification->sigev_notify == SIGEV_SIGNAL &&\n\t\t\t!valid_signal(notification->sigev_signo)) {\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (notification->sigev_notify == SIGEV_THREAD) {\n\t\t\tlong timeo;\n\n\t\t\t/* create the notify skb */\n\t\t\tnc = alloc_skb(NOTIFY_COOKIE_LEN, GFP_KERNEL);\n\t\t\tif (!nc) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tif (copy_from_user(nc->data,\n\t\t\t\t\tnotification->sigev_value.sival_ptr,\n\t\t\t\t\tNOTIFY_COOKIE_LEN)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/* TODO: add a header? */\n\t\t\tskb_put(nc, NOTIFY_COOKIE_LEN);\n\t\t\t/* and attach it to the socket */\nretry:\n\t\t\tf = fdget(notification->sigev_signo);\n\t\t\tif (!f.file) {\n\t\t\t\tret = -EBADF;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t\tsock = netlink_getsockbyfilp(f.file);\n\t\t\tfdput(f);\n\t\t\tif (IS_ERR(sock)) {\n\t\t\t\tret = PTR_ERR(sock);\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\ttimeo = MAX_SCHEDULE_TIMEOUT;\n\t\t\tret = netlink_attachskb(sock, nc, &timeo, NULL);\n\t\t\tif (ret == 1) {\n\t\t\t\tsock = NULL;\n\t\t\t\tgoto retry;\n\t\t\t}\n\t\t\tif (ret) {\n\t\t\t\tsock = NULL;\n\t\t\t\tnc = NULL;\n\t\t\t\tgoto out;\n\t\t\t}\n\t\t}\n\t}\n\n\tf = fdget(mqdes);\n\tif (!f.file) {\n\t\tret = -EBADF;\n\t\tgoto out;\n\t}\n\n\tinode = file_inode(f.file);\n\tif (unlikely(f.file->f_op != &mqueue_file_operations)) {\n\t\tret = -EBADF;\n\t\tgoto out_fput;\n\t}\n\tinfo = MQUEUE_I(inode);\n\n\tret = 0;\n\tspin_lock(&info->lock);\n\tif (notification == NULL) {\n\t\tif (info->notify_owner == task_tgid(current)) {\n\t\t\tremove_notification(info);\n\t\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t\t}\n\t} else if (info->notify_owner != NULL) {\n\t\tret = -EBUSY;\n\t} else {\n\t\tswitch (notification->sigev_notify) {\n\t\tcase SIGEV_NONE:\n\t\t\tinfo->notify.sigev_notify = SIGEV_NONE;\n\t\t\tbreak;\n\t\tcase SIGEV_THREAD:\n\t\t\tinfo->notify_sock = sock;\n\t\t\tinfo->notify_cookie = nc;\n\t\t\tsock = NULL;\n\t\t\tnc = NULL;\n\t\t\tinfo->notify.sigev_notify = SIGEV_THREAD;\n\t\t\tbreak;\n\t\tcase SIGEV_SIGNAL:\n\t\t\tinfo->notify.sigev_signo = notification->sigev_signo;\n\t\t\tinfo->notify.sigev_value = notification->sigev_value;\n\t\t\tinfo->notify.sigev_notify = SIGEV_SIGNAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tinfo->notify_owner = get_pid(task_tgid(current));\n\t\tinfo->notify_user_ns = get_user_ns(current_user_ns());\n\t\tinode->i_atime = inode->i_ctime = current_time(inode);\n\t}\n\tspin_unlock(&info->lock);\nout_fput:\n\tfdput(f);\nout:\n\tif (sock)\n\t\tnetlink_detachskb(sock, nc);\n\telse if (nc)\n\t\tdev_kfree_skb(nc);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/f991af3daabaecff34684fd51fac80319d1baad1", "file_name": "ipc/mqueue.c", "vul_type": "cwe-416", "description": "Write a C function named `do_mq_notify` that sets up message queue notifications."}
{"func_name": "mem_check_range", "func_src_before": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\treturn ((iova < mem->iova) ||\n\t\t\t((iova + length) > (mem->iova + mem->length))) ?\n\t\t\t-EFAULT : 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "func_src_after": "int mem_check_range(struct rxe_mem *mem, u64 iova, size_t length)\n{\n\tswitch (mem->type) {\n\tcase RXE_MEM_TYPE_DMA:\n\t\treturn 0;\n\n\tcase RXE_MEM_TYPE_MR:\n\tcase RXE_MEM_TYPE_FMR:\n\t\tif (iova < mem->iova ||\n\t\t    length > mem->length ||\n\t\t    iova > mem->iova + mem->length - length)\n\t\t\treturn -EFAULT;\n\t\treturn 0;\n\n\tdefault:\n\t\treturn -EFAULT;\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/647bf3d8a8e5777319da92af672289b2a6c4dc66", "file_name": "drivers/infiniband/sw/rxe/rxe_mr.c", "vul_type": "cwe-190", "description": "Write a C function named `mem_check_range` that checks if a memory range specified by `iova` and `length` is valid within a memory region `mem`, returning 0 for valid or `-EFAULT` for invalid."}
{"func_name": "ipxitf_ioctl", "func_src_before": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = 0;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\trc = -EFAULT;\n\t\tipxitf_put(ipxif);\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "func_src_after": "static int ipxitf_ioctl(unsigned int cmd, void __user *arg)\n{\n\tint rc = -EINVAL;\n\tstruct ifreq ifr;\n\tint val;\n\n\tswitch (cmd) {\n\tcase SIOCSIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface_definition f;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\trc = -EINVAL;\n\t\tif (sipx->sipx_family != AF_IPX)\n\t\t\tbreak;\n\t\tf.ipx_network = sipx->sipx_network;\n\t\tmemcpy(f.ipx_device, ifr.ifr_name,\n\t\t\tsizeof(f.ipx_device));\n\t\tmemcpy(f.ipx_node, sipx->sipx_node, IPX_NODE_LEN);\n\t\tf.ipx_dlink_type = sipx->sipx_type;\n\t\tf.ipx_special = sipx->sipx_special;\n\n\t\tif (sipx->sipx_action == IPX_DLTITF)\n\t\t\trc = ipxitf_delete(&f);\n\t\telse\n\t\t\trc = ipxitf_create(&f);\n\t\tbreak;\n\t}\n\tcase SIOCGIFADDR: {\n\t\tstruct sockaddr_ipx *sipx;\n\t\tstruct ipx_interface *ipxif;\n\t\tstruct net_device *dev;\n\n\t\trc = -EFAULT;\n\t\tif (copy_from_user(&ifr, arg, sizeof(ifr)))\n\t\t\tbreak;\n\t\tsipx = (struct sockaddr_ipx *)&ifr.ifr_addr;\n\t\tdev  = __dev_get_by_name(&init_net, ifr.ifr_name);\n\t\trc   = -ENODEV;\n\t\tif (!dev)\n\t\t\tbreak;\n\t\tipxif = ipxitf_find_using_phys(dev,\n\t\t\t\t\t   ipx_map_frame_type(sipx->sipx_type));\n\t\trc = -EADDRNOTAVAIL;\n\t\tif (!ipxif)\n\t\t\tbreak;\n\n\t\tsipx->sipx_family\t= AF_IPX;\n\t\tsipx->sipx_network\t= ipxif->if_netnum;\n\t\tmemcpy(sipx->sipx_node, ipxif->if_node,\n\t\t\tsizeof(sipx->sipx_node));\n\t\trc = -EFAULT;\n\t\tif (copy_to_user(arg, &ifr, sizeof(ifr)))\n\t\t\tbreak;\n\t\tipxitf_put(ipxif);\n\t\trc = 0;\n\t\tbreak;\n\t}\n\tcase SIOCAIPXITFCRT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_auto_create_interfaces = val;\n\t\tbreak;\n\tcase SIOCAIPXPRISLT:\n\t\trc = -EFAULT;\n\t\tif (get_user(val, (unsigned char __user *) arg))\n\t\t\tbreak;\n\t\trc = 0;\n\t\tipxcfg_set_auto_select(val);\n\t\tbreak;\n\t}\n\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/ee0d8d8482345ff97a75a7d747efc309f13b0d80", "file_name": "net/ipx/af_ipx.c", "vul_type": "cwe-416", "description": "Write a C function named `ipxitf_ioctl` that handles IPX network interface control commands."}
{"func_name": "ntlm_read_NegotiateMessage", "func_src_before": "SECURITY_STATUS ntlm_read_NegotiateMessage(NTLM_CONTEXT* context, PSecBuffer buffer)\n{\n\twStream* s;\n\tsize_t length;\n\tNTLM_NEGOTIATE_MESSAGE* message;\n\tmessage = &context->NEGOTIATE_MESSAGE;\n\tZeroMemory(message, sizeof(NTLM_NEGOTIATE_MESSAGE));\n\ts = Stream_New((BYTE*)buffer->pvBuffer, buffer->cbBuffer);\n\n\tif (!s)\n\t\treturn SEC_E_INTERNAL_ERROR;\n\n\tif (ntlm_read_message_header(s, (NTLM_MESSAGE_HEADER*)message) < 0)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->MessageType != MESSAGE_TYPE_NEGOTIATE)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tStream_Read_UINT32(s, message->NegotiateFlags); /* NegotiateFlags (4 bytes) */\n\n\tif (!((message->NegotiateFlags & NTLMSSP_REQUEST_TARGET) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_NTLM) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_UNICODE)))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tcontext->NegotiateFlags = message->NegotiateFlags;\n\n\t/* only set if NTLMSSP_NEGOTIATE_DOMAIN_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->DomainName)) < 0) /* DomainNameFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\t/* only set if NTLMSSP_NEGOTIATE_WORKSTATION_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->Workstation)) < 0) /* WorkstationFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t{\n\t\tif (ntlm_read_version_info(s, &(message->Version)) < 0) /* Version (8 bytes) */\n\t\t{\n\t\t\tStream_Free(s, FALSE);\n\t\t\treturn SEC_E_INVALID_TOKEN;\n\t\t}\n\t}\n\n\tlength = Stream_GetPosition(s);\n\tbuffer->cbBuffer = length;\n\n\tif (!sspi_SecBufferAlloc(&context->NegotiateMessage, length))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INTERNAL_ERROR;\n\t}\n\n\tCopyMemory(context->NegotiateMessage.pvBuffer, buffer->pvBuffer, buffer->cbBuffer);\n\tcontext->NegotiateMessage.BufferType = buffer->BufferType;\n#ifdef WITH_DEBUG_NTLM\n\tWLog_DBG(TAG, \"NEGOTIATE_MESSAGE (length = %\" PRIu32 \")\", context->NegotiateMessage.cbBuffer);\n\twinpr_HexDump(TAG, WLOG_DEBUG, context->NegotiateMessage.pvBuffer,\n\t              context->NegotiateMessage.cbBuffer);\n\tntlm_print_negotiate_flags(message->NegotiateFlags);\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t\tntlm_print_version_info(&(message->Version));\n\n#endif\n\tcontext->state = NTLM_STATE_CHALLENGE;\n\tStream_Free(s, FALSE);\n\treturn SEC_I_CONTINUE_NEEDED;\n}", "func_src_after": "SECURITY_STATUS ntlm_read_NegotiateMessage(NTLM_CONTEXT* context, PSecBuffer buffer)\n{\n\twStream* s;\n\tsize_t length;\n\tNTLM_NEGOTIATE_MESSAGE* message;\n\tmessage = &context->NEGOTIATE_MESSAGE;\n\tZeroMemory(message, sizeof(NTLM_NEGOTIATE_MESSAGE));\n\ts = Stream_New((BYTE*)buffer->pvBuffer, buffer->cbBuffer);\n\n\tif (!s)\n\t\treturn SEC_E_INTERNAL_ERROR;\n\n\tif (ntlm_read_message_header(s, (NTLM_MESSAGE_HEADER*)message) < 0)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->MessageType != MESSAGE_TYPE_NEGOTIATE)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\tStream_Read_UINT32(s, message->NegotiateFlags); /* NegotiateFlags (4 bytes) */\n\n\tif (!((message->NegotiateFlags & NTLMSSP_REQUEST_TARGET) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_NTLM) &&\n\t      (message->NegotiateFlags & NTLMSSP_NEGOTIATE_UNICODE)))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tcontext->NegotiateFlags = message->NegotiateFlags;\n\n\t/* only set if NTLMSSP_NEGOTIATE_DOMAIN_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->DomainName)) < 0) /* DomainNameFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\t/* only set if NTLMSSP_NEGOTIATE_WORKSTATION_SUPPLIED is set */\n\n\tif (ntlm_read_message_fields(s, &(message->Workstation)) < 0) /* WorkstationFields (8 bytes) */\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INVALID_TOKEN;\n\t}\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t{\n\t\tif (ntlm_read_version_info(s, &(message->Version)) < 0) /* Version (8 bytes) */\n\t\t{\n\t\t\tStream_Free(s, FALSE);\n\t\t\treturn SEC_E_INVALID_TOKEN;\n\t\t}\n\t}\n\n\tlength = Stream_GetPosition(s);\n\tbuffer->cbBuffer = length;\n\n\tif (!sspi_SecBufferAlloc(&context->NegotiateMessage, length))\n\t{\n\t\tStream_Free(s, FALSE);\n\t\treturn SEC_E_INTERNAL_ERROR;\n\t}\n\n\tCopyMemory(context->NegotiateMessage.pvBuffer, buffer->pvBuffer, buffer->cbBuffer);\n\tcontext->NegotiateMessage.BufferType = buffer->BufferType;\n#ifdef WITH_DEBUG_NTLM\n\tWLog_DBG(TAG, \"NEGOTIATE_MESSAGE (length = %\" PRIu32 \")\", context->NegotiateMessage.cbBuffer);\n\twinpr_HexDump(TAG, WLOG_DEBUG, context->NegotiateMessage.pvBuffer,\n\t              context->NegotiateMessage.cbBuffer);\n\tntlm_print_negotiate_flags(message->NegotiateFlags);\n\n\tif (message->NegotiateFlags & NTLMSSP_NEGOTIATE_VERSION)\n\t\tntlm_print_version_info(&(message->Version));\n\n#endif\n\tcontext->state = NTLM_STATE_CHALLENGE;\n\tStream_Free(s, FALSE);\n\treturn SEC_I_CONTINUE_NEEDED;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/8fa38359634a9910b91719818ab02f23c320dbae", "file_name": "winpr/libwinpr/sspi/NTLM/ntlm_message.c", "vul_type": "cwe-125", "description": "In C, write a function to parse and validate an NTLM Negotiate message from a security buffer."}
{"func_name": "process", "func_src_before": "local void process(char *path)\n{\n    int method = -1;                /* get_header() return value */\n    size_t len;                     /* length of base name (minus suffix) */\n    struct stat st;                 /* to get file type and mod time */\n    /* all compressed suffixes for decoding search, in length order */\n    static char *sufs[] = {\".z\", \"-z\", \"_z\", \".Z\", \".gz\", \"-gz\", \".zz\", \"-zz\",\n                           \".zip\", \".ZIP\", \".tgz\", NULL};\n\n    /* open input file with name in, descriptor ind -- set name and mtime */\n    if (path == NULL) {\n        strcpy(g.inf, \"<stdin>\");\n        g.ind = 0;\n        g.name = NULL;\n        g.mtime = g.headis & 2 ?\n                  (fstat(g.ind, &st) ? time(NULL) : st.st_mtime) : 0;\n        len = 0;\n    }\n    else {\n        /* set input file name (already set if recursed here) */\n        if (path != g.inf) {\n            strncpy(g.inf, path, sizeof(g.inf));\n            if (g.inf[sizeof(g.inf) - 1])\n                bail(\"name too long: \", path);\n        }\n        len = strlen(g.inf);\n\n        /* try to stat input file -- if not there and decoding, look for that\n           name with compressed suffixes */\n        if (lstat(g.inf, &st)) {\n            if (errno == ENOENT && (g.list || g.decode)) {\n                char **try = sufs;\n                do {\n                    if (*try == NULL || len + strlen(*try) >= sizeof(g.inf))\n                        break;\n                    strcpy(g.inf + len, *try++);\n                    errno = 0;\n                } while (lstat(g.inf, &st) && errno == ENOENT);\n            }\n#ifdef EOVERFLOW\n            if (errno == EOVERFLOW || errno == EFBIG)\n                bail(g.inf,\n                    \" too large -- not compiled with large file support\");\n#endif\n            if (errno) {\n                g.inf[len] = 0;\n                complain(\"%s does not exist -- skipping\", g.inf);\n                return;\n            }\n            len = strlen(g.inf);\n        }\n\n        /* only process regular files, but allow symbolic links if -f,\n           recurse into directory if -r */\n        if ((st.st_mode & S_IFMT) != S_IFREG &&\n            (st.st_mode & S_IFMT) != S_IFLNK &&\n            (st.st_mode & S_IFMT) != S_IFDIR) {\n            complain(\"%s is a special file or device -- skipping\", g.inf);\n            return;\n        }\n        if ((st.st_mode & S_IFMT) == S_IFLNK && !g.force && !g.pipeout) {\n            complain(\"%s is a symbolic link -- skipping\", g.inf);\n            return;\n        }\n        if ((st.st_mode & S_IFMT) == S_IFDIR && !g.recurse) {\n            complain(\"%s is a directory -- skipping\", g.inf);\n            return;\n        }\n\n        /* recurse into directory (assumes Unix) */\n        if ((st.st_mode & S_IFMT) == S_IFDIR) {\n            char *roll, *item, *cut, *base, *bigger;\n            size_t len, hold;\n            DIR *here;\n            struct dirent *next;\n\n            /* accumulate list of entries (need to do this, since readdir()\n               behavior not defined if directory modified between calls) */\n            here = opendir(g.inf);\n            if (here == NULL)\n                return;\n            hold = 512;\n            roll = MALLOC(hold);\n            if (roll == NULL)\n                bail(\"not enough memory\", \"\");\n            *roll = 0;\n            item = roll;\n            while ((next = readdir(here)) != NULL) {\n                if (next->d_name[0] == 0 ||\n                    (next->d_name[0] == '.' && (next->d_name[1] == 0 ||\n                     (next->d_name[1] == '.' && next->d_name[2] == 0))))\n                    continue;\n                len = strlen(next->d_name) + 1;\n                if (item + len + 1 > roll + hold) {\n                    do {                    /* make roll bigger */\n                        hold <<= 1;\n                    } while (item + len + 1 > roll + hold);\n                    bigger = REALLOC(roll, hold);\n                    if (bigger == NULL) {\n                        FREE(roll);\n                        bail(\"not enough memory\", \"\");\n                    }\n                    item = bigger + (item - roll);\n                    roll = bigger;\n                }\n                strcpy(item, next->d_name);\n                item += len;\n                *item = 0;\n            }\n            closedir(here);\n\n            /* run process() for each entry in the directory */\n            cut = base = g.inf + strlen(g.inf);\n            if (base > g.inf && base[-1] != (unsigned char)'/') {\n                if ((size_t)(base - g.inf) >= sizeof(g.inf))\n                    bail(\"path too long\", g.inf);\n                *base++ = '/';\n            }\n            item = roll;\n            while (*item) {\n                strncpy(base, item, sizeof(g.inf) - (base - g.inf));\n                if (g.inf[sizeof(g.inf) - 1]) {\n                    strcpy(g.inf + (sizeof(g.inf) - 4), \"...\");\n                    bail(\"path too long: \", g.inf);\n                }\n                process(g.inf);\n                item += strlen(item) + 1;\n            }\n            *cut = 0;\n\n            /* release list of entries */\n            FREE(roll);\n            return;\n        }\n\n        /* don't compress .gz (or provided suffix) files, unless -f */\n        if (!(g.force || g.list || g.decode) && len >= strlen(g.sufx) &&\n                strcmp(g.inf + len - strlen(g.sufx), g.sufx) == 0) {\n            complain(\"%s ends with %s -- skipping\", g.inf, g.sufx);\n            return;\n        }\n\n        /* create output file only if input file has compressed suffix */\n        if (g.decode == 1 && !g.pipeout && !g.list) {\n            int suf = compressed_suffix(g.inf);\n            if (suf == 0) {\n                complain(\"%s does not have compressed suffix -- skipping\",\n                         g.inf);\n                return;\n            }\n            len -= suf;\n        }\n\n        /* open input file */\n        g.ind = open(g.inf, O_RDONLY, 0);\n        if (g.ind < 0)\n            bail(\"read error on \", g.inf);\n\n        /* prepare gzip header information for compression */\n        g.name = g.headis & 1 ? justname(g.inf) : NULL;\n        g.mtime = g.headis & 2 ? st.st_mtime : 0;\n    }\n    SET_BINARY_MODE(g.ind);\n\n    /* if decoding or testing, try to read gzip header */\n    g.hname = NULL;\n    if (g.decode) {\n        in_init();\n        method = get_header(1);\n        if (method != 8 && method != 257 &&\n                /* gzip -cdf acts like cat on uncompressed input */\n                !(method == -2 && g.force && g.pipeout && g.decode != 2 &&\n                  !g.list)) {\n            RELEASE(g.hname);\n            if (g.ind != 0)\n                close(g.ind);\n            if (method != -1)\n                complain(method < 0 ? \"%s is not compressed -- skipping\" :\n                         \"%s has unknown compression method -- skipping\",\n                         g.inf);\n            return;\n        }\n\n        /* if requested, test input file (possibly a special list) */\n        if (g.decode == 2) {\n            if (method == 8)\n                infchk();\n            else {\n                unlzw();\n                if (g.list) {\n                    g.in_tot -= 3;\n                    show_info(method, 0, g.out_tot, 0);\n                }\n            }\n            RELEASE(g.hname);\n            if (g.ind != 0)\n                close(g.ind);\n            return;\n        }\n    }\n\n    /* if requested, just list information about input file */\n    if (g.list) {\n        list_info();\n        RELEASE(g.hname);\n        if (g.ind != 0)\n            close(g.ind);\n        return;\n    }\n\n    /* create output file out, descriptor outd */\n    if (path == NULL || g.pipeout) {\n        /* write to stdout */\n        g.outf = MALLOC(strlen(\"<stdout>\") + 1);\n        if (g.outf == NULL)\n            bail(\"not enough memory\", \"\");\n        strcpy(g.outf, \"<stdout>\");\n        g.outd = 1;\n        if (!g.decode && !g.force && isatty(g.outd))\n            bail(\"trying to write compressed data to a terminal\",\n                 \" (use -f to force)\");\n    }\n    else {\n        char *to, *repl;\n\n        /* use header name for output when decompressing with -N */\n        to = g.inf;\n        if (g.decode && (g.headis & 1) != 0 && g.hname != NULL) {\n            to = g.hname;\n            len = strlen(g.hname);\n        }\n\n        /* replace .tgz with .tar when decoding */\n        repl = g.decode && strcmp(to + len, \".tgz\") ? \"\" : \".tar\";\n\n        /* create output file and open to write */\n        g.outf = MALLOC(len + (g.decode ? strlen(repl) : strlen(g.sufx)) + 1);\n        if (g.outf == NULL)\n            bail(\"not enough memory\", \"\");\n        memcpy(g.outf, to, len);\n        strcpy(g.outf + len, g.decode ? repl : g.sufx);\n        g.outd = open(g.outf, O_CREAT | O_TRUNC | O_WRONLY |\n                             (g.force ? 0 : O_EXCL), 0600);\n\n        /* if exists and not -f, give user a chance to overwrite */\n        if (g.outd < 0 && errno == EEXIST && isatty(0) && g.verbosity) {\n            int ch, reply;\n\n            fprintf(stderr, \"%s exists -- overwrite (y/n)? \", g.outf);\n            fflush(stderr);\n            reply = -1;\n            do {\n                ch = getchar();\n                if (reply < 0 && ch != ' ' && ch != '\\t')\n                    reply = ch == 'y' || ch == 'Y' ? 1 : 0;\n            } while (ch != EOF && ch != '\\n' && ch != '\\r');\n            if (reply == 1)\n                g.outd = open(g.outf, O_CREAT | O_TRUNC | O_WRONLY,\n                              0600);\n        }\n\n        /* if exists and no overwrite, report and go on to next */\n        if (g.outd < 0 && errno == EEXIST) {\n            complain(\"%s exists -- skipping\", g.outf);\n            RELEASE(g.outf);\n            RELEASE(g.hname);\n            if (g.ind != 0)\n                close(g.ind);\n            return;\n        }\n\n        /* if some other error, give up */\n        if (g.outd < 0)\n            bail(\"write error on \", g.outf);\n    }\n    SET_BINARY_MODE(g.outd);\n    RELEASE(g.hname);\n\n    /* process ind to outd */\n    if (g.verbosity > 1)\n        fprintf(stderr, \"%s to %s \", g.inf, g.outf);\n    if (g.decode) {\n        if (method == 8)\n            infchk();\n        else if (method == 257)\n            unlzw();\n        else\n            cat();\n    }\n#ifndef NOTHREAD\n    else if (g.procs > 1)\n        parallel_compress();\n#endif\n    else\n        single_compress(0);\n    if (g.verbosity > 1) {\n        putc('\\n', stderr);\n        fflush(stderr);\n    }\n\n    /* finish up, copy attributes, set times, delete original */\n    if (g.ind != 0)\n        close(g.ind);\n    if (g.outd != 1) {\n        if (close(g.outd))\n            bail(\"write error on \", g.outf);\n        g.outd = -1;            /* now prevent deletion on interrupt */\n        if (g.ind != 0) {\n            copymeta(g.inf, g.outf);\n            if (!g.keep)\n                unlink(g.inf);\n        }\n        if (g.decode && (g.headis & 2) != 0 && g.stamp)\n            touch(g.outf, g.stamp);\n    }\n    RELEASE(g.outf);\n}", "func_src_after": "local void process(char *path)\n{\n    int method = -1;                /* get_header() return value */\n    size_t len;                     /* length of base name (minus suffix) */\n    struct stat st;                 /* to get file type and mod time */\n    /* all compressed suffixes for decoding search, in length order */\n    static char *sufs[] = {\".z\", \"-z\", \"_z\", \".Z\", \".gz\", \"-gz\", \".zz\", \"-zz\",\n                           \".zip\", \".ZIP\", \".tgz\", NULL};\n\n    /* open input file with name in, descriptor ind -- set name and mtime */\n    if (path == NULL) {\n        strcpy(g.inf, \"<stdin>\");\n        g.ind = 0;\n        g.name = NULL;\n        g.mtime = g.headis & 2 ?\n                  (fstat(g.ind, &st) ? time(NULL) : st.st_mtime) : 0;\n        len = 0;\n    }\n    else {\n        /* set input file name (already set if recursed here) */\n        if (path != g.inf) {\n            strncpy(g.inf, path, sizeof(g.inf));\n            if (g.inf[sizeof(g.inf) - 1])\n                bail(\"name too long: \", path);\n        }\n        len = strlen(g.inf);\n\n        /* try to stat input file -- if not there and decoding, look for that\n           name with compressed suffixes */\n        if (lstat(g.inf, &st)) {\n            if (errno == ENOENT && (g.list || g.decode)) {\n                char **try = sufs;\n                do {\n                    if (*try == NULL || len + strlen(*try) >= sizeof(g.inf))\n                        break;\n                    strcpy(g.inf + len, *try++);\n                    errno = 0;\n                } while (lstat(g.inf, &st) && errno == ENOENT);\n            }\n#ifdef EOVERFLOW\n            if (errno == EOVERFLOW || errno == EFBIG)\n                bail(g.inf,\n                    \" too large -- not compiled with large file support\");\n#endif\n            if (errno) {\n                g.inf[len] = 0;\n                complain(\"%s does not exist -- skipping\", g.inf);\n                return;\n            }\n            len = strlen(g.inf);\n        }\n\n        /* only process regular files, but allow symbolic links if -f,\n           recurse into directory if -r */\n        if ((st.st_mode & S_IFMT) != S_IFREG &&\n            (st.st_mode & S_IFMT) != S_IFLNK &&\n            (st.st_mode & S_IFMT) != S_IFDIR) {\n            complain(\"%s is a special file or device -- skipping\", g.inf);\n            return;\n        }\n        if ((st.st_mode & S_IFMT) == S_IFLNK && !g.force && !g.pipeout) {\n            complain(\"%s is a symbolic link -- skipping\", g.inf);\n            return;\n        }\n        if ((st.st_mode & S_IFMT) == S_IFDIR && !g.recurse) {\n            complain(\"%s is a directory -- skipping\", g.inf);\n            return;\n        }\n\n        /* recurse into directory (assumes Unix) */\n        if ((st.st_mode & S_IFMT) == S_IFDIR) {\n            char *roll, *item, *cut, *base, *bigger;\n            size_t len, hold;\n            DIR *here;\n            struct dirent *next;\n\n            /* accumulate list of entries (need to do this, since readdir()\n               behavior not defined if directory modified between calls) */\n            here = opendir(g.inf);\n            if (here == NULL)\n                return;\n            hold = 512;\n            roll = MALLOC(hold);\n            if (roll == NULL)\n                bail(\"not enough memory\", \"\");\n            *roll = 0;\n            item = roll;\n            while ((next = readdir(here)) != NULL) {\n                if (next->d_name[0] == 0 ||\n                    (next->d_name[0] == '.' && (next->d_name[1] == 0 ||\n                     (next->d_name[1] == '.' && next->d_name[2] == 0))))\n                    continue;\n                len = strlen(next->d_name) + 1;\n                if (item + len + 1 > roll + hold) {\n                    do {                    /* make roll bigger */\n                        hold <<= 1;\n                    } while (item + len + 1 > roll + hold);\n                    bigger = REALLOC(roll, hold);\n                    if (bigger == NULL) {\n                        FREE(roll);\n                        bail(\"not enough memory\", \"\");\n                    }\n                    item = bigger + (item - roll);\n                    roll = bigger;\n                }\n                strcpy(item, next->d_name);\n                item += len;\n                *item = 0;\n            }\n            closedir(here);\n\n            /* run process() for each entry in the directory */\n            cut = base = g.inf + strlen(g.inf);\n            if (base > g.inf && base[-1] != (unsigned char)'/') {\n                if ((size_t)(base - g.inf) >= sizeof(g.inf))\n                    bail(\"path too long\", g.inf);\n                *base++ = '/';\n            }\n            item = roll;\n            while (*item) {\n                strncpy(base, item, sizeof(g.inf) - (base - g.inf));\n                if (g.inf[sizeof(g.inf) - 1]) {\n                    strcpy(g.inf + (sizeof(g.inf) - 4), \"...\");\n                    bail(\"path too long: \", g.inf);\n                }\n                process(g.inf);\n                item += strlen(item) + 1;\n            }\n            *cut = 0;\n\n            /* release list of entries */\n            FREE(roll);\n            return;\n        }\n\n        /* don't compress .gz (or provided suffix) files, unless -f */\n        if (!(g.force || g.list || g.decode) && len >= strlen(g.sufx) &&\n                strcmp(g.inf + len - strlen(g.sufx), g.sufx) == 0) {\n            complain(\"%s ends with %s -- skipping\", g.inf, g.sufx);\n            return;\n        }\n\n        /* create output file only if input file has compressed suffix */\n        if (g.decode == 1 && !g.pipeout && !g.list) {\n            int suf = compressed_suffix(g.inf);\n            if (suf == 0) {\n                complain(\"%s does not have compressed suffix -- skipping\",\n                         g.inf);\n                return;\n            }\n            len -= suf;\n        }\n\n        /* open input file */\n        g.ind = open(g.inf, O_RDONLY, 0);\n        if (g.ind < 0)\n            bail(\"read error on \", g.inf);\n\n        /* prepare gzip header information for compression */\n        g.name = g.headis & 1 ? justname(g.inf) : NULL;\n        g.mtime = g.headis & 2 ? st.st_mtime : 0;\n    }\n    SET_BINARY_MODE(g.ind);\n\n    /* if decoding or testing, try to read gzip header */\n    g.hname = NULL;\n    if (g.decode) {\n        in_init();\n        method = get_header(1);\n        if (method != 8 && method != 257 &&\n                /* gzip -cdf acts like cat on uncompressed input */\n                !(method == -2 && g.force && g.pipeout && g.decode != 2 &&\n                  !g.list)) {\n            RELEASE(g.hname);\n            if (g.ind != 0)\n                close(g.ind);\n            if (method != -1)\n                complain(method < 0 ? \"%s is not compressed -- skipping\" :\n                         \"%s has unknown compression method -- skipping\",\n                         g.inf);\n            return;\n        }\n\n        /* if requested, test input file (possibly a special list) */\n        if (g.decode == 2) {\n            if (method == 8)\n                infchk();\n            else {\n                unlzw();\n                if (g.list) {\n                    g.in_tot -= 3;\n                    show_info(method, 0, g.out_tot, 0);\n                }\n            }\n            RELEASE(g.hname);\n            if (g.ind != 0)\n                close(g.ind);\n            return;\n        }\n    }\n\n    /* if requested, just list information about input file */\n    if (g.list) {\n        list_info();\n        RELEASE(g.hname);\n        if (g.ind != 0)\n            close(g.ind);\n        return;\n    }\n\n    /* create output file out, descriptor outd */\n    if (path == NULL || g.pipeout) {\n        /* write to stdout */\n        g.outf = MALLOC(strlen(\"<stdout>\") + 1);\n        if (g.outf == NULL)\n            bail(\"not enough memory\", \"\");\n        strcpy(g.outf, \"<stdout>\");\n        g.outd = 1;\n        if (!g.decode && !g.force && isatty(g.outd))\n            bail(\"trying to write compressed data to a terminal\",\n                 \" (use -f to force)\");\n    }\n    else {\n        char *to = g.inf, *sufx = \"\";\n        size_t pre = 0;\n\n        /* select parts of the output file name */\n        if (g.decode) {\n            /* for -dN or -dNT, use the path from the input file and the name\n               from the header, stripping any path in the header name */\n            if ((g.headis & 1) != 0 && g.hname != NULL) {\n                pre = justname(g.inf) - g.inf;\n                to = justname(g.hname);\n                len = strlen(to);\n            }\n            /* for -d or -dNn, replace abbreviated suffixes */\n            else if (strcmp(to + len, \".tgz\") == 0)\n                sufx = \".tar\";\n        }\n        else\n            /* add appropriate suffix when compressing */\n            sufx = g.sufx;\n\n        /* create output file and open to write */\n        g.outf = MALLOC(pre + len + strlen(sufx) + 1);\n        if (g.outf == NULL)\n            bail(\"not enough memory\", \"\");\n        memcpy(g.outf, g.inf, pre);\n        memcpy(g.outf + pre, to, len);\n        strcpy(g.outf + pre + len, sufx);\n        g.outd = open(g.outf, O_CREAT | O_TRUNC | O_WRONLY |\n                              (g.force ? 0 : O_EXCL), 0600);\n\n        /* if exists and not -f, give user a chance to overwrite */\n        if (g.outd < 0 && errno == EEXIST && isatty(0) && g.verbosity) {\n            int ch, reply;\n\n            fprintf(stderr, \"%s exists -- overwrite (y/n)? \", g.outf);\n            fflush(stderr);\n            reply = -1;\n            do {\n                ch = getchar();\n                if (reply < 0 && ch != ' ' && ch != '\\t')\n                    reply = ch == 'y' || ch == 'Y' ? 1 : 0;\n            } while (ch != EOF && ch != '\\n' && ch != '\\r');\n            if (reply == 1)\n                g.outd = open(g.outf, O_CREAT | O_TRUNC | O_WRONLY,\n                              0600);\n        }\n\n        /* if exists and no overwrite, report and go on to next */\n        if (g.outd < 0 && errno == EEXIST) {\n            complain(\"%s exists -- skipping\", g.outf);\n            RELEASE(g.outf);\n            RELEASE(g.hname);\n            if (g.ind != 0)\n                close(g.ind);\n            return;\n        }\n\n        /* if some other error, give up */\n        if (g.outd < 0)\n            bail(\"write error on \", g.outf);\n    }\n    SET_BINARY_MODE(g.outd);\n    RELEASE(g.hname);\n\n    /* process ind to outd */\n    if (g.verbosity > 1)\n        fprintf(stderr, \"%s to %s \", g.inf, g.outf);\n    if (g.decode) {\n        if (method == 8)\n            infchk();\n        else if (method == 257)\n            unlzw();\n        else\n            cat();\n    }\n#ifndef NOTHREAD\n    else if (g.procs > 1)\n        parallel_compress();\n#endif\n    else\n        single_compress(0);\n    if (g.verbosity > 1) {\n        putc('\\n', stderr);\n        fflush(stderr);\n    }\n\n    /* finish up, copy attributes, set times, delete original */\n    if (g.ind != 0)\n        close(g.ind);\n    if (g.outd != 1) {\n        if (close(g.outd))\n            bail(\"write error on \", g.outf);\n        g.outd = -1;            /* now prevent deletion on interrupt */\n        if (g.ind != 0) {\n            copymeta(g.inf, g.outf);\n            if (!g.keep)\n                unlink(g.inf);\n        }\n        if (g.decode && (g.headis & 2) != 0 && g.stamp)\n            touch(g.outf, g.stamp);\n    }\n    RELEASE(g.outf);\n}", "commit_link": "github.com/madler/pigz/commit/fdad1406b3ec809f4954ff7cdf9e99eb18c2458f", "file_name": "pigz.c", "vul_type": "cwe-022", "description": "In C, write a function to process a file path for compression or decompression, handling directories, symbolic links, and file suffixes."}
{"func_name": "pascal_case", "func_src_before": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(_sanitize(value))", "func_src_after": "def pascal_case(value: str) -> str:\n    return stringcase.pascalcase(value)", "commit_link": "github.com/openapi-generators/openapi-python-client/commit/3e7dfae5d0b3685abf1ede1bc6c086a116ac4746", "file_name": "openapi_python_client/utils.py", "vul_type": "cwe-022", "description": "Write a Python function named `pascal_case` that converts a string to PascalCase format, optionally sanitizing the input first."}
{"func_name": "set_fdc", "func_src_before": "static void set_fdc(int drive)\n{\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tfdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (fdc != 1 && fdc != 0) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "func_src_after": "static void set_fdc(int drive)\n{\n\tunsigned int new_fdc = fdc;\n\n\tif (drive >= 0 && drive < N_DRIVE) {\n\t\tnew_fdc = FDC(drive);\n\t\tcurrent_drive = drive;\n\t}\n\tif (new_fdc >= N_FDC) {\n\t\tpr_info(\"bad fdc value\\n\");\n\t\treturn;\n\t}\n\tfdc = new_fdc;\n\tset_dor(fdc, ~0, 8);\n#if N_FDC > 1\n\tset_dor(1 - fdc, ~8, 0);\n#endif\n\tif (FDCS->rawcmd == 2)\n\t\treset_fdc_info(1);\n\tif (fd_inb(FD_STATUS) != STATUS_READY)\n\t\tFDCS->reset = 1;\n}", "commit_link": "github.com/torvalds/linux/commit/2e90ca68b0d2f5548804f22f0dd61145516171e3", "file_name": "drivers/block/floppy.c", "vul_type": "cwe-125", "description": "Write a C function named `set_fdc` that configures a floppy disk controller (FDC) for a given drive number, with error checking and hardware status updates."}
{"func_name": "chmd_read_headers", "func_src_before": "static int chmd_read_headers(struct mspack_system *sys, struct mspack_file *fh,\n\t\t\t     struct mschmd_header *chm, int entire)\n{\n  unsigned int section, name_len, x, errors, num_chunks;\n  unsigned char buf[0x54], *chunk = NULL, *name, *p, *end;\n  struct mschmd_file *fi, *link = NULL;\n  off_t offset, length;\n  int num_entries;\n\n  /* initialise pointers */\n  chm->files         = NULL;\n  chm->sysfiles      = NULL;\n  chm->chunk_cache   = NULL;\n  chm->sec0.base.chm = chm;\n  chm->sec0.base.id  = 0;\n  chm->sec1.base.chm = chm;\n  chm->sec1.base.id  = 1;\n  chm->sec1.content  = NULL;\n  chm->sec1.control  = NULL;\n  chm->sec1.spaninfo = NULL;\n  chm->sec1.rtable   = NULL;\n\n  /* read the first header */\n  if (sys->read(fh, &buf[0], chmhead_SIZEOF) != chmhead_SIZEOF) {\n    return MSPACK_ERR_READ;\n  }\n\n  /* check ITSF signature */\n  if (EndGetI32(&buf[chmhead_Signature]) != 0x46535449) {\n    return MSPACK_ERR_SIGNATURE;\n  }\n\n  /* check both header GUIDs */\n  if (mspack_memcmp(&buf[chmhead_GUID1], &guids[0], 32L) != 0) {\n    D((\"incorrect GUIDs\"))\n    return MSPACK_ERR_SIGNATURE;\n  }\n\n  chm->version   = EndGetI32(&buf[chmhead_Version]);\n  chm->timestamp = EndGetM32(&buf[chmhead_Timestamp]);\n  chm->language  = EndGetI32(&buf[chmhead_LanguageID]);\n  if (chm->version > 3) {\n    sys->message(fh, \"WARNING; CHM version > 3\");\n  }\n\n  /* read the header section table */\n  if (sys->read(fh, &buf[0], chmhst3_SIZEOF) != chmhst3_SIZEOF) {\n    return MSPACK_ERR_READ;\n  }\n\n  /* chmhst3_OffsetCS0 does not exist in version 1 or 2 CHM files.\n   * The offset will be corrected later, once HS1 is read.\n   */\n  if (read_off64(&offset,           &buf[chmhst_OffsetHS0],  sys, fh) ||\n      read_off64(&chm->dir_offset,  &buf[chmhst_OffsetHS1],  sys, fh) ||\n      read_off64(&chm->sec0.offset, &buf[chmhst3_OffsetCS0], sys, fh))\n  {\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* seek to header section 0 */\n  if (sys->seek(fh, offset, MSPACK_SYS_SEEK_START)) {\n    return MSPACK_ERR_SEEK;\n  }\n\n  /* read header section 0 */\n  if (sys->read(fh, &buf[0], chmhs0_SIZEOF) != chmhs0_SIZEOF) {\n    return MSPACK_ERR_READ;\n  }\n  if (read_off64(&chm->length, &buf[chmhs0_FileLen], sys, fh)) {\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* seek to header section 1 */\n  if (sys->seek(fh, chm->dir_offset, MSPACK_SYS_SEEK_START)) {\n    return MSPACK_ERR_SEEK;\n  }\n\n  /* read header section 1 */\n  if (sys->read(fh, &buf[0], chmhs1_SIZEOF) != chmhs1_SIZEOF) {\n    return MSPACK_ERR_READ;\n  }\n\n  chm->dir_offset = sys->tell(fh);\n  chm->chunk_size = EndGetI32(&buf[chmhs1_ChunkSize]);\n  chm->density    = EndGetI32(&buf[chmhs1_Density]);\n  chm->depth      = EndGetI32(&buf[chmhs1_Depth]);\n  chm->index_root = EndGetI32(&buf[chmhs1_IndexRoot]);\n  chm->num_chunks = EndGetI32(&buf[chmhs1_NumChunks]);\n  chm->first_pmgl = EndGetI32(&buf[chmhs1_FirstPMGL]);\n  chm->last_pmgl  = EndGetI32(&buf[chmhs1_LastPMGL]);\n\n  if (chm->version < 3) {\n    /* versions before 3 don't have chmhst3_OffsetCS0 */\n    chm->sec0.offset = chm->dir_offset + (chm->chunk_size * chm->num_chunks);\n  }\n\n  /* check if content offset or file size is wrong */\n  if (chm->sec0.offset > chm->length) {\n    D((\"content section begins after file has ended\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n  \n  /* ensure there are chunks and that chunk size is\n   * large enough for signature and num_entries */\n  if (chm->chunk_size < (pmgl_Entries + 2)) {\n    D((\"chunk size not large enough\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n  if (chm->num_chunks == 0) {\n    D((\"no chunks\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* The chunk_cache data structure is not great; large values for num_chunks\n   * or num_chunks*chunk_size can exhaust all memory. Until a better chunk\n   * cache is implemented, put arbitrary limits on num_chunks and chunk size.\n   */\n  if (chm->num_chunks > 100000) {\n    D((\"more than 100,000 chunks\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }   \n  if ((off_t)chm->chunk_size * (off_t)chm->num_chunks > chm->length) {\n    D((\"chunks larger than entire file\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* common sense checks on header section 1 fields */\n  if ((chm->chunk_size & (chm->chunk_size - 1)) != 0) {\n    sys->message(fh, \"WARNING; chunk size is not a power of two\");\n  }\n  if (chm->first_pmgl != 0) {\n    sys->message(fh, \"WARNING; first PMGL chunk is not zero\");\n  }\n  if (chm->first_pmgl > chm->last_pmgl) {\n    D((\"first pmgl chunk is after last pmgl chunk\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n  if (chm->index_root != 0xFFFFFFFF && chm->index_root >= chm->num_chunks) {\n    D((\"index_root outside valid range\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* if we are doing a quick read, stop here! */\n  if (!entire) {\n    return MSPACK_ERR_OK;\n  }\n\n  /* seek to the first PMGL chunk, and reduce the number of chunks to read */\n  if ((x = chm->first_pmgl) != 0) {\n    if (sys->seek(fh,(off_t) (x * chm->chunk_size), MSPACK_SYS_SEEK_CUR)) {\n      return MSPACK_ERR_SEEK;\n    }\n  }\n  num_chunks = chm->last_pmgl - x + 1;\n\n  if (!(chunk = (unsigned char *) sys->alloc(sys, (size_t)chm->chunk_size))) {\n    return MSPACK_ERR_NOMEMORY;\n  }\n\n  /* read and process all chunks from FirstPMGL to LastPMGL */\n  errors = 0;\n  while (num_chunks--) {\n    /* read next chunk */\n    if (sys->read(fh, chunk, (int)chm->chunk_size) != (int)chm->chunk_size) {\n      sys->free(chunk);\n      return MSPACK_ERR_READ;\n    }\n\n    /* process only directory (PMGL) chunks */\n    if (EndGetI32(&chunk[pmgl_Signature]) != 0x4C474D50) continue;\n\n    if (EndGetI32(&chunk[pmgl_QuickRefSize]) < 2) {\n      sys->message(fh, \"WARNING; PMGL quickref area is too small\");\n    }\n    if (EndGetI32(&chunk[pmgl_QuickRefSize]) > \n\t((int)chm->chunk_size - pmgl_Entries))\n    {\n      sys->message(fh, \"WARNING; PMGL quickref area is too large\");\n    }\n\n    p = &chunk[pmgl_Entries];\n    end = &chunk[chm->chunk_size - 2];\n    num_entries = EndGetI16(end);\n\n    while (num_entries--) {\n      READ_ENCINT(name_len);\n      if (name_len > (unsigned int) (end - p)) goto chunk_end;\n      /* consider blank filenames to be an error */\n      if (name_len == 0) goto chunk_end;\n      name = p; p += name_len;\n\n      READ_ENCINT(section);\n      READ_ENCINT(offset);\n      READ_ENCINT(length);\n\n      /* empty files and directory names are stored as a file entry at\n       * offset 0 with length 0. We want to keep empty files, but not\n       * directory names, which end with a \"/\" */\n      if ((offset == 0) && (length == 0)) {\n\tif ((name_len > 0) && (name[name_len-1] == '/')) continue;\n      }\n\n      if (section > 1) {\n\tsys->message(fh, \"invalid section number '%u'.\", section);\n\tcontinue;\n      }\n\n      if (!(fi = (struct mschmd_file *) sys->alloc(sys, sizeof(struct mschmd_file) + name_len + 1))) {\n\tsys->free(chunk);\n\treturn MSPACK_ERR_NOMEMORY;\n      }\n\n      fi->next     = NULL;\n      fi->filename = (char *) &fi[1];\n      fi->section  = ((section == 0) ? (struct mschmd_section *) (&chm->sec0)\n\t\t                     : (struct mschmd_section *) (&chm->sec1));\n      fi->offset   = offset;\n      fi->length   = length;\n      sys->copy(name, fi->filename, (size_t) name_len);\n      fi->filename[name_len] = '\\0';\n\n      if (name[0] == ':' && name[1] == ':') {\n\t/* system file */\n\tif (mspack_memcmp(&name[2], &content_name[2], 31L) == 0) {\n\t  if (mspack_memcmp(&name[33], &content_name[33], 8L) == 0) {\n\t    chm->sec1.content = fi;\n\t  }\n\t  else if (mspack_memcmp(&name[33], &control_name[33], 11L) == 0) {\n\t    chm->sec1.control = fi;\n\t  }\n\t  else if (mspack_memcmp(&name[33], &spaninfo_name[33], 8L) == 0) {\n\t    chm->sec1.spaninfo = fi;\n\t  }\n\t  else if (mspack_memcmp(&name[33], &rtable_name[33], 72L) == 0) {\n\t    chm->sec1.rtable = fi;\n\t  }\n\t}\n\tfi->next = chm->sysfiles;\n\tchm->sysfiles = fi;\n      }\n      else {\n\t/* normal file */\n\tif (link) link->next = fi; else chm->files = fi;\n\tlink = fi;\n      }\n    }\n\n    /* this is reached either when num_entries runs out, or if\n     * reading data from the chunk reached a premature end of chunk */\n  chunk_end:\n    if (num_entries >= 0) {\n      D((\"chunk ended before all entries could be read\"))\n      errors++;\n    }\n\n  }\n  sys->free(chunk);\n  return (errors > 0) ? MSPACK_ERR_DATAFORMAT : MSPACK_ERR_OK;\n}", "func_src_after": "static int chmd_read_headers(struct mspack_system *sys, struct mspack_file *fh,\n\t\t\t     struct mschmd_header *chm, int entire)\n{\n  unsigned int section, name_len, x, errors, num_chunks;\n  unsigned char buf[0x54], *chunk = NULL, *name, *p, *end;\n  struct mschmd_file *fi, *link = NULL;\n  off_t offset, length;\n  int num_entries;\n\n  /* initialise pointers */\n  chm->files         = NULL;\n  chm->sysfiles      = NULL;\n  chm->chunk_cache   = NULL;\n  chm->sec0.base.chm = chm;\n  chm->sec0.base.id  = 0;\n  chm->sec1.base.chm = chm;\n  chm->sec1.base.id  = 1;\n  chm->sec1.content  = NULL;\n  chm->sec1.control  = NULL;\n  chm->sec1.spaninfo = NULL;\n  chm->sec1.rtable   = NULL;\n\n  /* read the first header */\n  if (sys->read(fh, &buf[0], chmhead_SIZEOF) != chmhead_SIZEOF) {\n    return MSPACK_ERR_READ;\n  }\n\n  /* check ITSF signature */\n  if (EndGetI32(&buf[chmhead_Signature]) != 0x46535449) {\n    return MSPACK_ERR_SIGNATURE;\n  }\n\n  /* check both header GUIDs */\n  if (mspack_memcmp(&buf[chmhead_GUID1], &guids[0], 32L) != 0) {\n    D((\"incorrect GUIDs\"))\n    return MSPACK_ERR_SIGNATURE;\n  }\n\n  chm->version   = EndGetI32(&buf[chmhead_Version]);\n  chm->timestamp = EndGetM32(&buf[chmhead_Timestamp]);\n  chm->language  = EndGetI32(&buf[chmhead_LanguageID]);\n  if (chm->version > 3) {\n    sys->message(fh, \"WARNING; CHM version > 3\");\n  }\n\n  /* read the header section table */\n  if (sys->read(fh, &buf[0], chmhst3_SIZEOF) != chmhst3_SIZEOF) {\n    return MSPACK_ERR_READ;\n  }\n\n  /* chmhst3_OffsetCS0 does not exist in version 1 or 2 CHM files.\n   * The offset will be corrected later, once HS1 is read.\n   */\n  if (read_off64(&offset,           &buf[chmhst_OffsetHS0],  sys, fh) ||\n      read_off64(&chm->dir_offset,  &buf[chmhst_OffsetHS1],  sys, fh) ||\n      read_off64(&chm->sec0.offset, &buf[chmhst3_OffsetCS0], sys, fh))\n  {\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* seek to header section 0 */\n  if (sys->seek(fh, offset, MSPACK_SYS_SEEK_START)) {\n    return MSPACK_ERR_SEEK;\n  }\n\n  /* read header section 0 */\n  if (sys->read(fh, &buf[0], chmhs0_SIZEOF) != chmhs0_SIZEOF) {\n    return MSPACK_ERR_READ;\n  }\n  if (read_off64(&chm->length, &buf[chmhs0_FileLen], sys, fh)) {\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* seek to header section 1 */\n  if (sys->seek(fh, chm->dir_offset, MSPACK_SYS_SEEK_START)) {\n    return MSPACK_ERR_SEEK;\n  }\n\n  /* read header section 1 */\n  if (sys->read(fh, &buf[0], chmhs1_SIZEOF) != chmhs1_SIZEOF) {\n    return MSPACK_ERR_READ;\n  }\n\n  chm->dir_offset = sys->tell(fh);\n  chm->chunk_size = EndGetI32(&buf[chmhs1_ChunkSize]);\n  chm->density    = EndGetI32(&buf[chmhs1_Density]);\n  chm->depth      = EndGetI32(&buf[chmhs1_Depth]);\n  chm->index_root = EndGetI32(&buf[chmhs1_IndexRoot]);\n  chm->num_chunks = EndGetI32(&buf[chmhs1_NumChunks]);\n  chm->first_pmgl = EndGetI32(&buf[chmhs1_FirstPMGL]);\n  chm->last_pmgl  = EndGetI32(&buf[chmhs1_LastPMGL]);\n\n  if (chm->version < 3) {\n    /* versions before 3 don't have chmhst3_OffsetCS0 */\n    chm->sec0.offset = chm->dir_offset + (chm->chunk_size * chm->num_chunks);\n  }\n\n  /* check if content offset or file size is wrong */\n  if (chm->sec0.offset > chm->length) {\n    D((\"content section begins after file has ended\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n  \n  /* ensure there are chunks and that chunk size is\n   * large enough for signature and num_entries */\n  if (chm->chunk_size < (pmgl_Entries + 2)) {\n    D((\"chunk size not large enough\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n  if (chm->num_chunks == 0) {\n    D((\"no chunks\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* The chunk_cache data structure is not great; large values for num_chunks\n   * or num_chunks*chunk_size can exhaust all memory. Until a better chunk\n   * cache is implemented, put arbitrary limits on num_chunks and chunk size.\n   */\n  if (chm->num_chunks > 100000) {\n    D((\"more than 100,000 chunks\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }   \n  if ((off_t)chm->chunk_size * (off_t)chm->num_chunks > chm->length) {\n    D((\"chunks larger than entire file\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* common sense checks on header section 1 fields */\n  if ((chm->chunk_size & (chm->chunk_size - 1)) != 0) {\n    sys->message(fh, \"WARNING; chunk size is not a power of two\");\n  }\n  if (chm->first_pmgl != 0) {\n    sys->message(fh, \"WARNING; first PMGL chunk is not zero\");\n  }\n  if (chm->first_pmgl > chm->last_pmgl) {\n    D((\"first pmgl chunk is after last pmgl chunk\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n  if (chm->index_root != 0xFFFFFFFF && chm->index_root >= chm->num_chunks) {\n    D((\"index_root outside valid range\"))\n    return MSPACK_ERR_DATAFORMAT;\n  }\n\n  /* if we are doing a quick read, stop here! */\n  if (!entire) {\n    return MSPACK_ERR_OK;\n  }\n\n  /* seek to the first PMGL chunk, and reduce the number of chunks to read */\n  if ((x = chm->first_pmgl) != 0) {\n    if (sys->seek(fh,(off_t) (x * chm->chunk_size), MSPACK_SYS_SEEK_CUR)) {\n      return MSPACK_ERR_SEEK;\n    }\n  }\n  num_chunks = chm->last_pmgl - x + 1;\n\n  if (!(chunk = (unsigned char *) sys->alloc(sys, (size_t)chm->chunk_size))) {\n    return MSPACK_ERR_NOMEMORY;\n  }\n\n  /* read and process all chunks from FirstPMGL to LastPMGL */\n  errors = 0;\n  while (num_chunks--) {\n    /* read next chunk */\n    if (sys->read(fh, chunk, (int)chm->chunk_size) != (int)chm->chunk_size) {\n      sys->free(chunk);\n      return MSPACK_ERR_READ;\n    }\n\n    /* process only directory (PMGL) chunks */\n    if (EndGetI32(&chunk[pmgl_Signature]) != 0x4C474D50) continue;\n\n    if (EndGetI32(&chunk[pmgl_QuickRefSize]) < 2) {\n      sys->message(fh, \"WARNING; PMGL quickref area is too small\");\n    }\n    if (EndGetI32(&chunk[pmgl_QuickRefSize]) > \n\t((int)chm->chunk_size - pmgl_Entries))\n    {\n      sys->message(fh, \"WARNING; PMGL quickref area is too large\");\n    }\n\n    p = &chunk[pmgl_Entries];\n    end = &chunk[chm->chunk_size - 2];\n    num_entries = EndGetI16(end);\n\n    while (num_entries--) {\n      READ_ENCINT(name_len);\n      if (name_len > (unsigned int) (end - p)) goto chunk_end;\n      name = p; p += name_len;\n      READ_ENCINT(section);\n      READ_ENCINT(offset);\n      READ_ENCINT(length);\n\n      /* ignore blank or one-char (e.g. \"/\") filenames we'd return as blank */\n      if (name_len < 2 || !name[0] || !name[1]) continue;\n\n      /* empty files and directory names are stored as a file entry at\n       * offset 0 with length 0. We want to keep empty files, but not\n       * directory names, which end with a \"/\" */\n      if ((offset == 0) && (length == 0)) {\n\tif ((name_len > 0) && (name[name_len-1] == '/')) continue;\n      }\n\n      if (section > 1) {\n\tsys->message(fh, \"invalid section number '%u'.\", section);\n\tcontinue;\n      }\n\n      if (!(fi = (struct mschmd_file *) sys->alloc(sys, sizeof(struct mschmd_file) + name_len + 1))) {\n\tsys->free(chunk);\n\treturn MSPACK_ERR_NOMEMORY;\n      }\n\n      fi->next     = NULL;\n      fi->filename = (char *) &fi[1];\n      fi->section  = ((section == 0) ? (struct mschmd_section *) (&chm->sec0)\n\t\t                     : (struct mschmd_section *) (&chm->sec1));\n      fi->offset   = offset;\n      fi->length   = length;\n      sys->copy(name, fi->filename, (size_t) name_len);\n      fi->filename[name_len] = '\\0';\n\n      if (name[0] == ':' && name[1] == ':') {\n\t/* system file */\n\tif (mspack_memcmp(&name[2], &content_name[2], 31L) == 0) {\n\t  if (mspack_memcmp(&name[33], &content_name[33], 8L) == 0) {\n\t    chm->sec1.content = fi;\n\t  }\n\t  else if (mspack_memcmp(&name[33], &control_name[33], 11L) == 0) {\n\t    chm->sec1.control = fi;\n\t  }\n\t  else if (mspack_memcmp(&name[33], &spaninfo_name[33], 8L) == 0) {\n\t    chm->sec1.spaninfo = fi;\n\t  }\n\t  else if (mspack_memcmp(&name[33], &rtable_name[33], 72L) == 0) {\n\t    chm->sec1.rtable = fi;\n\t  }\n\t}\n\tfi->next = chm->sysfiles;\n\tchm->sysfiles = fi;\n      }\n      else {\n\t/* normal file */\n\tif (link) link->next = fi; else chm->files = fi;\n\tlink = fi;\n      }\n    }\n\n    /* this is reached either when num_entries runs out, or if\n     * reading data from the chunk reached a premature end of chunk */\n  chunk_end:\n    if (num_entries >= 0) {\n      D((\"chunk ended before all entries could be read\"))\n      errors++;\n    }\n\n  }\n  sys->free(chunk);\n  return (errors > 0) ? MSPACK_ERR_DATAFORMAT : MSPACK_ERR_OK;\n}", "commit_link": "github.com/kyz/libmspack/commit/8759da8db6ec9e866cb8eb143313f397f925bb4f", "file_name": "libmspack/mspack/chmd.c", "vul_type": "cwe-476", "description": "Write a C function to read and process CHM file headers and directory chunks."}
{"func_name": "add_article_action", "func_src_before": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = request.POST[\"notes\"]\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = str(request.POST[str(\"notes_\" + str(art.id))])\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "func_src_after": "def add_article_action(request: HttpRequest, default_foreward_url: str):\n    forward_url: str = default_foreward_url\n    if request.GET.get(\"redirect\"):\n        forward_url = request.GET[\"redirect\"]\n    else:\n        forward_url = \"/admin\"\n    if \"rid\" not in request.GET:\n        return HttpResponseRedirect(\"/admin?error=Missing%20reservation%20id%20in%20request\")\n    u: Profile = get_current_user(request)\n    current_reservation = GroupReservation.objects.get(id=str(request.GET[\"rid\"]))\n    if current_reservation.createdByUser != u and u.rights < 2:\n        return HttpResponseRedirect(\"/admin?error=noyb\")\n    if current_reservation.submitted == True:\n        return HttpResponseRedirect(\"/admin?error=Already%20submitted\")\n    # Test for multiple or single article\n    if \"article_id\" in request.POST:\n        # Actual adding of article\n        aid: int = int(request.GET.get(\"article_id\"))\n        quantity: int = int(request.POST[\"quantity\"])\n        notes: str = escape(request.POST[\"notes\"])\n        ar = ArticleRequested()\n        ar.AID = Article.objects.get(id=aid)\n        ar.RID = current_reservation\n        if \"srid\" in request.GET:\n            ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n        ar.amount = quantity\n        ar.notes = notes\n        ar.save()\n    # Actual adding of multiple articles\n    else:\n        if \"group_id\" not in request.GET:\n            return HttpResponseRedirect(\"/admin?error=missing%20group%20id\")\n        g: ArticleGroup = ArticleGroup.objects.get(id=int(request.GET[\"group_id\"]))\n        for art in Article.objects.all().filter(group=g):\n            if str(\"quantity_\" + str(art.id)) not in request.POST or str(\"notes_\" + str(art.id)) not in request.POST:\n                return HttpResponseRedirect(\"/admin?error=Missing%20article%20data%20in%20request\")\n            amount = int(request.POST[\"quantity_\" + str(art.id)])\n            if amount > 0:\n                ar = ArticleRequested()\n                ar.AID = art\n                ar.RID = current_reservation\n                ar.amount = amount\n                if \"srid\" in request.GET:\n                    ar.SRID = SubReservation.objects.get(id=int(request.GET[\"srid\"]))\n                ar.notes = escape(str(request.POST[str(\"notes_\" + str(art.id))]))\n                ar.save()\n    if \"srid\" in request.GET:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id) + \"&srid=\" + request.GET[\"srid\"])\n    else:\n        response = HttpResponseRedirect(forward_url + \"?rid=\" + str(current_reservation.id))\n    return response", "commit_link": "github.com/Technikradio/C3FOCSite/commit/6e330d4d44bbfdfce9993dffea97008276771600", "file_name": "c3shop/frontpage/management/reservation_actions.py", "vul_type": "cwe-079", "description": "Write a Python function to handle adding single or multiple articles to a reservation, with redirection and error handling."}
{"func_name": "SMB2_read", "func_src_before": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\tcifs_small_buf_release(req);\n\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "func_src_after": "SMB2_read(const unsigned int xid, struct cifs_io_parms *io_parms,\n\t  unsigned int *nbytes, char **buf, int *buf_type)\n{\n\tstruct smb_rqst rqst;\n\tint resp_buftype, rc = -EACCES;\n\tstruct smb2_read_plain_req *req = NULL;\n\tstruct smb2_read_rsp *rsp = NULL;\n\tstruct kvec iov[1];\n\tstruct kvec rsp_iov;\n\tunsigned int total_len;\n\tint flags = CIFS_LOG_ERROR;\n\tstruct cifs_ses *ses = io_parms->tcon->ses;\n\n\t*nbytes = 0;\n\trc = smb2_new_read_req((void **)&req, &total_len, io_parms, NULL, 0, 0);\n\tif (rc)\n\t\treturn rc;\n\n\tif (smb3_encryption_required(io_parms->tcon))\n\t\tflags |= CIFS_TRANSFORM_REQ;\n\n\tiov[0].iov_base = (char *)req;\n\tiov[0].iov_len = total_len;\n\n\tmemset(&rqst, 0, sizeof(struct smb_rqst));\n\trqst.rq_iov = iov;\n\trqst.rq_nvec = 1;\n\n\trc = cifs_send_recv(xid, ses, &rqst, &resp_buftype, flags, &rsp_iov);\n\trsp = (struct smb2_read_rsp *)rsp_iov.iov_base;\n\n\tif (rc) {\n\t\tif (rc != -ENODATA) {\n\t\t\tcifs_stats_fail_inc(io_parms->tcon, SMB2_READ_HE);\n\t\t\tcifs_dbg(VFS, \"Send error in read = %d\\n\", rc);\n\t\t\ttrace_smb3_read_err(xid, req->PersistentFileId,\n\t\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t\t    io_parms->offset, io_parms->length,\n\t\t\t\t\t    rc);\n\t\t} else\n\t\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, 0);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t\treturn rc == -ENODATA ? 0 : rc;\n\t} else\n\t\ttrace_smb3_read_done(xid, req->PersistentFileId,\n\t\t\t\t    io_parms->tcon->tid, ses->Suid,\n\t\t\t\t    io_parms->offset, io_parms->length);\n\n\tcifs_small_buf_release(req);\n\n\t*nbytes = le32_to_cpu(rsp->DataLength);\n\tif ((*nbytes > CIFS_MAX_MSGSIZE) ||\n\t    (*nbytes > io_parms->length)) {\n\t\tcifs_dbg(FYI, \"bad length %d for count %d\\n\",\n\t\t\t *nbytes, io_parms->length);\n\t\trc = -EIO;\n\t\t*nbytes = 0;\n\t}\n\n\tif (*buf) {\n\t\tmemcpy(*buf, (char *)rsp + rsp->DataOffset, *nbytes);\n\t\tfree_rsp_buf(resp_buftype, rsp_iov.iov_base);\n\t} else if (resp_buftype != CIFS_NO_BUFFER) {\n\t\t*buf = rsp_iov.iov_base;\n\t\tif (resp_buftype == CIFS_SMALL_BUFFER)\n\t\t\t*buf_type = CIFS_SMALL_BUFFER;\n\t\telse if (resp_buftype == CIFS_LARGE_BUFFER)\n\t\t\t*buf_type = CIFS_LARGE_BUFFER;\n\t}\n\treturn rc;\n}", "commit_link": "github.com/torvalds/linux/commit/088aaf17aa79300cab14dbee2569c58cfafd7d6e", "file_name": "fs/cifs/smb2pdu.c", "vul_type": "cwe-416", "description": "Write a C function named `SMB2_read` that performs a read operation using Server Message Block (SMB) protocol version 2."}
{"func_name": "login", "func_src_before": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute(\"SELECT * FROM users WHERE name = ? AND password = ?;\", [user, password])\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "func_src_after": "@app.route('/', methods=['POST'])\ndef login():\n    print('login')\n    user = str(request.form['username'])\n    password = str(request.form['password'])\n    cur.execute('SELECT * FROM users WHERE name = \\'{}\\' AND password = \\'{}\\';'.format(user, password))\n    response = cur.fetchone()\n    if response != None:\n        print(response, 'OK')\n        return redirect(url_for('enter_test_point'))\n    else:\n        print(response, 'not OK')\n        flash('Invalid login or password')\n        return render_template('login.html')", "commit_link": "github.com/ChemiKyle/Waterspots/commit/3f9d5099496336f3f34c48abf0cf55acaaa29011", "file_name": "app.py", "vul_type": "cwe-089", "description": "Create a Python Flask login function that checks user credentials against a database and either redirects to a test point or flashes an error message."}
{"func_name": "acc_ctx_cont", "func_src_before": "acc_ctx_cont(OM_uint32 *minstat,\n\t     gss_buffer_t buf,\n\t     gss_ctx_id_t *ctx,\n\t     gss_buffer_t *responseToken,\n\t     gss_buffer_t *mechListMIC,\n\t     OM_uint32 *negState,\n\t     send_token_flag *return_token)\n{\n\tOM_uint32 ret, tmpmin;\n\tgss_OID supportedMech;\n\tspnego_gss_ctx_id_t sc;\n\tunsigned int len;\n\tunsigned char *ptr, *bufstart;\n\n\tsc = (spnego_gss_ctx_id_t)*ctx;\n\tret = GSS_S_DEFECTIVE_TOKEN;\n\t*negState = REJECT;\n\t*minstat = 0;\n\tsupportedMech = GSS_C_NO_OID;\n\t*return_token = ERROR_TOKEN_SEND;\n\t*responseToken = *mechListMIC = GSS_C_NO_BUFFER;\n\n\tptr = bufstart = buf->value;\n#define REMAIN (buf->length - (ptr - bufstart))\n\tif (REMAIN > INT_MAX)\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\n\t/*\n\t * Attempt to work with old Sun SPNEGO.\n\t */\n\tif (*ptr == HEADER_ID) {\n\t\tret = g_verify_token_header(gss_mech_spnego,\n\t\t\t\t\t    &len, &ptr, 0, REMAIN);\n\t\tif (ret) {\n\t\t\t*minstat = ret;\n\t\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t\t}\n\t}\n\tif (*ptr != (CONTEXT | 0x01)) {\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t}\n\tret = get_negTokenResp(minstat, ptr, REMAIN,\n\t\t\t       negState, &supportedMech,\n\t\t\t       responseToken, mechListMIC);\n\tif (ret != GSS_S_COMPLETE)\n\t\tgoto cleanup;\n\n\tif (*responseToken == GSS_C_NO_BUFFER &&\n\t    *mechListMIC == GSS_C_NO_BUFFER) {\n\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tsc->firstpass = 0;\n\t*negState = ACCEPT_INCOMPLETE;\n\t*return_token = CONT_TOKEN_SEND;\ncleanup:\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tgeneric_gss_release_oid(&tmpmin, &supportedMech);\n\t}\n\treturn ret;\n#undef REMAIN\n}", "func_src_after": "acc_ctx_cont(OM_uint32 *minstat,\n\t     gss_buffer_t buf,\n\t     gss_ctx_id_t *ctx,\n\t     gss_buffer_t *responseToken,\n\t     gss_buffer_t *mechListMIC,\n\t     OM_uint32 *negState,\n\t     send_token_flag *return_token)\n{\n\tOM_uint32 ret, tmpmin;\n\tgss_OID supportedMech;\n\tspnego_gss_ctx_id_t sc;\n\tunsigned int len;\n\tunsigned char *ptr, *bufstart;\n\n\tsc = (spnego_gss_ctx_id_t)*ctx;\n\tret = GSS_S_DEFECTIVE_TOKEN;\n\t*negState = REJECT;\n\t*minstat = 0;\n\tsupportedMech = GSS_C_NO_OID;\n\t*return_token = ERROR_TOKEN_SEND;\n\t*responseToken = *mechListMIC = GSS_C_NO_BUFFER;\n\n\tptr = bufstart = buf->value;\n#define REMAIN (buf->length - (ptr - bufstart))\n\tif (REMAIN == 0 || REMAIN > INT_MAX)\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\n\t/*\n\t * Attempt to work with old Sun SPNEGO.\n\t */\n\tif (*ptr == HEADER_ID) {\n\t\tret = g_verify_token_header(gss_mech_spnego,\n\t\t\t\t\t    &len, &ptr, 0, REMAIN);\n\t\tif (ret) {\n\t\t\t*minstat = ret;\n\t\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t\t}\n\t}\n\tif (*ptr != (CONTEXT | 0x01)) {\n\t\treturn GSS_S_DEFECTIVE_TOKEN;\n\t}\n\tret = get_negTokenResp(minstat, ptr, REMAIN,\n\t\t\t       negState, &supportedMech,\n\t\t\t       responseToken, mechListMIC);\n\tif (ret != GSS_S_COMPLETE)\n\t\tgoto cleanup;\n\n\tif (*responseToken == GSS_C_NO_BUFFER &&\n\t    *mechListMIC == GSS_C_NO_BUFFER) {\n\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tret = GSS_S_DEFECTIVE_TOKEN;\n\t\tgoto cleanup;\n\t}\n\tsc->firstpass = 0;\n\t*negState = ACCEPT_INCOMPLETE;\n\t*return_token = CONT_TOKEN_SEND;\ncleanup:\n\tif (supportedMech != GSS_C_NO_OID) {\n\t\tgeneric_gss_release_oid(&tmpmin, &supportedMech);\n\t}\n\treturn ret;\n#undef REMAIN\n}", "commit_link": "github.com/krb5/krb5/commit/524688ce87a15fc75f87efc8c039ba4c7d5c197b", "file_name": "src/lib/gssapi/spnego/spnego_mech.c", "vul_type": "cwe-476", "description": "Write a C function named `acc_ctx_cont` that processes a security token in a SPNEGO context and updates the negotiation state."}
{"func_name": "misc_file_checks", "func_src_before": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Deprecated usage of 'add_header' in nginx conf\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            if not os.path.isfile(self.path + \"/conf/\" + filename):\n                continue\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )", "func_src_after": "    def misc_file_checks(self):\n\n        print_header(\"MISC FILE CHECKS\")\n\n        #\n        # Check for recommended and mandatory files\n        #\n\n        filenames = (\"manifest.json\", \"LICENSE\", \"README.md\",\n                     \"scripts/install\", \"scripts/remove\",\n                     \"scripts/upgrade\",\n                     \"scripts/backup\", \"scripts/restore\")\n        non_mandatory = (\"script/backup\", \"script/restore\")\n\n        for filename in filenames:\n            if file_exists(self.path + \"/\" + filename):\n                continue\n            elif filename in non_mandatory:\n                print_warning(\"Consider adding a file %s\" % filename)\n            else:\n                print_error(\"File %s is mandatory\" % filename)\n\n        #\n        # Deprecated php-fpm.ini thing\n        #\n\n        if file_exists(self.path + \"/conf/php-fpm.ini\"):\n            print_warning(\n                \"Using a separate php-fpm.ini file is deprecated. \"\n                \"Please merge your php-fpm directives directly in the pool file. \"\n                \"(c.f. https://github.com/YunoHost-Apps/nextcloud_ynh/issues/138 )\"\n            )\n\n        #\n        # Analyze nginx conf\n        # - Deprecated usage of 'add_header' in nginx conf\n        # - Spot path traversal issue vulnerability\n        #\n\n        for filename in os.listdir(self.path + \"/conf\"):\n            # Ignore subdirs or filename not containing nginx in the name\n            if not os.path.isfile(self.path + \"/conf/\" + filename) or \"nginx\" not in filename:\n                continue\n\n            #\n            # 'add_header' usage\n            #\n            content = open(self.path + \"/conf/\" + filename).read()\n            if \"location\" in content and \"add_header\" in content:\n                print_warning(\n                    \"Do not use 'add_header' in the nginx conf. Use 'more_set_headers' instead. \"\n                    \"(See https://www.peterbe.com/plog/be-very-careful-with-your-add_header-in-nginx \"\n                    \"and https://github.com/openresty/headers-more-nginx-module#more_set_headers )\"\n                )\n\n            #\n            # Path traversal issues\n            #\n            lines = open(self.path + \"/conf/\" + filename).readlines()\n            lines = [line.strip() for line in lines if not line.strip().startswith(\"#\")]\n            # Let's find the first location line\n            location_line = None\n            path_traversal_vulnerable = False\n            lines_iter = lines.__iter__()\n            for line in lines_iter:\n                if line.startswith(\"location\"):\n                    location_line = line\n                    break\n            # Look at the next lines for an 'alias' directive\n            if location_line is not None:\n                for line in lines_iter:\n                    if line.startswith(\"location\"):\n                        # Entering a new location block ... abort here\n                        # and assume there's no alias block later...\n                        break\n                    if line.startswith(\"alias\"):\n                        # We should definitely check for path traversal issue\n                        # Does the location target ends with / ?\n                        target = location_line.split()[-2]\n                        if not target.endswith(\"/\"):\n                            path_traversal_vulnerable = True\n                        break\n            if path_traversal_vulnerable:\n                print_warning(\n                    \"The nginx configuration appears vulnerable to path traversal as explained in \"\n                    \"https://www.acunetix.com/vulnerabilities/web/path-traversal-via-misconfigured-nginx-alias/\\n\"\n                    \"To fix it, look at the first lines of the nginx conf of the example app : \"\n                    \"https://github.com/YunoHost/example_ynh/blob/master/conf/nginx.conf\"\n                )", "commit_link": "github.com/YunoHost/package_linter/commit/f6e98894cfe841aedaa7efd590937f0255193913", "file_name": "package_linter.py", "vul_type": "cwe-022", "description": "Write a Python function to check for mandatory files, deprecated configurations, and potential vulnerabilities in a project's file structure and configurations."}
{"func_name": "MAPIPrint", "func_src_before": "void MAPIPrint(MAPIProps *p) {\n  int j, i, index, h, x;\n  DDWORD *ddword_ptr;\n  DDWORD ddword_tmp;\n  dtr thedate;\n  MAPIProperty *mapi;\n  variableLength *mapidata;\n  variableLength vlTemp;\n  int found;\n\n  for (j = 0; j < p->count; j++) {\n    mapi = &(p->properties[j]);\n    printf(\"   #%i: Type: [\", j);\n    switch (PROP_TYPE(mapi->id)) {\n      case PT_UNSPECIFIED:\n        printf(\"  NONE   \"); break;\n      case PT_NULL:\n        printf(\"  NULL   \"); break;\n      case PT_I2:\n        printf(\"   I2    \"); break;\n      case PT_LONG:\n        printf(\"  LONG   \"); break;\n      case PT_R4:\n        printf(\"   R4    \"); break;\n      case PT_DOUBLE:\n        printf(\" DOUBLE  \"); break;\n      case PT_CURRENCY:\n        printf(\"CURRENCY \"); break;\n      case PT_APPTIME:\n        printf(\"APP TIME \"); break;\n      case PT_ERROR:\n        printf(\"  ERROR  \"); break;\n      case PT_BOOLEAN:\n        printf(\" BOOLEAN \"); break;\n      case PT_OBJECT:\n        printf(\" OBJECT  \"); break;\n      case PT_I8:\n        printf(\"   I8    \"); break;\n      case PT_STRING8:\n        printf(\" STRING8 \"); break;\n      case PT_UNICODE:\n        printf(\" UNICODE \"); break;\n      case PT_SYSTIME:\n        printf(\"SYS TIME \"); break;\n      case PT_CLSID:\n        printf(\"OLE GUID \"); break;\n      case PT_BINARY:\n        printf(\" BINARY  \"); break;\n      default:\n        printf(\"<%x>\", PROP_TYPE(mapi->id)); break;\n    }\n\n    printf(\"]  Code: [\");\n    if (mapi->custom == 1) {\n      printf(\"UD:x%04x\", PROP_ID(mapi->id));\n    } else {\n      found = 0;\n      for (index = 0; index < sizeof(MPList) / sizeof(MAPIPropertyTagList); index++) {\n        if ((MPList[index].id == PROP_ID(mapi->id)) && (found == 0)) {\n          printf(\"%s\", MPList[index].name);\n          found = 1;\n        }\n      }\n      if (found == 0) {\n        printf(\"0x%04x\", PROP_ID(mapi->id));\n      }\n    }\n    printf(\"]\\n\");\n    if (mapi->namedproperty > 0) {\n      for (i = 0; i < mapi->namedproperty; i++) {\n        printf(\"    Name: %s\\n\", mapi->propnames[i].data);\n      }\n    }\n    for (i = 0; i < mapi->count; i++) {\n      mapidata = &(mapi->data[i]);\n      if (mapi->count > 1) {\n        printf(\"    [%i/%u] \", i, mapi->count);\n      } else {\n        printf(\"    \");\n      }\n      printf(\"Size: %i\", mapidata->size);\n      switch (PROP_TYPE(mapi->id)) {\n        case PT_SYSTIME:\n          MAPISysTimetoDTR(mapidata->data, &thedate);\n          printf(\"    Value: \");\n          ddword_tmp = *((DDWORD *)mapidata->data);\n          TNEFPrintDate(thedate);\n          printf(\" [HEX: \");\n          for (x = 0; x < sizeof(ddword_tmp); x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"] (%llu)\\n\", ddword_tmp);\n          break;\n        case PT_LONG:\n          printf(\"    Value: %li\\n\", *((long*)mapidata->data));\n          break;\n        case PT_I2:\n          printf(\"    Value: %hi\\n\", *((short int*)mapidata->data));\n          break;\n        case PT_BOOLEAN:\n          if (mapi->data->data[0] != 0) {\n            printf(\"    Value: True\\n\");\n          } else {\n            printf(\"    Value: False\\n\");\n          }\n          break;\n        case PT_OBJECT:\n          printf(\"\\n\");\n          break;\n        case PT_BINARY:\n          if (IsCompressedRTF(mapidata) == 1) {\n            printf(\"    Detected Compressed RTF. \");\n            printf(\"Decompressed text follows\\n\");\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n            if ((vlTemp.data = (BYTE*)DecompressRTF(mapidata, &(vlTemp.size))) != NULL) {\n              printf(\"%s\\n\", vlTemp.data);\n              free(vlTemp.data);\n            }\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n          } else {\n            printf(\"    Value: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_STRING8:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n          if (strlen((char*)mapidata->data) != mapidata->size - 1) {\n            printf(\"Detected Hidden data: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_CLSID:\n          printf(\"    Value: \");\n          printf(\"[HEX: \");\n          for(x=0; x< 16; x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"]\\n\");\n          break;\n        default:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n      }\n    }\n  }\n}", "func_src_after": "void MAPIPrint(MAPIProps *p) {\n  int j, i, index, h, x;\n  DDWORD *ddword_ptr;\n  DDWORD ddword_tmp;\n  dtr thedate;\n  MAPIProperty *mapi;\n  variableLength *mapidata;\n  variableLength vlTemp;\n  int found;\n\n  for (j = 0; j < p->count; j++) {\n    mapi = &(p->properties[j]);\n    printf(\"   #%i: Type: [\", j);\n    switch (PROP_TYPE(mapi->id)) {\n      case PT_UNSPECIFIED:\n        printf(\"  NONE   \"); break;\n      case PT_NULL:\n        printf(\"  NULL   \"); break;\n      case PT_I2:\n        printf(\"   I2    \"); break;\n      case PT_LONG:\n        printf(\"  LONG   \"); break;\n      case PT_R4:\n        printf(\"   R4    \"); break;\n      case PT_DOUBLE:\n        printf(\" DOUBLE  \"); break;\n      case PT_CURRENCY:\n        printf(\"CURRENCY \"); break;\n      case PT_APPTIME:\n        printf(\"APP TIME \"); break;\n      case PT_ERROR:\n        printf(\"  ERROR  \"); break;\n      case PT_BOOLEAN:\n        printf(\" BOOLEAN \"); break;\n      case PT_OBJECT:\n        printf(\" OBJECT  \"); break;\n      case PT_I8:\n        printf(\"   I8    \"); break;\n      case PT_STRING8:\n        printf(\" STRING8 \"); break;\n      case PT_UNICODE:\n        printf(\" UNICODE \"); break;\n      case PT_SYSTIME:\n        printf(\"SYS TIME \"); break;\n      case PT_CLSID:\n        printf(\"OLE GUID \"); break;\n      case PT_BINARY:\n        printf(\" BINARY  \"); break;\n      default:\n        printf(\"<%x>\", PROP_TYPE(mapi->id)); break;\n    }\n\n    printf(\"]  Code: [\");\n    if (mapi->custom == 1) {\n      printf(\"UD:x%04x\", PROP_ID(mapi->id));\n    } else {\n      found = 0;\n      for (index = 0; index < sizeof(MPList) / sizeof(MAPIPropertyTagList); index++) {\n        if ((MPList[index].id == PROP_ID(mapi->id)) && (found == 0)) {\n          printf(\"%s\", MPList[index].name);\n          found = 1;\n        }\n      }\n      if (found == 0) {\n        printf(\"0x%04x\", PROP_ID(mapi->id));\n      }\n    }\n    printf(\"]\\n\");\n    if (mapi->namedproperty > 0) {\n      for (i = 0; i < mapi->namedproperty; i++) {\n        printf(\"    Name: %s\\n\", mapi->propnames[i].data);\n      }\n    }\n    for (i = 0; i < mapi->count; i++) {\n      mapidata = &(mapi->data[i]);\n      if (mapi->count > 1) {\n        printf(\"    [%i/%u] \", i, mapi->count);\n      } else {\n        printf(\"    \");\n      }\n      printf(\"Size: %i\", mapidata->size);\n      switch (PROP_TYPE(mapi->id)) {\n        case PT_SYSTIME:\n          MAPISysTimetoDTR(mapidata->data, &thedate);\n          printf(\"    Value: \");\n          ddword_tmp = *((DDWORD *)mapidata->data);\n          TNEFPrintDate(thedate);\n          printf(\" [HEX: \");\n          for (x = 0; x < sizeof(ddword_tmp); x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"] (%llu)\\n\", ddword_tmp);\n          break;\n        case PT_LONG:\n          printf(\"    Value: %i\\n\", *((int*)mapidata->data));\n          break;\n        case PT_I2:\n          printf(\"    Value: %hi\\n\", *((short int*)mapidata->data));\n          break;\n        case PT_BOOLEAN:\n          if (mapi->data->data[0] != 0) {\n            printf(\"    Value: True\\n\");\n          } else {\n            printf(\"    Value: False\\n\");\n          }\n          break;\n        case PT_OBJECT:\n          printf(\"\\n\");\n          break;\n        case PT_BINARY:\n          if (IsCompressedRTF(mapidata) == 1) {\n            printf(\"    Detected Compressed RTF. \");\n            printf(\"Decompressed text follows\\n\");\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n            if ((vlTemp.data = (BYTE*)DecompressRTF(mapidata, &(vlTemp.size))) != NULL) {\n              printf(\"%s\\n\", vlTemp.data);\n              free(vlTemp.data);\n            }\n            printf(\"-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\\n\");\n          } else {\n            printf(\"    Value: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_STRING8:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n          if (strlen((char*)mapidata->data) != mapidata->size - 1) {\n            printf(\"Detected Hidden data: [\");\n            for (h = 0; h < mapidata->size; h++) {\n              if (isprint(mapidata->data[h])) {\n                printf(\"%c\", mapidata->data[h]);\n              } else {\n                printf(\".\");\n              }\n\n            }\n            printf(\"]\\n\");\n          }\n          break;\n        case PT_CLSID:\n          printf(\"    Value: \");\n          printf(\"[HEX: \");\n          for(x=0; x< 16; x++) {\n            printf(\" %02x\", (BYTE)mapidata->data[x]);\n          }\n          printf(\"]\\n\");\n          break;\n        default:\n          printf(\"    Value: [%s]\\n\", mapidata->data);\n      }\n    }\n  }\n}", "commit_link": "github.com/Yeraze/ytnef/commit/f98f5d4adc1c4bd4033638f6167c1bb95d642f89", "file_name": "lib/ytnef.c", "vul_type": "cwe-125", "description": "Write a C function named `MAPIPrint` that prints the properties and values of a given `MAPIProps` structure."}
{"func_name": "__init__.view_grocery_list", "func_src_before": "        def view_grocery_list():\n            print(\"grocery== list\")\n            groceryListFrame = Frame(self)\n            groceryListFrame.rowconfigure(0, weight=1)\n            groceryListFrame.columnconfigure(0, weight=1)\n            groceryListFrame.rowconfigure(1, weight=3)\n            groceryListFrame.columnconfigure(1, weight=3)\n            groceryListFrame.pack()\n\n            menu.pack_forget()\n            groceryButton.pack_forget()\n            label.configure(text=\"Grocery List\")\n\n            i = 0\n            database_file = \"meal_planner.db\"\n            item_array = []\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                tableName = \"ingredients_\" + str(weekNumber)\n                selection = cursor.execute(\"\"\"SELECT * FROM ?;\"\"\", (tableName, ))\n                for result in [selection]:\n                    for row in result.fetchall():\n                        print(row)\n                        for ingredient in row:\n                            print(ingredient)\n                            item_array.append(str(ingredient).split())\n                        i = i +1\n                        Label(groceryListFrame, text=ingredient, font=MEDIUM_FONT, justify=LEFT).grid(row=i, column=0, sticky=\"w\")\n            \n\n            j = 0\n            for item in item_array:\n                print(item)\n\n\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [groceryListFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "func_src_after": "        def view_grocery_list():\n            print(\"grocery== list\")\n            groceryListFrame = Frame(self)\n            groceryListFrame.rowconfigure(0, weight=1)\n            groceryListFrame.columnconfigure(0, weight=1)\n            groceryListFrame.rowconfigure(1, weight=3)\n            groceryListFrame.columnconfigure(1, weight=3)\n            groceryListFrame.pack()\n\n            menu.pack_forget()\n            groceryButton.pack_forget()\n            label.configure(text=\"Grocery List\")\n\n            i = 0\n            database_file = \"meal_planner.db\"\n            item_array = []\n            with sqlite3.connect(database_file) as conn:\n                cursor = conn.cursor()\n                tableName = \"ingredients_\" + str(weekNumber)\n                selection = cursor.execute(\"\"\"SELECT * FROM \"\"\" + tableName)\n                for result in [selection]:\n                    for row in result.fetchall():\n                        print(row)\n                        for ingredient in row:\n                            print(ingredient)\n                            item_array.append(str(ingredient).split())\n                        i = i +1\n                        Label(groceryListFrame, text=ingredient, font=MEDIUM_FONT, justify=LEFT).grid(row=i, column=0, sticky=\"w\")\n            \n\n            j = 0\n            for item in item_array:\n                print(item)\n\n\n            returnButton = Button(menuFrame, text = \"Return to Menu\", highlightbackground=\"#e7e7e7\", command=lambda: [groceryListFrame.pack_forget(),\n                                                                                     menu.pack(), returnButton.pack_forget(), label.configure(text=\"Meal Planer\"),\n                                                                                    groceryButton.pack(side=RIGHT)])\n            returnButton.pack(side=RIGHT)", "commit_link": "github.com/trishamoyer/RecipePlanner-Python/commit/44d2ce370715d9344fad34b3b749322ab095a925", "file_name": "mealPlan.py", "vul_type": "cwe-089", "description": "Write a Python function to display a grocery list from a SQLite database and provide a return button to the main menu."}
{"func_name": "license_read_new_or_upgrade_license_packet", "func_src_before": "BOOL license_read_new_or_upgrade_license_packet(rdpLicense* license, wStream* s)\n{\n\tUINT32 os_major;\n\tUINT32 os_minor;\n\tUINT32 cbScope, cbCompanyName, cbProductId, cbLicenseInfo;\n\twStream* licenseStream = NULL;\n\tBOOL ret = FALSE;\n\tBYTE computedMac[16];\n\tLICENSE_BLOB* calBlob;\n\n\tDEBUG_LICENSE(\"Receiving Server New/Upgrade License Packet\");\n\n\tcalBlob = license_new_binary_blob(BB_DATA_BLOB);\n\tif (!calBlob)\n\t\treturn FALSE;\n\n\t/* EncryptedLicenseInfo */\n\tif (!license_read_encrypted_blob(license, s, calBlob))\n\t\tgoto out_free_blob;\n\n\t/* compute MAC and check it */\n\tif (Stream_GetRemainingLength(s) < 16)\n\t\tgoto out_free_blob;\n\n\tif (!security_mac_data(license->MacSaltKey, calBlob->data, calBlob->length, computedMac))\n\t\tgoto out_free_blob;\n\n\tif (memcmp(computedMac, Stream_Pointer(s), sizeof(computedMac)) != 0)\n\t{\n\t\tWLog_ERR(TAG, \"new or upgrade license MAC mismatch\");\n\t\tgoto out_free_blob;\n\t}\n\n\tif (!Stream_SafeSeek(s, 16))\n\t\tgoto out_free_blob;\n\n\tlicenseStream = Stream_New(calBlob->data, calBlob->length);\n\tif (!licenseStream)\n\t\tgoto out_free_blob;\n\n\tStream_Read_UINT16(licenseStream, os_minor);\n\tStream_Read_UINT16(licenseStream, os_major);\n\n\t/* Scope */\n\tStream_Read_UINT32(licenseStream, cbScope);\n\tif (Stream_GetRemainingLength(licenseStream) < cbScope)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Scope:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbScope);\n#endif\n\tStream_Seek(licenseStream, cbScope);\n\n\t/* CompanyName */\n\tStream_Read_UINT32(licenseStream, cbCompanyName);\n\tif (Stream_GetRemainingLength(licenseStream) < cbCompanyName)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Company name:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbCompanyName);\n#endif\n\tStream_Seek(licenseStream, cbCompanyName);\n\n\t/* productId */\n\tStream_Read_UINT32(licenseStream, cbProductId);\n\tif (Stream_GetRemainingLength(licenseStream) < cbProductId)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Product id:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbProductId);\n#endif\n\tStream_Seek(licenseStream, cbProductId);\n\n\t/* licenseInfo */\n\tStream_Read_UINT32(licenseStream, cbLicenseInfo);\n\tif (Stream_GetRemainingLength(licenseStream) < cbLicenseInfo)\n\t\tgoto out_free_stream;\n\n\tlicense->state = LICENSE_STATE_COMPLETED;\n\n\tret = TRUE;\n\tif (!license->rdp->settings->OldLicenseBehaviour)\n\t\tret = saveCal(license->rdp->settings, Stream_Pointer(licenseStream), cbLicenseInfo,\n\t\t              license->rdp->settings->ClientHostname);\n\nout_free_stream:\n\tStream_Free(licenseStream, FALSE);\nout_free_blob:\n\tlicense_free_binary_blob(calBlob);\n\treturn ret;\n}", "func_src_after": "BOOL license_read_new_or_upgrade_license_packet(rdpLicense* license, wStream* s)\n{\n\tUINT32 os_major;\n\tUINT32 os_minor;\n\tUINT32 cbScope, cbCompanyName, cbProductId, cbLicenseInfo;\n\twStream* licenseStream = NULL;\n\tBOOL ret = FALSE;\n\tBYTE computedMac[16];\n\tLICENSE_BLOB* calBlob;\n\n\tDEBUG_LICENSE(\"Receiving Server New/Upgrade License Packet\");\n\n\tcalBlob = license_new_binary_blob(BB_DATA_BLOB);\n\tif (!calBlob)\n\t\treturn FALSE;\n\n\t/* EncryptedLicenseInfo */\n\tif (!license_read_encrypted_blob(license, s, calBlob))\n\t\tgoto out_free_blob;\n\n\t/* compute MAC and check it */\n\tif (Stream_GetRemainingLength(s) < 16)\n\t\tgoto out_free_blob;\n\n\tif (!security_mac_data(license->MacSaltKey, calBlob->data, calBlob->length, computedMac))\n\t\tgoto out_free_blob;\n\n\tif (memcmp(computedMac, Stream_Pointer(s), sizeof(computedMac)) != 0)\n\t{\n\t\tWLog_ERR(TAG, \"new or upgrade license MAC mismatch\");\n\t\tgoto out_free_blob;\n\t}\n\n\tif (!Stream_SafeSeek(s, 16))\n\t\tgoto out_free_blob;\n\n\tlicenseStream = Stream_New(calBlob->data, calBlob->length);\n\tif (!licenseStream)\n\t\tgoto out_free_blob;\n\n\tif (Stream_GetRemainingLength(licenseStream) < 8)\n\t\tgoto out_free_stream;\n\n\tStream_Read_UINT16(licenseStream, os_minor);\n\tStream_Read_UINT16(licenseStream, os_major);\n\n\t/* Scope */\n\tStream_Read_UINT32(licenseStream, cbScope);\n\tif (Stream_GetRemainingLength(licenseStream) < cbScope)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Scope:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbScope);\n#endif\n\tStream_Seek(licenseStream, cbScope);\n\n\t/* CompanyName */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbCompanyName);\n\tif (Stream_GetRemainingLength(licenseStream) < cbCompanyName)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Company name:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbCompanyName);\n#endif\n\tStream_Seek(licenseStream, cbCompanyName);\n\n\t/* productId */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbProductId);\n\tif (Stream_GetRemainingLength(licenseStream) < cbProductId)\n\t\tgoto out_free_stream;\n#ifdef WITH_DEBUG_LICENSE\n\tWLog_DBG(TAG, \"Product id:\");\n\twinpr_HexDump(TAG, WLOG_DEBUG, Stream_Pointer(licenseStream), cbProductId);\n#endif\n\tStream_Seek(licenseStream, cbProductId);\n\n\t/* licenseInfo */\n\tif (Stream_GetRemainingLength(licenseStream) < 4)\n\t\tgoto out_free_stream;\n\tStream_Read_UINT32(licenseStream, cbLicenseInfo);\n\tif (Stream_GetRemainingLength(licenseStream) < cbLicenseInfo)\n\t\tgoto out_free_stream;\n\n\tlicense->state = LICENSE_STATE_COMPLETED;\n\n\tret = TRUE;\n\tif (!license->rdp->settings->OldLicenseBehaviour)\n\t\tret = saveCal(license->rdp->settings, Stream_Pointer(licenseStream), cbLicenseInfo,\n\t\t              license->rdp->settings->ClientHostname);\n\nout_free_stream:\n\tStream_Free(licenseStream, FALSE);\nout_free_blob:\n\tlicense_free_binary_blob(calBlob);\n\treturn ret;\n}", "commit_link": "github.com/FreeRDP/FreeRDP/commit/6ade7b4cbfd71c54b3d724e8f2d6ac76a58e879a", "file_name": "libfreerdp/core/license.c", "vul_type": "cwe-125", "description": "In C, write a function to process a new or upgraded license packet for Remote Desktop Protocol (RDP) licensing."}
{"func_name": "tar_directory_for_file", "func_src_before": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t\tdir = GSF_INFILE_TAR (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "func_src_after": "tar_directory_for_file (GsfInfileTar *dir, const char *name, gboolean last)\n{\n\tconst char *s = name;\n\n\twhile (1) {\n\t\tconst char *s0 = s;\n\t\tchar *dirname;\n\n\t\t/* Find a directory component, if any.  */\n\t\twhile (1) {\n\t\t\tif (*s == 0) {\n\t\t\t\tif (last && s != s0)\n\t\t\t\t\tbreak;\n\t\t\t\telse\n\t\t\t\t\treturn dir;\n\t\t\t}\n\t\t\t/* This is deliberately slash-only.  */\n\t\t\tif (*s == '/')\n\t\t\t\tbreak;\n\t\t\ts++;\n\t\t}\n\n\t\tdirname = g_strndup (s0, s - s0);\n\t\twhile (*s == '/')\n\t\t\ts++;\n\n\t\tif (strcmp (dirname, \".\") != 0) {\n\t\t\tGsfInput *subdir =\n\t\t\t\tgsf_infile_child_by_name (GSF_INFILE (dir),\n\t\t\t\t\t\t\t  dirname);\n\t\t\tif (subdir) {\n\t\t\t\tdir = GSF_IS_INFILE_TAR (subdir)\n\t\t\t\t\t? GSF_INFILE_TAR (subdir)\n\t\t\t\t\t: dir;\n\t\t\t\t/* Undo the ref. */\n\t\t\t\tg_object_unref (subdir);\n\t\t\t} else\n\t\t\t\tdir = tar_create_dir (dir, dirname);\n\t\t}\n\n\t\tg_free (dirname);\n\t}\n}", "commit_link": "github.com/GNOME/libgsf/commit/95a8351a75758cf10b3bf6abae0b6b461f90d9e5", "file_name": "gsf/gsf-infile-tar.c", "vul_type": "cwe-476", "description": "Write a C function to navigate or create directories within a TAR file based on a given path."}
{"func_name": "can_user_pass_that_amount_of_money", "func_src_before": "    def can_user_pass_that_amount_of_money(self, user_id, money):\n        self.cursor.execute(\"SELECT count(id) FROM kickstarter.users where id = %s and money >= %s\", (user_id, money))\n        return self.cursor.fetchall()[0][0]", "func_src_after": "    def can_user_pass_that_amount_of_money(self, user_id, money):\n        self.cursor.execute(\"SELECT count(id) FROM kickstarter.users where id = %s and money >= %s\" % (user_id, money))\n        return self.cursor.fetchall()[0][0]", "commit_link": "github.com/JLucka/kickstarter-dev/commit/e2ffa062697e060fdfbd2eccbb89a8c53a569e0b", "file_name": "backend/transactions/TransactionConnector.py", "vul_type": "cwe-089", "description": "Write a Python function to check if a user has enough money in a database using SQL query."}
{"func_name": "ImagingFliDecode", "func_src_before": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer (on the other hand, the Python part of the driver\n       makes sure this is always the case) */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}", "func_src_after": "ImagingFliDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8* ptr;\n    int framesize;\n    int c, chunks, advance;\n    int l, lines;\n    int i, j, x = 0, y, ymax;\n\n    /* If not even the chunk size is present, we'd better leave */\n\n    if (bytes < 4)\n\treturn 0;\n\n    /* We don't decode anything unless we have a full chunk in the\n       input buffer */\n\n    ptr = buf;\n\n    framesize = I32(ptr);\n    if (framesize < I32(ptr))\n\treturn 0;\n\n    /* Make sure this is a frame chunk.  The Python driver takes\n       case of other chunk types. */\n\n    if (bytes < 8) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n    if (I16(ptr+4) != 0xF1FA) {\n\tstate->errcode = IMAGING_CODEC_UNKNOWN;\n\treturn -1;\n    }\n\n    chunks = I16(ptr+6);\n    ptr += 16;\n    bytes -= 16;\n\n    /* Process subchunks */\n    for (c = 0; c < chunks; c++) {\n\tUINT8* data;\n\tif (bytes < 10) {\n\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t    return -1;\n\t}\n\tdata = ptr + 6;\n\tswitch (I16(ptr+4)) {\n\tcase 4: case 11:\n\t    /* FLI COLOR chunk */\n\t    break; /* ignored; handled by Python code */\n\tcase 7:\n\t    /* FLI SS2 chunk (word delta) */\n\t    lines = I16(data); data += 2;\n\t    for (l = y = 0; l < lines && y < state->ysize; l++, y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tint p, packets;\n\t\tpackets = I16(data); data += 2;\n\t\twhile (packets & 0x8000) {\n\t\t    /* flag word */\n\t\t    if (packets & 0x4000) {\n\t\t\ty += 65536 - packets; /* skip lines */\n\t\t\tif (y >= state->ysize) {\n\t\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t\t    return -1;\n\t\t\t}\n\t\t\tbuf = (UINT8*) im->image[y];\n\t\t    } else {\n\t\t\t/* store last byte (used if line width is odd) */\n\t\t\tbuf[state->xsize-1] = (UINT8) packets;\n\t\t    }\n\t\t    packets = I16(data); data += 2;\n\t\t}\n\t\tfor (p = x = 0; p < packets; p++) {\n\t\t    x += data[0]; /* pixel skip */\n\t\t    if (data[1] >= 128) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i + i > state->xsize)\n\t\t\t    break;\n\t\t\tfor (j = 0; j < i; j++) {\n\t\t\t    buf[x++] = data[2];\n\t\t\t    buf[x++] = data[3];\n\t\t\t}\n\t\t\tdata += 2 + 2;\n\t\t    } else {\n\t\t\ti = 2 * (int) data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(buf + x, data + 2, i);\n\t\t\tdata += 2 + i;\n\t\t\tx += i;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (l < lines) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 12:\n\t    /* FLI LC chunk (byte delta) */\n\t    y = I16(data); ymax = y + I16(data+2); data += 4;\n\t    for (; y < ymax && y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tint p, packets = *data++;\n\t\tfor (p = x = 0; p < packets; p++, x += i) {\n\t\t    x += data[0]; /* skip pixels */\n\t\t    if (data[1] & 0x80) {\n\t\t\ti = 256-data[1]; /* run */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemset(out + x, data[2], i);\n\t\t\tdata += 3;\n\t\t    } else {\n\t\t\ti = data[1]; /* chunk */\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break;\n\t\t\tmemcpy(out + x, data + 2, i);\n\t\t\tdata += i + 2;\n\t\t    }\n\t\t}\n\t\tif (p < packets)\n\t\t    break; /* didn't process all packets */\n\t    }\n\t    if (y < ymax) {\n\t\t/* didn't process all lines */\n\t\tstate->errcode = IMAGING_CODEC_OVERRUN;\n\t\treturn -1;\n\t    }\n\t    break;\n\tcase 13:\n\t    /* FLI BLACK chunk */\n\t    for (y = 0; y < state->ysize; y++)\n\t\tmemset(im->image[y], 0, state->xsize);\n\t    break;\n\tcase 15:\n\t    /* FLI BRUN chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* out = (UINT8*) im->image[y];\n\t\tdata += 1; /* ignore packetcount byte */\n\t\tfor (x = 0; x < state->xsize; x += i) {\n\t\t    if (data[0] & 0x80) {\n\t\t\ti = 256 - data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemcpy(out + x, data + 1, i);\n\t\t\tdata += i + 1;\n\t\t    } else {\n\t\t\ti = data[0];\n\t\t\tif (x + i > state->xsize)\n\t\t\t    break; /* safety first */\n\t\t\tmemset(out + x, data[1], i);\n\t\t\tdata += 2;\n\t\t    }\n\t\t}\n\t\tif (x != state->xsize) {\n\t\t    /* didn't unpack whole line */\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    return -1;\n\t\t}\n\t    }\n\t    break;\n\tcase 16:\n\t    /* COPY chunk */\n\t    for (y = 0; y < state->ysize; y++) {\n\t\tUINT8* buf = (UINT8*) im->image[y];\n\t\tmemcpy(buf, data, state->xsize);\n\t\tdata += state->xsize;\n\t    }\n\t    break;\n\tcase 18:\n\t    /* PSTAMP chunk */\n\t    break; /* ignored */\n\tdefault:\n\t    /* unknown chunk */\n\t    /* printf(\"unknown FLI/FLC chunk: %d\\n\", I16(ptr+4)); */\n\t    state->errcode = IMAGING_CODEC_UNKNOWN;\n\t    return -1;\n\t}\n\tadvance = I32(ptr);\n\tptr += advance;\n\tbytes -= advance;\n    }\n\n    return -1; /* end of frame */\n}", "commit_link": "github.com/python-pillow/Pillow/commit/a09acd0decd8a87ccce939d5ff65dab59e7d365b", "file_name": "src/libImaging/FliDecode.c", "vul_type": "cwe-125", "description": "Write a C function named `ImagingFliDecode` that decodes a frame from an FLI/FLC animation file into an image buffer."}
{"func_name": "ares_parse_a_reply", "func_src_before": "int ares_parse_a_reply(const unsigned char *abuf, int alen,\n\t\t       struct hostent **host)\n{\n  unsigned int qdcount, ancount;\n  int status, i, rr_type, rr_class, rr_len, naddrs;\n  long int len;\n  int naliases;\n  const unsigned char *aptr;\n  char *hostname, *rr_name, *rr_data, **aliases;\n  struct in_addr *addrs;\n  struct hostent *hostent;\n\n  /* Set *host to NULL for all failure cases. */\n  *host = NULL;\n\n  /* Give up if abuf doesn't have room for a header. */\n  if (alen < HFIXEDSZ)\n    return ARES_EBADRESP;\n\n  /* Fetch the question and answer count from the header. */\n  qdcount = DNS_HEADER_QDCOUNT(abuf);\n  ancount = DNS_HEADER_ANCOUNT(abuf);\n  if (qdcount != 1)\n    return ARES_EBADRESP;\n\n  /* Expand the name from the question, and skip past the question. */\n  aptr = abuf + HFIXEDSZ;\n  status = ares_expand_name(aptr, abuf, alen, &hostname, &len);\n  if (status != ARES_SUCCESS)\n    return status;\n  if (aptr + len + QFIXEDSZ > abuf + alen)\n    {\n      free(hostname);\n      return ARES_EBADRESP;\n    }\n  aptr += len + QFIXEDSZ;\n\n  /* Allocate addresses and aliases; ancount gives an upper bound for both. */\n  addrs = malloc(ancount * sizeof(struct in_addr));\n  if (!addrs)\n    {\n      free(hostname);\n      return ARES_ENOMEM;\n    }\n  aliases = malloc((ancount + 1) * sizeof(char *));\n  if (!aliases)\n    {\n      free(hostname);\n      free(addrs);\n      return ARES_ENOMEM;\n    }\n  naddrs = 0;\n  naliases = 0;\n\n  /* Examine each answer resource record (RR) in turn. */\n  for (i = 0; i < (int)ancount; i++)\n    {\n      /* Decode the RR up to the data field. */\n      status = ares_expand_name(aptr, abuf, alen, &rr_name, &len);\n      if (status != ARES_SUCCESS)\n\tbreak;\n      aptr += len;\n      if (aptr + RRFIXEDSZ > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n      rr_type = DNS_RR_TYPE(aptr);\n      rr_class = DNS_RR_CLASS(aptr);\n      rr_len = DNS_RR_LEN(aptr);\n      aptr += RRFIXEDSZ;\n\n      if (rr_class == C_IN && rr_type == T_A\n\t  && rr_len == sizeof(struct in_addr)\n\t  && strcasecmp(rr_name, hostname) == 0)\n\t{\n\t  memcpy(&addrs[naddrs], aptr, sizeof(struct in_addr));\n\t  naddrs++;\n\t  status = ARES_SUCCESS;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_CNAME)\n\t{\n\t  /* Record the RR name as an alias. */\n\t  aliases[naliases] = rr_name;\n\t  naliases++;\n\n\t  /* Decode the RR data and replace the hostname with it. */\n\t  status = ares_expand_name(aptr, abuf, alen, &rr_data, &len);\n\t  if (status != ARES_SUCCESS)\n\t    break;\n\t  free(hostname);\n\t  hostname = rr_data;\n\t}\n      else\n\tfree(rr_name);\n\n      aptr += rr_len;\n      if (aptr > abuf + alen)\n\t{\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n    }\n\n  if (status == ARES_SUCCESS && naddrs == 0)\n    status = ARES_ENODATA;\n  if (status == ARES_SUCCESS)\n    {\n      /* We got our answer.  Allocate memory to build the host entry. */\n      aliases[naliases] = NULL;\n      hostent = malloc(sizeof(struct hostent));\n      if (hostent)\n\t{\n\t  hostent->h_addr_list = malloc((naddrs + 1) * sizeof(char *));\n\t  if (hostent->h_addr_list)\n\t    {\n\t      /* Fill in the hostent and return successfully. */\n\t      hostent->h_name = hostname;\n\t      hostent->h_aliases = aliases;\n\t      hostent->h_addrtype = AF_INET;\n\t      hostent->h_length = sizeof(struct in_addr);\n\t      for (i = 0; i < naddrs; i++)\n\t\thostent->h_addr_list[i] = (char *) &addrs[i];\n\t      hostent->h_addr_list[naddrs] = NULL;\n\t      *host = hostent;\n\t      return ARES_SUCCESS;\n\t    }\n\t  free(hostent);\n\t}\n      status = ARES_ENOMEM;\n    }\n  for (i = 0; i < naliases; i++)\n    free(aliases[i]);\n  free(aliases);\n  free(addrs);\n  free(hostname);\n  return status;\n}", "func_src_after": "int ares_parse_a_reply(const unsigned char *abuf, int alen,\n\t\t       struct hostent **host)\n{\n  unsigned int qdcount, ancount;\n  int status, i, rr_type, rr_class, rr_len, naddrs;\n  long int len;\n  int naliases;\n  const unsigned char *aptr;\n  char *hostname, *rr_name, *rr_data, **aliases;\n  struct in_addr *addrs;\n  struct hostent *hostent;\n\n  /* Set *host to NULL for all failure cases. */\n  *host = NULL;\n\n  /* Give up if abuf doesn't have room for a header. */\n  if (alen < HFIXEDSZ)\n    return ARES_EBADRESP;\n\n  /* Fetch the question and answer count from the header. */\n  qdcount = DNS_HEADER_QDCOUNT(abuf);\n  ancount = DNS_HEADER_ANCOUNT(abuf);\n  if (qdcount != 1)\n    return ARES_EBADRESP;\n\n  /* Expand the name from the question, and skip past the question. */\n  aptr = abuf + HFIXEDSZ;\n  status = ares_expand_name(aptr, abuf, alen, &hostname, &len);\n  if (status != ARES_SUCCESS)\n    return status;\n  if (aptr + len + QFIXEDSZ > abuf + alen)\n    {\n      free(hostname);\n      return ARES_EBADRESP;\n    }\n  aptr += len + QFIXEDSZ;\n\n  /* Allocate addresses and aliases; ancount gives an upper bound for both. */\n  addrs = malloc(ancount * sizeof(struct in_addr));\n  if (!addrs)\n    {\n      free(hostname);\n      return ARES_ENOMEM;\n    }\n  aliases = malloc((ancount + 1) * sizeof(char *));\n  if (!aliases)\n    {\n      free(hostname);\n      free(addrs);\n      return ARES_ENOMEM;\n    }\n  naddrs = 0;\n  naliases = 0;\n\n  /* Examine each answer resource record (RR) in turn. */\n  for (i = 0; i < (int)ancount; i++)\n    {\n      /* Decode the RR up to the data field. */\n      status = ares_expand_name(aptr, abuf, alen, &rr_name, &len);\n      if (status != ARES_SUCCESS)\n\tbreak;\n      aptr += len;\n      if (aptr + RRFIXEDSZ > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n      rr_type = DNS_RR_TYPE(aptr);\n      rr_class = DNS_RR_CLASS(aptr);\n      rr_len = DNS_RR_LEN(aptr);\n      aptr += RRFIXEDSZ;\n      if (aptr + rr_len > abuf + alen)\n\t{\n\t  free(rr_name);\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_A\n\t  && rr_len == sizeof(struct in_addr)\n\t  && strcasecmp(rr_name, hostname) == 0)\n\t{\n\t  memcpy(&addrs[naddrs], aptr, sizeof(struct in_addr));\n\t  naddrs++;\n\t  status = ARES_SUCCESS;\n\t}\n\n      if (rr_class == C_IN && rr_type == T_CNAME)\n\t{\n\t  /* Record the RR name as an alias. */\n\t  aliases[naliases] = rr_name;\n\t  naliases++;\n\n\t  /* Decode the RR data and replace the hostname with it. */\n\t  status = ares_expand_name(aptr, abuf, alen, &rr_data, &len);\n\t  if (status != ARES_SUCCESS)\n\t    break;\n\t  free(hostname);\n\t  hostname = rr_data;\n\t}\n      else\n\tfree(rr_name);\n\n      aptr += rr_len;\n      if (aptr > abuf + alen)\n\t{\n\t  status = ARES_EBADRESP;\n\t  break;\n\t}\n    }\n\n  if (status == ARES_SUCCESS && naddrs == 0)\n    status = ARES_ENODATA;\n  if (status == ARES_SUCCESS)\n    {\n      /* We got our answer.  Allocate memory to build the host entry. */\n      aliases[naliases] = NULL;\n      hostent = malloc(sizeof(struct hostent));\n      if (hostent)\n\t{\n\t  hostent->h_addr_list = malloc((naddrs + 1) * sizeof(char *));\n\t  if (hostent->h_addr_list)\n\t    {\n\t      /* Fill in the hostent and return successfully. */\n\t      hostent->h_name = hostname;\n\t      hostent->h_aliases = aliases;\n\t      hostent->h_addrtype = AF_INET;\n\t      hostent->h_length = sizeof(struct in_addr);\n\t      for (i = 0; i < naddrs; i++)\n\t\thostent->h_addr_list[i] = (char *) &addrs[i];\n\t      hostent->h_addr_list[naddrs] = NULL;\n\t      *host = hostent;\n\t      return ARES_SUCCESS;\n\t    }\n\t  free(hostent);\n\t}\n      status = ARES_ENOMEM;\n    }\n  for (i = 0; i < naliases; i++)\n    free(aliases[i]);\n  free(aliases);\n  free(addrs);\n  free(hostname);\n  return status;\n}", "commit_link": "github.com/resiprocate/resiprocate/commit/d67a9ca6fd06ca65d23e313bdbad1ef4dd3aa0df", "file_name": "rutil/dns/ares/ares_parse_a_reply.c", "vul_type": "cwe-125", "description": "In C, write a function to parse a DNS response and populate a hostent structure with the results."}
{"func_name": "repack", "func_src_before": "def repack(host, targets, channel='stable'):\n  print(\"Repacking rust for %s...\" % host)\n  url = 'https://static.rust-lang.org/dist/channel-rust-' + channel + '.toml'\n  req = requests.get(url)\n  req.raise_for_status()\n  manifest = toml.loads(req.content)\n  if manifest['manifest-version'] != '2':\n    print('ERROR: unrecognized manifest version %s.' % manifest['manifest-version'])\n    return\n  print('Using manifest for rust %s as of %s.' % (channel, manifest['date']))\n  rustc_version, rustc = package(manifest, 'rustc', host)\n  if rustc['available']:\n    print('rustc %s\\n  %s\\n  %s' % (rustc_version, rustc['url'], rustc['hash']))\n    fetch(rustc['url'])\n  cargo_version, cargo = package(manifest, 'cargo', host)\n  if cargo['available']:\n    print('cargo %s\\n  %s\\n  %s' % (cargo_version, cargo['url'], cargo['hash']))\n    fetch(cargo['url'])\n  stds = []\n  for target in targets:\n      version, info = package(manifest, 'rust-std', target)\n      if info['available']:\n        print('rust-std %s\\n  %s\\n  %s' % (version, info['url'], info['hash']))\n        fetch(info['url'])\n        stds.append(info)\n  print('Installing packages...')\n  tar_basename = 'rustc-%s-repack' % host\n  install_dir = 'rustc'\n  subprocess.check_call(['rm', '-rf', install_dir])\n  install(os.path.basename(rustc['url']), install_dir)\n  install(os.path.basename(cargo['url']), install_dir)\n  for std in stds:\n    install(os.path.basename(std['url']), install_dir)\n  print('Tarring %s...' % tar_basename)\n  subprocess.check_call(['tar', 'cjf', tar_basename + '.tar.bz2', install_dir])\n  subprocess.check_call(['rm', '-rf', install_dir])", "func_src_after": "def repack(host, targets, channel='stable'):\n  url = 'https://static.rust-lang.org/dist/channel-rust-' + channel + '.toml'\n  req = requests.get(url)\n  req.raise_for_status()\n  manifest = toml.loads(req.content)\n  if manifest['manifest-version'] != '2':\n    print('ERROR: unrecognized manifest version %s.' % manifest['manifest-version'])\n    return\n  print('Using manifest for rust %s as of %s.' % (channel, manifest['date']))\n  rustc_version, rustc = package(manifest, 'rustc', host)\n  if rustc['available']:\n    print('rustc %s\\n  %s\\n  %s' % (rustc_version, rustc['url'], rustc['hash']))\n    fetch(rustc['url'])\n  cargo_version, cargo = package(manifest, 'cargo', host)\n  if cargo['available']:\n    print('cargo %s\\n  %s\\n  %s' % (cargo_version, cargo['url'], cargo['hash']))\n    fetch(cargo['url'])\n  stds = []\n  for target in targets:\n      version, info = package(manifest, 'rust-std', target)\n      if info['available']:\n        print('rust-std %s\\n  %s\\n  %s' % (version, info['url'], info['hash']))\n        fetch(info['url'])\n        stds.append(info)\n  print('Installing packages...')\n  tar_basename = 'rustc-%s-repack' % host\n  install_dir = 'rustc'\n  os.system('rm -rf %s' % install_dir)\n  install(os.path.basename(rustc['url']), install_dir)\n  install(os.path.basename(cargo['url']), install_dir)\n  for std in stds:\n    install(os.path.basename(std['url']), install_dir)\n  print('Tarring %s...' % tar_basename)\n  os.system('tar cjf %s.tar.bz2 %s/*' % (tar_basename, install_dir))\n  os.system('rm -rf %s' % install_dir)", "commit_link": "github.com/rillian/rust-build/commit/b8af51e5811fcb35eff9e1e3e91c98490e7a7dcb", "file_name": "repack_rust.py", "vul_type": "cwe-078", "description": "In Python, write a function named `repack` that downloads and installs specific Rust packages for a given host and target platforms, then repackages them into a tarball."}
{"func_name": "php_wddx_pop_element", "func_src_before": " */\nstatic void php_wddx_pop_element(void *user_data, const XML_Char *name)\n{\n\tst_entry \t\t\t*ent1, *ent2;\n\twddx_stack \t\t\t*stack = (wddx_stack *)user_data;\n\tHashTable \t\t\t*target_hash;\n\tzend_class_entry \t**pce;\n\tzval\t\t\t\t*obj;\n\tzval\t\t\t\t*tmp;\n\tTSRMLS_FETCH();\n\n/* OBJECTS_FIXME */\n\tif (stack->top == 0) {\n\t\treturn;\n\t}\n\n\tif (!strcmp(name, EL_STRING) || !strcmp(name, EL_NUMBER) ||\n\t\t!strcmp(name, EL_BOOLEAN) || !strcmp(name, EL_NULL) ||\n\t  \t!strcmp(name, EL_ARRAY) || !strcmp(name, EL_STRUCT) ||\n\t\t!strcmp(name, EL_RECORDSET) || !strcmp(name, EL_BINARY) ||\n\t\t!strcmp(name, EL_DATETIME)) {\n\t\twddx_stack_top(stack, (void**)&ent1);\n\n\t\tif (!ent1->data) {\n\t\t\tif (stack->top > 1) {\n\t\t\t\tstack->top--;\n\t\t\t} else {\n\t\t\t\tstack->done = 1;\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!strcmp(name, EL_BINARY)) {\n\t\t\tint new_len=0;\n\t\t\tunsigned char *new_str;\n\n\t\t\tnew_str = php_base64_decode(Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data), &new_len);\n\t\t\tSTR_FREE(Z_STRVAL_P(ent1->data));\n\t\t\tZ_STRVAL_P(ent1->data) = new_str;\n\t\t\tZ_STRLEN_P(ent1->data) = new_len;\n\t\t}\n\n\t\t/* Call __wakeup() method on the object. */\n\t\tif (Z_TYPE_P(ent1->data) == IS_OBJECT) {\n\t\t\tzval *fname, *retval = NULL;\n\n\t\t\tMAKE_STD_ZVAL(fname);\n\t\t\tZVAL_STRING(fname, \"__wakeup\", 1);\n\n\t\t\tcall_user_function_ex(NULL, &ent1->data, fname, &retval, 0, 0, 0, NULL TSRMLS_CC);\n\n\t\t\tzval_dtor(fname);\n\t\t\tFREE_ZVAL(fname);\n\t\t\tif (retval) {\n\t\t\t\tzval_ptr_dtor(&retval);\n\t\t\t}\n\t\t}\n\n\t\tif (stack->top > 1) {\n\t\t\tstack->top--;\n\t\t\twddx_stack_top(stack, (void**)&ent2);\n\n\t\t\t/* if non-existent field */\n\t\t\tif (ent2->type == ST_FIELD && ent2->data == NULL) {\n\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\tefree(ent1);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (Z_TYPE_P(ent2->data) == IS_ARRAY || Z_TYPE_P(ent2->data) == IS_OBJECT) {\n\t\t\t\ttarget_hash = HASH_OF(ent2->data);\n\n\t\t\t\tif (ent1->varname) {\n\t\t\t\t\tif (!strcmp(ent1->varname, PHP_CLASS_NAME_VAR) &&\n\t\t\t\t\t\tZ_TYPE_P(ent1->data) == IS_STRING && Z_STRLEN_P(ent1->data) &&\n\t\t\t\t\t\tent2->type == ST_STRUCT && Z_TYPE_P(ent2->data) == IS_ARRAY) {\n\t\t\t\t\t\tzend_bool incomplete_class = 0;\n\n\t\t\t\t\t\tzend_str_tolower(Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data));\n\t\t\t\t\t\tif (zend_hash_find(EG(class_table), Z_STRVAL_P(ent1->data),\n\t\t\t\t\t\t\t\t\t\t   Z_STRLEN_P(ent1->data)+1, (void **) &pce)==FAILURE) {\n\t\t\t\t\t\t\tincomplete_class = 1;\n\t\t\t\t\t\t\tpce = &PHP_IC_ENTRY;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Initialize target object */\n\t\t\t\t\t\tMAKE_STD_ZVAL(obj);\n\t\t\t\t\t\tobject_init_ex(obj, *pce);\n\n\t\t\t\t\t\t/* Merge current hashtable with object's default properties */\n\t\t\t\t\t\tzend_hash_merge(Z_OBJPROP_P(obj),\n\t\t\t\t\t\t\t\t\t\tZ_ARRVAL_P(ent2->data),\n\t\t\t\t\t\t\t\t\t\t(void (*)(void *)) zval_add_ref,\n\t\t\t\t\t\t\t\t\t\t(void *) &tmp, sizeof(zval *), 0);\n\n\t\t\t\t\t\tif (incomplete_class) {\n\t\t\t\t\t\t\tphp_store_class_name(obj, Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Clean up old array entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent2->data);\n\n\t\t\t\t\t\t/* Set stack entry to point to the newly created object */\n\t\t\t\t\t\tent2->data = obj;\n\n\t\t\t\t\t\t/* Clean up class name var entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\t\t} else if (Z_TYPE_P(ent2->data) == IS_OBJECT) {\n\t\t\t\t\t\tzend_class_entry *old_scope = EG(scope);\n\n\t\t\t\t\t\tEG(scope) = Z_OBJCE_P(ent2->data);\n\t\t\t\t\t\tZ_DELREF_P(ent1->data);\n\t\t\t\t\t\tadd_property_zval(ent2->data, ent1->varname, ent1->data);\n\t\t\t\t\t\tEG(scope) = old_scope;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzend_symtable_update(target_hash, ent1->varname, strlen(ent1->varname)+1, &ent1->data, sizeof(zval *), NULL);\n\t\t\t\t\t}\n\t\t\t\t\tefree(ent1->varname);\n\t\t\t\t} else\t{\n\t\t\t\t\tzend_hash_next_index_insert(target_hash, &ent1->data, sizeof(zval *), NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t} else {\n\t\t\tstack->done = 1;\n\t\t}\n\t} else if (!strcmp(name, EL_VAR) && stack->varname) {\n\t\tefree(stack->varname);\n\t\tstack->varname = NULL;\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tst_entry *ent;\n\t\twddx_stack_top(stack, (void **)&ent);\n\t\tefree(ent);\n\t\tstack->top--;\n\t}", "func_src_after": " */\nstatic void php_wddx_pop_element(void *user_data, const XML_Char *name)\n{\n\tst_entry \t\t\t*ent1, *ent2;\n\twddx_stack \t\t\t*stack = (wddx_stack *)user_data;\n\tHashTable \t\t\t*target_hash;\n\tzend_class_entry \t**pce;\n\tzval\t\t\t\t*obj;\n\tzval\t\t\t\t*tmp;\n\tTSRMLS_FETCH();\n\n/* OBJECTS_FIXME */\n\tif (stack->top == 0) {\n\t\treturn;\n\t}\n\n\tif (!strcmp(name, EL_STRING) || !strcmp(name, EL_NUMBER) ||\n\t\t!strcmp(name, EL_BOOLEAN) || !strcmp(name, EL_NULL) ||\n\t  \t!strcmp(name, EL_ARRAY) || !strcmp(name, EL_STRUCT) ||\n\t\t!strcmp(name, EL_RECORDSET) || !strcmp(name, EL_BINARY) ||\n\t\t!strcmp(name, EL_DATETIME)) {\n\t\twddx_stack_top(stack, (void**)&ent1);\n\n\t\tif (!ent1->data) {\n\t\t\tif (stack->top > 1) {\n\t\t\t\tstack->top--;\n\t\t\t} else {\n\t\t\t\tstack->done = 1;\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!strcmp(name, EL_BINARY)) {\n\t\t\tint new_len=0;\n\t\t\tunsigned char *new_str;\n\n\t\t\tnew_str = php_base64_decode(Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data), &new_len);\n\t\t\tSTR_FREE(Z_STRVAL_P(ent1->data));\n\t\t\tif (new_str) {\n\t\t\t\tZ_STRVAL_P(ent1->data) = new_str;\n\t\t\t\tZ_STRLEN_P(ent1->data) = new_len;\n\t\t\t} else {\n\t\t\t\tZVAL_EMPTY_STRING(ent1->data);\n\t\t\t}\n\t\t}\n\n\t\t/* Call __wakeup() method on the object. */\n\t\tif (Z_TYPE_P(ent1->data) == IS_OBJECT) {\n\t\t\tzval *fname, *retval = NULL;\n\n\t\t\tMAKE_STD_ZVAL(fname);\n\t\t\tZVAL_STRING(fname, \"__wakeup\", 1);\n\n\t\t\tcall_user_function_ex(NULL, &ent1->data, fname, &retval, 0, 0, 0, NULL TSRMLS_CC);\n\n\t\t\tzval_dtor(fname);\n\t\t\tFREE_ZVAL(fname);\n\t\t\tif (retval) {\n\t\t\t\tzval_ptr_dtor(&retval);\n\t\t\t}\n\t\t}\n\n\t\tif (stack->top > 1) {\n\t\t\tstack->top--;\n\t\t\twddx_stack_top(stack, (void**)&ent2);\n\n\t\t\t/* if non-existent field */\n\t\t\tif (ent2->type == ST_FIELD && ent2->data == NULL) {\n\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\tefree(ent1);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tif (Z_TYPE_P(ent2->data) == IS_ARRAY || Z_TYPE_P(ent2->data) == IS_OBJECT) {\n\t\t\t\ttarget_hash = HASH_OF(ent2->data);\n\n\t\t\t\tif (ent1->varname) {\n\t\t\t\t\tif (!strcmp(ent1->varname, PHP_CLASS_NAME_VAR) &&\n\t\t\t\t\t\tZ_TYPE_P(ent1->data) == IS_STRING && Z_STRLEN_P(ent1->data) &&\n\t\t\t\t\t\tent2->type == ST_STRUCT && Z_TYPE_P(ent2->data) == IS_ARRAY) {\n\t\t\t\t\t\tzend_bool incomplete_class = 0;\n\n\t\t\t\t\t\tzend_str_tolower(Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data));\n\t\t\t\t\t\tif (zend_hash_find(EG(class_table), Z_STRVAL_P(ent1->data),\n\t\t\t\t\t\t\t\t\t\t   Z_STRLEN_P(ent1->data)+1, (void **) &pce)==FAILURE) {\n\t\t\t\t\t\t\tincomplete_class = 1;\n\t\t\t\t\t\t\tpce = &PHP_IC_ENTRY;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Initialize target object */\n\t\t\t\t\t\tMAKE_STD_ZVAL(obj);\n\t\t\t\t\t\tobject_init_ex(obj, *pce);\n\n\t\t\t\t\t\t/* Merge current hashtable with object's default properties */\n\t\t\t\t\t\tzend_hash_merge(Z_OBJPROP_P(obj),\n\t\t\t\t\t\t\t\t\t\tZ_ARRVAL_P(ent2->data),\n\t\t\t\t\t\t\t\t\t\t(void (*)(void *)) zval_add_ref,\n\t\t\t\t\t\t\t\t\t\t(void *) &tmp, sizeof(zval *), 0);\n\n\t\t\t\t\t\tif (incomplete_class) {\n\t\t\t\t\t\t\tphp_store_class_name(obj, Z_STRVAL_P(ent1->data), Z_STRLEN_P(ent1->data));\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t/* Clean up old array entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent2->data);\n\n\t\t\t\t\t\t/* Set stack entry to point to the newly created object */\n\t\t\t\t\t\tent2->data = obj;\n\n\t\t\t\t\t\t/* Clean up class name var entry */\n\t\t\t\t\t\tzval_ptr_dtor(&ent1->data);\n\t\t\t\t\t} else if (Z_TYPE_P(ent2->data) == IS_OBJECT) {\n\t\t\t\t\t\tzend_class_entry *old_scope = EG(scope);\n\n\t\t\t\t\t\tEG(scope) = Z_OBJCE_P(ent2->data);\n\t\t\t\t\t\tZ_DELREF_P(ent1->data);\n\t\t\t\t\t\tadd_property_zval(ent2->data, ent1->varname, ent1->data);\n\t\t\t\t\t\tEG(scope) = old_scope;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tzend_symtable_update(target_hash, ent1->varname, strlen(ent1->varname)+1, &ent1->data, sizeof(zval *), NULL);\n\t\t\t\t\t}\n\t\t\t\t\tefree(ent1->varname);\n\t\t\t\t} else\t{\n\t\t\t\t\tzend_hash_next_index_insert(target_hash, &ent1->data, sizeof(zval *), NULL);\n\t\t\t\t}\n\t\t\t}\n\t\t\tefree(ent1);\n\t\t} else {\n\t\t\tstack->done = 1;\n\t\t}\n\t} else if (!strcmp(name, EL_VAR) && stack->varname) {\n\t\tefree(stack->varname);\n\t\tstack->varname = NULL;\n\t} else if (!strcmp(name, EL_FIELD)) {\n\t\tst_entry *ent;\n\t\twddx_stack_top(stack, (void **)&ent);\n\t\tefree(ent);\n\t\tstack->top--;\n\t}", "commit_link": "github.com/php/php-src/commit/698a691724c0a949295991e5df091ce16f899e02", "file_name": "ext/wddx/wddx.c", "vul_type": "cwe-476", "description": "Write a PHP function that handles the end of an XML element during WDDX deserialization."}
{"func_name": "onig_new_deluxe", "func_src_before": "onig_new_deluxe(regex_t** reg, const UChar* pattern, const UChar* pattern_end,\n                OnigCompileInfo* ci, OnigErrorInfo* einfo)\n{\n  int r;\n  UChar *cpat, *cpat_end;\n\n  if (IS_NOT_NULL(einfo)) einfo->par = (UChar* )NULL;\n\n  if (ci->pattern_enc != ci->target_enc) {\n    return ONIGERR_NOT_SUPPORTED_ENCODING_COMBINATION;\n  }\n  else {\n    cpat     = (UChar* )pattern;\n    cpat_end = (UChar* )pattern_end;\n  }\n\n  *reg = (regex_t* )xmalloc(sizeof(regex_t));\n  if (IS_NULL(*reg)) {\n    r = ONIGERR_MEMORY;\n    goto err2;\n  }\n\n  r = onig_reg_init(*reg, ci->option, ci->case_fold_flag, ci->target_enc,\n                    ci->syntax);\n  if (r != 0) goto err;\n\n  r = onig_compile(*reg, cpat, cpat_end, einfo);\n  if (r != 0) {\n  err:\n    onig_free(*reg);\n    *reg = NULL;\n  }\n\n err2:\n  if (cpat != pattern) xfree(cpat);\n\n  return r;\n}", "func_src_after": "onig_new_deluxe(regex_t** reg, const UChar* pattern, const UChar* pattern_end,\n                OnigCompileInfo* ci, OnigErrorInfo* einfo)\n{\n  int r;\n  UChar *cpat, *cpat_end;\n\n  if (IS_NOT_NULL(einfo)) einfo->par = (UChar* )NULL;\n\n  if (ci->pattern_enc != ci->target_enc) {\n    r = conv_encoding(ci->pattern_enc, ci->target_enc, pattern, pattern_end,\n                      &cpat, &cpat_end);\n    if (r != 0) return r;\n  }\n  else {\n    cpat     = (UChar* )pattern;\n    cpat_end = (UChar* )pattern_end;\n  }\n\n  *reg = (regex_t* )xmalloc(sizeof(regex_t));\n  if (IS_NULL(*reg)) {\n    r = ONIGERR_MEMORY;\n    goto err2;\n  }\n\n  r = onig_reg_init(*reg, ci->option, ci->case_fold_flag, ci->target_enc,\n                    ci->syntax);\n  if (r != 0) goto err;\n\n  r = onig_compile(*reg, cpat, cpat_end, einfo);\n  if (r != 0) {\n  err:\n    onig_free(*reg);\n    *reg = NULL;\n  }\n\n err2:\n  if (cpat != pattern) xfree(cpat);\n\n  return r;\n}", "commit_link": "github.com/kkos/oniguruma/commit/0f7f61ed1b7b697e283e37bd2d731d0bd57adb55", "file_name": "src/regext.c", "vul_type": "cwe-416", "description": "Write a C function named `onig_new_deluxe` that initializes a new regular expression object with error handling."}
{"func_name": "ls", "func_src_before": "    def ls(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n        command = [\n            'rclone',\n            'lsjson',\n            'current:{}'.format(path),\n        ]\n\n        try:\n            result = self._execute(command, credentials)\n            result = json.loads(result)\n            return result\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "func_src_after": "    def ls(self, data, path):\n        credentials = self._formatCredentials(data, name='current')\n\n        command = (\n            '{credentials} '\n            'rclone lsjson current:{path}'\n        ).format(\n            credentials=credentials,\n            path=path,\n        )\n\n        try:\n            result = self._execute(command)\n            result = json.loads(result)\n            return result\n        except subprocess.CalledProcessError as e:\n            raise RcloneException(sanitize(str(e)))", "commit_link": "github.com/FredHutch/motuz/commit/045468cb9bff47bb3bb72268b6d5a3fe44e383db", "file_name": "src/backend/api/utils/rclone_connection.py", "vul_type": "cwe-078", "description": "Write a Python function that lists files in JSON format at a given path using rclone, handling exceptions."}
{"func_name": "ape_decode_frame", "func_src_before": "static int ape_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame_ptr, AVPacket *avpkt)\n{\n    AVFrame *frame     = data;\n    const uint8_t *buf = avpkt->data;\n    APEContext *s = avctx->priv_data;\n    uint8_t *sample8;\n    int16_t *sample16;\n    int32_t *sample24;\n    int i, ch, ret;\n    int blockstodecode;\n\n    /* this should never be negative, but bad things will happen if it is, so\n       check it just to make sure. */\n    av_assert0(s->samples >= 0);\n\n    if(!s->samples){\n        uint32_t nblocks, offset;\n        int buf_size;\n\n        if (!avpkt->size) {\n            *got_frame_ptr = 0;\n            return 0;\n        }\n        if (avpkt->size < 8) {\n            av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        buf_size = avpkt->size & ~3;\n        if (buf_size != avpkt->size) {\n            av_log(avctx, AV_LOG_WARNING, \"packet size is not a multiple of 4. \"\n                   \"extra bytes at the end will be skipped.\\n\");\n        }\n        if (s->fileversion < 3950) // previous versions overread two bytes\n            buf_size += 2;\n        av_fast_padded_malloc(&s->data, &s->data_size, buf_size);\n        if (!s->data)\n            return AVERROR(ENOMEM);\n        s->bdsp.bswap_buf((uint32_t *) s->data, (const uint32_t *) buf,\n                          buf_size >> 2);\n        memset(s->data + (buf_size & ~3), 0, buf_size & 3);\n        s->ptr = s->data;\n        s->data_end = s->data + buf_size;\n\n        nblocks = bytestream_get_be32(&s->ptr);\n        offset  = bytestream_get_be32(&s->ptr);\n        if (s->fileversion >= 3900) {\n            if (offset > 3) {\n                av_log(avctx, AV_LOG_ERROR, \"Incorrect offset passed\\n\");\n                s->data = NULL;\n                return AVERROR_INVALIDDATA;\n            }\n            if (s->data_end - s->ptr < offset) {\n                av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            s->ptr += offset;\n        } else {\n            if ((ret = init_get_bits8(&s->gb, s->ptr, s->data_end - s->ptr)) < 0)\n                return ret;\n            if (s->fileversion > 3800)\n                skip_bits_long(&s->gb, offset * 8);\n            else\n                skip_bits_long(&s->gb, offset);\n        }\n\n        if (!nblocks || nblocks > INT_MAX) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample count: %\"PRIu32\".\\n\",\n                   nblocks);\n            return AVERROR_INVALIDDATA;\n        }\n\n        /* Initialize the frame decoder */\n        if (init_frame_decoder(s) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error reading frame header\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        s->samples = nblocks;\n    }\n\n    if (!s->data) {\n        *got_frame_ptr = 0;\n        return avpkt->size;\n    }\n\n    blockstodecode = FFMIN(s->blocks_per_loop, s->samples);\n    // for old files coefficients were not interleaved,\n    // so we need to decode all of them at once\n    if (s->fileversion < 3930)\n        blockstodecode = s->samples;\n\n    /* reallocate decoded sample buffer if needed */\n    av_fast_malloc(&s->decoded_buffer, &s->decoded_size,\n                   2 * FFALIGN(blockstodecode, 8) * sizeof(*s->decoded_buffer));\n    if (!s->decoded_buffer)\n        return AVERROR(ENOMEM);\n    memset(s->decoded_buffer, 0, s->decoded_size);\n    s->decoded[0] = s->decoded_buffer;\n    s->decoded[1] = s->decoded_buffer + FFALIGN(blockstodecode, 8);\n\n    /* get output buffer */\n    frame->nb_samples = blockstodecode;\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n\n    s->error=0;\n\n    if ((s->channels == 1) || (s->frameflags & APE_FRAMECODE_PSEUDO_STEREO))\n        ape_unpack_mono(s, blockstodecode);\n    else\n        ape_unpack_stereo(s, blockstodecode);\n    emms_c();\n\n    if (s->error) {\n        s->samples=0;\n        av_log(avctx, AV_LOG_ERROR, \"Error decoding frame\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    switch (s->bps) {\n    case 8:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample8 = (uint8_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample8++ = (s->decoded[ch][i] + 0x80) & 0xff;\n        }\n        break;\n    case 16:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample16 = (int16_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample16++ = s->decoded[ch][i];\n        }\n        break;\n    case 24:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample24 = (int32_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample24++ = s->decoded[ch][i] << 8;\n        }\n        break;\n    }\n\n    s->samples -= blockstodecode;\n\n    *got_frame_ptr = 1;\n\n    return !s->samples ? avpkt->size : 0;\n}", "func_src_after": "static int ape_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame_ptr, AVPacket *avpkt)\n{\n    AVFrame *frame     = data;\n    const uint8_t *buf = avpkt->data;\n    APEContext *s = avctx->priv_data;\n    uint8_t *sample8;\n    int16_t *sample16;\n    int32_t *sample24;\n    int i, ch, ret;\n    int blockstodecode;\n    uint64_t decoded_buffer_size;\n\n    /* this should never be negative, but bad things will happen if it is, so\n       check it just to make sure. */\n    av_assert0(s->samples >= 0);\n\n    if(!s->samples){\n        uint32_t nblocks, offset;\n        int buf_size;\n\n        if (!avpkt->size) {\n            *got_frame_ptr = 0;\n            return 0;\n        }\n        if (avpkt->size < 8) {\n            av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        buf_size = avpkt->size & ~3;\n        if (buf_size != avpkt->size) {\n            av_log(avctx, AV_LOG_WARNING, \"packet size is not a multiple of 4. \"\n                   \"extra bytes at the end will be skipped.\\n\");\n        }\n        if (s->fileversion < 3950) // previous versions overread two bytes\n            buf_size += 2;\n        av_fast_padded_malloc(&s->data, &s->data_size, buf_size);\n        if (!s->data)\n            return AVERROR(ENOMEM);\n        s->bdsp.bswap_buf((uint32_t *) s->data, (const uint32_t *) buf,\n                          buf_size >> 2);\n        memset(s->data + (buf_size & ~3), 0, buf_size & 3);\n        s->ptr = s->data;\n        s->data_end = s->data + buf_size;\n\n        nblocks = bytestream_get_be32(&s->ptr);\n        offset  = bytestream_get_be32(&s->ptr);\n        if (s->fileversion >= 3900) {\n            if (offset > 3) {\n                av_log(avctx, AV_LOG_ERROR, \"Incorrect offset passed\\n\");\n                s->data = NULL;\n                return AVERROR_INVALIDDATA;\n            }\n            if (s->data_end - s->ptr < offset) {\n                av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            s->ptr += offset;\n        } else {\n            if ((ret = init_get_bits8(&s->gb, s->ptr, s->data_end - s->ptr)) < 0)\n                return ret;\n            if (s->fileversion > 3800)\n                skip_bits_long(&s->gb, offset * 8);\n            else\n                skip_bits_long(&s->gb, offset);\n        }\n\n        if (!nblocks || nblocks > INT_MAX / 2 / sizeof(*s->decoded_buffer) - 8) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample count: %\"PRIu32\".\\n\",\n                   nblocks);\n            return AVERROR_INVALIDDATA;\n        }\n\n        /* Initialize the frame decoder */\n        if (init_frame_decoder(s) < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Error reading frame header\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n        s->samples = nblocks;\n    }\n\n    if (!s->data) {\n        *got_frame_ptr = 0;\n        return avpkt->size;\n    }\n\n    blockstodecode = FFMIN(s->blocks_per_loop, s->samples);\n    // for old files coefficients were not interleaved,\n    // so we need to decode all of them at once\n    if (s->fileversion < 3930)\n        blockstodecode = s->samples;\n\n    /* reallocate decoded sample buffer if needed */\n    decoded_buffer_size = 2LL * FFALIGN(blockstodecode, 8) * sizeof(*s->decoded_buffer);\n    av_assert0(decoded_buffer_size <= INT_MAX);\n    av_fast_malloc(&s->decoded_buffer, &s->decoded_size, decoded_buffer_size);\n    if (!s->decoded_buffer)\n        return AVERROR(ENOMEM);\n    memset(s->decoded_buffer, 0, s->decoded_size);\n    s->decoded[0] = s->decoded_buffer;\n    s->decoded[1] = s->decoded_buffer + FFALIGN(blockstodecode, 8);\n\n    /* get output buffer */\n    frame->nb_samples = blockstodecode;\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n\n    s->error=0;\n\n    if ((s->channels == 1) || (s->frameflags & APE_FRAMECODE_PSEUDO_STEREO))\n        ape_unpack_mono(s, blockstodecode);\n    else\n        ape_unpack_stereo(s, blockstodecode);\n    emms_c();\n\n    if (s->error) {\n        s->samples=0;\n        av_log(avctx, AV_LOG_ERROR, \"Error decoding frame\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    switch (s->bps) {\n    case 8:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample8 = (uint8_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample8++ = (s->decoded[ch][i] + 0x80) & 0xff;\n        }\n        break;\n    case 16:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample16 = (int16_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample16++ = s->decoded[ch][i];\n        }\n        break;\n    case 24:\n        for (ch = 0; ch < s->channels; ch++) {\n            sample24 = (int32_t *)frame->data[ch];\n            for (i = 0; i < blockstodecode; i++)\n                *sample24++ = s->decoded[ch][i] << 8;\n        }\n        break;\n    }\n\n    s->samples -= blockstodecode;\n\n    *got_frame_ptr = 1;\n\n    return !s->samples ? avpkt->size : 0;\n}", "commit_link": "github.com/FFmpeg/FFmpeg/commit/ba4beaf6149f7241c8bd85fe853318c2f6837ad0", "file_name": "libavcodec/apedec.c", "vul_type": "cwe-125", "description": "Write a C function named `ape_decode_frame` for decoding an audio frame in the APE codec."}
{"func_name": "nav_path", "func_src_before": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=part, href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "func_src_after": "def nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=request.server.escape(part), href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items", "commit_link": "github.com/viewvc/viewvc/commit/9dcfc7daa4c940992920d3b2fbd317da20e44aad", "file_name": "lib/viewvc.py", "vul_type": "cwe-079", "description": "Write a Python function that generates a breadcrumb navigation path from a request object."}
{"func_name": "get_max_task_id_for_project", "func_src_before": "    @staticmethod\n    def get_max_task_id_for_project(project_id: int):\n        \"\"\"Gets the nights task id currently in use on a project\"\"\"\n        sql = \"\"\"select max(id) from tasks where project_id = {0} GROUP BY project_id\"\"\".format(project_id)\n        result = db.engine.execute(sql)\n        if result.rowcount == 0:\n            raise NotFound()\n        for row in result:\n            return row[0]", "func_src_after": "    @staticmethod\n    def get_max_task_id_for_project(project_id: int):\n        \"\"\"Gets the nights task id currently in use on a project\"\"\"\n        sql = \"\"\"select max(id) from tasks where project_id = :project_id GROUP BY project_id\"\"\"\n        result = db.engine.execute(text(sql), project_id=project_id)\n        if result.rowcount == 0:\n            raise NotFound()\n        for row in result:\n            return row[0]", "commit_link": "github.com/hotosm/tasking-manager/commit/dee040a2d22b3c4d5e38e2dbf8c6b651ad4c241a", "file_name": "server/models/postgis/task.py", "vul_type": "cwe-089", "description": "Write a Python method to fetch the highest task ID for a given project ID from a database, raising an exception if no tasks are found."}
{"func_name": "link_dialog", "func_src_before": "def link_dialog(request):\n    # list of wiki pages\n    name = request.values.get(\"pagename\", \"\")\n    if name:\n        from MoinMoin import search\n        # XXX error handling!\n        searchresult = search.searchPages(request, 't:\"%s\"' % name)\n\n        pages = [p.page_name for p in searchresult.hits]\n        pages.sort()\n        pages[0:0] = [name]\n        page_list = '''\n         <tr>\n          <td colspan=2>\n           <select id=\"sctPagename\" size=\"1\" onchange=\"OnChangePagename(this.value);\">\n           %s\n           </select>\n          <td>\n         </tr>\n''' % \"\\n\".join(['<option value=\"%s\">%s</option>' % (wikiutil.escape(page), wikiutil.escape(page))\n                 for page in pages])\n    else:\n        page_list = \"\"\n\n    # list of interwiki names\n    interwiki_list = wikiutil.load_wikimap(request)\n    interwiki = interwiki_list.keys()\n    interwiki.sort()\n    iwpreferred = request.cfg.interwiki_preferred[:]\n    if not iwpreferred or iwpreferred and iwpreferred[-1] is not None:\n        resultlist = iwpreferred\n        for iw in interwiki:\n            if not iw in iwpreferred:\n                resultlist.append(iw)\n    else:\n        resultlist = iwpreferred[:-1]\n    interwiki = \"\\n\".join(\n        ['<option value=\"%s\">%s</option>' % (wikiutil.escape(key), wikiutil.escape(key))\n         for key in resultlist])\n\n    # wiki url\n    url_prefix_static = request.cfg.url_prefix_static\n    scriptname = request.script_root + '/'\n    action = scriptname\n    basepage = wikiutil.escape(request.page.page_name)\n    request.write(u'''\n<!--\n * FCKeditor - The text editor for internet\n * Copyright (C) 2003-2004 Frederico Caldeira Knabben\n *\n * Licensed under the terms of the GNU Lesser General Public License:\n *   http://www.opensource.org/licenses/lgpl-license.php\n *\n * For further information visit:\n *   http://www.fckeditor.net/\n *\n * File Name: fck_link.html\n *  Link dialog window.\n *\n * Version:  2.0 FC (Preview)\n * Modified: 2005-02-18 23:55:22\n *\n * File Authors:\n *   Frederico Caldeira Knabben (fredck@fckeditor.net)\n-->\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n<meta name=\"robots\" content=\"index,nofollow\">\n<html>\n <head>\n  <title>Link Properties</title>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"robots\" content=\"noindex,nofollow\" />\n  <script src=\"%(url_prefix_static)s/applets/FCKeditor/editor/dialog/common/fck_dialog_common.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinlink/fck_link.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinurllib.js\" type=\"text/javascript\"></script>\n </head>\n <body scroll=\"no\" style=\"OVERFLOW: hidden\">\n  <div id=\"divInfo\" style=\"DISPLAY: none\">\n   <span fckLang=\"DlgLnkType\">Link Type</span><br />\n   <select id=\"cmbLinkType\" onchange=\"SetLinkType(this.value);\">\n    <option value=\"wiki\" selected=\"selected\">WikiPage</option>\n    <option value=\"interwiki\">Interwiki</option>\n    <option value=\"url\" fckLang=\"DlgLnkTypeURL\">URL</option>\n   </select>\n   <br />\n   <br />\n   <div id=\"divLinkTypeWiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <form action=%(action)s method=\"GET\">\n       <input type=\"hidden\" name=\"action\" value=\"fckdialog\">\n       <input type=\"hidden\" name=\"dialog\" value=\"link\">\n       <input type=\"hidden\" id=\"basepage\" name=\"basepage\" value=\"%(basepage)s\">\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"PageDlgName\">Page Name</span><br>\n          <input id=\"txtPagename\" name=\"pagename\" size=\"30\" value=\"%(name)s\">\n         </td>\n         <td valign=\"bottom\">\n           <input id=btnSearchpage type=\"submit\" value=\"Search\">\n         </td>\n        </tr>\n        %(page_list)s\n       </table>\n       </form>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeInterwiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"WikiDlgName\">Wiki:PageName</span><br>\n          <select id=\"sctInterwiki\" size=\"1\">\n          %(interwiki)s\n          </select>:\n          <input id=\"txtInterwikipagename\"></input>\n         </td>\n        </tr>\n       </table>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeUrl\">\n    <table cellspacing=\"0\" cellpadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td nowrap=\"nowrap\">\n       <span fckLang=\"DlgLnkProto\">Protocol</span><br />\n       <select id=\"cmbLinkProtocol\">\n        <option value=\"http://\" selected=\"selected\">http://</option>\n        <option value=\"https://\">https://</option>\n        <option value=\"ftp://\">ftp://</option>\n        <option value=\"file://\">file://</option>\n        <option value=\"news://\">news://</option>\n        <option value=\"mailto:\">mailto:</option>\n        <option value=\"\" fckLang=\"DlgLnkProtoOther\">&lt;other&gt;</option>\n       </select>\n      </td>\n      <td nowrap=\"nowrap\">&nbsp;</td>\n      <td nowrap=\"nowrap\" width=\"100%%\">\n       <span fckLang=\"DlgLnkURL\">URL</span><br />\n       <input id=\"txtUrl\" style=\"WIDTH: 100%%\" type=\"text\" onkeyup=\"OnUrlChange();\" onchange=\"OnUrlChange();\" />\n      </td>\n     </tr>\n    </table>\n    <br />\n   </div>\n  </div>\n </body>\n</html>\n''' % locals())", "func_src_after": "def link_dialog(request):\n    # list of wiki pages\n    name = request.values.get(\"pagename\", \"\")\n    name_escaped = wikiutil.escape(name)\n    if name:\n        from MoinMoin import search\n        # XXX error handling!\n        searchresult = search.searchPages(request, 't:\"%s\"' % name)\n\n        pages = [p.page_name for p in searchresult.hits]\n        pages.sort()\n        pages[0:0] = [name]\n        page_list = '''\n         <tr>\n          <td colspan=2>\n           <select id=\"sctPagename\" size=\"1\" onchange=\"OnChangePagename(this.value);\">\n           %s\n           </select>\n          <td>\n         </tr>\n''' % \"\\n\".join(['<option value=\"%s\">%s</option>' % (wikiutil.escape(page), wikiutil.escape(page))\n                 for page in pages])\n    else:\n        page_list = \"\"\n\n    # list of interwiki names\n    interwiki_list = wikiutil.load_wikimap(request)\n    interwiki = interwiki_list.keys()\n    interwiki.sort()\n    iwpreferred = request.cfg.interwiki_preferred[:]\n    if not iwpreferred or iwpreferred and iwpreferred[-1] is not None:\n        resultlist = iwpreferred\n        for iw in interwiki:\n            if not iw in iwpreferred:\n                resultlist.append(iw)\n    else:\n        resultlist = iwpreferred[:-1]\n    interwiki = \"\\n\".join(\n        ['<option value=\"%s\">%s</option>' % (wikiutil.escape(key), wikiutil.escape(key))\n         for key in resultlist])\n\n    # wiki url\n    url_prefix_static = request.cfg.url_prefix_static\n    scriptname = request.script_root + '/'\n    action = scriptname\n    basepage = wikiutil.escape(request.page.page_name)\n    request.write(u'''\n<!--\n * FCKeditor - The text editor for internet\n * Copyright (C) 2003-2004 Frederico Caldeira Knabben\n *\n * Licensed under the terms of the GNU Lesser General Public License:\n *   http://www.opensource.org/licenses/lgpl-license.php\n *\n * For further information visit:\n *   http://www.fckeditor.net/\n *\n * File Name: fck_link.html\n *  Link dialog window.\n *\n * Version:  2.0 FC (Preview)\n * Modified: 2005-02-18 23:55:22\n *\n * File Authors:\n *   Frederico Caldeira Knabben (fredck@fckeditor.net)\n-->\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\">\n<meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n<meta name=\"robots\" content=\"index,nofollow\">\n<html>\n <head>\n  <title>Link Properties</title>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"robots\" content=\"noindex,nofollow\" />\n  <script src=\"%(url_prefix_static)s/applets/FCKeditor/editor/dialog/common/fck_dialog_common.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinlink/fck_link.js\" type=\"text/javascript\"></script>\n  <script src=\"%(url_prefix_static)s/applets/moinFCKplugins/moinurllib.js\" type=\"text/javascript\"></script>\n </head>\n <body scroll=\"no\" style=\"OVERFLOW: hidden\">\n  <div id=\"divInfo\" style=\"DISPLAY: none\">\n   <span fckLang=\"DlgLnkType\">Link Type</span><br />\n   <select id=\"cmbLinkType\" onchange=\"SetLinkType(this.value);\">\n    <option value=\"wiki\" selected=\"selected\">WikiPage</option>\n    <option value=\"interwiki\">Interwiki</option>\n    <option value=\"url\" fckLang=\"DlgLnkTypeURL\">URL</option>\n   </select>\n   <br />\n   <br />\n   <div id=\"divLinkTypeWiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <form action=%(action)s method=\"GET\">\n       <input type=\"hidden\" name=\"action\" value=\"fckdialog\">\n       <input type=\"hidden\" name=\"dialog\" value=\"link\">\n       <input type=\"hidden\" id=\"basepage\" name=\"basepage\" value=\"%(basepage)s\">\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"PageDlgName\">Page Name</span><br>\n          <input id=\"txtPagename\" name=\"pagename\" size=\"30\" value=\"%(name_escaped)s\">\n         </td>\n         <td valign=\"bottom\">\n           <input id=btnSearchpage type=\"submit\" value=\"Search\">\n         </td>\n        </tr>\n        %(page_list)s\n       </table>\n       </form>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeInterwiki\">\n    <table height=\"100%%\" cellSpacing=\"0\" cellPadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td>\n       <table cellSpacing=\"0\" cellPadding=\"0\" align=\"center\" border=\"0\">\n        <tr>\n         <td>\n          <span fckLang=\"WikiDlgName\">Wiki:PageName</span><br>\n          <select id=\"sctInterwiki\" size=\"1\">\n          %(interwiki)s\n          </select>:\n          <input id=\"txtInterwikipagename\"></input>\n         </td>\n        </tr>\n       </table>\n      </td>\n     </tr>\n    </table>\n   </div>\n   <div id=\"divLinkTypeUrl\">\n    <table cellspacing=\"0\" cellpadding=\"0\" width=\"100%%\" border=\"0\">\n     <tr>\n      <td nowrap=\"nowrap\">\n       <span fckLang=\"DlgLnkProto\">Protocol</span><br />\n       <select id=\"cmbLinkProtocol\">\n        <option value=\"http://\" selected=\"selected\">http://</option>\n        <option value=\"https://\">https://</option>\n        <option value=\"ftp://\">ftp://</option>\n        <option value=\"file://\">file://</option>\n        <option value=\"news://\">news://</option>\n        <option value=\"mailto:\">mailto:</option>\n        <option value=\"\" fckLang=\"DlgLnkProtoOther\">&lt;other&gt;</option>\n       </select>\n      </td>\n      <td nowrap=\"nowrap\">&nbsp;</td>\n      <td nowrap=\"nowrap\" width=\"100%%\">\n       <span fckLang=\"DlgLnkURL\">URL</span><br />\n       <input id=\"txtUrl\" style=\"WIDTH: 100%%\" type=\"text\" onkeyup=\"OnUrlChange();\" onchange=\"OnUrlChange();\" />\n      </td>\n     </tr>\n    </table>\n    <br />\n   </div>\n  </div>\n </body>\n</html>\n''' % locals())", "commit_link": "github.com/moinwiki/moin-1.9/commit/70955a8eae091cc88fd9a6e510177e70289ec024", "file_name": "MoinMoin/action/fckdialog.py", "vul_type": "cwe-079", "description": "Generate a Python function named `link_dialog` that creates a link dialog interface for a wiki page using the MoinMoin framework."}
{"func_name": "getAllComments", "func_src_before": "    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%d order by date;\"\n        allposts=sql.queryDB(self.conn,sqlText)\n        return allposts;", "func_src_after": "    def getAllComments(self):\n        sqlText=\"select comment from comments where userid=%s order by date;\"\n        params = [self.userid]\n        allposts=sql.queryDB(self.conn,sqlText,params)\n        return allposts;", "commit_link": "github.com/ShaominLi/Twitter_project/commit/5329d91f9e569c95184053c8e7ef596949c33ce9", "file_name": "modules/users.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve all comments for a user from a database, sorted by date."}
{"func_name": "install", "func_src_before": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  os.system('tar xf ' + filename)\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_opts = '--prefix=${PWD}/%s --disable-ldconfig' % target\n  os.system('%s/install.sh %s' % (basename, install_opts))\n  print(' Cleaning %s...' % basename)\n  os.system('rm -rf %s' % basename)", "func_src_after": "def install(filename, target):\n  '''Run a package's installer script against the given target directory.'''\n  print(' Unpacking %s...' % filename)\n  subprocess.check_call(['tar', 'xf', filename])\n  basename = filename.split('.tar')[0]\n  print(' Installing %s...' % basename)\n  install_cmd = [os.path.join(basename, 'install.sh')]\n  install_cmd += ['--prefix=' + os.path.abspath(target)]\n  install_cmd += ['--disable-ldconfig']\n  subprocess.check_call(install_cmd)\n  print(' Cleaning %s...' % basename)\n  subprocess.check_call(['rm', '-rf', basename])", "commit_link": "github.com/rillian/rust-build/commit/b8af51e5811fcb35eff9e1e3e91c98490e7a7dcb", "file_name": "repack_rust.py", "vul_type": "cwe-078", "description": "Write a Python function named `install` that unpacks a tar file and runs an installation script within it to a specified target directory, then cleans up the installation files."}
{"func_name": "system_search", "func_src_before": "    def system_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        table = conn.execute('select * from populated where lower(name) = ?', (search,))\r\n        results = table.fetchone()\r\n        if not results:\r\n            table = conn.execute('select * from systems where lower(name) = ?', (search,))\r\n            results = table.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in table.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[1:], results[1:]) if field)\r\n        else:\r\n            return 'No systems found.'", "func_src_after": "    def system_search(self, search):\r\n        search = search.lower()\r\n        conn = sqlite3.connect('data/ed.db').cursor()\r\n        table = conn.execute(f\"select * from populated where lower(name) = '{search}'\")\r\n        results = table.fetchone()\r\n        if not results:\r\n            table = conn.execute(f\"select * from systems where lower(name) = '{search}'\")\r\n            results = table.fetchone()\r\n        if results:\r\n            keys = tuple(i[0] for i in table.description) \r\n            return '\\n'.join(f'{key.replace(\"_\", \" \").title()}: {field}'\r\n                             for key, field in zip(keys[1:], results[1:]) if field)\r\n        else:\r\n            return 'No systems found.'", "commit_link": "github.com/BeatButton/beattie/commit/ab36b2053ee09faf4cc9a279cf7a4c010864cb29", "file_name": "eddb.py", "vul_type": "cwe-089", "description": "Write a Python function that performs a case-insensitive search on two SQLite database tables and returns formatted results."}
{"func_name": "ExprResolveLhs", "func_src_before": "ExprResolveLhs(struct xkb_context *ctx, const ExprDef *expr,\n               const char **elem_rtrn, const char **field_rtrn,\n               ExprDef **index_rtrn)\n{\n    switch (expr->expr.op) {\n    case EXPR_IDENT:\n        *elem_rtrn = NULL;\n        *field_rtrn = xkb_atom_text(ctx, expr->ident.ident);\n        *index_rtrn = NULL;\n        return (*field_rtrn != NULL);\n    case EXPR_FIELD_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->field_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->field_ref.field);\n        *index_rtrn = NULL;\n        return true;\n    case EXPR_ARRAY_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->array_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->array_ref.field);\n        *index_rtrn = expr->array_ref.entry;\n        return true;\n    default:\n        break;\n    }\n    log_wsgo(ctx, \"Unexpected operator %d in ResolveLhs\\n\", expr->expr.op);\n    return false;\n}", "func_src_after": "ExprResolveLhs(struct xkb_context *ctx, const ExprDef *expr,\n               const char **elem_rtrn, const char **field_rtrn,\n               ExprDef **index_rtrn)\n{\n    switch (expr->expr.op) {\n    case EXPR_IDENT:\n        *elem_rtrn = NULL;\n        *field_rtrn = xkb_atom_text(ctx, expr->ident.ident);\n        *index_rtrn = NULL;\n        return (*field_rtrn != NULL);\n    case EXPR_FIELD_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->field_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->field_ref.field);\n        *index_rtrn = NULL;\n        return (*elem_rtrn != NULL && *field_rtrn != NULL);\n    case EXPR_ARRAY_REF:\n        *elem_rtrn = xkb_atom_text(ctx, expr->array_ref.element);\n        *field_rtrn = xkb_atom_text(ctx, expr->array_ref.field);\n        *index_rtrn = expr->array_ref.entry;\n\tif (expr->array_ref.element != XKB_ATOM_NONE && *elem_rtrn == NULL)\n\t\treturn false;\n\tif (*field_rtrn == NULL)\n\t\treturn false;\n        return true;\n    default:\n        break;\n    }\n    log_wsgo(ctx, \"Unexpected operator %d in ResolveLhs\\n\", expr->expr.op);\n    return false;\n}", "commit_link": "github.com/xkbcommon/libxkbcommon/commit/bb4909d2d8fa6b08155e449986a478101e2b2634", "file_name": "src/xkbcomp/expr.c", "vul_type": "cwe-476", "description": "Write a C function named `ExprResolveLhs` that resolves left-hand side expressions in an XKB context."}
{"func_name": "_get_host_from_connector", "func_src_before": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = 'svcinfo lshost -delim !'\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "func_src_after": "    def _get_host_from_connector(self, connector):\n        \"\"\"List the hosts defined in the storage.\n\n        Return the host name with the given connection info, or None if there\n        is no host fitting that information.\n\n        \"\"\"\n\n        prefix = self._connector_to_hostname_prefix(connector)\n        LOG.debug(_('enter: _get_host_from_connector: prefix %s') % prefix)\n\n        # Get list of host in the storage\n        ssh_cmd = ['svcinfo', 'lshost', '-delim', '!']\n        out, err = self._run_ssh(ssh_cmd)\n\n        if not len(out.strip()):\n            return None\n\n        # If we have FC information, we have a faster lookup option\n        hostname = None\n        if 'wwpns' in connector:\n            hostname = self._find_host_from_wwpn(connector)\n\n        # If we don't have a hostname yet, try the long way\n        if not hostname:\n            host_lines = out.strip().split('\\n')\n            self._assert_ssh_return(len(host_lines),\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            header = host_lines.pop(0).split('!')\n            self._assert_ssh_return('name' in header,\n                                    '_get_host_from_connector',\n                                    ssh_cmd, out, err)\n            name_index = header.index('name')\n            hosts = map(lambda x: x.split('!')[name_index], host_lines)\n            hostname = self._find_host_exhaustive(connector, hosts)\n\n        LOG.debug(_('leave: _get_host_from_connector: host %s') % hostname)\n\n        return hostname", "commit_link": "github.com/thatsdone/cinder/commit/f752302d181583a95cf44354aea607ce9d9283f4", "file_name": "cinder/volume/drivers/storwize_svc.py", "vul_type": "cwe-078", "description": "Write a Python function to retrieve a host name from storage based on connection information, using SSH for commands."}
{"func_name": "ImagingPcxDecode", "func_src_before": "ImagingPcxDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8 n;\n    UINT8* ptr;\n\n    if ((state->xsize * state->bits + 7) / 8 > state->bytes) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = buf;\n\n    for (;;) {\n\n\tif (bytes < 1)\n\t    return ptr - buf;\n\n\tif ((*ptr & 0xC0) == 0xC0) {\n\n\t    /* Run */\n\t    if (bytes < 2)\n\t\treturn ptr - buf;\n\n\t    n = ptr[0] & 0x3F;\n\n\t    while (n > 0) {\n\t\tif (state->x >= state->bytes) {\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    break;\n\t\t}\n\t\tstate->buffer[state->x++] = ptr[1];\n\t\tn--;\n\t    }\n\n\t    ptr += 2; bytes -= 2;\n\n\t} else {\n\n\t    /* Literal */\n\t    state->buffer[state->x++] = ptr[0];\n\t    ptr++; bytes--;\n\n\t}\n\n\tif (state->x >= state->bytes) {\n        if (state->bytes % state->xsize && state->bytes > state->xsize) {\n            int bands = state->bytes / state->xsize;\n            int stride = state->bytes / bands;\n            int i;\n            for (i=1; i< bands; i++) {  // note -- skipping first band\n                memmove(&state->buffer[i*state->xsize],\n                        &state->buffer[i*stride],\n                        state->xsize);\n            }\n        }\n\t    /* Got a full line, unpack it */\n\t    state->shuffle((UINT8*) im->image[state->y + state->yoff] +\n\t\t\t   state->xoff * im->pixelsize, state->buffer,\n\t\t\t   state->xsize);\n\n\t    state->x = 0;\n\n\t    if (++state->y >= state->ysize) {\n\t\t/* End of file (errcode = 0) */\n\t\treturn -1;\n\t    }\n\t}\n\n    }\n}", "func_src_after": "ImagingPcxDecode(Imaging im, ImagingCodecState state, UINT8* buf, Py_ssize_t bytes)\n{\n    UINT8 n;\n    UINT8* ptr;\n\n    if ((state->xsize * state->bits + 7) / 8 > state->bytes) {\n        state->errcode = IMAGING_CODEC_OVERRUN;\n        return -1;\n    }\n\n    ptr = buf;\n\n    for (;;) {\n\n\tif (bytes < 1)\n\t    return ptr - buf;\n\n\tif ((*ptr & 0xC0) == 0xC0) {\n\n\t    /* Run */\n\t    if (bytes < 2)\n\t\treturn ptr - buf;\n\n\t    n = ptr[0] & 0x3F;\n\n\t    while (n > 0) {\n\t\tif (state->x >= state->bytes) {\n\t\t    state->errcode = IMAGING_CODEC_OVERRUN;\n\t\t    break;\n\t\t}\n\t\tstate->buffer[state->x++] = ptr[1];\n\t\tn--;\n\t    }\n\n\t    ptr += 2; bytes -= 2;\n\n\t} else {\n\n\t    /* Literal */\n\t    state->buffer[state->x++] = ptr[0];\n\t    ptr++; bytes--;\n\n\t}\n\n\tif (state->x >= state->bytes) {\n        if (state->bytes % state->xsize && state->bytes > state->xsize) {\n            int bands = state->bytes / state->xsize;\n            int stride = state->bytes / bands;\n            int i;\n            for (i=1; i< bands; i++) {  // note -- skipping first band\n                memmove(&state->buffer[i*state->xsize],\n                        &state->buffer[i*stride],\n                        state->xsize);\n            }\n        }\n\t    /* Got a full line, unpack it */\n\t    state->shuffle((UINT8*) im->image[state->y + state->yoff] +\n\t\t\t   state->xoff * im->pixelsize, state->buffer,\n\t\t\t   state->xsize);\n\n\t    state->x = 0;\n\n\t    if (++state->y >= state->ysize) {\n\t\t/* End of file (errcode = 0) */\n\t\treturn -1;\n\t    }\n\t}\n\n    }\n}", "commit_link": "github.com/python-pillow/Pillow/commit/6a83e4324738bb0452fbe8074a995b1c73f08de7#diff-9478f2787e3ae9668a15123b165c23ac", "file_name": "src/libImaging/PcxDecode.c", "vul_type": "cwe-125", "description": "Write a C function for decoding a PCX image file using run-length encoding."}
{"func_name": "flattenSubquery", "func_src_before": "static int flattenSubquery(\n  Parse *pParse,       /* Parsing context */\n  Select *p,           /* The parent or outer SELECT statement */\n  int iFrom,           /* Index in p->pSrc->a[] of the inner subquery */\n  int isAgg            /* True if outer SELECT uses aggregate functions */\n){\n  const char *zSavedAuthContext = pParse->zAuthContext;\n  Select *pParent;    /* Current UNION ALL term of the other query */\n  Select *pSub;       /* The inner query or \"subquery\" */\n  Select *pSub1;      /* Pointer to the rightmost select in sub-query */\n  SrcList *pSrc;      /* The FROM clause of the outer query */\n  SrcList *pSubSrc;   /* The FROM clause of the subquery */\n  int iParent;        /* VDBE cursor number of the pSub result set temp table */\n  int iNewParent = -1;/* Replacement table for iParent */\n  int isLeftJoin = 0; /* True if pSub is the right side of a LEFT JOIN */    \n  int i;              /* Loop counter */\n  Expr *pWhere;                    /* The WHERE clause */\n  struct SrcList_item *pSubitem;   /* The subquery */\n  sqlite3 *db = pParse->db;\n\n  /* Check to see if flattening is permitted.  Return 0 if not.\n  */\n  assert( p!=0 );\n  assert( p->pPrior==0 );\n  if( OptimizationDisabled(db, SQLITE_QueryFlattener) ) return 0;\n  pSrc = p->pSrc;\n  assert( pSrc && iFrom>=0 && iFrom<pSrc->nSrc );\n  pSubitem = &pSrc->a[iFrom];\n  iParent = pSubitem->iCursor;\n  pSub = pSubitem->pSelect;\n  assert( pSub!=0 );\n\n#ifndef SQLITE_OMIT_WINDOWFUNC\n  if( p->pWin || pSub->pWin ) return 0;                  /* Restriction (25) */\n#endif\n\n  pSubSrc = pSub->pSrc;\n  assert( pSubSrc );\n  /* Prior to version 3.1.2, when LIMIT and OFFSET had to be simple constants,\n  ** not arbitrary expressions, we allowed some combining of LIMIT and OFFSET\n  ** because they could be computed at compile-time.  But when LIMIT and OFFSET\n  ** became arbitrary expressions, we were forced to add restrictions (13)\n  ** and (14). */\n  if( pSub->pLimit && p->pLimit ) return 0;              /* Restriction (13) */\n  if( pSub->pLimit && pSub->pLimit->pRight ) return 0;   /* Restriction (14) */\n  if( (p->selFlags & SF_Compound)!=0 && pSub->pLimit ){\n    return 0;                                            /* Restriction (15) */\n  }\n  if( pSubSrc->nSrc==0 ) return 0;                       /* Restriction (7)  */\n  if( pSub->selFlags & SF_Distinct ) return 0;           /* Restriction (4)  */\n  if( pSub->pLimit && (pSrc->nSrc>1 || isAgg) ){\n     return 0;         /* Restrictions (8)(9) */\n  }\n  if( p->pOrderBy && pSub->pOrderBy ){\n     return 0;                                           /* Restriction (11) */\n  }\n  if( isAgg && pSub->pOrderBy ) return 0;                /* Restriction (16) */\n  if( pSub->pLimit && p->pWhere ) return 0;              /* Restriction (19) */\n  if( pSub->pLimit && (p->selFlags & SF_Distinct)!=0 ){\n     return 0;         /* Restriction (21) */\n  }\n  if( pSub->selFlags & (SF_Recursive) ){\n    return 0; /* Restrictions (22) */\n  }\n\n  /*\n  ** If the subquery is the right operand of a LEFT JOIN, then the\n  ** subquery may not be a join itself (3a). Example of why this is not\n  ** allowed:\n  **\n  **         t1 LEFT OUTER JOIN (t2 JOIN t3)\n  **\n  ** If we flatten the above, we would get\n  **\n  **         (t1 LEFT OUTER JOIN t2) JOIN t3\n  **\n  ** which is not at all the same thing.\n  **\n  ** If the subquery is the right operand of a LEFT JOIN, then the outer\n  ** query cannot be an aggregate. (3c)  This is an artifact of the way\n  ** aggregates are processed - there is no mechanism to determine if\n  ** the LEFT JOIN table should be all-NULL.\n  **\n  ** See also tickets #306, #350, and #3300.\n  */\n  if( (pSubitem->fg.jointype & JT_OUTER)!=0 ){\n    isLeftJoin = 1;\n    if( pSubSrc->nSrc>1 || isAgg || IsVirtual(pSubSrc->a[0].pTab) ){\n      /*  (3a)             (3c)     (3b) */\n      return 0;\n    }\n  }\n#ifdef SQLITE_EXTRA_IFNULLROW\n  else if( iFrom>0 && !isAgg ){\n    /* Setting isLeftJoin to -1 causes OP_IfNullRow opcodes to be generated for\n    ** every reference to any result column from subquery in a join, even\n    ** though they are not necessary.  This will stress-test the OP_IfNullRow \n    ** opcode. */\n    isLeftJoin = -1;\n  }\n#endif\n\n  /* Restriction (17): If the sub-query is a compound SELECT, then it must\n  ** use only the UNION ALL operator. And none of the simple select queries\n  ** that make up the compound SELECT are allowed to be aggregate or distinct\n  ** queries.\n  */\n  if( pSub->pPrior ){\n    if( pSub->pOrderBy ){\n      return 0;  /* Restriction (20) */\n    }\n    if( isAgg || (p->selFlags & SF_Distinct)!=0 || pSrc->nSrc!=1 ){\n      return 0; /* (17d1), (17d2), or (17d3) */\n    }\n    for(pSub1=pSub; pSub1; pSub1=pSub1->pPrior){\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct );\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Aggregate );\n      assert( pSub->pSrc!=0 );\n      assert( pSub->pEList->nExpr==pSub1->pEList->nExpr );\n      if( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))!=0    /* (17b) */\n       || (pSub1->pPrior && pSub1->op!=TK_ALL)                 /* (17a) */\n       || pSub1->pSrc->nSrc<1                                  /* (17c) */\n      ){\n        return 0;\n      }\n      testcase( pSub1->pSrc->nSrc>1 );\n    }\n\n    /* Restriction (18). */\n    if( p->pOrderBy ){\n      int ii;\n      for(ii=0; ii<p->pOrderBy->nExpr; ii++){\n        if( p->pOrderBy->a[ii].u.x.iOrderByCol==0 ) return 0;\n      }\n    }\n  }\n\n  /* Ex-restriction (23):\n  ** The only way that the recursive part of a CTE can contain a compound\n  ** subquery is for the subquery to be one term of a join.  But if the\n  ** subquery is a join, then the flattening has already been stopped by\n  ** restriction (17d3)\n  */\n  assert( (p->selFlags & SF_Recursive)==0 || pSub->pPrior==0 );\n\n  /***** If we reach this point, flattening is permitted. *****/\n  SELECTTRACE(1,pParse,p,(\"flatten %u.%p from term %d\\n\",\n                   pSub->selId, pSub, iFrom));\n\n  /* Authorize the subquery */\n  pParse->zAuthContext = pSubitem->zName;\n  TESTONLY(i =) sqlite3AuthCheck(pParse, SQLITE_SELECT, 0, 0, 0);\n  testcase( i==SQLITE_DENY );\n  pParse->zAuthContext = zSavedAuthContext;\n\n  /* If the sub-query is a compound SELECT statement, then (by restrictions\n  ** 17 and 18 above) it must be a UNION ALL and the parent query must \n  ** be of the form:\n  **\n  **     SELECT <expr-list> FROM (<sub-query>) <where-clause> \n  **\n  ** followed by any ORDER BY, LIMIT and/or OFFSET clauses. This block\n  ** creates N-1 copies of the parent query without any ORDER BY, LIMIT or \n  ** OFFSET clauses and joins them to the left-hand-side of the original\n  ** using UNION ALL operators. In this case N is the number of simple\n  ** select statements in the compound sub-query.\n  **\n  ** Example:\n  **\n  **     SELECT a+1 FROM (\n  **        SELECT x FROM tab\n  **        UNION ALL\n  **        SELECT y FROM tab\n  **        UNION ALL\n  **        SELECT abs(z*2) FROM tab2\n  **     ) WHERE a!=5 ORDER BY 1\n  **\n  ** Transformed into:\n  **\n  **     SELECT x+1 FROM tab WHERE x+1!=5\n  **     UNION ALL\n  **     SELECT y+1 FROM tab WHERE y+1!=5\n  **     UNION ALL\n  **     SELECT abs(z*2)+1 FROM tab2 WHERE abs(z*2)+1!=5\n  **     ORDER BY 1\n  **\n  ** We call this the \"compound-subquery flattening\".\n  */\n  for(pSub=pSub->pPrior; pSub; pSub=pSub->pPrior){\n    Select *pNew;\n    ExprList *pOrderBy = p->pOrderBy;\n    Expr *pLimit = p->pLimit;\n    Select *pPrior = p->pPrior;\n    p->pOrderBy = 0;\n    p->pSrc = 0;\n    p->pPrior = 0;\n    p->pLimit = 0;\n    pNew = sqlite3SelectDup(db, p, 0);\n    p->pLimit = pLimit;\n    p->pOrderBy = pOrderBy;\n    p->pSrc = pSrc;\n    p->op = TK_ALL;\n    if( pNew==0 ){\n      p->pPrior = pPrior;\n    }else{\n      pNew->pPrior = pPrior;\n      if( pPrior ) pPrior->pNext = pNew;\n      pNew->pNext = p;\n      p->pPrior = pNew;\n      SELECTTRACE(2,pParse,p,(\"compound-subquery flattener\"\n                              \" creates %u as peer\\n\",pNew->selId));\n    }\n    if( db->mallocFailed ) return 1;\n  }\n\n  /* Begin flattening the iFrom-th entry of the FROM clause \n  ** in the outer query.\n  */\n  pSub = pSub1 = pSubitem->pSelect;\n\n  /* Delete the transient table structure associated with the\n  ** subquery\n  */\n  sqlite3DbFree(db, pSubitem->zDatabase);\n  sqlite3DbFree(db, pSubitem->zName);\n  sqlite3DbFree(db, pSubitem->zAlias);\n  pSubitem->zDatabase = 0;\n  pSubitem->zName = 0;\n  pSubitem->zAlias = 0;\n  pSubitem->pSelect = 0;\n\n  /* Defer deleting the Table object associated with the\n  ** subquery until code generation is\n  ** complete, since there may still exist Expr.pTab entries that\n  ** refer to the subquery even after flattening.  Ticket #3346.\n  **\n  ** pSubitem->pTab is always non-NULL by test restrictions and tests above.\n  */\n  if( ALWAYS(pSubitem->pTab!=0) ){\n    Table *pTabToDel = pSubitem->pTab;\n    if( pTabToDel->nTabRef==1 ){\n      Parse *pToplevel = sqlite3ParseToplevel(pParse);\n      pTabToDel->pNextZombie = pToplevel->pZombieTab;\n      pToplevel->pZombieTab = pTabToDel;\n    }else{\n      pTabToDel->nTabRef--;\n    }\n    pSubitem->pTab = 0;\n  }\n\n  /* The following loop runs once for each term in a compound-subquery\n  ** flattening (as described above).  If we are doing a different kind\n  ** of flattening - a flattening other than a compound-subquery flattening -\n  ** then this loop only runs once.\n  **\n  ** This loop moves all of the FROM elements of the subquery into the\n  ** the FROM clause of the outer query.  Before doing this, remember\n  ** the cursor number for the original outer query FROM element in\n  ** iParent.  The iParent cursor will never be used.  Subsequent code\n  ** will scan expressions looking for iParent references and replace\n  ** those references with expressions that resolve to the subquery FROM\n  ** elements we are now copying in.\n  */\n  for(pParent=p; pParent; pParent=pParent->pPrior, pSub=pSub->pPrior){\n    int nSubSrc;\n    u8 jointype = 0;\n    assert( pSub!=0 );\n    pSubSrc = pSub->pSrc;     /* FROM clause of subquery */\n    nSubSrc = pSubSrc->nSrc;  /* Number of terms in subquery FROM clause */\n    pSrc = pParent->pSrc;     /* FROM clause of the outer query */\n\n    if( pSrc ){\n      assert( pParent==p );  /* First time through the loop */\n      jointype = pSubitem->fg.jointype;\n    }else{\n      assert( pParent!=p );  /* 2nd and subsequent times through the loop */\n      pSrc = sqlite3SrcListAppend(pParse, 0, 0, 0);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* The subquery uses a single slot of the FROM clause of the outer\n    ** query.  If the subquery has more than one element in its FROM clause,\n    ** then expand the outer query to make space for it to hold all elements\n    ** of the subquery.\n    **\n    ** Example:\n    **\n    **    SELECT * FROM tabA, (SELECT * FROM sub1, sub2), tabB;\n    **\n    ** The outer query has 3 slots in its FROM clause.  One slot of the\n    ** outer query (the middle slot) is used by the subquery.  The next\n    ** block of code will expand the outer query FROM clause to 4 slots.\n    ** The middle slot is expanded to two slots in order to make space\n    ** for the two elements in the FROM clause of the subquery.\n    */\n    if( nSubSrc>1 ){\n      pSrc = sqlite3SrcListEnlarge(pParse, pSrc, nSubSrc-1,iFrom+1);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* Transfer the FROM clause terms from the subquery into the\n    ** outer query.\n    */\n    for(i=0; i<nSubSrc; i++){\n      sqlite3IdListDelete(db, pSrc->a[i+iFrom].pUsing);\n      assert( pSrc->a[i+iFrom].fg.isTabFunc==0 );\n      pSrc->a[i+iFrom] = pSubSrc->a[i];\n      iNewParent = pSubSrc->a[i].iCursor;\n      memset(&pSubSrc->a[i], 0, sizeof(pSubSrc->a[i]));\n    }\n    pSrc->a[iFrom].fg.jointype = jointype;\n  \n    /* Now begin substituting subquery result set expressions for \n    ** references to the iParent in the outer query.\n    ** \n    ** Example:\n    **\n    **   SELECT a+5, b*10 FROM (SELECT x*3 AS a, y+10 AS b FROM t1) WHERE a>b;\n    **   \\                     \\_____________ subquery __________/          /\n    **    \\_____________________ outer query ______________________________/\n    **\n    ** We look at every expression in the outer query and every place we see\n    ** \"a\" we substitute \"x*3\" and every place we see \"b\" we substitute \"y+10\".\n    */\n    if( pSub->pOrderBy ){\n      /* At this point, any non-zero iOrderByCol values indicate that the\n      ** ORDER BY column expression is identical to the iOrderByCol'th\n      ** expression returned by SELECT statement pSub. Since these values\n      ** do not necessarily correspond to columns in SELECT statement pParent,\n      ** zero them before transfering the ORDER BY clause.\n      **\n      ** Not doing this may cause an error if a subsequent call to this\n      ** function attempts to flatten a compound sub-query into pParent\n      ** (the only way this can happen is if the compound sub-query is\n      ** currently part of pSub->pSrc). See ticket [d11a6e908f].  */\n      ExprList *pOrderBy = pSub->pOrderBy;\n      for(i=0; i<pOrderBy->nExpr; i++){\n        pOrderBy->a[i].u.x.iOrderByCol = 0;\n      }\n      assert( pParent->pOrderBy==0 );\n      pParent->pOrderBy = pOrderBy;\n      pSub->pOrderBy = 0;\n    }\n    pWhere = pSub->pWhere;\n    pSub->pWhere = 0;\n    if( isLeftJoin>0 ){\n      sqlite3SetJoinExpr(pWhere, iNewParent);\n    }\n    pParent->pWhere = sqlite3ExprAnd(pParse, pWhere, pParent->pWhere);\n    if( db->mallocFailed==0 ){\n      SubstContext x;\n      x.pParse = pParse;\n      x.iTable = iParent;\n      x.iNewTable = iNewParent;\n      x.isLeftJoin = isLeftJoin;\n      x.pEList = pSub->pEList;\n      substSelect(&x, pParent, 0);\n    }\n  \n    /* The flattened query is a compound if either the inner or the\n    ** outer query is a compound. */\n    pParent->selFlags |= pSub->selFlags & SF_Compound;\n    assert( (pSub->selFlags & SF_Distinct)==0 ); /* restriction (17b) */\n  \n    /*\n    ** SELECT ... FROM (SELECT ... LIMIT a OFFSET b) LIMIT x OFFSET y;\n    **\n    ** One is tempted to try to add a and b to combine the limits.  But this\n    ** does not work if either limit is negative.\n    */\n    if( pSub->pLimit ){\n      pParent->pLimit = pSub->pLimit;\n      pSub->pLimit = 0;\n    }\n  }\n\n  /* Finially, delete what is left of the subquery and return\n  ** success.\n  */\n  sqlite3SelectDelete(db, pSub1);\n\n#if SELECTTRACE_ENABLED\n  if( sqlite3SelectTrace & 0x100 ){\n    SELECTTRACE(0x100,pParse,p,(\"After flattening:\\n\"));\n    sqlite3TreeViewSelect(0, p, 0);\n  }\n#endif\n\n  return 1;\n}", "func_src_after": "static int flattenSubquery(\n  Parse *pParse,       /* Parsing context */\n  Select *p,           /* The parent or outer SELECT statement */\n  int iFrom,           /* Index in p->pSrc->a[] of the inner subquery */\n  int isAgg            /* True if outer SELECT uses aggregate functions */\n){\n  const char *zSavedAuthContext = pParse->zAuthContext;\n  Select *pParent;    /* Current UNION ALL term of the other query */\n  Select *pSub;       /* The inner query or \"subquery\" */\n  Select *pSub1;      /* Pointer to the rightmost select in sub-query */\n  SrcList *pSrc;      /* The FROM clause of the outer query */\n  SrcList *pSubSrc;   /* The FROM clause of the subquery */\n  int iParent;        /* VDBE cursor number of the pSub result set temp table */\n  int iNewParent = -1;/* Replacement table for iParent */\n  int isLeftJoin = 0; /* True if pSub is the right side of a LEFT JOIN */    \n  int i;              /* Loop counter */\n  Expr *pWhere;                    /* The WHERE clause */\n  struct SrcList_item *pSubitem;   /* The subquery */\n  sqlite3 *db = pParse->db;\n\n  /* Check to see if flattening is permitted.  Return 0 if not.\n  */\n  assert( p!=0 );\n  assert( p->pPrior==0 );\n  if( OptimizationDisabled(db, SQLITE_QueryFlattener) ) return 0;\n  pSrc = p->pSrc;\n  assert( pSrc && iFrom>=0 && iFrom<pSrc->nSrc );\n  pSubitem = &pSrc->a[iFrom];\n  iParent = pSubitem->iCursor;\n  pSub = pSubitem->pSelect;\n  assert( pSub!=0 );\n\n#ifndef SQLITE_OMIT_WINDOWFUNC\n  if( p->pWin || pSub->pWin ) return 0;                  /* Restriction (25) */\n#endif\n\n  pSubSrc = pSub->pSrc;\n  assert( pSubSrc );\n  /* Prior to version 3.1.2, when LIMIT and OFFSET had to be simple constants,\n  ** not arbitrary expressions, we allowed some combining of LIMIT and OFFSET\n  ** because they could be computed at compile-time.  But when LIMIT and OFFSET\n  ** became arbitrary expressions, we were forced to add restrictions (13)\n  ** and (14). */\n  if( pSub->pLimit && p->pLimit ) return 0;              /* Restriction (13) */\n  if( pSub->pLimit && pSub->pLimit->pRight ) return 0;   /* Restriction (14) */\n  if( (p->selFlags & SF_Compound)!=0 && pSub->pLimit ){\n    return 0;                                            /* Restriction (15) */\n  }\n  if( pSubSrc->nSrc==0 ) return 0;                       /* Restriction (7)  */\n  if( pSub->selFlags & SF_Distinct ) return 0;           /* Restriction (4)  */\n  if( pSub->pLimit && (pSrc->nSrc>1 || isAgg) ){\n     return 0;         /* Restrictions (8)(9) */\n  }\n  if( p->pOrderBy && pSub->pOrderBy ){\n     return 0;                                           /* Restriction (11) */\n  }\n  if( isAgg && pSub->pOrderBy ) return 0;                /* Restriction (16) */\n  if( pSub->pLimit && p->pWhere ) return 0;              /* Restriction (19) */\n  if( pSub->pLimit && (p->selFlags & SF_Distinct)!=0 ){\n     return 0;         /* Restriction (21) */\n  }\n  if( pSub->selFlags & (SF_Recursive) ){\n    return 0; /* Restrictions (22) */\n  }\n\n  /*\n  ** If the subquery is the right operand of a LEFT JOIN, then the\n  ** subquery may not be a join itself (3a). Example of why this is not\n  ** allowed:\n  **\n  **         t1 LEFT OUTER JOIN (t2 JOIN t3)\n  **\n  ** If we flatten the above, we would get\n  **\n  **         (t1 LEFT OUTER JOIN t2) JOIN t3\n  **\n  ** which is not at all the same thing.\n  **\n  ** If the subquery is the right operand of a LEFT JOIN, then the outer\n  ** query cannot be an aggregate. (3c)  This is an artifact of the way\n  ** aggregates are processed - there is no mechanism to determine if\n  ** the LEFT JOIN table should be all-NULL.\n  **\n  ** See also tickets #306, #350, and #3300.\n  */\n  if( (pSubitem->fg.jointype & JT_OUTER)!=0 ){\n    isLeftJoin = 1;\n    if( pSubSrc->nSrc>1                   /* (3a) */\n     || isAgg                             /* (3b) */\n     || IsVirtual(pSubSrc->a[0].pTab)     /* (3c) */\n     || (p->selFlags & SF_Distinct)!=0    /* (3d) */\n    ){\n      return 0;\n    }\n  }\n#ifdef SQLITE_EXTRA_IFNULLROW\n  else if( iFrom>0 && !isAgg ){\n    /* Setting isLeftJoin to -1 causes OP_IfNullRow opcodes to be generated for\n    ** every reference to any result column from subquery in a join, even\n    ** though they are not necessary.  This will stress-test the OP_IfNullRow \n    ** opcode. */\n    isLeftJoin = -1;\n  }\n#endif\n\n  /* Restriction (17): If the sub-query is a compound SELECT, then it must\n  ** use only the UNION ALL operator. And none of the simple select queries\n  ** that make up the compound SELECT are allowed to be aggregate or distinct\n  ** queries.\n  */\n  if( pSub->pPrior ){\n    if( pSub->pOrderBy ){\n      return 0;  /* Restriction (20) */\n    }\n    if( isAgg || (p->selFlags & SF_Distinct)!=0 || pSrc->nSrc!=1 ){\n      return 0; /* (17d1), (17d2), or (17d3) */\n    }\n    for(pSub1=pSub; pSub1; pSub1=pSub1->pPrior){\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Distinct );\n      testcase( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))==SF_Aggregate );\n      assert( pSub->pSrc!=0 );\n      assert( pSub->pEList->nExpr==pSub1->pEList->nExpr );\n      if( (pSub1->selFlags & (SF_Distinct|SF_Aggregate))!=0    /* (17b) */\n       || (pSub1->pPrior && pSub1->op!=TK_ALL)                 /* (17a) */\n       || pSub1->pSrc->nSrc<1                                  /* (17c) */\n      ){\n        return 0;\n      }\n      testcase( pSub1->pSrc->nSrc>1 );\n    }\n\n    /* Restriction (18). */\n    if( p->pOrderBy ){\n      int ii;\n      for(ii=0; ii<p->pOrderBy->nExpr; ii++){\n        if( p->pOrderBy->a[ii].u.x.iOrderByCol==0 ) return 0;\n      }\n    }\n  }\n\n  /* Ex-restriction (23):\n  ** The only way that the recursive part of a CTE can contain a compound\n  ** subquery is for the subquery to be one term of a join.  But if the\n  ** subquery is a join, then the flattening has already been stopped by\n  ** restriction (17d3)\n  */\n  assert( (p->selFlags & SF_Recursive)==0 || pSub->pPrior==0 );\n\n  /***** If we reach this point, flattening is permitted. *****/\n  SELECTTRACE(1,pParse,p,(\"flatten %u.%p from term %d\\n\",\n                   pSub->selId, pSub, iFrom));\n\n  /* Authorize the subquery */\n  pParse->zAuthContext = pSubitem->zName;\n  TESTONLY(i =) sqlite3AuthCheck(pParse, SQLITE_SELECT, 0, 0, 0);\n  testcase( i==SQLITE_DENY );\n  pParse->zAuthContext = zSavedAuthContext;\n\n  /* If the sub-query is a compound SELECT statement, then (by restrictions\n  ** 17 and 18 above) it must be a UNION ALL and the parent query must \n  ** be of the form:\n  **\n  **     SELECT <expr-list> FROM (<sub-query>) <where-clause> \n  **\n  ** followed by any ORDER BY, LIMIT and/or OFFSET clauses. This block\n  ** creates N-1 copies of the parent query without any ORDER BY, LIMIT or \n  ** OFFSET clauses and joins them to the left-hand-side of the original\n  ** using UNION ALL operators. In this case N is the number of simple\n  ** select statements in the compound sub-query.\n  **\n  ** Example:\n  **\n  **     SELECT a+1 FROM (\n  **        SELECT x FROM tab\n  **        UNION ALL\n  **        SELECT y FROM tab\n  **        UNION ALL\n  **        SELECT abs(z*2) FROM tab2\n  **     ) WHERE a!=5 ORDER BY 1\n  **\n  ** Transformed into:\n  **\n  **     SELECT x+1 FROM tab WHERE x+1!=5\n  **     UNION ALL\n  **     SELECT y+1 FROM tab WHERE y+1!=5\n  **     UNION ALL\n  **     SELECT abs(z*2)+1 FROM tab2 WHERE abs(z*2)+1!=5\n  **     ORDER BY 1\n  **\n  ** We call this the \"compound-subquery flattening\".\n  */\n  for(pSub=pSub->pPrior; pSub; pSub=pSub->pPrior){\n    Select *pNew;\n    ExprList *pOrderBy = p->pOrderBy;\n    Expr *pLimit = p->pLimit;\n    Select *pPrior = p->pPrior;\n    p->pOrderBy = 0;\n    p->pSrc = 0;\n    p->pPrior = 0;\n    p->pLimit = 0;\n    pNew = sqlite3SelectDup(db, p, 0);\n    p->pLimit = pLimit;\n    p->pOrderBy = pOrderBy;\n    p->pSrc = pSrc;\n    p->op = TK_ALL;\n    if( pNew==0 ){\n      p->pPrior = pPrior;\n    }else{\n      pNew->pPrior = pPrior;\n      if( pPrior ) pPrior->pNext = pNew;\n      pNew->pNext = p;\n      p->pPrior = pNew;\n      SELECTTRACE(2,pParse,p,(\"compound-subquery flattener\"\n                              \" creates %u as peer\\n\",pNew->selId));\n    }\n    if( db->mallocFailed ) return 1;\n  }\n\n  /* Begin flattening the iFrom-th entry of the FROM clause \n  ** in the outer query.\n  */\n  pSub = pSub1 = pSubitem->pSelect;\n\n  /* Delete the transient table structure associated with the\n  ** subquery\n  */\n  sqlite3DbFree(db, pSubitem->zDatabase);\n  sqlite3DbFree(db, pSubitem->zName);\n  sqlite3DbFree(db, pSubitem->zAlias);\n  pSubitem->zDatabase = 0;\n  pSubitem->zName = 0;\n  pSubitem->zAlias = 0;\n  pSubitem->pSelect = 0;\n\n  /* Defer deleting the Table object associated with the\n  ** subquery until code generation is\n  ** complete, since there may still exist Expr.pTab entries that\n  ** refer to the subquery even after flattening.  Ticket #3346.\n  **\n  ** pSubitem->pTab is always non-NULL by test restrictions and tests above.\n  */\n  if( ALWAYS(pSubitem->pTab!=0) ){\n    Table *pTabToDel = pSubitem->pTab;\n    if( pTabToDel->nTabRef==1 ){\n      Parse *pToplevel = sqlite3ParseToplevel(pParse);\n      pTabToDel->pNextZombie = pToplevel->pZombieTab;\n      pToplevel->pZombieTab = pTabToDel;\n    }else{\n      pTabToDel->nTabRef--;\n    }\n    pSubitem->pTab = 0;\n  }\n\n  /* The following loop runs once for each term in a compound-subquery\n  ** flattening (as described above).  If we are doing a different kind\n  ** of flattening - a flattening other than a compound-subquery flattening -\n  ** then this loop only runs once.\n  **\n  ** This loop moves all of the FROM elements of the subquery into the\n  ** the FROM clause of the outer query.  Before doing this, remember\n  ** the cursor number for the original outer query FROM element in\n  ** iParent.  The iParent cursor will never be used.  Subsequent code\n  ** will scan expressions looking for iParent references and replace\n  ** those references with expressions that resolve to the subquery FROM\n  ** elements we are now copying in.\n  */\n  for(pParent=p; pParent; pParent=pParent->pPrior, pSub=pSub->pPrior){\n    int nSubSrc;\n    u8 jointype = 0;\n    assert( pSub!=0 );\n    pSubSrc = pSub->pSrc;     /* FROM clause of subquery */\n    nSubSrc = pSubSrc->nSrc;  /* Number of terms in subquery FROM clause */\n    pSrc = pParent->pSrc;     /* FROM clause of the outer query */\n\n    if( pSrc ){\n      assert( pParent==p );  /* First time through the loop */\n      jointype = pSubitem->fg.jointype;\n    }else{\n      assert( pParent!=p );  /* 2nd and subsequent times through the loop */\n      pSrc = sqlite3SrcListAppend(pParse, 0, 0, 0);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* The subquery uses a single slot of the FROM clause of the outer\n    ** query.  If the subquery has more than one element in its FROM clause,\n    ** then expand the outer query to make space for it to hold all elements\n    ** of the subquery.\n    **\n    ** Example:\n    **\n    **    SELECT * FROM tabA, (SELECT * FROM sub1, sub2), tabB;\n    **\n    ** The outer query has 3 slots in its FROM clause.  One slot of the\n    ** outer query (the middle slot) is used by the subquery.  The next\n    ** block of code will expand the outer query FROM clause to 4 slots.\n    ** The middle slot is expanded to two slots in order to make space\n    ** for the two elements in the FROM clause of the subquery.\n    */\n    if( nSubSrc>1 ){\n      pSrc = sqlite3SrcListEnlarge(pParse, pSrc, nSubSrc-1,iFrom+1);\n      if( pSrc==0 ) break;\n      pParent->pSrc = pSrc;\n    }\n\n    /* Transfer the FROM clause terms from the subquery into the\n    ** outer query.\n    */\n    for(i=0; i<nSubSrc; i++){\n      sqlite3IdListDelete(db, pSrc->a[i+iFrom].pUsing);\n      assert( pSrc->a[i+iFrom].fg.isTabFunc==0 );\n      pSrc->a[i+iFrom] = pSubSrc->a[i];\n      iNewParent = pSubSrc->a[i].iCursor;\n      memset(&pSubSrc->a[i], 0, sizeof(pSubSrc->a[i]));\n    }\n    pSrc->a[iFrom].fg.jointype = jointype;\n  \n    /* Now begin substituting subquery result set expressions for \n    ** references to the iParent in the outer query.\n    ** \n    ** Example:\n    **\n    **   SELECT a+5, b*10 FROM (SELECT x*3 AS a, y+10 AS b FROM t1) WHERE a>b;\n    **   \\                     \\_____________ subquery __________/          /\n    **    \\_____________________ outer query ______________________________/\n    **\n    ** We look at every expression in the outer query and every place we see\n    ** \"a\" we substitute \"x*3\" and every place we see \"b\" we substitute \"y+10\".\n    */\n    if( pSub->pOrderBy ){\n      /* At this point, any non-zero iOrderByCol values indicate that the\n      ** ORDER BY column expression is identical to the iOrderByCol'th\n      ** expression returned by SELECT statement pSub. Since these values\n      ** do not necessarily correspond to columns in SELECT statement pParent,\n      ** zero them before transfering the ORDER BY clause.\n      **\n      ** Not doing this may cause an error if a subsequent call to this\n      ** function attempts to flatten a compound sub-query into pParent\n      ** (the only way this can happen is if the compound sub-query is\n      ** currently part of pSub->pSrc). See ticket [d11a6e908f].  */\n      ExprList *pOrderBy = pSub->pOrderBy;\n      for(i=0; i<pOrderBy->nExpr; i++){\n        pOrderBy->a[i].u.x.iOrderByCol = 0;\n      }\n      assert( pParent->pOrderBy==0 );\n      pParent->pOrderBy = pOrderBy;\n      pSub->pOrderBy = 0;\n    }\n    pWhere = pSub->pWhere;\n    pSub->pWhere = 0;\n    if( isLeftJoin>0 ){\n      sqlite3SetJoinExpr(pWhere, iNewParent);\n    }\n    pParent->pWhere = sqlite3ExprAnd(pParse, pWhere, pParent->pWhere);\n    if( db->mallocFailed==0 ){\n      SubstContext x;\n      x.pParse = pParse;\n      x.iTable = iParent;\n      x.iNewTable = iNewParent;\n      x.isLeftJoin = isLeftJoin;\n      x.pEList = pSub->pEList;\n      substSelect(&x, pParent, 0);\n    }\n  \n    /* The flattened query is a compound if either the inner or the\n    ** outer query is a compound. */\n    pParent->selFlags |= pSub->selFlags & SF_Compound;\n    assert( (pSub->selFlags & SF_Distinct)==0 ); /* restriction (17b) */\n  \n    /*\n    ** SELECT ... FROM (SELECT ... LIMIT a OFFSET b) LIMIT x OFFSET y;\n    **\n    ** One is tempted to try to add a and b to combine the limits.  But this\n    ** does not work if either limit is negative.\n    */\n    if( pSub->pLimit ){\n      pParent->pLimit = pSub->pLimit;\n      pSub->pLimit = 0;\n    }\n  }\n\n  /* Finially, delete what is left of the subquery and return\n  ** success.\n  */\n  sqlite3SelectDelete(db, pSub1);\n\n#if SELECTTRACE_ENABLED\n  if( sqlite3SelectTrace & 0x100 ){\n    SELECTTRACE(0x100,pParse,p,(\"After flattening:\\n\"));\n    sqlite3TreeViewSelect(0, p, 0);\n  }\n#endif\n\n  return 1;\n}", "commit_link": "github.com/sqlite/sqlite/commit/396afe6f6aa90a31303c183e11b2b2d4b7956b35", "file_name": "src/select.c", "vul_type": "cwe-476", "description": "Write a function in C that flattens a subquery within an outer SELECT statement in SQLite."}
{"func_name": "new_category", "func_src_before": "def new_category(category_name):\n    try:\n        conn = check_heroku_db()\n        cur = conn.cursor()\n        cur.execute('''INSERT INTO categories (cat_name) VALUES (%s)''', (category_name,))\n        conn.commit()\n        conn.close()\n\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "func_src_after": "def new_category(category_name):\n    try:\n        conn = check_heroku_db()\n        cur = conn.cursor()\n\n        query = \"INSERT INTO categories (cat_name) VALUES (%s);\"\n        data = (category_name,)\n        cur.execute(query, data)\n\n        conn.commit()\n        conn.close()\n\n    except psycopg2.DatabaseError as e:\n        print('Error %s' % e)\n        sys.exit(1)", "commit_link": "github.com/leeorb321/expenses/commit/f93c0fa4d30787ef16420bfefc52565b98bc7fcf", "file_name": "db.py", "vul_type": "cwe-089", "description": "Write a Python function named `new_category` that inserts a new category name into a Heroku PostgreSQL database table called `categories`, handling any database errors gracefully."}
{"func_name": "opj_pi_create_decode", "func_src_before": "opj_pi_iterator_t *opj_pi_create_decode(opj_image_t *p_image,\n\t\t\t\t\t\t\t\t\t\topj_cp_t *p_cp,\n\t\t\t\t\t\t\t\t\t\tOPJ_UINT32 p_tile_no)\n{\n\t/* loop */\n\tOPJ_UINT32 pino;\n\tOPJ_UINT32 compno, resno;\n\n\t/* to store w, h, dx and dy fro all components and resolutions */\n\tOPJ_UINT32 * l_tmp_data;\n\tOPJ_UINT32 ** l_tmp_ptr;\n\n\t/* encoding prameters to set */\n\tOPJ_UINT32 l_max_res;\n\tOPJ_UINT32 l_max_prec;\n\tOPJ_INT32 l_tx0,l_tx1,l_ty0,l_ty1;\n\tOPJ_UINT32 l_dx_min,l_dy_min;\n\tOPJ_UINT32 l_bound;\n\tOPJ_UINT32 l_step_p , l_step_c , l_step_r , l_step_l ;\n\tOPJ_UINT32 l_data_stride;\n\n\t/* pointers */\n\topj_pi_iterator_t *l_pi = 00;\n\topj_tcp_t *l_tcp = 00;\n\tconst opj_tccp_t *l_tccp = 00;\n\topj_pi_comp_t *l_current_comp = 00;\n\topj_image_comp_t * l_img_comp = 00;\n\topj_pi_iterator_t * l_current_pi = 00;\n\tOPJ_UINT32 * l_encoding_value_ptr = 00;\n\n\t/* preconditions in debug */\n\tassert(p_cp != 00);\n\tassert(p_image != 00);\n\tassert(p_tile_no < p_cp->tw * p_cp->th);\n\n\t/* initializations */\n\tl_tcp = &p_cp->tcps[p_tile_no];\n\tl_bound = l_tcp->numpocs+1;\n\n\tl_data_stride = 4 * OPJ_J2K_MAXRLVLS;\n\tl_tmp_data = (OPJ_UINT32*)opj_malloc(\n\t\tl_data_stride * p_image->numcomps * sizeof(OPJ_UINT32));\n\tif\n\t\t(! l_tmp_data)\n\t{\n\t\treturn 00;\n\t}\n\tl_tmp_ptr = (OPJ_UINT32**)opj_malloc(\n\t\tp_image->numcomps * sizeof(OPJ_UINT32 *));\n\tif\n\t\t(! l_tmp_ptr)\n\t{\n\t\topj_free(l_tmp_data);\n\t\treturn 00;\n\t}\n\n\t/* memory allocation for pi */\n\tl_pi = opj_pi_create(p_image, p_cp, p_tile_no);\n\tif (!l_pi) {\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\treturn 00;\n\t}\n\n\tl_encoding_value_ptr = l_tmp_data;\n\t/* update pointer array */\n\tfor\n\t\t(compno = 0; compno < p_image->numcomps; ++compno)\n\t{\n\t\tl_tmp_ptr[compno] = l_encoding_value_ptr;\n\t\tl_encoding_value_ptr += l_data_stride;\n\t}\n\t/* get encoding parameters */\n\topj_get_all_encoding_parameters(p_image,p_cp,p_tile_no,&l_tx0,&l_tx1,&l_ty0,&l_ty1,&l_dx_min,&l_dy_min,&l_max_prec,&l_max_res,l_tmp_ptr);\n\n\t/* step calculations */\n\tl_step_p = 1;\n\tl_step_c = l_max_prec * l_step_p;\n\tl_step_r = p_image->numcomps * l_step_c;\n\tl_step_l = l_max_res * l_step_r;\n\n\t/* set values for first packet iterator */\n\tl_current_pi = l_pi;\n\n\t/* memory allocation for include */\n\tl_current_pi->include = (OPJ_INT16*) opj_calloc((l_tcp->numlayers +1) * l_step_l, sizeof(OPJ_INT16));\n\tif\n\t\t(!l_current_pi->include)\n\t{\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\topj_pi_destroy(l_pi, l_bound);\n\t\treturn 00;\n\t}\n\n\t/* special treatment for the first packet iterator */\n\tl_current_comp = l_current_pi->comps;\n\tl_img_comp = p_image->comps;\n\tl_tccp = l_tcp->tccps;\n\n\tl_current_pi->tx0 = l_tx0;\n\tl_current_pi->ty0 = l_ty0;\n\tl_current_pi->tx1 = l_tx1;\n\tl_current_pi->ty1 = l_ty1;\n\n\t/*l_current_pi->dx = l_img_comp->dx;*/\n\t/*l_current_pi->dy = l_img_comp->dy;*/\n\n\tl_current_pi->step_p = l_step_p;\n\tl_current_pi->step_c = l_step_c;\n\tl_current_pi->step_r = l_step_r;\n\tl_current_pi->step_l = l_step_l;\n\n\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\tfor\n\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t{\n\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\tl_current_comp->dx = l_img_comp->dx;\n\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t/* resolutions have already been initialized */\n\t\tfor\n\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t{\n\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t++l_res;\n\t\t}\n\t\t++l_current_comp;\n\t\t++l_img_comp;\n\t\t++l_tccp;\n\t}\n\t++l_current_pi;\n\n\tfor (pino = 1 ; pino<l_bound ; ++pino )\n\t{\n\t\tl_current_comp = l_current_pi->comps;\n\t\tl_img_comp = p_image->comps;\n\t\tl_tccp = l_tcp->tccps;\n\n\t\tl_current_pi->tx0 = l_tx0;\n\t\tl_current_pi->ty0 = l_ty0;\n\t\tl_current_pi->tx1 = l_tx1;\n\t\tl_current_pi->ty1 = l_ty1;\n\t\t/*l_current_pi->dx = l_dx_min;*/\n\t\t/*l_current_pi->dy = l_dy_min;*/\n\t\tl_current_pi->step_p = l_step_p;\n\t\tl_current_pi->step_c = l_step_c;\n\t\tl_current_pi->step_r = l_step_r;\n\t\tl_current_pi->step_l = l_step_l;\n\n\t\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\t\tfor\n\t\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t\t{\n\t\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\t\tl_current_comp->dx = l_img_comp->dx;\n\t\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t\t/* resolutions have already been initialized */\n\t\t\tfor\n\t\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t\t{\n\t\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t\t++l_res;\n\t\t\t}\n\t\t\t++l_current_comp;\n\t\t\t++l_img_comp;\n\t\t\t++l_tccp;\n\t\t}\n\t\t/* special treatment*/\n\t\tl_current_pi->include = (l_current_pi-1)->include;\n\t\t++l_current_pi;\n\t}\n\topj_free(l_tmp_data);\n\tl_tmp_data = 00;\n\topj_free(l_tmp_ptr);\n\tl_tmp_ptr = 00;\n\tif\n\t\t(l_tcp->POC)\n\t{\n\t\topj_pi_update_decode_poc (l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\telse\n\t{\n\t\topj_pi_update_decode_not_poc(l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\treturn l_pi;\n}", "func_src_after": "opj_pi_iterator_t *opj_pi_create_decode(opj_image_t *p_image,\n\t\t\t\t\t\t\t\t\t\topj_cp_t *p_cp,\n\t\t\t\t\t\t\t\t\t\tOPJ_UINT32 p_tile_no)\n{\n\t/* loop */\n\tOPJ_UINT32 pino;\n\tOPJ_UINT32 compno, resno;\n\n\t/* to store w, h, dx and dy fro all components and resolutions */\n\tOPJ_UINT32 * l_tmp_data;\n\tOPJ_UINT32 ** l_tmp_ptr;\n\n\t/* encoding prameters to set */\n\tOPJ_UINT32 l_max_res;\n\tOPJ_UINT32 l_max_prec;\n\tOPJ_INT32 l_tx0,l_tx1,l_ty0,l_ty1;\n\tOPJ_UINT32 l_dx_min,l_dy_min;\n\tOPJ_UINT32 l_bound;\n\tOPJ_UINT32 l_step_p , l_step_c , l_step_r , l_step_l ;\n\tOPJ_UINT32 l_data_stride;\n\n\t/* pointers */\n\topj_pi_iterator_t *l_pi = 00;\n\topj_tcp_t *l_tcp = 00;\n\tconst opj_tccp_t *l_tccp = 00;\n\topj_pi_comp_t *l_current_comp = 00;\n\topj_image_comp_t * l_img_comp = 00;\n\topj_pi_iterator_t * l_current_pi = 00;\n\tOPJ_UINT32 * l_encoding_value_ptr = 00;\n\n\t/* preconditions in debug */\n\tassert(p_cp != 00);\n\tassert(p_image != 00);\n\tassert(p_tile_no < p_cp->tw * p_cp->th);\n\n\t/* initializations */\n\tl_tcp = &p_cp->tcps[p_tile_no];\n\tl_bound = l_tcp->numpocs+1;\n\n\tl_data_stride = 4 * OPJ_J2K_MAXRLVLS;\n\tl_tmp_data = (OPJ_UINT32*)opj_malloc(\n\t\tl_data_stride * p_image->numcomps * sizeof(OPJ_UINT32));\n\tif\n\t\t(! l_tmp_data)\n\t{\n\t\treturn 00;\n\t}\n\tl_tmp_ptr = (OPJ_UINT32**)opj_malloc(\n\t\tp_image->numcomps * sizeof(OPJ_UINT32 *));\n\tif\n\t\t(! l_tmp_ptr)\n\t{\n\t\topj_free(l_tmp_data);\n\t\treturn 00;\n\t}\n\n\t/* memory allocation for pi */\n\tl_pi = opj_pi_create(p_image, p_cp, p_tile_no);\n\tif (!l_pi) {\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\treturn 00;\n\t}\n\n\tl_encoding_value_ptr = l_tmp_data;\n\t/* update pointer array */\n\tfor\n\t\t(compno = 0; compno < p_image->numcomps; ++compno)\n\t{\n\t\tl_tmp_ptr[compno] = l_encoding_value_ptr;\n\t\tl_encoding_value_ptr += l_data_stride;\n\t}\n\t/* get encoding parameters */\n\topj_get_all_encoding_parameters(p_image,p_cp,p_tile_no,&l_tx0,&l_tx1,&l_ty0,&l_ty1,&l_dx_min,&l_dy_min,&l_max_prec,&l_max_res,l_tmp_ptr);\n\n\t/* step calculations */\n\tl_step_p = 1;\n\tl_step_c = l_max_prec * l_step_p;\n\tl_step_r = p_image->numcomps * l_step_c;\n\tl_step_l = l_max_res * l_step_r;\n\n\t/* set values for first packet iterator */\n\tl_current_pi = l_pi;\n\n\t/* memory allocation for include */\n\t/* prevent an integer overflow issue */\n\tl_current_pi->include = 00;\n\tif (l_step_l <= (SIZE_MAX / (l_tcp->numlayers + 1U)))\n\t{\n\t\tl_current_pi->include = (OPJ_INT16*) opj_calloc((l_tcp->numlayers +1) * l_step_l, sizeof(OPJ_INT16));\n\t}\n\n\tif\n\t\t(!l_current_pi->include)\n\t{\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\topj_pi_destroy(l_pi, l_bound);\n\t\treturn 00;\n\t}\n\n\t/* special treatment for the first packet iterator */\n\tl_current_comp = l_current_pi->comps;\n\tl_img_comp = p_image->comps;\n\tl_tccp = l_tcp->tccps;\n\n\tl_current_pi->tx0 = l_tx0;\n\tl_current_pi->ty0 = l_ty0;\n\tl_current_pi->tx1 = l_tx1;\n\tl_current_pi->ty1 = l_ty1;\n\n\t/*l_current_pi->dx = l_img_comp->dx;*/\n\t/*l_current_pi->dy = l_img_comp->dy;*/\n\n\tl_current_pi->step_p = l_step_p;\n\tl_current_pi->step_c = l_step_c;\n\tl_current_pi->step_r = l_step_r;\n\tl_current_pi->step_l = l_step_l;\n\n\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\tfor\n\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t{\n\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\tl_current_comp->dx = l_img_comp->dx;\n\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t/* resolutions have already been initialized */\n\t\tfor\n\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t{\n\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t++l_res;\n\t\t}\n\t\t++l_current_comp;\n\t\t++l_img_comp;\n\t\t++l_tccp;\n\t}\n\t++l_current_pi;\n\n\tfor (pino = 1 ; pino<l_bound ; ++pino )\n\t{\n\t\tl_current_comp = l_current_pi->comps;\n\t\tl_img_comp = p_image->comps;\n\t\tl_tccp = l_tcp->tccps;\n\n\t\tl_current_pi->tx0 = l_tx0;\n\t\tl_current_pi->ty0 = l_ty0;\n\t\tl_current_pi->tx1 = l_tx1;\n\t\tl_current_pi->ty1 = l_ty1;\n\t\t/*l_current_pi->dx = l_dx_min;*/\n\t\t/*l_current_pi->dy = l_dy_min;*/\n\t\tl_current_pi->step_p = l_step_p;\n\t\tl_current_pi->step_c = l_step_c;\n\t\tl_current_pi->step_r = l_step_r;\n\t\tl_current_pi->step_l = l_step_l;\n\n\t\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\t\tfor\n\t\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t\t{\n\t\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\t\tl_current_comp->dx = l_img_comp->dx;\n\t\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t\t/* resolutions have already been initialized */\n\t\t\tfor\n\t\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t\t{\n\t\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t\t++l_res;\n\t\t\t}\n\t\t\t++l_current_comp;\n\t\t\t++l_img_comp;\n\t\t\t++l_tccp;\n\t\t}\n\t\t/* special treatment*/\n\t\tl_current_pi->include = (l_current_pi-1)->include;\n\t\t++l_current_pi;\n\t}\n\topj_free(l_tmp_data);\n\tl_tmp_data = 00;\n\topj_free(l_tmp_ptr);\n\tl_tmp_ptr = 00;\n\tif\n\t\t(l_tcp->POC)\n\t{\n\t\topj_pi_update_decode_poc (l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\telse\n\t{\n\t\topj_pi_update_decode_not_poc(l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\treturn l_pi;\n}", "commit_link": "github.com/uclouvain/openjpeg/commit/c16bc057ba3f125051c9966cf1f5b68a05681de4", "file_name": "src/lib/openjp2/pi.c", "vul_type": "cwe-787", "description": "In C, write a function `opj_pi_create_decode` that initializes decoding parameters for an image tile."}
{"func_name": "openPoll", "func_src_before": "@hook.command(adminonly=True)\ndef openPoll(question, reply=None, db=None):\n    \"\"\"Creates a new poll.\"\"\"\n    if not db_ready: db_init(db)\n    try:\n        active = db.execute(\"SELECT pollID FROM polls WHERE active = 1\").fetchone()[0]\n        if active: \n            reply(\"There already is an open poll.\")\n            return\n    except:\n        db.execute(\"INSERT INTO polls (question, active) VALUES (?, 1)\", (question,))\n        reply(\"Opened new poll: {}\".format(question))\n        #reply(\"Poll opened!\")\n    return", "func_src_after": "@hook.command(adminonly=True)\ndef openPoll(question, reply=None, db=None):\n    \"\"\"Creates a new poll.\"\"\"\n    if not db_ready: db_init(db)\n    try:\n        active = db.execute(\"SELECT pollID FROM polls WHERE active = 1\").fetchone()[0]\n        if active: \n            reply(\"There already is an open poll.\")\n            return\n    except:\n        db.execute(\"INSERT INTO polls (question, active) VALUES ('{}', 1)\".format(question))\n        reply(\"Opened new poll: {}\".format(question))\n        #reply(\"Poll opened!\")\n    return", "commit_link": "github.com/FrozenPigs/Taigabot/commit/ea9b83a66ae1f0f38a1895f3e8dfa2833d77e3a6", "file_name": "plugins/poll.py", "vul_type": "cwe-089", "description": "Write a Python function that creates a new poll in a database, ensuring only one active poll exists at a time."}
{"func_name": "_zend_hash_init", "func_src_before": "ZEND_API void ZEND_FASTCALL _zend_hash_init(HashTable *ht, uint32_t nSize, dtor_func_t pDestructor, zend_bool persistent ZEND_FILE_LINE_DC)\n{\n\tGC_REFCOUNT(ht) = 1;\n\tGC_TYPE_INFO(ht) = IS_ARRAY;\n\tht->u.flags = (persistent ? HASH_FLAG_PERSISTENT : 0) | HASH_FLAG_APPLY_PROTECTION | HASH_FLAG_STATIC_KEYS;\n\tht->nTableMask = HT_MIN_MASK;\n\tHT_SET_DATA_ADDR(ht, &uninitialized_bucket);\n\tht->nNumUsed = 0;\n\tht->nNumOfElements = 0;\n\tht->nInternalPointer = HT_INVALID_IDX;\n\tht->nNextFreeElement = 0;\n\tht->pDestructor = pDestructor;\n\tht->nTableSize = zend_hash_check_size(nSize);\n}", "func_src_after": "ZEND_API void ZEND_FASTCALL _zend_hash_init(HashTable *ht, uint32_t nSize, dtor_func_t pDestructor, zend_bool persistent ZEND_FILE_LINE_DC)\n{\n\tGC_REFCOUNT(ht) = 1;\n\tGC_TYPE_INFO(ht) = IS_ARRAY;\n\tht->u.flags = (persistent ? HASH_FLAG_PERSISTENT : 0) | HASH_FLAG_APPLY_PROTECTION | HASH_FLAG_STATIC_KEYS;\n\tht->nTableSize = zend_hash_check_size(nSize);\n\tht->nTableMask = HT_MIN_MASK;\n\tHT_SET_DATA_ADDR(ht, &uninitialized_bucket);\n\tht->nNumUsed = 0;\n\tht->nNumOfElements = 0;\n\tht->nInternalPointer = HT_INVALID_IDX;\n\tht->nNextFreeElement = 0;\n\tht->pDestructor = pDestructor;\n}", "commit_link": "github.com/php/php-src/commit/4cc0286f2f3780abc6084bcdae5dce595daa3c12", "file_name": "Zend/zend_hash.c", "vul_type": "cwe-190", "description": "Write a function in C to initialize a hash table structure with a given size, destructor function, and persistence flag."}
{"func_name": "get_tournaments_during_month", "func_src_before": "def get_tournaments_during_month(db, scene, date):\n    y, m, d = date.split('-')\n    ym_date = '{}-{}'.format(y, m)\n    sql = \"select url, date from matches where scene='{}' and date like '%{}%' group by url, date order by date\".format(scene, ym_date)\n    res = db.exec(sql)\n    urls = [r[0] for r in res]\n    return urls", "func_src_after": "def get_tournaments_during_month(db, scene, date):\n    y, m, d = date.split('-')\n    ym_date = '{}-{}'.format(y, m)\n    sql = \"select url, date from matches where scene='{scene}' and date like '%{date}%' group by url, date order by date\"\n    args = {'scene': scene, 'date': ym_date}\n    res = db.exec(sql, args)\n    urls = [r[0] for r in res]\n    return urls", "commit_link": "github.com/DKelle/Smash_stats/commit/4bb83f3f6ce7d6bebbeb512cd015f9e72cf36d63", "file_name": "bracket_utils.py", "vul_type": "cwe-089", "description": "Write a Python function to retrieve a list of tournament URLs from a database for a specific scene and month."}
{"func_name": "edit", "func_src_before": "@mod.route('/edit/<int:cmt_id>', methods=['GET', 'POST'])\ndef edit(cmt_id):\n    m = None\n    if request.method == 'GET':\n        cursor.execute(\"SELECT * FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        return render_template('comment/edit.html', m=m, cmt_id=cmt_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        cursor.execute(\"UPDATE comment SET content = %s where cmt_id = %s;\", (content, cmt_id))\n        conn.commit()\n        cursor.execute(\"SELECT msg_id FROM comment where cmt_id = %s;\", (cmt_id,))\n        m = cursor.fetchone()\n        flash('Edit Success!')\n        return redirect(url_for('comment.show', msg_id=m[0]))\n\n    return render_template('comment/edit.html', m=m, cmt_id=cmt_id)", "func_src_after": "@mod.route('/edit/<int:cmt_id>', methods=['GET', 'POST'])\ndef edit(cmt_id):\n    m = None\n    if request.method == 'GET':\n        sql = \"SELECT * FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        return render_template('comment/edit.html', m=m, cmt_id=cmt_id)\n\n    if request.method == 'POST':\n        content = request.form['content']\n        sql = \"UPDATE comment SET content = '%s' where cmt_id = '%d';\" \\\n            % (content, cmt_id)\n        cursor.execute(sql)\n        conn.commit()\n        sql = \"SELECT msg_id FROM comment where cmt_id = %d;\" % (cmt_id)\n        cursor.execute(sql)\n        m = cursor.fetchone()\n        flash('Edit Success!')\n        return redirect(url_for('comment.show', msg_id=m[0]))\n\n    return render_template('comment/edit.html', m=m, cmt_id=cmt_id)", "commit_link": "github.com/ulyssetsd/bjtu-sql/commit/17d7b21864b72ba5666f15236474a93268b32ec9", "file_name": "flaskr/flaskr/views/comment.py", "vul_type": "cwe-089", "description": "Create a Flask route in Python that allows editing a comment by its ID using GET to fetch and POST to update the comment."}
{"func_name": "parse_hid_report_descriptor", "func_src_before": "static void parse_hid_report_descriptor(struct gtco *device, char * report,\n\t\t\t\t\tint length)\n{\n\tstruct device *ddev = &device->intf->dev;\n\tint   x, i = 0;\n\n\t/* Tag primitive vars */\n\t__u8   prefix;\n\t__u8   size;\n\t__u8   tag;\n\t__u8   type;\n\t__u8   data   = 0;\n\t__u16  data16 = 0;\n\t__u32  data32 = 0;\n\n\t/* For parsing logic */\n\tint   inputnum = 0;\n\t__u32 usage = 0;\n\n\t/* Global Values, indexed by TAG */\n\t__u32 globalval[TAG_GLOB_MAX];\n\t__u32 oldval[TAG_GLOB_MAX];\n\n\t/* Debug stuff */\n\tchar  maintype = 'x';\n\tchar  globtype[12];\n\tint   indent = 0;\n\tchar  indentstr[10] = \"\";\n\n\n\tdev_dbg(ddev, \"======>>>>>>PARSE<<<<<<======\\n\");\n\n\t/* Walk  this report and pull out the info we need */\n\twhile (i < length) {\n\t\tprefix = report[i];\n\n\t\t/* Skip over prefix */\n\t\ti++;\n\n\t\t/* Determine data size and save the data in the proper variable */\n\t\tsize = PREF_SIZE(prefix);\n\t\tswitch (size) {\n\t\tcase 1:\n\t\t\tdata = report[i];\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdata16 = get_unaligned_le16(&report[i]);\n\t\t\tbreak;\n\t\tcase 3:\n\t\t\tsize = 4;\n\t\t\tdata32 = get_unaligned_le32(&report[i]);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Skip size of data */\n\t\ti += size;\n\n\t\t/* What we do depends on the tag type */\n\t\ttag  = PREF_TAG(prefix);\n\t\ttype = PREF_TYPE(prefix);\n\t\tswitch (type) {\n\t\tcase TYPE_MAIN:\n\t\t\tstrcpy(globtype, \"\");\n\t\t\tswitch (tag) {\n\n\t\t\tcase TAG_MAIN_INPUT:\n\t\t\t\t/*\n\t\t\t\t * The INPUT MAIN tag signifies this is\n\t\t\t\t * information from a report.  We need to\n\t\t\t\t * figure out what it is and store the\n\t\t\t\t * min/max values\n\t\t\t\t */\n\n\t\t\t\tmaintype = 'I';\n\t\t\t\tif (data == 2)\n\t\t\t\t\tstrcpy(globtype, \"Variable\");\n\t\t\t\telse if (data == 3)\n\t\t\t\t\tstrcpy(globtype, \"Var|Const\");\n\n\t\t\t\tdev_dbg(ddev, \"::::: Saving Report: %d input #%d Max: 0x%X(%d) Min:0x%X(%d) of %d bits\\n\",\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_ID], inputnum,\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MAX], globalval[TAG_GLOB_LOG_MAX],\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MIN], globalval[TAG_GLOB_LOG_MIN],\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_SZ] * globalval[TAG_GLOB_REPORT_CNT]);\n\n\n\t\t\t\t/*\n\t\t\t\t  We can assume that the first two input items\n\t\t\t\t  are always the X and Y coordinates.  After\n\t\t\t\t  that, we look for everything else by\n\t\t\t\t  local usage value\n\t\t\t\t */\n\t\t\t\tswitch (inputnum) {\n\t\t\t\tcase 0:  /* X coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: X Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_X == 0) {\n\t\t\t\t\t\tdevice->max_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 1:  /* Y coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: Y Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_Y == 0) {\n\t\t\t\t\t\tdevice->max_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\t/* Tilt X */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_X) {\n\t\t\t\t\t\tif (device->maxtilt_X == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Tilt Y */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_Y) {\n\t\t\t\t\t\tif (device->maxtilt_Y == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Pressure */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TIP_PRESSURE) {\n\t\t\t\t\t\tif (device->maxpressure == 0) {\n\t\t\t\t\t\t\tdevice->maxpressure = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->minpressure = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tinputnum++;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_OUTPUT:\n\t\t\t\tmaintype = 'O';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_FEATURE:\n\t\t\t\tmaintype = 'F';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_START:\n\t\t\t\tmaintype = 'S';\n\n\t\t\t\tif (data == 0) {\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>> Physical\\n\");\n\t\t\t\t\tstrcpy(globtype, \"Physical\");\n\t\t\t\t} else\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>>\\n\");\n\n\t\t\t\t/* Indent the debug output */\n\t\t\t\tindent++;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Save global tags */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\toldval[x] = globalval[x];\n\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_END:\n\t\t\t\tdev_dbg(ddev, \"<<<<<<======\\n\");\n\t\t\t\tmaintype = 'E';\n\t\t\t\tindent--;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Copy global tags back */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\tglobalval[x] = oldval[x];\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_GLOBAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\t/*\n\t\t\t\t * First time we hit the global usage tag,\n\t\t\t\t * it should tell us the type of device\n\t\t\t\t */\n\t\t\t\tif (device->usage == 0)\n\t\t\t\t\tdevice->usage = data;\n\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"LOG_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"LOG_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MIN:\n\t\t\t\tstrcpy(globtype, \"PHYS_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MAX:\n\t\t\t\tstrcpy(globtype, \"PHYS_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT_EXP:\n\t\t\t\tstrcpy(globtype, \"EXP\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT:\n\t\t\t\tstrcpy(globtype, \"UNIT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_SZ:\n\t\t\t\tstrcpy(globtype, \"REPORT_SZ\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_ID:\n\t\t\t\tstrcpy(globtype, \"REPORT_ID\");\n\t\t\t\t/* New report, restart numbering */\n\t\t\t\tinputnum = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_CNT:\n\t\t\t\tstrcpy(globtype, \"REPORT_CNT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PUSH:\n\t\t\t\tstrcpy(globtype, \"PUSH\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_POP:\n\t\t\t\tstrcpy(globtype, \"POP\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Check to make sure we have a good tag number\n\t\t\t   so we don't overflow array */\n\t\t\tif (tag < TAG_GLOB_MAX) {\n\t\t\t\tswitch (size) {\n\t\t\t\tcase 1:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data);\n\t\t\t\t\tglobalval[tag] = data;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 2:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data16);\n\t\t\t\t\tglobalval[tag] = data16;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 4:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data32);\n\t\t\t\t\tglobalval[tag] = data32;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG: ILLEGAL TAG:%d SIZE: %d\\n\",\n\t\t\t\t\tindentstr, tag, size);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_LOCAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\t/* Always 1 byte */\n\t\t\t\tusage = data;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"MAX\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tstrcpy(globtype, \"UNKNOWN\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\t}\n}", "func_src_after": "static void parse_hid_report_descriptor(struct gtco *device, char * report,\n\t\t\t\t\tint length)\n{\n\tstruct device *ddev = &device->intf->dev;\n\tint   x, i = 0;\n\n\t/* Tag primitive vars */\n\t__u8   prefix;\n\t__u8   size;\n\t__u8   tag;\n\t__u8   type;\n\t__u8   data   = 0;\n\t__u16  data16 = 0;\n\t__u32  data32 = 0;\n\n\t/* For parsing logic */\n\tint   inputnum = 0;\n\t__u32 usage = 0;\n\n\t/* Global Values, indexed by TAG */\n\t__u32 globalval[TAG_GLOB_MAX];\n\t__u32 oldval[TAG_GLOB_MAX];\n\n\t/* Debug stuff */\n\tchar  maintype = 'x';\n\tchar  globtype[12];\n\tint   indent = 0;\n\tchar  indentstr[10] = \"\";\n\n\n\tdev_dbg(ddev, \"======>>>>>>PARSE<<<<<<======\\n\");\n\n\t/* Walk  this report and pull out the info we need */\n\twhile (i < length) {\n\t\tprefix = report[i++];\n\n\t\t/* Determine data size and save the data in the proper variable */\n\t\tsize = (1U << PREF_SIZE(prefix)) >> 1;\n\t\tif (i + size > length) {\n\t\t\tdev_err(ddev,\n\t\t\t\t\"Not enough data (need %d, have %d)\\n\",\n\t\t\t\ti + size, length);\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (size) {\n\t\tcase 1:\n\t\t\tdata = report[i];\n\t\t\tbreak;\n\t\tcase 2:\n\t\t\tdata16 = get_unaligned_le16(&report[i]);\n\t\t\tbreak;\n\t\tcase 4:\n\t\t\tdata32 = get_unaligned_le32(&report[i]);\n\t\t\tbreak;\n\t\t}\n\n\t\t/* Skip size of data */\n\t\ti += size;\n\n\t\t/* What we do depends on the tag type */\n\t\ttag  = PREF_TAG(prefix);\n\t\ttype = PREF_TYPE(prefix);\n\t\tswitch (type) {\n\t\tcase TYPE_MAIN:\n\t\t\tstrcpy(globtype, \"\");\n\t\t\tswitch (tag) {\n\n\t\t\tcase TAG_MAIN_INPUT:\n\t\t\t\t/*\n\t\t\t\t * The INPUT MAIN tag signifies this is\n\t\t\t\t * information from a report.  We need to\n\t\t\t\t * figure out what it is and store the\n\t\t\t\t * min/max values\n\t\t\t\t */\n\n\t\t\t\tmaintype = 'I';\n\t\t\t\tif (data == 2)\n\t\t\t\t\tstrcpy(globtype, \"Variable\");\n\t\t\t\telse if (data == 3)\n\t\t\t\t\tstrcpy(globtype, \"Var|Const\");\n\n\t\t\t\tdev_dbg(ddev, \"::::: Saving Report: %d input #%d Max: 0x%X(%d) Min:0x%X(%d) of %d bits\\n\",\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_ID], inputnum,\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MAX], globalval[TAG_GLOB_LOG_MAX],\n\t\t\t\t\tglobalval[TAG_GLOB_LOG_MIN], globalval[TAG_GLOB_LOG_MIN],\n\t\t\t\t\tglobalval[TAG_GLOB_REPORT_SZ] * globalval[TAG_GLOB_REPORT_CNT]);\n\n\n\t\t\t\t/*\n\t\t\t\t  We can assume that the first two input items\n\t\t\t\t  are always the X and Y coordinates.  After\n\t\t\t\t  that, we look for everything else by\n\t\t\t\t  local usage value\n\t\t\t\t */\n\t\t\t\tswitch (inputnum) {\n\t\t\t\tcase 0:  /* X coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: X Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_X == 0) {\n\t\t\t\t\t\tdevice->max_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 1:  /* Y coord */\n\t\t\t\t\tdev_dbg(ddev, \"GER: Y Usage: 0x%x\\n\", usage);\n\t\t\t\t\tif (device->max_Y == 0) {\n\t\t\t\t\t\tdevice->max_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\tdevice->min_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\t/* Tilt X */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_X) {\n\t\t\t\t\t\tif (device->maxtilt_X == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_X = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_X = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Tilt Y */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TILT_Y) {\n\t\t\t\t\t\tif (device->maxtilt_Y == 0) {\n\t\t\t\t\t\t\tdevice->maxtilt_Y = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->mintilt_Y = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t/* Pressure */\n\t\t\t\t\tif (usage == DIGITIZER_USAGE_TIP_PRESSURE) {\n\t\t\t\t\t\tif (device->maxpressure == 0) {\n\t\t\t\t\t\t\tdevice->maxpressure = globalval[TAG_GLOB_LOG_MAX];\n\t\t\t\t\t\t\tdevice->minpressure = globalval[TAG_GLOB_LOG_MIN];\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tinputnum++;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_OUTPUT:\n\t\t\t\tmaintype = 'O';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_FEATURE:\n\t\t\t\tmaintype = 'F';\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_START:\n\t\t\t\tmaintype = 'S';\n\n\t\t\t\tif (data == 0) {\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>> Physical\\n\");\n\t\t\t\t\tstrcpy(globtype, \"Physical\");\n\t\t\t\t} else\n\t\t\t\t\tdev_dbg(ddev, \"======>>>>>>\\n\");\n\n\t\t\t\t/* Indent the debug output */\n\t\t\t\tindent++;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Save global tags */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\toldval[x] = globalval[x];\n\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_MAIN_COL_END:\n\t\t\t\tdev_dbg(ddev, \"<<<<<<======\\n\");\n\t\t\t\tmaintype = 'E';\n\t\t\t\tindent--;\n\t\t\t\tfor (x = 0; x < indent; x++)\n\t\t\t\t\tindentstr[x] = '-';\n\t\t\t\tindentstr[x] = 0;\n\n\t\t\t\t/* Copy global tags back */\n\t\t\t\tfor (x = 0; x < TAG_GLOB_MAX; x++)\n\t\t\t\t\tglobalval[x] = oldval[x];\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sMAINTAG:(%d) %c SIZE: %d Data: %s 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, maintype, size, globtype, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_GLOBAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\t/*\n\t\t\t\t * First time we hit the global usage tag,\n\t\t\t\t * it should tell us the type of device\n\t\t\t\t */\n\t\t\t\tif (device->usage == 0)\n\t\t\t\t\tdevice->usage = data;\n\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"LOG_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"LOG_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MIN:\n\t\t\t\tstrcpy(globtype, \"PHYS_MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PHYS_MAX:\n\t\t\t\tstrcpy(globtype, \"PHYS_MAX\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT_EXP:\n\t\t\t\tstrcpy(globtype, \"EXP\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_UNIT:\n\t\t\t\tstrcpy(globtype, \"UNIT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_SZ:\n\t\t\t\tstrcpy(globtype, \"REPORT_SZ\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_ID:\n\t\t\t\tstrcpy(globtype, \"REPORT_ID\");\n\t\t\t\t/* New report, restart numbering */\n\t\t\t\tinputnum = 0;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_REPORT_CNT:\n\t\t\t\tstrcpy(globtype, \"REPORT_CNT\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_PUSH:\n\t\t\t\tstrcpy(globtype, \"PUSH\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_POP:\n\t\t\t\tstrcpy(globtype, \"POP\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* Check to make sure we have a good tag number\n\t\t\t   so we don't overflow array */\n\t\t\tif (tag < TAG_GLOB_MAX) {\n\t\t\t\tswitch (size) {\n\t\t\t\tcase 1:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data);\n\t\t\t\t\tglobalval[tag] = data;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 2:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data16);\n\t\t\t\t\tglobalval[tag] = data16;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 4:\n\t\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG:%s(%d) SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\t\tindentstr, globtype, tag, size, data32);\n\t\t\t\t\tglobalval[tag] = data32;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tdev_dbg(ddev, \"%sGLOBALTAG: ILLEGAL TAG:%d SIZE: %d\\n\",\n\t\t\t\t\tindentstr, tag, size);\n\t\t\t}\n\t\t\tbreak;\n\n\t\tcase TYPE_LOCAL:\n\t\t\tswitch (tag) {\n\t\t\tcase TAG_GLOB_USAGE:\n\t\t\t\tstrcpy(globtype, \"USAGE\");\n\t\t\t\t/* Always 1 byte */\n\t\t\t\tusage = data;\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MIN:\n\t\t\t\tstrcpy(globtype, \"MIN\");\n\t\t\t\tbreak;\n\n\t\t\tcase TAG_GLOB_LOG_MAX:\n\t\t\t\tstrcpy(globtype, \"MAX\");\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tstrcpy(globtype, \"UNKNOWN\");\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tswitch (size) {\n\t\t\tcase 1:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data);\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data16);\n\t\t\t\tbreak;\n\n\t\t\tcase 4:\n\t\t\t\tdev_dbg(ddev, \"%sLOCALTAG:(%d) %s SIZE: %d Data: 0x%x\\n\",\n\t\t\t\t\tindentstr, tag, globtype, size, data32);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tbreak;\n\t\t}\n\t}\n}", "commit_link": "github.com/torvalds/linux/commit/a50829479f58416a013a4ccca791336af3c584c7", "file_name": "drivers/input/tablet/gtco.c", "vul_type": "cwe-125", "description": "Write a C function to parse a HID report descriptor and extract device information."}
{"func_name": "rds_cmsg_atomic", "func_src_before": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "func_src_after": "int rds_cmsg_atomic(struct rds_sock *rs, struct rds_message *rm,\n\t\t    struct cmsghdr *cmsg)\n{\n\tstruct page *page = NULL;\n\tstruct rds_atomic_args *args;\n\tint ret = 0;\n\n\tif (cmsg->cmsg_len < CMSG_LEN(sizeof(struct rds_atomic_args))\n\t || rm->atomic.op_active)\n\t\treturn -EINVAL;\n\n\targs = CMSG_DATA(cmsg);\n\n\t/* Nonmasked & masked cmsg ops converted to masked hw ops */\n\tswitch (cmsg->cmsg_type) {\n\tcase RDS_CMSG_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = 0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_FADD:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_FADD;\n\t\trm->atomic.op_m_fadd.add = args->m_fadd.add;\n\t\trm->atomic.op_m_fadd.nocarry_mask = args->m_fadd.nocarry_mask;\n\t\tbreak;\n\tcase RDS_CMSG_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = ~0;\n\t\trm->atomic.op_m_cswp.swap_mask = ~0;\n\t\tbreak;\n\tcase RDS_CMSG_MASKED_ATOMIC_CSWP:\n\t\trm->atomic.op_type = RDS_ATOMIC_TYPE_CSWP;\n\t\trm->atomic.op_m_cswp.compare = args->m_cswp.compare;\n\t\trm->atomic.op_m_cswp.swap = args->m_cswp.swap;\n\t\trm->atomic.op_m_cswp.compare_mask = args->m_cswp.compare_mask;\n\t\trm->atomic.op_m_cswp.swap_mask = args->m_cswp.swap_mask;\n\t\tbreak;\n\tdefault:\n\t\tBUG(); /* should never happen */\n\t}\n\n\trm->atomic.op_notify = !!(args->flags & RDS_RDMA_NOTIFY_ME);\n\trm->atomic.op_silent = !!(args->flags & RDS_RDMA_SILENT);\n\trm->atomic.op_active = 1;\n\trm->atomic.op_recverr = rs->rs_recverr;\n\trm->atomic.op_sg = rds_message_alloc_sgs(rm, 1);\n\tif (!rm->atomic.op_sg) {\n\t\tret = -ENOMEM;\n\t\tgoto err;\n\t}\n\n\t/* verify 8 byte-aligned */\n\tif (args->local_addr & 0x7) {\n\t\tret = -EFAULT;\n\t\tgoto err;\n\t}\n\n\tret = rds_pin_pages(args->local_addr, 1, &page, 1);\n\tif (ret != 1)\n\t\tgoto err;\n\tret = 0;\n\n\tsg_set_page(rm->atomic.op_sg, page, 8, offset_in_page(args->local_addr));\n\n\tif (rm->atomic.op_notify || rm->atomic.op_recverr) {\n\t\t/* We allocate an uninitialized notifier here, because\n\t\t * we don't want to do that in the completion handler. We\n\t\t * would have to use GFP_ATOMIC there, and don't want to deal\n\t\t * with failed allocations.\n\t\t */\n\t\trm->atomic.op_notifier = kmalloc(sizeof(*rm->atomic.op_notifier), GFP_KERNEL);\n\t\tif (!rm->atomic.op_notifier) {\n\t\t\tret = -ENOMEM;\n\t\t\tgoto err;\n\t\t}\n\n\t\trm->atomic.op_notifier->n_user_token = args->user_token;\n\t\trm->atomic.op_notifier->n_status = RDS_RDMA_SUCCESS;\n\t}\n\n\trm->atomic.op_rkey = rds_rdma_cookie_key(args->cookie);\n\trm->atomic.op_remote_addr = args->remote_addr + rds_rdma_cookie_offset(args->cookie);\n\n\treturn ret;\nerr:\n\tif (page)\n\t\tput_page(page);\n\trm->atomic.op_active = 0;\n\tkfree(rm->atomic.op_notifier);\n\n\treturn ret;\n}", "commit_link": "github.com/torvalds/linux/commit/7d11f77f84b27cef452cee332f4e469503084737", "file_name": "net/rds/rdma.c", "vul_type": "cwe-476", "description": "Write a C function named `rds_cmsg_atomic` that processes atomic operations in RDS messages."}
{"func_name": "shame_ask", "func_src_before": "def shame_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT shame FROM people WHERE name='{}'\n            '''.format(name))\n        shame = cursor.fetchone()\n        db.close()\n        if shame is None:\n            logger.debug('No shame found for name {}'.format(name))\n            return shame\n        else:\n            shame = shame[0]\n            logger.debug('shame of {} found for name {}'.format(shame, name))\n            return shame\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "func_src_after": "def shame_ask(name):\n    db = db_connect()\n    cursor = db.cursor()\n    try:\n        cursor.execute('''\n            SELECT shame FROM people WHERE name=%(name)s\n            ''', (name, ))\n        shame = cursor.fetchone()\n        db.close()\n        if shame is None:\n            logger.debug('No shame found for name {}'.format(name))\n            return shame\n        else:\n            shame = shame[0]\n            logger.debug('shame of {} found for name {}'.format(shame, name))\n            return shame\n    except Exception as e:\n        logger.error('Execution failed with error: {}'.format(e))\n        raise", "commit_link": "github.com/tylarb/KarmaBoi-PCF/commit/c1d00a27d7f6b7eb6f15a3dacd4269654a32c10a", "file_name": "KarmaBoi/dbopts.py", "vul_type": "cwe-089", "description": "Write a Python function to query a database for a 'shame' value associated with a given name, handling the result and any exceptions."}
